[{"conference": "iclr18", "review_id": "B104VQCgM", "review_text": "The paper basically propose keep using the typical data-augmentation transformations done during training also in evaluation time, to prevent adversarial attacks. In the paper they analyze only 2 random resizing and random padding, but I suppose others like random contrast, random relighting, random colorization, ... could be applicable.\n\nSome of the pros of the proposed tricks is that it doesn't require re-training existing models, although as the authors pointed out re-training for adversarial images is necessary to obtain good results.\n\n\nTypically images have different sizes, however in the Dataset are described as having 299x299x3 size, are all the test images resized before hand? How would this method work with variable size images?\n\nThe proposed defense requires increasing the size of the input images, have you analyzed the impact in performance? Also it would be good to know how robust is the method for smaller sizes.\n\nSection 4.6.2 seems to indicate that 1 pixel padding or just resizing 1 pixel is enough to get most of the benefit, please provide an analysis of how results improve as the padding or size increase. \n\nIn section 5 for the challenge authors used a lot more evaluations per image, could you provide how much extra computation is needed for that model?\n\n", "gold_annotation": {"interpretation": 0, "review_id": "B104VQCgM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper basicaly propose keep using the typicaldata-augmentation transformations done during training alo in evalation time, to prevent adversarialattacks.", "In the paper they analze only 2 random resizing and random padding, but I suppose others like random contrast, random relighting, random colorization, ... could be applicable.", "Some of the pros of the proposed tricks is that it doesn't reqire re-training existing models, alhough as the authors pointed out re-training for adversarialimages is necessary to obtain good results.", "Typicaly images have different sizes, however in the Dataset are described as having 299x299x3 size, are al the test images resized before hand?", "How would this method work with variable size images?", "The proposed defense reqires increasing the size of the input images, have you analzed the impact in performance?", "Also it would be good to know how robust is the method for smaler sizes.", "secion 4 6 2 seems to indicate that 1 pixel padding or just resizing 1 pixel is enough to get most of the benefit, please provide an analsis of how results improve as the padding or size increase.", "In secion 5 for the chalenge authors used a lot more evalations per image, could you provide how much extra computation is needed for that model?"], "all_annotations": [{"interpretation": 0, "review_id": "B104VQCgM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B10Nn-jlf", "review_text": "The authors consider new attacks for generating adversarial samples against neural networks. In particular, they are interested in approximating gradient-based white-box attacks such as FGSM in a black-box setting by estimating gradients from queries to the classifier. They assume that the attacker is able to query, for any example x, the vector of probabilities p(x) corresponding to each class.\n\nGiven such query access it\u2019s trivial to estimate the gradients of p using finite differences. As a consequence one can implement FGSM using these estimates assuming cross-entropy loss, as well as a logit-based loss. They consider both iterative and single-step FGSM attacks in the targeted (i.e. the adversary\u2019s goal is to switch the example\u2019s label to a specific alternative label) and un-targeted settings (any mislabelling is a success). They compare themselves to transfer black-box attacks, where the adversary trains a proxy model and generates the adversarial sample by running a white-box attack on that model.  For a number of target classifiers on both MNIST and CIFAR-10, they show that these attacks outperform the transfer-based attacks, and are comparable to white-box attacks, while maintaining low distortion on the attack samples. \n\nOne drawback of estimating gradients using finite differences is that the number of queries required scales with the dimensionality of the examples, which can be prohibitive in the case of images. They therefore describe two practical approaches for query reduction \u2014 one based on random feature grouping, and the other on PCA (which requires access to training data). They once again demonstrate the effectiveness of these methods across a number of models and datasets, including models deploying adversarially trained defenses. \n\nFinally, they demonstrate compelling real-world deployment against Clarifai classification models designed to flag \u201cNot Safe for Work\u201d content. \n\nOverall, the paper provides a very thorough experimental examination of a practical black-box attack that can be deployed against real-world systems. While there are some similarities with Chen et al. with respect to utilizing finite-differences to estimate gradients, I believe the work is still valuable for its very thorough experimental verification, as well as the practicality of their methods. The authors may want to be more explicit about their claim in the Related Work section that the running time of their attack is \u201c40x\u201d less than that of Chen et al. While this is believable, there is no running time comparison in the body of the paper. ", "gold_annotation": {"interpretation": 0, "review_id": "B10Nn-jlf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 1, "method": null}, "score": 3.0, "tokenized_review_text": ["The authors consider new attacks for generating adversarialsamples against neuralnetworks.", "In particular, they are interested in approximating gradient-based white-box attacks such as FGSM in a black-box setting by estimating gradients from queries to the classifier.", "They assume that the attacker is able to query, for any example x, the vector of probabilities p(x) corresponding to each class.", "Given such query access it\u2019s trivialto estimate the gradients of p using finite differences.", "As a conseqence one can implement FGSM using these estimates assuming cross-entropy loss, as well as a logit-based loss.", "They consider both iterative and single-step FGSM attacks in the targeted (i e the adversary\u2019s goalis to switch the example\u2019s label to a specific alernative label) and un-targeted settings (any mislabelling is a success).", "They compare themselves to transfer black-box attacks, where the adversary trains a proxy model and generates the adversarialsample by running a white-box attack on that model.", "For a number of target classifiers on both MNIST and CIFAR-10, they show that these attacks outperform the transfer-based attacks, and are comparable to white-box attacks, while maintaining low distortion on the attack samples.", "One drawback of estimating gradients using finite differences is that the number of queries reqired scals with the dimensionalty of the examples, which can be prohibitive in the case of images.", "They therefore describe two practicalapproaches for query reduction \u2014 one based on random feature grouping, and the other on PCA (which reqires access to training data).", "They once again demonstrate the effectiveness of these methods across a number of models and datasets, including models deploying adversarialy trained defenses.", "Finaly, they demonstrate compelling realworld deployment against Clarifai classification models designed to flag \u201cNot Safe for Work\u201d content.", "Overal, the paper provides a very thorough experimentalexamination of a practicalblack-box attack that can be deployed against realworld systems.", "While there are some similarities with Chen et al with respect to utilizing finite-differences to estimate gradients, I believe the work is still valable for its very thorough experimentalverification, as well as the practicalty of their methods.", "The authors may want to be more explicit about their claim in the Related Work secion that the running time of their attack is \u201c40x\u201d less than that of Chen et al While this is believable, there is no running time comparison in the body of the paper."], "all_annotations": [{"interpretation": 0, "review_id": "B10Nn-jlf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 1, "method": null}]}, {"conference": "iclr18", "review_id": "B129GzFxf", "review_text": "This paper proposes a new method for reverse curriculum generation by gradually reseting the environment in phases and classifying states that tend to lead to success. It additionally proposes a mechanism for learning from human-provided \"key states\".\n\nThe ideas in this paper are quite nice, but the paper has significant issues with regard to clarity and applicability to real-world problems:\nFirst, it is unclear is the proposed method requires access only high-dimensional observations (e.g. images) during training or if it additionally requires low-dimensional states (e.g. sufficient information to reset the environment). In most compelling problems settings where a low-dimensional representation that sufficiently explains the current state of the world is available during training, then it is also likely that one can write down a nicely shaped reward function using that state information during training, in which case, it makes sense to use such a reward function. This paper seems to require access to low-dimensional states, and specifically considers the sparse-reward setting, which seems contrived.\nSecond, the paper states that the assumption \"when resetting, the agent can be reset to any state\" can be satisfied in problems such as real-world robotic manipulation. This is not correct. If the robot could autonomously reset to any state, then we would have largely solved robotic manipulation. Further, it is not always realistic to assume access to low-dimensional state information during training on a real robotic system (e.g. knowing the poses of all of the objects in the world).\nThird, the experiments section lacks crucial information needed to understand the experiments. What is the state, observation, and action space for each problem setting? What is the reward function for each problem setting? What reinforcement learning algorithm is used in combination with the curriculum and tendency rewards? Are the states and actions continuous or discrete? Without this information, it is difficult to judge the merit of the experimental setting.\nFourth, the proposed method seems to lack motivation, making the proposed scheme seem a bit ad hoc. Could each of the components be motivated further through more discussion and/or ablative studies?\nFinally, the main text of the paper is substantially longer than the recommended page limit. It should be shortened by making the writing more concise.\n\nBeyond my feedback on clarity and significance, here are further pieces of feedback with regard to the technical content, experiments, and related work:\nI'm wondering -- can the reward shaping in Equation 2 be made to satisfy the property of not affecting the final policy? (see Ng et al. '09) If so, such a reward shaping would make the method even more appealing.\nHow do the experiments in section 5.4 compare to prior methods and ablations? Without such a comparison, it is impossible to judge the performance of the proposed method and the level of difficulty of these tasks. At the very least, the paper should compare the performance of the proposed method to the performance a random policy.\n\nThe paper is missing some highly relevant references. First, how does the proposed method compare to hindsight experience replay? [1] Second, learning from keyframes (rather than demonstrations) has been explored in the past [1]. It would be preferable to use the standard terminology of \"keyframe\".\n\n[1] Andrychowicz et al. Hindsight Experience Replay. 2017\n[2] Akgun et al. Keyframe-based Learning from Demonstration. 2012\n\nIn summary, I think this paper has a number of promising ideas and experimental results, but given the significant issues in clarity and significance to real world problems, I don't think that the current version of this paper is suitable for publication in ICLR.\n\nMore minor feedback on clarity and correctness:\n- Abstract: \"Deep RL algorithms have proven successful in a vast variety of domains\" -- This is an overstatement.\n- The introduction should be more clear with regard to the assumptions. In particular, it would be helpful to see discussion of requiring human-provided keyframes. As is, it is unclear what is meant by \"checkpoint scheme\", which is not commonly used terminology.\n- \"This kind of spare reward, goal-oriented tasks are considered the most difficult challenges\" -- This is also an overstatement. Long-horizon tasks and high-dimensional observations are also very difficult. Also, the sentence is not grammatically correct.\n- \"That is, environment\" -> \"That is, the environment\"\n- In the last paragraph of the intro, it would be helpful to more clearly state what the experiments can accomplish. Can they handle raw pixel inputs?\n- \"diverse domains\" -> \"diverse simulated domains\"\n- \"a robotic grasping task\" -> \"a simulated robotic grasping task\"\n- There are a number of issues and errors in citations, e.g. missing the year, including the first name, incorrect reference\n- Assumption 1: \\mathcal{P} has not yet been defined.\n- The last two paragraphs of section 3.2 are very difficult to understand without reading the method yet\n- \"conventional RL solver tend\" -> \"conventional RL tend\", also should mention sparse reward in this sentence.\n- Algorithm 1 and Figure 1 are not referenced in the text anywhere, and should be\n- The text in Figure 1 and Figure 3 is extremely small\n- The text in Figure 3 is extremely small\n\n\n", "gold_annotation": {"interpretation": 1, "review_id": "B129GzFxf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 5, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, "score": 4.5, "tokenized_review_text": ["This paper proposes a new method for reverse curriculum generation by gradualy reseting the environment in phases and classifying states that tend to lead to success.", "It additionaly proposes a mechanism for learning from human-provided \"key states\".", "The ideas in this paper are quite nice, but the paper has significant issues with regard to clarity and applicability to realworld problems: First, it is unclear is the proposed method reqires access only high-dimensionalobservations (e g images) during training or if it additionaly reqires low-dimensionalstates (e g sufficient information to reset the environment).", "In most compelling problems settings where a low-dimensionalrepresentation that sufficiently explains the current state of the world is available during training, then it is alo likely that one can write down a nicely shaped reward function using that state information during training, in which case, it makes sense to use such a reward function.", "This paper seems to reqire access to low-dimensionalstates, and specificaly considers the sparse-reward setting, which seems contrived.", "secnd, the paper states that the assumption \"when resetting, the agent can be reset to any state\" can be satisfied in problems such as realworld robotic manipulation.", "This is not correct.", "If the robot could autonomously reset to any state, then we would have largely solved robotic manipulation.", "Further, it is not alays realstic to assume access to low-dimensionalstate information during training on a realrobotic system (e g knowing the poses of al of the objects in the world).", "Third, the experiments secion lacks crucialinformation needed to understand the experiments.", "What is the state, observation, and action space for each problem setting?", "What is the reward function for each problem setting?", "What reinforcement learning alorithm is used in combination with the curriculum and tendency rewards?", "Are the states and actions continuous or discrete?", "Without this information, it is difficult to judge the merit of the experimentalsetting.", "Fourth, the proposed method seems to lack motivation, making the proposed scheme seem a bit ad hoc.", "Could each of the components be motivated further through more discussion and/or ablative studies?", "Finaly, the main text of the paper is substantialy longer than the recommended page limit.", "It should be shortened by making the writing more concise.", "Beyond my feedback on clarity and significance, here are further pieces of feedback with regard to the technicalcontent, experiments, and related work: I'm wondering -- can the reward shaping in eqation 2 be made to satisfy the property of not affecting the finalpolicy?", "(see Ng et al '09) If so, such a reward shaping would make the method even more appealng.", "How do the experiments in secion 5 4 compare to prior methods and ablations?", "Without such a comparison, it is impossible to judge the performance of the proposed method and the level of difficulty of these tasks.", "At the very least, the paper should compare the performance of the proposed method to the performance a random policy.", "The paper is missing some highly relevant references.", "First, how does the proposed method compare to hindsight experience replay?", "[1] secnd, learning from keyframes (rather than demonstrations) has been explored in the past [1].", "It would be preferable to use the standard terminology of \"keyframe\".", "[1] Andrychowicz et al Hindsight Experience Replay.", "2017 [2] Akgun et al Keyframe-based Learning from Demonstration.", "2012 In summary, I think this paper has a number of promising ideas and experimentalresults, but given the significant issues in clarity and significance to realworld problems, I don't think that the current version of this paper is suitable for publication in ICLR.", "More minor feedback on clarity and correctness: - Abstract: \"Deep RL alorithms have proven successful in a vast variety of domains\" -- This is an overstatement.", "- The introduction should be more clear with regard to the assumptions.", "In particular, it would be helpful to see discussion of reqiring human-provided keyframes.", "As is, it is unclear what is meant by \"checkpoint scheme\", which is not commonly used terminology.", "- \"This kind of spare reward, goaloriented tasks are considered the most difficult chalenges\" -- This is alo an overstatement.", "Long-horizon tasks and high-dimensionalobservations are alo very difficult.", "Also, the sentence is not grammaticaly correct.", "- \"That is, environment\" -> \"That is, the environment\" - In the last paragraph of the intro, it would be helpful to more clearly state what the experiments can accomplish.", "Can they handle raw pixel inputs?", "- \"diverse domains\" -> \"diverse simulated domains\" - \"a robotic grasping task\" -> \"a simulated robotic grasping task\" - There are a number of issues and errors in citations, e g missing the year, including the first name, incorrect reference - Assumption 1: \\mathcalP} has not yet been defined.", "- The last two paragraphs of secion 3 2 are very difficult to understand without reading the method yet - \"conventionalRL solver tend\" -> \"conventionalRL tend\", alo should mention sparse reward in this sentence.", "- Algorithm 1 and figre 1 are not referenced in the text anywhere, and should be - The text in figre 1 and figre 3 is extremely smal - The text in figre 3 is extremely smal"], "all_annotations": [{"interpretation": 1, "review_id": "B129GzFxf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 5, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "B143HDlWM", "review_text": "The below review addresses the first revision of the paper. The revised version does address my concerns. The fact that the paper does not come with substantial theoretical contributions/justification still stands out.\n\n---\n\nThe authors present a variant of the adversarial feature learning (AFL) approach by Edwards & Storkey. AFL aims to find a data representation that allows to construct a predictive model for target variable Y, and at the same time prevents to build a predictor for sensitive variable S. The key idea is to solve a minimax problem where the log-likelihood of a model predicting Y is maximized, and the log-likelihood of an adversarial model predicting S is minimized. The authors suggest the use of multiple adversarial models, which can be interpreted as using an ensemble model instead of a single model.\n\nThe way the log-likelihoods of the multiple adversarial models are aggregated does not yield a probability distribution as stated in Eq. 2. While there is no requirement to have a distribution here - a simple loss term is sufficient - the scale of this term differs compared to calibrated log-likelihoods coming from a single adversary. Hence, lambda in Eq. 3 may need to be chosen differently depending on the adversarial model. Without tuning lambda for each method, the empirical experiments seem unfair. This may also explain why, for example, the baseline method with one adversary effectively fails for Opp-L. A better comparison would be to plot the performance of the predictor of S against the performance of Y for varying lambdas. The area under this curve allows much better to compare the various methods.\n\nThere are little theoretical contributions. Basically, instead of a single adversarial model - e.g., a single-layer NN or a multi-layer NN - the authors propose to train multiple adversarial models on different views of the data. An alternative interpretation is to use an ensemble learner where each learner is trained on a different (overlapping) feature set. Though, there is no theoretical justification why ensemble learning is expected to better trade-off model capacity and robustness against an adversary. Tuning the architecture of the single multi-layer NN adversary might be as good?\n\nIn short, in the current experiments, the trade-off of the predictive performance and the effectiveness of obtaining anonymized representations effectively differs between the compared methods. This renders the comparison unfair. Given that there is also no theoretical argument why an ensemble approach is expected to perform better, I recommend to reject the paper.", "gold_annotation": {"interpretation": 1, "review_id": "B143HDlWM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["The below review addresses the first revision of the paper.", "The revised version does address my concerns.", "The fact that the paper does not come with substantialtheoreticalcontributions/justification still stands out.", "--- The authors present a variant of the adversarialfeature learning (AFL) approach by Edwards & Storkey.", "AFL aims to find a data representation that alows to construct a predictive model for target variable Y, and at the same time prevents to build a predictor for sensitive variable S The key idea is to solve a minimax problem where the log-likelihood of a model predicting Y is maximized, and the log-likelihood of an adversarialmodel predicting S is minimized.", "The authors suggest the use of multiple adversarialmodels, which can be interpreted as using an ensemble model instead of a single model.", "The way the log-likelihoods of the multiple adversarialmodels are aggregated does not yield a probability distribution as stated in eq 2, While there is no reqirement to have a distribution here - a simple loss term is sufficient - the scal of this term differs compared to calbrated log-likelihoods coming from a single adversary.", "Hence, lambda in eq 3 may need to be chosen differently depending on the adversarialmodel.", "Without tuning lambda for each method, the empiricalexperiments seem unfair.", "This may alo explain why, for example, the baseline method with one adversary effectively fails for Opp-L A better comparison would be to plot the performance of the predictor of S against the performance of Y for varying lambdas.", "The area under this curve alows much better to compare the various methods.", "There are little theoreticalcontributions.", "Basicaly, instead of a single adversarialmodel - e g , a single-layer NN or a multi-layer NN - the authors propose to train multiple adversarialmodels on different views of the data.", "An alernative interpretation is to use an ensemble learner where each learner is trained on a different (overlapping) feature set.", "Though, there is no theoreticaljustification why ensemble learning is expected to better trade-off model capacity and robustness against an adversary.", "Tuning the architecture of the single multi-layer NN adversary might be as good?", "In short, in the current experiments, the trade-off of the predictive performance and the effectiveness of obtaining anonymized representations effectively differs between the compared methods.", "This renders the comparison unfair.", "Given that there is alo no theoreticalargument why an ensemble approach is expected to perform better, I recommend to reject the paper."], "all_annotations": [{"interpretation": 1, "review_id": "B143HDlWM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1A7YkceM", "review_text": "The authors propose a procedure to generate an ensemble of sparse structured models. To do this, the authors propose to (1) sample models using SG-MCMC with group sparse prior, (2) prune hidden units with small weights, (3) and retrain weights by optimizing each pruned model. The ensemble is applied to MNIST classification and language modelling on PTB dataset. \n\nI have two major concerns on the paper. First, the proposed procedure is quite empirically designed. So, it is difficult to understand why it works well in some problems. Particularly. the justification on the retraining phase is weak. It seems more like to use SG-MCMC to *initialize* models which will then be *optimized* to find MAP with the sparse-model constraints. The second problem is about the baselines in the MNIST experiments. The FNN-300-100 model without dropout, batch-norm, etc. seems unreasonably weak baseline. So, the results on Table 1 on this small network is not much informative practically. Lastly, I also found a significant effort is also desired to improve the writing. \n\nThe following reference also needs to be discussed in the context of using SG-MCMC in RNN.\n- \"Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling\", Zhe Gan*, Chunyuan Li*, Changyou Chen, Yunchen Pu, Qinliang Su, Lawrence Carin", "gold_annotation": {"interpretation": 1, "review_id": "B1A7YkceM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The authors propose a procedure to generate an ensemble of sparse structured models.", "To do this, the authors propose to (1) sample models using SG-MCMC with group sparse prior, (2) prune hidden units with smal weights, (3) and retrain weights by optimizing each pruned model.", "The ensemble is applied to MNIST classification and language modelling on PTB dataset.", "I have two major concerns on the paper.", "First, the proposed procedure is quite empiricaly designed.", "So, it is difficult to understand why it works well in some problems.", "Particularly.", "the justification on the retraining phase is weak.", "It seems more like to use SG-MCMC to *initialze* models which will then be *optimized* to find MAP with the sparse-model constraints.", "The secnd problem is about the baselines in the MNIST experiments.", "The FNN-300-100 model without dropout, batch-norm, etc seems unreasonably weak baseline.", "So, the results on Table 1 on this smal network is not much informative practicaly.", "Lastly, I alo found a significant effort is alo desired to improve the writing.", "The following reference alo needs to be discussed in the context of using SG-MCMC in RNN.", "- \"Scalble Bayesian Learning of Recurrent NeuralNetworks for Language Modeling\", Zhe Gan*, Chunyuan Li*, Changyou Chen, Yunchen Pu, Qinliang Su, Lawrence Carin"], "all_annotations": [{"interpretation": 1, "review_id": "B1A7YkceM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1B3e0Oef", "review_text": "This work introduces a particular parametrization of a stochastic policy (a uniform mixture of deterministic policies). They find this parametrization, when trained with stochastic value gradient outperforms DDPG on several OpenAI gym benchmarks.\n\nThis paper unfortunately misses many significant pieces of prior work training stochastic policies. The most relevant is [1] which should definitely be cited. The algorithm here can be seen as SVG(0) with a particular parametrization of the policy. However, numerous other works have examined stochastic policies including [2] (A3C which also used the Torcs environment) and [3].\n\nThe wide use of stochastic policies in prior work makes the introductory explanation of the potential benefits for stochastic policies distracting, instead the focus should be on the particular choice and benefits of the particular stochastic parametrization chosen here and the choice of stochastic value gradient as a training method (as opposed to many on-policy methods).\n\nThe empirical comparison is also hampered by only comparing with DDPG, there are numerous stochastic policy algorithms that have been compared on these environments. Additionally, the DDPG performance here is lower for several environments than the results reported in Henderson et al. 2017 (cited in the paper, table 2 here, table 3 Henderson) which should be explained.\n\nWhile this particular parametrization may provide some benefits, the lack of engagement with relevant prior work and other stochastic baselines significant limits the impact of this work and makes assessing its significance difficult.\n\nThis work would benefit from careful copyediting.\n\n[1] Heess, N., Wayne, G., Silver, D., Lillicrap, T., Erez, T., & Tassa, Y. (2015). Learning continuous control policies by stochastic value gradients. In Advances in Neural Information Processing Systems (pp. 2944-2952).\n\n[2] Mnih, V., Badia, A. P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., ... & Kavukcuoglu, K. (2016, June). Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning (pp. 1928-1937).\n\n[3] Schulman, J., Moritz, P., Levine, S., Jordan, M., & Abbeel, P. (2015). High-dimensional continuous control using generalized advantage estimation. arXiv preprint arXiv:1506.02438.\n\n", "gold_annotation": {"interpretation": 0, "review_id": "B1B3e0Oef", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}, "score": 3.5, "tokenized_review_text": ["This work introduces a particular parametrization of a stochastic policy (a uniform mixture of deterministic policies).", "They find this parametrization, when trained with stochastic vale gradient outperforms DDPG on severalOpenAI gym benchmarks.", "This paper unfortunately misses many significant pieces of prior work training stochastic policies.", "The most relevant is [1] which should definitely be cited.", "The alorithm here can be seen as SVG(0) with a particular parametrization of the policy.", "However, numerous other works have examined stochastic policies including [2] (A3C which alo used the Torcs environment) and [3].", "The wide use of stochastic policies in prior work makes the introductory explanation of the potentialbenefits for stochastic policies distracting, instead the focus should be on the particular choice and benefits of the particular stochastic parametrization chosen here and the choice of stochastic vale gradient as a training method (as opposed to many on-policy methods).", "The empiricalcomparison is alo hampered by only comparing with DDPG, there are numerous stochastic policy alorithms that have been compared on these environments.", "Additionaly, the DDPG performance here is lower for severalenvironments than the results reported in Henderson et al 2017 (cited in the paper, table 2 here, table 3 Henderson) which should be explained.", "While this particular parametrization may provide some benefits, the lack of engagement with relevant prior work and other stochastic baselines significant limits the impact of this work and makes assessing its significance difficult.", "This work would benefit from careful copyediting.", "[1] Heess, N , Wayne, G , Silver, D , Lillicrap, T , Erez, T , & Tassa, Y (2015).", "Learning continuous control policies by stochastic vale gradients.", "In Advances in NeuralInformation Processing Systems (pp.", "2944-2952).", "[2] Mnih, V , Badia, A P , Mirza, M , Graves, A , Lillicrap, T , Harley, T , ... & Kavukcuoglu, K (2016, June).", "Asynchronous methods for deep reinforcement learning.", "In InternationalConference on Machine Learning (pp.", "1928-1937).", "[3] Schulman, J , Moritz, P , Levine, S , Jordan, M , & Abbeel, P (2015).", "High-dimensionalcontinuous control using generalzed advantage estimation.", "arXiv preprint arXiv:1506.02438,"], "all_annotations": [{"interpretation": 0, "review_id": "B1B3e0Oef", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1Fe0Zqxz", "review_text": "** post-rebuttal revision **\n\nI thank the authors for running the baseline experiments, especially for running the TwinNet to learn an agreement between two RNNs going forward in time. This raises my confidence that what is reported is better than mere distillation of an ensemble of rnns. I am raising the score.\n\n** original review **\n\n\nThe paper presents a way to regularize a sequence generator by making the hidden states also predict the hidden states of an RNN working backward.\n\nApplied to sequence-to-sequence networks, the approach requires training one encoder, and two separate decoders, that generate the target sequence in forward and reversed orders. A penalty term is added that forces an agreement between the hidden states of the two decoders. During model evaluation only the forward decoder is used, with the backward operating decoder discarded. The method can be interpreted to generalize other recurrent network regularizers, such as putting an L2 loss on the hidden states.\n\nExperiments indicate that the  approach is most successful when the regularized RNNs are conditional generators, which emit sequences of low entropy, such as decoders of a seq2seq speech recognition network. Negative results were reported when the proposed regularization technique was applied to language models, whose output distribution has more entropy.\n\nThe proposed regularization is evaluated with positive results on a speech recognition task and on an  image captioning task, and with negative results (no improvement, but also no deterioration) on a language modeling and sequential MNIST digit generation tasks.\n\nI have one question about baselines: is the proposed approach better than training to forward generators and force an agreement between them (in the spirit of the concurrent ICLR submission https://openreview.net/forum?id=rkr1UDeC-)? \n\nAlso, would using the backward RNN, e.g. for rescoring, bring another advantage? In other words, what is (and is there) a gap between an ensemble of a forward and backward rnn and the forward-rnn only, but trained with the state-matching penalty?\n\nQuality:\nThe proposed approach is well motivated and the experiments show the limits of applicability range of the technique.\n\nClarity:\nThe paper is clearly written.\n\nOriginality:\nThe presented idea seems novel.\n\nSignificance:\nThe method may prove to be useful to regularize recurrent networks, however I would like to see a comparison with ensemble methods. Also, as the authors note the method seems to be limited to conditional sequence generators.\n\nPros and cons:\nPros: the method is simple to implement, the paper lists for what kind of datasets it can be used.\nCons: the method needs to be compared with typical ensembles of models going only forward in time, it may turn that it using the backward RNN is not necessary\n", "gold_annotation": {"interpretation": 1, "review_id": "B1Fe0Zqxz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["** post-rebuttalrevision ** I thank the authors for running the baseline experiments, especialy for running the TwinNet to learn an agreement between two RNNs going forward in time.", "This raises my confidence that what is reported is better than mere distillation of an ensemble of rnns.", "I am raising the score.", "** originalreview ** The paper presents a way to regularize a seqence generator by making the hidden states alo predict the hidden states of an RNN working backward.", "Applied to seqence-to-seqence networks, the approach reqires training one encoder, and two separate decoders, that generate the target seqence in forward and reversed orders.", "A penaly term is added that forces an agreement between the hidden states of the two decoders.", "During model evalation only the forward decoder is used, with the backward operating decoder discarded.", "The method can be interpreted to generalze other recurrent network regularizers, such as putting an L2 loss on the hidden states.", "Experiments indicate that the approach is most successful when the regularized RNNs are conditionalgenerators, which emit seqences of low entropy, such as decoders of a seqseqspeech recognition network.", "Negative results were reported when the proposed regularization technique was applied to language models, whose output distribution has more entropy.", "The proposed regularization is evalated with positive results on a speech recognition task and on an image captioning task, and with negative results (no improvement, but alo no deterioration) on a language modeling and seqentialMNIST digit generation tasks.", "I have one question about baselines: is the proposed approach better than training to forward generators and force an agreement between them (in the spirit of the concurrent ICLR submission https://openreview.net/forum?id=rkr1UDeC-)?", "Also, would using the backward RNN, e g for rescoring, bring another advantage?", "In other words, what is (and is there) a gap between an ensemble of a forward and backward rnn and the forward-rnn only, but trained with the state-matching penaly?", "Qualty: The proposed approach is well motivated and the experiments show the limits of applicability range of the technique.", "Clarity: The paper is clearly written.", "Originalty: The presented idea seems novel.", "Significance: The method may prove to be useful to regularize recurrent networks, however I would like to see a comparison with ensemble methods.", "Also, as the authors note the method seems to be limited to conditionalseqence generators.", "Pros and cons: Pros: the method is simple to implement, the paper lists for what kind of datasets it can be used.", "Cons: the method needs to be compared with typicalensembles of models going only forward in time, it may turn that it using the backward RNN is not necessary"], "all_annotations": [{"interpretation": 1, "review_id": "B1Fe0Zqxz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1IwI-2xz", "review_text": "This paper proposes an empirical measure of the intrinsic dimensionality of a neural network problem. Taking the full dimensionality to be the total number of parameters of the network model, the authors assess intrinsic dimensionality by randomly projecting the network to a domain with fewer parameters (corresponding to a low-dimensional subspace within the original parameter), and then training the original network while restricting the projections of its parameters to lie within this subspace. Performance on this subspace is then evaluated relative to that over the full parameter space (the baseline). As an empirical standard, the authors focus on the subspace dimension that achieves a performance of 90% of the baseline. The authors then test out their measure of intrinsic dimensionality for fully-connected networks and convolutional networks, for several well-known datasets, and draw some interesting conclusions.\n\nPros:\n\n* This paper continues the recent research trend towards a better characterization of neural networks and their performance. The authors show a good awareness of the recent literature, and to the best of my knowledge, their empirical characterization of the number of latent parameters is original. \n\n* The characterization of the number of latent variables is an important one, and their measure does perform in a way that one would intuitively expect. For example, as reported by the authors, when training a fully-connected network on the MNIST image dataset, shuffling pixels does not result in a change in their intrinsic dimensionality. For a convolutional network the observed 3-fold rise in intrinsic dimension is explained by the authors as due to the need to accomplish the classification task while respecting the structural constraints of the convnet.\n\n* The proposed measures seem very practical - training on random projections uses far fewer parameters than in the original space (the baseline), and presumably the cost of determining the intrinsic dimensionality would presumably be only a fraction of the cost of this baseline training.\n\n* Except for the occasional typo or grammatical error, the paper is well-written and organized. The issues are clearly identified, for the most part (but see below...).\n\nCons:\n\n* In the main paper, the authors perform experiments and draw conclusions without taking into account the variability of performance across different random projections. Variance should be taken into account explicitly, in presenting experimental results and in the definition and analysis of the empirical intrinsic dimension itself. How often does a random projection lead to a high-quality solution, and how often does it not?\n\n* The authors are careful to point out that training in restricted subspaces cannot lead to an optimal solution for the full parameter domain unless the subspace intersects the optimal solution region (which in general cannot be guaranteed). In their experiments (FC networks of varying depths and layer widths for the MNIST dataset), between projected and original solutions achieving 90% of baseline performance, they find an order of magnitude gap in the number of parameters needed. This calls into question the validity of random projection as an empirical means of categorizing the intrinsic dimensionality of a neural network.\n\n* The authors then go on to propose that compression of the network be achieved by random projection to a subspace of dimensionality greater than or equal to the intrinsic dimension. However, I don't think that they make a convincing case for this approach. Again, variation is the difficulty: two different projective subspaces of the same dimensionality can lead to solutions that are extremely different in character or quality. How then can we be sure that our compressed network can be reconstituted into a solution of reasonable quality, even when its dimensionality greatly exceeds the intrinsic dimension?\n\n* The authors argue for a relationship between intrinsic dimensionality and the minimum description length (MDL) of their solution, in that the intrinsic dimensionality should serve as an upper bound on the MDL. However they don't formally acknowledge that there is no standard relationship between the number of parameters and the actual number of bits needed to represent the model - it varies from setting to setting, with some parameters potentially requiring many more bits than others. And given this uncertain connection, and given the lack of consideration given to variation in the proposed measure of intrinsic dimensionality, it is hard to accept that \"there is some rigor behind\" their conclusion that LeNet is better than FC networks for classification on MNIST because its empirical intrinsic dimensionality score is lower.\n\n* The experimental validation of their measure of intrinsic dimension could be made more extensive. In the main paper, they use three image datasets - MNIST, CIFAR-10 and ImageNet. In the supplemental information, they report intrinsic dimensions for reinforcement learning and other training tasks on four other sets.\n\nOverall, I think that this characterization does have the potential to give insights into the performance of neural networks, provided that variation across projections is properly taken into account. For now, more work is needed.\n\n====================================================================================================\nAddendum:\n\nThe authors have revised their paper to take into account the effect of variation across projections, with results that greatly strengthen their results and provide a much better justification of their approach. I'm satisfied too with their explanations, and how they incorporated them into their revised version. I've adjusted my rating of the paper accordingly.\n\nOne point, however: the revisions seem somewhat rushed, due to the many typos and grammatical errors in the updated sections. I would like to encourage the authors to check their manuscript once more, very carefully, before finalizing the paper.\n====================================================================================================", "gold_annotation": {"interpretation": 1, "review_id": "B1IwI-2xz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper proposes an empiricalmeasure of the intrinsic dimensionalty of a neuralnetwork problem.", "Taking the full dimensionalty to be the totalnumber of parameters of the network model, the authors assess intrinsic dimensionalty by randomly projecting the network to a domain with fewer parameters (corresponding to a low-dimensionalsubspace within the originalparameter), and then training the originalnetwork while restricting the projections of its parameters to lie within this subspace.", "Performance on this subspace is then evalated relative to that over the full parameter space (the baseline).", "As an empiricalstandard, the authors focus on the subspace dimension that achieves a performance of 90% of the baseline.", "The authors then test out their measure of intrinsic dimensionalty for fully-connected networks and convolutionalnetworks, for severalwell-known datasets, and draw some interesting conclusions.", "Pros: * This paper continues the recent research trend towards a better characterization of neuralnetworks and their performance.", "The authors show a good awareness of the recent literature, and to the best of my knowledge, their empiricalcharacterization of the number of latent parameters is original * The characterization of the number of latent variables is an important one, and their measure does perform in a way that one would intuitively expect.", "For example, as reported by the authors, when training a fully-connected network on the MNIST image dataset, shuffling pixels does not result in a change in their intrinsic dimensionalty.", "For a convolutionalnetwork the observed 3-fold rise in intrinsic dimension is explained by the authors as due to the need to accomplish the classification task while respecting the structuralconstraints of the convnet.", "* The proposed measures seem very practical- training on random projections uses far fewer parameters than in the originalspace (the baseline), and presumably the cost of determining the intrinsic dimensionalty would presumably be only a fraction of the cost of this baseline training.", "* Except for the occasionaltypo or grammaticalerror, the paper is well-written and organized.", "The issues are clearly identified, for the most part (but see below...).", "Cons: * In the main paper, the authors perform experiments and draw conclusions without taking into account the variability of performance across different random projections.", "Variance should be taken into account explicitly, in presenting experimentalresults and in the definition and analsis of the empiricalintrinsic dimension itself.", "How often does a random projection lead to a high-qualty solution, and how often does it not?", "* The authors are careful to point out that training in restricted subspaces cannot lead to an optimalsolution for the full parameter domain unless the subspace intersecs the optimalsolution region (which in generalcannot be guaranteed).", "In their experiments (FC networks of varying depths and layer widths for the MNIST dataset), between projected and originalsolutions achieving 90% of baseline performance, they find an order of magnitude gap in the number of parameters needed.", "This cals into question the valdity of random projection as an empiricalmeans of categorizing the intrinsic dimensionalty of a neuralnetwork.", "* The authors then go on to propose that compression of the network be achieved by random projection to a subspace of dimensionalty greater than or eqalto the intrinsic dimension.", "However, I don't think that they make a convincing case for this approach.", "Again, variation is the difficulty: two different projective subspaces of the same dimensionalty can lead to solutions that are extremely different in character or qualty.", "How then can we be sure that our compressed network can be reconstituted into a solution of reasonable qualty, even when its dimensionalty greatly exceeds the intrinsic dimension?", "* The authors argue for a relationship between intrinsic dimensionalty and the minimum description length (MDL) of their solution, in that the intrinsic dimensionalty should serve as an upper bound on the MDL.", "However they don't formaly acknowledge that there is no standard relationship between the number of parameters and the actualnumber of bits needed to represent the model - it varies from setting to setting, with some parameters potentialy reqiring many more bits than others.", "And given this uncertain connection, and given the lack of consideration given to variation in the proposed measure of intrinsic dimensionalty, it is hard to accept that \"there is some rigor behind\" their conclusion that LeNet is better than FC networks for classification on MNIST because its empiricalintrinsic dimensionalty score is lower.", "* The experimentalvaldation of their measure of intrinsic dimension could be made more extensive.", "In the main paper, they use three image datasets - MNIST, CIFAR-10 and ImageNet.", "In the supplementalinformation, they report intrinsic dimensions for reinforcement learning and other training tasks on four other sets.", "Overal, I think that this characterization does have the potentialto give insights into the performance of neuralnetworks, provided that variation across projections is properly taken into account.", "For now, more work is needed.", "==================================================================================================== Addendum: The authors have revised their paper to take into account the effect of variation across projections, with results that greatly strengthen their results and provide a much better justification of their approach.", "I'm satisfied too with their explanations, and how they incorporated them into their revised version.", "I've adjusted my rating of the paper accordingly.", "One point, however: the revisions seem somewhat rushed, due to the many typos and grammaticalerrors in the updated secions.", "I would like to encourage the authors to check their manuscript once more, very carefully, before finalzing the paper.", "===================================================================================================="], "all_annotations": [{"interpretation": 1, "review_id": "B1IwI-2xz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1LfYs_gf", "review_text": "This paper proposes to use 3D conditional GAN models to generate\nfMRI scans. Using the generated images, paper reports improvement\nin classification accuracy on various tasks.\n\nOne claim of the paper is that a generative model of fMRI\ndata can help to caracterize and understand variability of scans\nacross subjects.\n\nArticle is based on recent works such as Wasserstein GANs and AC-GANs\nby (Odena et al., 2016).\n\nDespite the rich literature of this recent topic the related work\nsection is rather convincing.\n\nModel presented extends IW-GAN by using 3D convolution and also\nby supervising the generator using sample labels.\n\nMajor:\n\n- The size of the generated images is up to 26x31x22 which is limited\n(about half the size of the actual resolution of fMRI data). As a\nconsequence results on decoding learning task using low resolution\nimages can end up worse than with the actual data (as pointed out).\nWhat it means is that the actual impact of the work is probably limited.\n\n- Generating high resolution images with GANs even on faces for which\nthere is almost infinite data is still a challenge. Here a few thousand\ndata points are used. So it raises too concerns: First is it enough?\nUsing so-called learning curves is a good way to answer this. Second\nis what are the contributions to the state-of-the-art of the 2\nmethods introduced? Said differently, as there\nis no classification results using images produced by an another\nGAN architecture it is hard to say that the extra complexity\nproposed here (which is a bit contribution of the work) is actually\nnecessary.\n\nMinor:\n\n- Fonts in figure 4 are too small.\n", "gold_annotation": {"interpretation": 1, "review_id": "B1LfYs_gf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper proposes to use 3D conditionalGAN models to generate fMRI scans.", "Using the generated images, paper reports improvement in classification accuracy on various tasks.", "One claim of the paper is that a generative model of fMRI data can help to caracterize and understand variability of scans across subjects.", "Article is based on recent works such as Wasserstein GANs and AC-GANs by (Odena et al, 2016).", "Despite the rich literature of this recent topic the related work secion is rather convincing.", "Model presented extends IW-GAN by using 3D convolution and alo by supervising the generator using sample labels.", "Major: - The size of the generated images is up to 26x31x22 which is limited (about hal the size of the actualresolution of fMRI data).", "As a conseqence results on decoding learning task using low resolution images can end up worse than with the actualdata (as pointed out).", "What it means is that the actualimpact of the work is probably limited.", "- Generating high resolution images with GANs even on faces for which there is alost infinite data is still a chalenge.", "Here a few thousand data points are used.", "So it raises too concerns: First is it enough?", "Using so-caled learning curves is a good way to answer this.", "secnd is what are the contributions to the state-of-the-art of the 2 methods introduced?", "Said differently, as there is no classification results using images produced by an another GAN architecture it is hard to say that the extra complexity proposed here (which is a bit contribution of the work) is actualy necessary.", "Minor: - Fonts in figre 4 are too smal."], "all_annotations": [{"interpretation": 1, "review_id": "B1LfYs_gf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "B1P-gBclf", "review_text": "The quality of the paper is good, and clarity is mostly good. The proposed metric is interesting, but it is hard to judge the significance without more thorough experiments demonstrating that it works in practice.\n\nPros:\n - clear definitions of terms\n - overall outline of paper is good\n - novel metric\n\nCons\n - text is a bit over-wordy, and flow/meaning sometimes get lost. A strict editor would be helpful, because the underlying content is good\n - odd that your definition of generalization in GANs appears immediately preceding the section titled \"Generalisation in GANs\"\n - the paragraph at the end of the \"Generalisation in GANs\" section is confusing. I think this section and the previous (\"The objective of unsupervised learning\") could be combined, removing some repetition, adding some subtitles to improve clarity. This would cut down the text a bit to make space for more experiments.\n - why is your definition of generalization that the test set distance is strictly less than training set ? I would think this should be less-than-or-equal\n - there is a sentence that doesn't end at the top of p.3: \"... the original GAN paper showed that [ends here]\"\n - should state in the abstract what your \"notion of generalization\" for gans is, instead of being vague about it\n - more experiments showing a comparison of the proposed metric to others (e.g. inception score, Mturk assessments of sample quality, etc.) would be necessary to find the metric convincing\n - what is a \"pushforward measure\"? (p.2)\n - the related work section is well-written and interesting, but it's a bit odd to have it at the end. Earlier in the work (e.g. before experiments and discussion) would allow the comparison with MMD to inform the context of the introduction\n - there are some errors in figures that I think were all mentioned by previous commentators.", "gold_annotation": {"interpretation": 0, "review_id": "B1P-gBclf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["The qualty of the paper is good, and clarity is mostly good.", "The proposed metric is interesting, but it is hard to judge the significance without more thorough experiments demonstrating that it works in practice.", "Pros: - clear definitions of terms - overal outline of paper is good - novel metric Cons - text is a bit over-wordy, and flow/meaning sometimes get lost.", "A strict editor would be helpful, because the underlying content is good - odd that your definition of generalzation in GANs appears immediately preceding the secion titled \"Generalsation in GANs\" - the paragraph at the end of the \"Generalsation in GANs\" secion is confusing.", "I think this secion and the previous (\"The objective of unsupervised learning\") could be combined, removing some repetition, adding some subtitles to improve clarity.", "This would cut down the text a bit to make space for more experiments.", "- why is your definition of generalzation that the test set distance is strictly less than training set ?", "I would think this should be less-than-or-eqal - there is a sentence that doesn't end at the top of p 3: \"... the originalGAN paper showed that [ends here]\" - should state in the abstract what your \"notion of generalzation\" for gans is, instead of being vague about it - more experiments showing a comparison of the proposed metric to others (e g inception score, Mturk assessments of sample qualty, etc) would be necessary to find the metric convincing - what is a \"pushforward measure\"?", "(p 2) - the related work secion is well-written and interesting, but it's a bit odd to have it at the end.", "Earlier in the work (e g before experiments and discussion) would alow the comparison with MMD to inform the context of the introduction - there are some errors in figres that I think were al mentioned by previous commentators."], "all_annotations": [{"interpretation": 0, "review_id": "B1P-gBclf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "B1ZlEVXyf", "review_text": "Summary\n========\n\nThe authors present CLEVER, an algorithm which consists in evaluating the (local) Lipschitz constant of a trained network around a data point. This is used to compute a lower-bound on the minimal perturbation of the data point needed to fool the network.\n\nThe method proposed in the paper already exists for classical function, they only transpose it to neural networks. Moreover, the lower bound comes from basic results in the analysis of Lipschitz continuous functions.\n\n\nClarity\n=====\n\nThe paper is clear and well-written.\n\n\nOriginality\n=========\n\nThis idea is not new: if we search for \"Lipschitz constant estimation\" in google scholar, we get for example\nWood, G. R., and B. P. Zhang. \"Estimation of the Lipschitz constant of a function.\" (1996)\nwhich presents a similar algorithm (i.e., estimation of the maximum slope with reverse Weibull).\n\n\nTechnical quality\n==============\n\nThe main theoretical result in the paper is the analysis of the lower-bound on \\delta, the smallest perturbation to apply on\na data point to fool the network. This result is obtained almost directly by writing the bound on Lipschitz-continuous function\n | f(y)-f(x) | < L || y-x ||\nwhere x = x_0 and y = x_0 + \\delta.\n\nComments:\n- Lemma 3.1: why citing Paulavicius and Zilinskas for the definition of Lipschitz continuity? Moreover, a Lipschitz-continuous function does not need to be differentiable at all (e.g. |x| is Lipschitz with constant 1 but sharp at x=0). Indeed, this constant can be easier obtained if the gradient exists, but this is not a requirement.\n\n- (Flaw?) Theorem 3.2 : This theorem works for fixed target-class since g = f_c - f_j for fixed g. However, once g = min_j f_c - f_j, this theorem is not clear with the constant Lq. Indeed, the function g should be \ng(x) = min_{k \\neq c} f_c(x) - f_k(x).\nThus its Lipschitz constant is different, potentially equal to\nL_q = max_{k} \\| L_q^k \\|, \nwhere L_q^k is the Lipschitz constant of f_c-f_k. If the theorem remains unchanged after this modification, you should clarify the proof. Otherwise, the theorem will work with the maximum over all Lipschitz constants but the theoretical result will be weakened.\n\n- Theorem 4.1: I do not see the purpose of this result in this paper. This should be better motivated.\n\n\nNumerical experiments\n====================\n\nGlobally, the numerical experiments are in favor of the presented method. The authors should also add information about the time it takes to compute the bound, the evolution of the bound in function of the number of samples and the distribution of the relative gap between the lower-bound and the best adversarial example.\n\nMoreover, the numerical experiments look to be realized in the context of targeted attack. To show the real effectiveness of the approach, the authors should also show the effectiveness of the lower-bound in the context of non-targeted attack.\n\n\n#######################################################\n\nPost-rebuttal review\n---------------------------\n\nGiven the details the authors provided to my review, I decided to adjust my score. The method is simple and shows to be extremely effective/accurate in practice.\n\nDetailed answers:\n\n1) Indeed, I was not aware that the paper only focuses on one dimensional functions. However, they still work with less assumption, i.e., with no differential functions. I was pointing out the similarities between their approach and your: the two algorithms (CLEVER and Slope) are basically the same, and using a limit you can go from \"slope\" to \"gradient norm\".\nIn any case, I have read the revision and the additional numerical experiment to compare Clever with their method is a good point.\n\n2) \" Overall, our analysis is simple and more intuitive, and we further facilitate numerical calculation of the bound by applying the extreme value theory in this work. \"\nThis is right. I am just surprised is has not been done before, since it requires only few lines of derivation. I searched a bit but it is not possible to find any kind of similar results. Moreover, this leads to good performances, so there is no needs to have something more complex.\n\n3) \"The usual Lipschitz continuity is defined in terms of L2 norm and the extension to an arbitrary Lp norm is not straightforward\"\nIndeed, people usually use the Lipschitz continuity using the L2norm, but the original definition is wider.\nQuickly, if you have a differential, scalar function from a space E -> R, then the gradient is a function from space E to E*, the dual of the space E.\nLet || . || the norm of space E. Then, || . ||* is the dual norm of ||.||, and also the norm of E*.\nIn that case, Lipschitz continuity writes\nf(x)-f(y) <= L || x-y ||, with L >= max_{x in E*} || f'(x) ||*\nIn the case where || . || is an \\ell-p norm, then || . ||* is an \\ell-q norm; with 1/p+1/q = 1.\n\nIf you are interested, there is a clear and concise explanation in the introduction of this paper: Accelerating the cubic regularization of Newton\u2019s method on convex problems, by Yurii Nesterov.\n\nI have no additional remarks for 4) -> 9), since everything is fixed in the new version of the paper.\n\n", "gold_annotation": {"interpretation": 1, "review_id": "B1ZlEVXyf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.5, "tokenized_review_text": ["Summary ======== The authors present CLEVER, an alorithm which consists in evalating the (local Lipschitz constant of a trained network around a data point.", "This is used to compute a lower-bound on the minimalperturbation of the data point needed to fool the network.", "The method proposed in the paper aleady exists for classicalfunction, they only transpose it to neuralnetworks.", "Moreover, the lower bound comes from basic results in the analsis of Lipschitz continuous functions.", "Clarity ===== The paper is clear and well-written.", "Originalty ========= This idea is not new: if we search for \"Lipschitz constant estimation\" in google scholar, we get for example Wood, G R , and B P Zhang.", "\"Estimation of the Lipschitz constant of a function.\"", "(1996) which presents a similar alorithm (i e , estimation of the maximum slope with reverse Weibull).", "Technicalqualty ============== The main theoreticalresult in the paper is the analsis of the lower-bound on \\delta, the smalest perturbation to apply on a data point to fool the network.", "This result is obtained alost directly by writing the bound on Lipschitz-continuous function | f(y)-f(x) | < L || y-x || where x = x_0 and y = x_0 + \\delta.", "Comments: - Lemma 3 1: why citing Paulavicius and Zilinskas for the definition of Lipschitz continuity?", "Moreover, a Lipschitz-continuous function does not need to be differentiable at al (e g |x| is Lipschitz with constant 1 but sharp at x=0).", "Indeed, this constant can be easier obtained if the gradient exists, but this is not a reqirement.", "- (Flaw?)", "Theorem 3 2 : This theorem works for fixed target-class since g = f_c - f_j for fixed g However, once g = min_j f_c - f_j, this theorem is not clear with the constant Lq.", "Indeed, the function g should be g(x) = min_{k \\neqc} f_c(x) - f_k(x).", "Thus its Lipschitz constant is different, potentialy eqalto L_q = max_{k} \\| L_q^k \\|, where L_q^k is the Lipschitz constant of f_c-f_k.", "If the theorem remains unchanged after this modification, you should clarify the proof.", "Otherwise, the theorem will work with the maximum over al Lipschitz constants but the theoreticalresult will be weakened.", "- Theorem 4 1: I do not see the purpose of this result in this paper.", "This should be better motivated.", "Numericalexperiments ==================== Globaly, the numericalexperiments are in favor of the presented method.", "The authors should alo add information about the time it takes to compute the bound, the evolution of the bound in function of the number of samples and the distribution of the relative gap between the lower-bound and the best adversarialexample.", "Moreover, the numericalexperiments look to be realzed in the context of targeted attack.", "To show the realeffectiveness of the approach, the authors should alo show the effectiveness of the lower-bound in the context of non-targeted attack.", "####################################################### Post-rebuttalreview --------------------------- Given the details the authors provided to my review, I decided to adjust my score.", "The method is simple and shows to be extremely effective/accurate in practice.", "Detailed answers: 1) Indeed, I was not aware that the paper only focuses on one dimensionalfunctions.", "However, they still work with less assumption, i e , with no differentialfunctions.", "I was pointing out the similarities between their approach and your: the two alorithms (CLEVER and Slope) are basicaly the same, and using a limit you can go from \"slope\" to \"gradient norm\".", "In any case, I have read the revision and the additionalnumericalexperiment to compare Clever with their method is a good point.", "2) \" Overal, our analsis is simple and more intuitive, and we further facilitate numericalcalulation of the bound by applying the extreme vale theory in this work. \"", "This is right.", "I am just surprised is has not been done before, since it reqires only few lines of derivation.", "I searched a bit but it is not possible to find any kind of similar results.", "Moreover, this leads to good performances, so there is no needs to have something more complex.", "3) \"The usualLipschitz continuity is defined in terms of L2 norm and the extension to an arbitrary Lp norm is not straightforward\" Indeed, people usualy use the Lipschitz continuity using the L2norm, but the originaldefinition is wider.", "Quickly, if you have a differential scalr function from a space E -> R, then the gradient is a function from space E to E*, the dualof the space E Let || .", "|| the norm of space E Then, || .", "||* is the dualnorm of ||.||, and alo the norm of E*.", "In that case, Lipschitz continuity writes f(x)-f(y) <= L || x-y ||, with L >= max_{x in E*} || f'(x) ||* In the case where || .", "|| is an \\ell-p norm, then || .", "||* is an \\ell-q norm; with 1/p+1/q = 1, If you are interested, there is a clear and concise explanation in the introduction of this paper: Accelerating the cubic regularization of Newton\u2019s method on convex problems, by Yurii Nesterov.", "I have no additionalremarks for 4) -> 9), since everything is fixed in the new version of the paper."], "all_annotations": [{"interpretation": 1, "review_id": "B1ZlEVXyf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1_TQ-clG", "review_text": "This paper studies learning to play two-player general-sum games with state (Markov games). The idea is to learn to cooperate (think prisoner's dilemma) but in more complex domains. Generally, in repeated prisoner's dilemma, one can punish one's opponent for noncooperation. In this paper, they design an apporach to learn to cooperate in a more complex game, like a hybrid pong meets prisoner's dilemma game. This is fun but I did not find it particularly surprising from a game-theoretic or from a deep learning point of view. \n\nFrom a game-theoretic point of view, the paper begins with somewhat sloppy definitions followed by a theorem that is not very surprising. It is basically a straightforward generalization of the idea of punishing, which is common in \"folk theorems\" from game theory, to give a particular equilibrium for cooperating in Markov games. Many Markov games do not have a cooperative equilibrium, so this paper restricts attention to those that do. Even in games where there is a cooperative solution that maximizes the total welfare, it is not clear why players would choose to do so. When the game is symmetric, this might be \"the natural\" solution but in general it is far from clear why all players would want to maximize the total payoff. \n\nThe paper follows with some fun experiments implementing these new game theory notions. Unfortunately, since the game theory was not particularly well-motivated, I did not find the overall story compelling. It is perhaps interesting that one can make deep learning learn to cooperate, but one could have illustrated the game theory equally well with other techniques.\n\nIn contrast, the paper \"Coco-Q: Learning in Stochastic Games with Side Payments\" by Sodomka et. al. is an example where they took a well-motivated game theoretic cooperative solution concept and explored how to implement that with reinforcement learning. I would think that generalizing such solution concepts to stochastic games and/or deep learning might be more interesting.\n\nIt should also be noted that I was asked to review another ICLR submission entitled \"CONSEQUENTIALIST CONDITIONAL COOPERATION IN\nSOCIAL DILEMMAS WITH IMPERFECT INFORMATION\n\" which amazingly introduced the same \"Pong Player\u2019s Dilemma\" game as in this paper. \n\nNotice the following suspiciously similar paragraphs from the two papers:\n\nFrom \"MAINTAINING COOPERATION IN COMPLEX SOCIAL DILEMMAS USING DEEP REINFORCEMENT LEARNING\":\nWe also look at an environment where strategies must be learned from raw pixels. We use the method\nof Tampuu et al. (2017) to alter the reward structure of Atari Pong so that whenever an agent scores a\npoint they receive a reward of 1 and the other player receives \u22122. We refer to this game as the Pong\nPlayer\u2019s Dilemma (PPD). In the PPD the only (jointly) winning move is not to play. However, a fully\ncooperative agent can be exploited by a defector.\n\nFrom \"CONSEQUENTIALIST CONDITIONAL COOPERATION IN SOCIAL DILEMMAS WITH IMPERFECT INFORMATION\":\nTo demonstrate this we follow the method of Tampuu et al. (2017) to construct a version of Atari Pong \nwhich makes the game into a social dilemma. In what we call the Pong Player\u2019s Dilemma (PPD) when an agent \nscores they gain a reward of 1 but the partner receives a reward of \u22122. Thus, in the PPD the only (jointly) winning\nmove is not to play, but selfish agents are again tempted to defect and try to score points even though\nthis decreases total social reward. We see that CCC is a successful, robust, and simple strategy in this\ngame.", "gold_annotation": {"interpretation": 0, "review_id": "B1_TQ-clG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 2.5, "tokenized_review_text": ["This paper studies learning to play two-player generalsum games with state (Markov games).", "The idea is to learn to cooperate (think prisoner's dilemma) but in more complex domains.", "Generaly, in repeated prisoner's dilemma, one can punish one's opponent for noncooperation.", "In this paper, they design an apporach to learn to cooperate in a more complex game, like a hybrid pong meets prisoner's dilemma game.", "This is fun but I did not find it particularly surprising from a game-theoretic or from a deep learning point of view.", "From a game-theoretic point of view, the paper begins with somewhat sloppy definitions followed by a theorem that is not very surprising.", "It is basicaly a straightforward generalzation of the idea of punishing, which is common in \"folk theorems\" from game theory, to give a particular eqilibrium for cooperating in Markov games.", "Many Markov games do not have a cooperative eqilibrium, so this paper restricts attention to those that do.", "Even in games where there is a cooperative solution that maximizes the totalwelfare, it is not clear why players would choose to do so.", "When the game is symmetric, this might be \"the natural solution but in generalit is far from clear why al players would want to maximize the totalpayoff.", "The paper follows with some fun experiments implementing these new game theory notions.", "Unfortunately, since the game theory was not particularly well-motivated, I did not find the overal story compelling.", "It is perhaps interesting that one can make deep learning learn to cooperate, but one could have illustrated the game theory eqaly well with other techniques.", "In contrast, the paper \"Coco-Q: Learning in Stochastic Games with Side Payments\" by Sodomka et.", "al is an example where they took a well-motivated game theoretic cooperative solution concept and explored how to implement that with reinforcement learning.", "I would think that generalzing such solution concepts to stochastic games and/or deep learning might be more interesting.", "It should alo be noted that I was asked to review another ICLR submission entitled \"CONSeqENTIALIST CONDITIONAL COOPERATION IN SOCIAL DILEMMAS WITH IMPERFECT INFORMATION \" which amazingly introduced the same \"Pong Player\u2019s Dilemma\" game as in this paper.", "Notice the following suspiciously similar paragraphs from the two papers: From \"MAINTAINING COOPERATION IN COMPLEX SOCIAL DILEMMAS USING DEEP REINFORCEMENT LEARNING\": We alo look at an environment where strategies must be learned from raw pixels.", "We use the method of Tampuu et al (2017) to aler the reward structure of Atari Pong so that whenever an agent scores a point they receive a reward of 1 and the other player receives \u22122, We refer to this game as the Pong Player\u2019s Dilemma (PPD).", "In the PPD the only (jointly) winning move is not to play.", "However, a fully cooperative agent can be exploited by a defector.", "From \"CONSeqENTIALIST CONDITIONAL COOPERATION IN SOCIAL DILEMMAS WITH IMPERFECT INFORMATION\": To demonstrate this we follow the method of Tampuu et al (2017) to construct a version of Atari Pong which makes the game into a socialdilemma.", "In what we cal the Pong Player\u2019s Dilemma (PPD) when an agent scores they gain a reward of 1 but the partner receives a reward of \u22122, Thus, in the PPD the only (jointly) winning move is not to play, but selfish agents are again tempted to defect and try to score points even though this decreases totalsocialreward.", "We see that CCC is a successful, robust, and simple strategy in this game."], "all_annotations": [{"interpretation": 0, "review_id": "B1_TQ-clG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "B1chwjFlz", "review_text": "The authors propose a scheme to generate questions based on some answer sentences, topics and question types. Topics are extracted from questions using similar words in question-answer pairs. It is similar to what we find in some Q&A systems (like lexical answer types in Watson). A sequence classifier is also used to tag the presence of topic words. Question types correspond mostly to salient questions words. LSTMs are used to encode the various inputs and generate the questions. \n\nThe paper is well written and easy to follow. I would expect more explanations why sentence classification and labeling results presented in Table 2 are so low. \n\nExperimental results on question generation are convincing and clearly indicate that the approach is effective to generate relevant and well-structured short questions. \n\nThe main weakness of the paper is the selected set of question types that seems to be a fuzzy combination of answer types and question types (for ex. yes/no). Some questions type can be highly ambiguous; for instance \u201cWhat\u201d might lead to a definition, a quantity, some named entities... Hence I suggest you revise your qt set. \n\nI would also suggest, for your next experiments, that you try to generate questions leading to answers with list of values. ", "gold_annotation": {"interpretation": 1, "review_id": "B1chwjFlz", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 2.5, "tokenized_review_text": ["The authors propose a scheme to generate questions based on some answer sentences, topics and question types.", "Topics are extracted from questions using similar words in question-answer pairs.", "It is similar to what we find in some Q&A systems (like lexicalanswer types in Watson).", "A seqence classifier is alo used to tag the presence of topic words.", "Question types correspond mostly to salent questions words.", "LSTMs are used to encode the various inputs and generate the questions.", "The paper is well written and easy to follow.", "I would expect more explanations why sentence classification and labeling results presented in Table 2 are so low.", "Experimentalresults on question generation are convincing and clearly indicate that the approach is effective to generate relevant and well-structured short questions.", "The main weakness of the paper is the selected set of question types that seems to be a fuzzy combination of answer types and question types (for ex.", "yes/no).", "Some questions type can be highly ambiguous; for instance \u201cWhat\u201d might lead to a definition, a quantity, some named entities...", "Hence I suggest you revise your qt set.", "I would alo suggest, for your next experiments, that you try to generate questions leading to answers with list of vales."], "all_annotations": [{"interpretation": 1, "review_id": "B1chwjFlz", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1fZIQcxM", "review_text": "The paper is not anonymized. In page 2, the first line, the authors revealed [15] is a self-citation and [15] is not anonumized in the reference list.\n\n", "gold_annotation": {"interpretation": 0, "review_id": "B1fZIQcxM", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, "score": 1.0, "tokenized_review_text": ["The paper is not anonymized.", "In page 2, the first line, the authors reveald [15] is a self-citation and [15] is not anonumized in the reference list."], "all_annotations": [{"interpretation": 0, "review_id": "B1fZIQcxM", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "B1g5pBTxz", "review_text": "The article \"Do GANs Learn the Distribution? Some Theory and Empirics\" considers the important problem of quantifying whether the distributions obtained from generative adversarial networks come close to the actual distribution of images. The authors argue that GANs in fact generate the distributions with fairly low support.\n\nThe proposed approach relies on so-called birthday paradox which allows to estimate the number of objects in the support by counting number of matching (or very similar) pairs in the generated sample. This test is expected to experimentally support the previous theoretical analysis by Arora et al. (2017). The further theoretical analysis is also performed showing that for encoder-decoder GAN architectures the distributions with low support can be very close to the optimum of the specific (BiGAN) objective.\n\nThe experimental part of the paper considers the CelebA and CIFAR-10 datasets. We definitely see many very similar images in fairly small sample generated. So, the general claim is supported. However, if you look closely at some pictures, you can see that they are very different though reported as similar. For example, some deer or truck pictures. That's why I would recommend to reevaluate the results visually, which may lead to some change in the number of near duplicates and consequently the final support estimates.\n\nTo sum up, I think that the general idea looks very natural and the results are supportive. On theoretical side, the results seem fair (though I didn't check the proofs) and, being partly based on the previous results of Arora et al. (2017), clearly make a step further.", "gold_annotation": {"interpretation": 1, "review_id": "B1g5pBTxz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 2.5, "tokenized_review_text": ["The article \"Do GANs Learn the Distribution?", "Some Theory and Empirics\" considers the important problem of quantifying whether the distributions obtained from generative adversarialnetworks come close to the actualdistribution of images.", "The authors argue that GANs in fact generate the distributions with fairly low support.", "The proposed approach relies on so-caled birthday paradox which alows to estimate the number of objects in the support by counting number of matching (or very similar) pairs in the generated sample.", "This test is expected to experimentaly support the previous theoreticalanalsis by Arora et al (2017).", "The further theoreticalanalsis is alo performed showing that for encoder-decoder GAN architectures the distributions with low support can be very close to the optimum of the specific (BiGAN) objective.", "The experimentalpart of the paper considers the CelebA and CIFAR-10 datasets.", "We definitely see many very similar images in fairly smal sample generated.", "So, the generalclaim is supported.", "However, if you look closely at some pictures, you can see that they are very different though reported as similar.", "For example, some deer or truck pictures.", "That's why I would recommend to reevalate the results visualy, which may lead to some change in the number of near duplicates and conseqently the finalsupport estimates.", "To sum up, I think that the generalidea looks very naturaland the results are supportive.", "On theoreticalside, the results seem fair (though I didn't check the proofs) and, being partly based on the previous results of Arora et al (2017), clearly make a step further."], "all_annotations": [{"interpretation": 1, "review_id": "B1g5pBTxz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1ja8-9lf", "review_text": "I have read authors' reply.  In response to authors' comprehensive reply and feedback. I upgrade my score to 6.\n\n-----------------------------\n\nThis paper presents a novel approach to calibrate classifiers for out of distribution samples. In additional to the original cross entropy loss, the \u201cconfidence loss\u201d  was proposed to guarantee the out of distribution points have low confidence in the classifier. As out of distribution samples are hard to obtain, authors also propose to use GAN generating \u201cboundary\u201d samples as out of distribution samples. \n\nThe problem setting is new and objective (1) is interesting and reasonable. However, I am not very convinced that objective (3) will generate boundary samples. Suppose that theta is set appropriately so that p_theta (y|x) gives a uniform distribution over labels for out of distribution samples. Because of the construction of U(y), which uniformly assign labels to generated out of distribution samples, the conditional probability p_g (y|x) should always be uniform so p_g (y|x) divided by p_theta (y|x) is almost always 1. The KL divergence in (a) of (3) should always be approximately 0 no matter what samples are generated. \n\nI also have a few other concerns: \n1. There seems to be a related work: \n[1] Perello-Nieto et al., Background Check: A general technique to build more reliable and versatile classifiers, ICDM 2016, \nWhere authors constructed a classifier, which output K+1 labels and the K+1-th label is the \u201cbackground noise\u201d label for this classification problem. Is the method in [1] applicable to this paper\u2019s setting?  Moreover, [1] did not seem to generate any out of distribution samples. \n\n2. I am not so sure that how the actual out of distribution detection was done (did I miss something here?). Authors repeatedly mentioned \u201cmaximum prediction values\u201d, but it was not defined throughout the paper. \nAlgorithm 1. is called \u201cminimization for detection and generating out of distribution (samples)\u201d, but this is only gradient descent, right? I do not see a detection procedure. Given the title also contains \u201cdetecting\u201d, I feel authors should write explicitly how the detection is done in the main body. \n", "gold_annotation": {"interpretation": 0, "review_id": "B1ja8-9lf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["I have read authors' reply.", "In response to authors' comprehensive reply and feedback.", "I upgrade my score to 6, ----------------------------- This paper presents a novel approach to calbrate classifiers for out of distribution samples.", "In additionalto the originalcross entropy loss, the \u201cconfidence loss\u201d was proposed to guarantee the out of distribution points have low confidence in the classifier.", "As out of distribution samples are hard to obtain, authors alo propose to use GAN generating \u201cboundary\u201d samples as out of distribution samples.", "The problem setting is new and objective (1) is interesting and reasonable.", "However, I am not very convinced that objective (3) will generate boundary samples.", "Suppose that theta is set appropriately so that p_theta (y|x) gives a uniform distribution over labels for out of distribution samples.", "Because of the construction of U(y), which uniformly assign labels to generated out of distribution samples, the conditionalprobability p_g (y|x) should alays be uniform so p_g (y|x) divided by p_theta (y|x) is alost alays 1, The KL divergence in (a) of (3) should alays be approximately 0 no matter what samples are generated.", "I alo have a few other concerns: 1, There seems to be a related work: [1] Perello-Nieto et al, Background Check: A generaltechnique to build more reliable and versatile classifiers, ICDM 2016, Where authors constructed a classifier, which output K+1 labels and the K+1-th label is the \u201cbackground noise\u201d label for this classification problem.", "Is the method in [1] applicable to this paper\u2019s setting?", "Moreover, [1] did not seem to generate any out of distribution samples.", "2, I am not so sure that how the actualout of distribution detection was done (did I miss something here?).", "Authors repeatedly mentioned \u201cmaximum prediction vales\u201d, but it was not defined throughout the paper.", "Algorithm 1, is caled \u201cminimization for detection and generating out of distribution (samples)\u201d, but this is only gradient descent, right?", "I do not see a detection procedure.", "Given the title alo contains \u201cdetecting\u201d, I feel authors should write explicitly how the detection is done in the main body."], "all_annotations": [{"interpretation": 0, "review_id": "B1ja8-9lf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1pcOYBlG", "review_text": "Quality\n\nThis paper demonstrates that convolutional and relational neural networks fail to solve visual relation problems by training networks on artificially generated visual relation data. This points at important limitations of current neural network architectures where architectures depend mainly on rote memorization.\n\nClarity\n\nThe rationale in the paper is straightforward. I do think that breakdown of networks by testing on increasing image variability is expected given that there is no reason that networks should generalize well to parts of input space that were never encountered before.\n\nOriginality\n\nWhile others have pointed out limitations before, this paper considers relational networks for the first time.\n\nSignificance \n\nThis work demonstrates failures of relational networks on relational tasks, which is an important message. At the same time, no new architectures are presented to address these limitations.\n\nPros\n\nImportant message about network limitations.\n\nCons\n\nStraightforward testing of network performance on specific visual relation tasks. No new theory development. Conclusions drawn by testing on out of sample data may not be completely valid.", "gold_annotation": {"interpretation": 1, "review_id": "B1pcOYBlG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 1, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 2.5, "tokenized_review_text": ["Qualty This paper demonstrates that convolutionaland relationalneuralnetworks fail to solve visualrelation problems by training networks on artificialy generated visualrelation data.", "This points at important limitations of current neuralnetwork architectures where architectures depend mainly on rote memorization.", "Clarity The rational in the paper is straightforward.", "I do think that breakdown of networks by testing on increasing image variability is expected given that there is no reason that networks should generalze well to parts of input space that were never encountered before.", "Originalty While others have pointed out limitations before, this paper considers relationalnetworks for the first time.", "Significance This work demonstrates failures of relationalnetworks on relationaltasks, which is an important message.", "At the same time, no new architectures are presented to address these limitations.", "Pros Important message about network limitations.", "Cons Straightforward testing of network performance on specific visualrelation tasks.", "No new theory development.", "Conclusions drawn by testing on out of sample data may not be completely vald."], "all_annotations": [{"interpretation": 1, "review_id": "B1pcOYBlG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 1, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "B1qbgHcxz", "review_text": "Summary:\nThis paper proposes a simple recipe to preserve proximity to zero mean for activations in deep neural networks. The proposal is to replace the non-linearity in half of the units in each layer with its \"bipolar\" version -- one that is obtained by flipping the function on both axes.\nThe technique is tested on deep stacks of recurrent layers, and on convolutional networks with depth of 28, showing that improved results over the baseline networks are obtained. \n\nClarity:\nThe paper is easy to read. The plots in Fig. 2 and the appendix are quite helpful in improving presentation. The experimental setups are explained in detail. \n\nQuality and significance:\nThe main idea from this paper is simple and intuitive. However, the experiments to support the idea do not seem to match the motivation of the paper. As stated in the beginning of the paper, the motivation behind having close to zero mean activations is that this is expected to speed up training using gradient descent. However, the presented results focus on the performance on held-out data instead of improvements in training speed. This is especially the case for the RNN experiments.\n\nFor the CIFAR-10 experiment, the training loss curves do show faster initial progress in learning. However, it is unclear that overall training time can be reduced with the help of this technique. To evaluate this speed up effect, the dependence on the choice of learning rate and other hyperparameters should also be considered.\n\nNevertheless, it is interesting to note the result that the proposed approach converts a deep network that does not train into one which does in many cases. The method appears to improve the training for moderately deep convolutional networks without batch normalization (although this is tested on a single dataset), but is not practically useful yet since the regularization benefits of Batch Normalization are also taken away.\n", "gold_annotation": {"interpretation": 1, "review_id": "B1qbgHcxz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary: This paper proposes a simple recipe to preserve proximity to zero mean for activations in deep neuralnetworks.", "The proposalis to replace the non-linearity in hal of the units in each layer with its \"bipolar\" version -- one that is obtained by flipping the function on both axes.", "The technique is tested on deep stacks of recurrent layers, and on convolutionalnetworks with depth of 28, showing that improved results over the baseline networks are obtained.", "Clarity: The paper is easy to read.", "The plots in fig 2 and the appendix are quite helpful in improving presentation.", "The experimentalsetups are explained in detail.", "Qualty and significance: The main idea from this paper is simple and intuitive.", "However, the experiments to support the idea do not seem to match the motivation of the paper.", "As stated in the beginning of the paper, the motivation behind having close to zero mean activations is that this is expected to speed up training using gradient descent.", "However, the presented results focus on the performance on held-out data instead of improvements in training speed.", "This is especialy the case for the RNN experiments.", "For the CIFAR-10 experiment, the training loss curves do show faster initialprogress in learning.", "However, it is unclear that overal training time can be reduced with the help of this technique.", "To evalate this speed up effect, the dependence on the choice of learning rate and other hyperparameters should alo be considered.", "Nevertheless, it is interesting to note the result that the proposed approach converts a deep network that does not train into one which does in many cases.", "The method appears to improve the training for moderately deep convolutionalnetworks without batch normalzation (alhough this is tested on a single dataset), but is not practicaly useful yet since the regularization benefits of Batch Normalzation are alo taken away."], "all_annotations": [{"interpretation": 1, "review_id": "B1qbgHcxz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "B1qhp-qeG", "review_text": "The paper investigates the iterative estimation view on gated recurrent networks (GNN). Authors observe that the average estimation error between a given hidden state and the last hidden state  gradually decreases toward zeros. This suggest that GNN are bias toward an identity mapping and learn to preserve the activation through time.\nGiven this observation, authors then propose RIN, a new RNN parametrization where the hidden to hidden matrix is decomposed as a learnable weight matrix plus the identity matrix.\nAuthors evaluate their RIN on the adding, sequential MNIST and the baby tasks and show that their IRNN outperforms the IRNN and LSTM models.\n\nQuestions:\n- Section 2 suggests that use of the gate  in GNNs encourages to learn an identity mapping. Does the average iteration error behaves differently in case of a tanh-RNN ?\n- It seems from Figure 4 (a) that the average estimation error is higher for RIN than IRNN and LSTM and only decrease toward zero at the very end. What could explain this phenomenon?\n- While the LSTM baseline matches the results of Le et al., later work such as Recurrent Batch Normalization or Unitary Evolution RNN have demonstrated much better performance with a vanilla LSTM on those tasks (outperforming both IRNN and RIN). What could explain this difference in the performances?\n- Unless I am mistaken, Gated Orthogonal Recurrent Units: On Learning to Forget from Jing et al. also reports better performances for the LSTM (and GRU) baselines that outperform RIN on the baby tasks with mean performances of 58.2 and 56.0 for GRU and LSTM respectively?\n\n- Quality/Clarity:\nThe paper is well written and pleasant to read\n\n- Originality:\nLooking at RNN from an iterative refinement point of view seems novel.\n\n- Significance:\nWhile looking at RNN from an iterative estimation is interesting, the experimental part does not really show what are the advantages of the propose RIN. In particular, the LSTM baseline seems to weak compared to other works.", "gold_annotation": {"interpretation": 1, "review_id": "B1qhp-qeG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}, "score": 3.5, "tokenized_review_text": ["The paper investigates the iterative estimation view on gated recurrent networks (GNN).", "Authors observe that the average estimation error between a given hidden state and the last hidden state gradualy decreases toward zeros.", "This suggest that GNN are bias toward an identity mapping and learn to preserve the activation through time.", "Given this observation, authors then propose RIN, a new RNN parametrization where the hidden to hidden matrix is decomposed as a learnable weight matrix plus the identity matrix.", "Authors evalate their RIN on the adding, seqentialMNIST and the baby tasks and show that their IRNN outperforms the IRNN and LSTM models.", "Questions: - secion 2 suggests that use of the gate in GNNs encourages to learn an identity mapping.", "Does the average iteration error behaves differently in case of a tanh-RNN ?", "- It seems from figre 4 (a) that the average estimation error is higher for RIN than IRNN and LSTM and only decrease toward zero at the very end.", "What could explain this phenomenon?", "- While the LSTM baseline matches the results of Le et al, later work such as Recurrent Batch Normalzation or Unitary Evolution RNN have demonstrated much better performance with a vanilla LSTM on those tasks (outperforming both IRNN and RIN).", "What could explain this difference in the performances?", "- Unless I am mistaken, Gated OrthogonalRecurrent Units: On Learning to Forget from Jing et al alo reports better performances for the LSTM (and GRU) baselines that outperform RIN on the baby tasks with mean performances of 58.2 and 56.0 for GRU and LSTM respectively?", "- Qualty/Clarity: The paper is well written and pleasant to read - Originalty: Looking at RNN from an iterative refinement point of view seems novel.", "- Significance: While looking at RNN from an iterative estimation is interesting, the experimentalpart does not realy show what are the advantages of the propose RIN.", "In particular, the LSTM baseline seems to weak compared to other works."], "all_annotations": [{"interpretation": 1, "review_id": "B1qhp-qeG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "B1y7_3YgM", "review_text": "This submission proposes a new seq2sel solution by adopting two new techniques, a sequence-to-set model and column attention mechanism. They show performance improve over existing studies on WikiSQL dataset.\n\nWhile the paper is written clearly, the contributions of the work heavily depends on the WikiSQL dataset. It is not sure if the approach is generally applicable to other sequence-to-sql workloads. Detailed comments are listed below:\n\n1. WikiSQL dataset contains only a small class of SQL queries, with aggregation over single table and various filtering conditions. It does not involve any complex operator in relational database system, e.g., join and groupby. Due to its simple structure, the problem of sequence-to-sql translation over WikiSQL is actually simplified as a parameter selection problem for a fixed template. This greatly limits the generalization of approaches only applicable to WikiSQL. The authors are encouraged to explore other datasets available in the literature.\n\n2. The \"order-matters\" motivation is not very convincing. It is straightforward to employ a global ordering approach to rank the columns and filtering conditions based on certain rules, e.g., alphabetical order. That could ensure the orders in the SQL results are always consistent.\n\n3. The experiments do not fully verify how the approaches bring performance improvements. In the current version, the authors only report superficial accuracy results on final outcomes, without any deep investigation into why and how their approach works. For instance, they could verify how much accuracy improvement is due to the insensitivity to order in filtering expressions.\n\n4. They do not compare against state-of-the-art solution on column and expression selection. While their attention mechanism over the columns could bring performance improvement, they should have included experiments over existing solutions designed for similar purpose. In (Yin, et al., IJCAI 2016), for example, representations over the columns are learned to generate better column selection.\n\nAs a conclusion, I find the submission contains certain interesting ideas but lacks serious research investigations. The quality of the paper could be much enhanced, if the authors deepen their studies on this direction.", "gold_annotation": {"interpretation": 1, "review_id": "B1y7_3YgM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, "score": 3.5, "tokenized_review_text": ["This submission proposes a new seqsel solution by adopting two new techniques, a seqence-to-set model and column attention mechanism.", "They show performance improve over existing studies on WikiSQL dataset.", "While the paper is written clearly, the contributions of the work heavily depends on the WikiSQL dataset.", "It is not sure if the approach is generaly applicable to other seqence-to-sql workloads.", "Detailed comments are listed below: 1, WikiSQL dataset contains only a smal class of SQL queries, with aggregation over single table and various filtering conditions.", "It does not involve any complex operator in relationaldatabase system, e g , join and groupby.", "Due to its simple structure, the problem of seqence-to-sql translation over WikiSQL is actualy simplified as a parameter selection problem for a fixed template.", "This greatly limits the generalzation of approaches only applicable to WikiSQL.", "The authors are encouraged to explore other datasets available in the literature.", "2, The \"order-matters\" motivation is not very convincing.", "It is straightforward to employ a globalordering approach to rank the columns and filtering conditions based on certain rules, e g , alhabeticalorder.", "That could ensure the orders in the SQL results are alays consistent.", "3, The experiments do not fully verify how the approaches bring performance improvements.", "In the current version, the authors only report superficialaccuracy results on finaloutcomes, without any deep investigation into why and how their approach works.", "For instance, they could verify how much accuracy improvement is due to the insensitivity to order in filtering expressions.", "4, They do not compare against state-of-the-art solution on column and expression selection.", "While their attention mechanism over the columns could bring performance improvement, they should have included experiments over existing solutions designed for similar purpose.", "In (Yin, et al, IJCAI 2016), for example, representations over the columns are learned to generate better column selection.", "As a conclusion, I find the submission contains certain interesting ideas but lacks serious research investigations.", "The qualty of the paper could be much enhanced, if the authors deepen their studies on this direction."], "all_annotations": [{"interpretation": 1, "review_id": "B1y7_3YgM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Hy4cMGVlf", "review_text": "The authors build on the work of Tang et al. (2017), who made a minor change to the skip-thought model by decoding only the next sentence, rather than the previous one also. The additional minor change in this paper is to use a CNN, rather than RNN, decoder.\n\nI am sympathetic to the goals of the work, and believe this sort of work should be carried out, but I see the contribution as too minor to constitute a paper at the conference track of a leading international conference such as ICLR. Given the incremental nature of the work, I think this would be a good fit for something like a short paper at *ACL.\n\nI found the more theoretical motivation of the CNN decoder not terribly convincing, and somewhat post-hoc. I feel as though analogous arguments could just as easily be made for an RNN decoder. Ultimately I see these questions - such as CNN vs. RNN for the decoder - as empirical ones.\n\nFinally, the authors have admirably attempted a thorough comparison with existing work, in the related work section, but this section takes up a large chunk of the paper at the end, and again I would have preferred this section to be much shorter and more concise.\n\nSummary: worthwhile empirical goal, but the paper could have been easily written using half as much space.\n", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["The authors build on the work of Tang et al (2017), who made a minor change to the skip-thought model by decoding only the next sentence, rather than the previous one alo.", "The additionalminor change in this paper is to use a CNN, rather than RNN, decoder.", "I am sympathetic to the goal of the work, and believe this sort of work should be carried out, but I see the contribution as too minor to constitute a paper at the conference track of a leading internationalconference such as ICLR.", "Given the incrementalnature of the work, I think this would be a good fit for something like a short paper at *ACL.", "I found the more theoreticalmotivation of the CNN decoder not terribly convincing, and somewhat post-hoc.", "I feel as though analgous arguments could just as easily be made for an RNN decoder.", "Ultimately I see these questions - such as CNN vs. RNN for the decoder - as empiricalones.", "Finaly, the authors have admirably attempted a thorough comparison with existing work, in the related work secion, but this secion takes up a large chunk of the paper at the end, and again I would have preferred this secion to be much shorter and more concise.", "Summary: worthwhile empiricalgoal but the paper could have been easily written using hal as much space."], "all_annotations": [{"interpretation": 1, "review_id": "Hy4cMGVlf", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 0}, {"interpretation": 1, "review_id": "Hy4cMGVlf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 0}, {"interpretation": 1, "review_id": "Hy4cMGVlf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "Hy4cMGVlf", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "yes-agree", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "Hy4tIW5xf", "review_text": "The paper \"IMPROVING SEARCH THROUGH A3C REINFORCEMENT LEARNING BASED CONVERSATIONAL AGENT\" proposes to define an agent to guide users in information retrieval tasks. By proposing refinements of the query, categorizations of the results or some other bookmarking actions, the agent is supposed to help the user in achieving his search. The proposed agent is learned via reinforcement learning. \n\nMy concern with this paper is about the experiments that are only based on simulated agents, as it is the case for learning. While it can be questionable for learning (but we understand why it is difficult to overcome), it is very problematic for the experiments to not have anything that demonstrates the usability of the approach in a real-world scenario. I have serious doubts about the performances of such an artificially learned approach for achieving real-world search tasks. Also, for me the experimental section is not sufficiently detailed, which lead to not reproducible results. Moreover, authors should have considered baselines (only the two proposed agents are compared which is clearly not sufficient). \n\nAlso, both models have some issues from my point of view. First, the Q-learning methods looks very complex: how could we expect to get an accurate model with 10^7 states ? No generalization about the situations is done here, examples of trajectories have to be collected for each individual considered state, which looks very huge (especially if we think about the number of possible trajectories in such an MDP). The second model is able to generalize from similar situations thanks to the neural architecture that is proposed. However, I have some concerns about it: why keeping the history of actions in the inputs since it is captured by the LSTM cell ? It is a redondant information that might disturb the process. Secondly, the proposed loss looks very heuristic for me, it is difficult to understand what is really optimized here. Particularly, the loss entropy function looks strange to me. Is it classical ? Are there some references of such a method to maintain some exploration ability. I understand the need of exploration, but including it in the loss function reduces the interpretability of the objective (wouldn't it be preferable to use a more classical loss but with an epsilon greedy policy?).\n\n\nOther remarks: \n   - In the begining of \"varying memory capacity\" section, what is \"100, 150 and 250\" ? Time steps ? What is the unit ? Seconds ?   \n   - I did not understand the \"Capturing seach context at local and global level\" at all\n   - In the loss entropy formula, the two negation signs could be removed\n  \n", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The paper \"IMPROVING SEARCH THROUGH A3C REINFORCEMENT LEARNING BASED CONVERSATIONAL AGENT\" proposes to define an agent to guide users in information retrievaltasks.", "By proposing refinements of the query, categorizations of the results or some other bookmarking actions, the agent is supposed to help the user in achieving his search.", "The proposed agent is learned via reinforcement learning.", "My concern with this paper is about the experiments that are only based on simulated agents, as it is the case for learning.", "While it can be questionable for learning (but we understand why it is difficult to overcome), it is very problematic for the experiments to not have anything that demonstrates the usability of the approach in a realworld scenario.", "I have serious doubts about the performances of such an artificialy learned approach for achieving realworld search tasks.", "Also, for me the experimentalsecion is not sufficiently detailed, which lead to not reproducible results.", "Moreover, authors should have considered baselines (only the two proposed agents are compared which is clearly not sufficient).", "Also, both models have some issues from my point of view.", "First, the Q-learning methods looks very complex: how could we expect to get an accurate model with 10^7 states ?", "No generalzation about the situations is done here, examples of trajectories have to be collected for each individualconsidered state, which looks very huge (especialy if we think about the number of possible trajectories in such an MDP).", "The secnd model is able to generalze from similar situations thanks to the neuralarchitecture that is proposed.", "However, I have some concerns about it: why keeping the history of actions in the inputs since it is captured by the LSTM cell ?", "It is a redondant information that might disturb the process.", "secndly, the proposed loss looks very heuristic for me, it is difficult to understand what is realy optimized here.", "Particularly, the loss entropy function looks strange to me.", "Is it classical?", "Are there some references of such a method to maintain some exploration ability.", "I understand the need of exploration, but including it in the loss function reduces the interpretability of the objective (wouldn't it be preferable to use a more classicalloss but with an epsilon greedy policy?).", "Other remarks: - In the begining of \"varying memory capacity\" secion, what is \"100, 150 and 250\" ?", "Time steps ?", "What is the unit ?", "secnds ?", "- I did not understand the \"Capturing seach context at localand globallevel\" at al - In the loss entropy formula, the two negation signs could be removed"], "all_annotations": [{"interpretation": 1, "review_id": "Hy4tIW5xf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hy4tIW5xf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "Hy4tIW5xf", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hy4tIW5xf", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Hy7Gjh9eM", "review_text": "The authors proposed to supplement adversarial training with an additional regularization that forces the embeddings of clean and adversarial inputs to be similar. The authors demonstrate on MNIST and CIFAR that the added regularization leads to more robustness to various kinds of attacks. The authors further propose to enhance the network with cascaded adversarial training, that is, learning against iteratively generated adversarial inputs, and showed improved performance against harder attacks. \n\nThe idea proposed is fairly straight-forward. Despite being a simple approach, the experimental results are quite promising.  The analysis on the gradient correlation coefficient and label leaking phenomenon provide some interesting insights.  \n\nAs pointed out in section 4.2, increasing the regularization coefficient leads to degenerated embeddings. Have the authors consider distance metrics that are less sensitive to the magnitude of the embeddings, for example, normalizing the inputs before sending it to the bidirectional or pivot loss, or use cosine distance etc.?\n\nTable 4 and 5 seem to suggest that cascaded adversarial learning have more negative impact on test set with one-step attacks than clean test set, which is a bit counter-intuitive. Do the authors have any insight on this? \n\nComments:\n1. The writing of the paper could be improved. For example, \"Transferability analysis\" in section 1 is barely understandable;\n2. Arrow in Figure 3 are not quite readable;\n3. The paper is over 11 pages. The authors might want to consider shrink it down the recommended length. ", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The authors proposed to supplement adversarialtraining with an additionalregularization that forces the embeddings of clean and adversarialinputs to be similar.", "The authors demonstrate on MNIST and CIFAR that the added regularization leads to more robustness to various kinds of attacks.", "The authors further propose to enhance the network with cascaded adversarialtraining, that is, learning against iteratively generated adversarialinputs, and showed improved performance against harder attacks.", "The idea proposed is fairly straight-forward.", "Despite being a simple approach, the experimentalresults are quite promising.", "The analsis on the gradient correlation coefficient and label leaking phenomenon provide some interesting insights.", "As pointed out in secion 4 2, increasing the regularization coefficient leads to degenerated embeddings.", "Have the authors consider distance metrics that are less sensitive to the magnitude of the embeddings, for example, normalzing the inputs before sending it to the bidirectionalor pivot loss, or use cosine distance etc?", "Table 4 and 5 seem to suggest that cascaded adversariallearning have more negative impact on test set with one-step attacks than clean test set, which is a bit counter-intuitive.", "Do the authors have any insight on this?", "Comments: 1, The writing of the paper could be improved.", "For example, \"Transferability analsis\" in secion 1 is barely understandable; 2, Arrow in figre 3 are not quite readable; 3, The paper is over 11 pages.", "The authors might want to consider shrink it down the recommended length."], "all_annotations": [{"interpretation": 1, "review_id": "Hy7Gjh9eM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hy7Gjh9eM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "Hy7Gjh9eM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hy7Gjh9eM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "HyJlQlQWf", "review_text": "The paper considers multi-task setting of machine learning. The first contribution of the paper is a novel PAC-Bayesian risk bound. This risk bound serves as an objective function for multi-task machine learning. A second contribution is an algorithm, called LAP, for minimizing a simplified version of this objective function. LAP algorithm uses several training tasks to learn a prior distribution P over hypothesis space. This prior distribution P is then used to find a posterior distribution Q that minimizes the same objective function over the test task. The third contribution is an empirical evaluation of LAP over toy dataset of two clusters and over MNIST.\n\nWhile the paper has the title of \"life-long learning\", the authors admit that all experiments are in multi-task setting, where\nthe training is done over all tasks simultaneously. The novel risk bound and LAP algorithm can definitely be applied to life-long setting, where training tasks are available sequentially. But since there is no empirical evaluation in this setting, I suggest to adjust the title of the paper. \n \nThe novel risk bound of the paper is an extension of the bound from [Pentina & Lampert, ICML 2014]. The extension seems to be quite significant. Unlike the bound of [Pentina & Lampert, ICML 2014], the new bound allows to re-use many different PAC-Bayesian complexity terms that were published previously. \n\nI liked risk bound and optimization sections of the paper. But I was less convinced by the empirical experiments. Since \nthe paper improves the risk bound of [Pentina & Lampert, ICML 2014], I expected to see an empirical comparison of LAP and optimization  algorithm from the latter paper. To make such comparison fair, both optimization algorithms should use the same base algorithm, e.g. ridge regression, as in [Pentina & Lampert, ICML 2014]. Also I suggest to use the datasets from the latter paper.  \n\nThe experiment with multi-task learning over MNIST dataset looks interesting, but it is still a toy experiment. This experiment  will be more convincing with more sophisticated datasets (CIFAR-10, ImageNet) and architectures (e.g. Inception-V4, ResNet). \n\nMinor remarks:\nSection 6, line 4: \"Combing\" -> \"Combining\"\nPage 14, first equation: There should be \"=\" before the second expectation.", "gold_annotation": null, "score": 3.5, "tokenized_review_text": ["The paper considers multi-task setting of machine learning.", "The first contribution of the paper is a novel PAC-Bayesian risk bound.", "This risk bound serves as an objective function for multi-task machine learning.", "A secnd contribution is an alorithm, caled LAP, for minimizing a simplified version of this objective function.", "LAP alorithm uses severaltraining tasks to learn a prior distribution P over hypothesis space.", "This prior distribution P is then used to find a posterior distribution Q that minimizes the same objective function over the test task.", "The third contribution is an empiricalevalation of LAP over toy dataset of two clusters and over MNIST.", "While the paper has the title of \"life-long learning\", the authors admit that al experiments are in multi-task setting, where the training is done over al tasks simultaneously.", "The novel risk bound and LAP alorithm can definitely be applied to life-long setting, where training tasks are available seqentialy.", "But since there is no empiricalevalation in this setting, I suggest to adjust the title of the paper.", "The novel risk bound of the paper is an extension of the bound from [Pentina & Lampert, ICML 2014].", "The extension seems to be quite significant.", "Unlike the bound of [Pentina & Lampert, ICML 2014], the new bound alows to re-use many different PAC-Bayesian complexity terms that were published previously.", "I liked risk bound and optimization secions of the paper.", "But I was less convinced by the empiricalexperiments.", "Since the paper improves the risk bound of [Pentina & Lampert, ICML 2014], I expected to see an empiricalcomparison of LAP and optimization alorithm from the latter paper.", "To make such comparison fair, both optimization alorithms should use the same base alorithm, e g ridge regression, as in [Pentina & Lampert, ICML 2014].", "Also I suggest to use the datasets from the latter paper.", "The experiment with multi-task learning over MNIST dataset looks interesting, but it is still a toy experiment.", "This experiment will be more convincing with more sophisticated datasets (CIFAR-10, ImageNet) and architectures (e g Inception-V4, ResNet).", "Minor remarks: secion 6, line 4: \"Combing\" -> \"Combining\" Page 14, first eqation: There should be \"=\" before the secnd expectation."], "all_annotations": [{"interpretation": 0, "review_id": "HyJlQlQWf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "HyJlQlQWf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "HyJlQlQWf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "HyJlQlQWf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "HyKlaaFxf", "review_text": "Overall, the paper is well-written and the proposed model is quite intuitive. Specifically, the idea is to represent entailment as a product of continuous functions over possible worlds. Specifically, the idea is to generate possible worlds, and compute the functions that encode entailment in those worlds. The functions themselves are designed as tree neural networks to take advantage of logical structure. Several different encoding benchmarks of the entailment task are designed to compare against the performance of the proposed model, using a newly created dataset. The results seem very impressive with > 99% accuracy on tests sets.\n\nOne weakness with the paper was that it was only tested on 1 dataset. Also, should some form of cross-validation be applied to smooth out variance in the evaluation results. I am not sure if there are standard \"shared\" datasets for this task, which would make the results much stronger.\nAlso how about the tradeoff, i.e., does training time significantly increase when we \"imagine\" more worlds. Also, in general, a discussion on the efficiency of training the proposed model as compared to TreeNN would be helpful.\nThe size of the world vectors, I would believe is quite important, so maybe a more detailed analysis on how this was chosen is important to replicate the results.\nThis problem, I think, is quite related to model counting. There has been a lot of work on model counting. a discussion on how this relates to those lines of work would be interesting.\n\n\nAfter revision\n\nI think the authors have improved the experiments substantially.", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["Overal, the paper is well-written and the proposed model is quite intuitive.", "Specificaly, the idea is to represent entailment as a product of continuous functions over possible worlds.", "Specificaly, the idea is to generate possible worlds, and compute the functions that encode entailment in those worlds.", "The functions themselves are designed as tree neuralnetworks to take advantage of logicalstructure.", "Severaldifferent encoding benchmarks of the entailment task are designed to compare against the performance of the proposed model, using a newly created dataset.", "The results seem very impressive with > 99% accuracy on tests sets.", "One weakness with the paper was that it was only tested on 1 dataset.", "Also, should some form of cross-valdation be applied to smooth out variance in the evalation results.", "I am not sure if there are standard \"shared\" datasets for this task, which would make the results much stronger.", "Also how about the tradeoff, i e , does training time significantly increase when we \"imagine\" more worlds.", "Also, in general a discussion on the efficiency of training the proposed model as compared to TreeNN would be helpful.", "The size of the world vectors, I would believe is quite important, so maybe a more detailed analsis on how this was chosen is important to replicate the results.", "This problem, I think, is quite related to model counting.", "There has been a lot of work on model counting.", "a discussion on how this relates to those lines of work would be interesting.", "After revision I think the authors have improved the experiments substantialy."], "all_annotations": [{"interpretation": 0, "review_id": "HyKlaaFxf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HyKlaaFxf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno2", "evidence": 1, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "HyKlaaFxf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HyKlaaFxf", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HyM5JWhgG", "review_text": "This paper discusses an application of survival analysis  in social networks.\n\nWhile the application area seems to be pertinent, the statistics as presented in this paper are suboptimal at best. There is no useful statistical setup described (what is random? etc etc), the interplay between censoring and end-of-life is left rather fuzzy, and mentioned clustering approaches are extensively studied in the statistical literature in so-called frailty analysis. The setting is also covered in statistics in the extensive literature on repeated measurements  and even time-series analysis. It's up to the authors discuss similarities and differences of results of the present approach and those areas.\n\nThe numerical result is not assessing the different design decisions of the approach (why use a Kuyper loss?) in this empirical paper.\n\n", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["This paper discusses an application of survivalanalsis in socialnetworks.", "While the application area seems to be pertinent, the statistics as presented in this paper are suboptimalat best.", "There is no useful statisticalsetup described (what is random?", "etcetc, the interplay between censoring and end-of-life is left rather fuzzy, and mentioned clustering approaches are extensively studied in the statisticalliterature in so-caled frailty analsis.", "The setting is alo covered in statistics in the extensive literature on repeated measurements and even time-series analsis.", "It's up to the authors discuss similarities and differences of results of the present approach and those areas.", "The numericalresult is not assessing the different design decisions of the approach (why use a Kuyper loss?)", "in this empiricalpaper."], "all_annotations": [{"interpretation": 1, "review_id": "HyM5JWhgG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HyM5JWhgG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "HyM5JWhgG", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "HyM5JWhgG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "yes-agree", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HyciX9dxM", "review_text": "\n1) Summary\nThis paper proposes a recurrent neural network (RNN) training formulation for encouraging RNN the hidden representations to contain information useful for predicting future timesteps reliably. The authors propose to train a forward and backward RNN in parallel. The forward RNN predicts forward in time and the backward RNN predicts backwards in time. While the forward RNN is trained to predict the next timestep, its hidden representation is forced to be similar to the representation of the backward RNN in the same optimization step. In experiments, it is shown that the proposed method improves training speed in terms of number of training iterations, achieves 0.8 CIDEr points improvement over baselines using the proposed training, and also achieves improved performance for the task of speech recognition.\n\n\n2) Pros:\n+ Novel idea that makes sense for learning a more robust representation for predicting the future and prevent only local temporal correlations learned.\n+ Informative analysis for clearly identifying the strengths of the proposed method and where it is failing to perform as expected.\n+ Improved performance in speech recognition task.\n+ The idea is clearly explained and well motivated.\n\n\n3) Cons:\nImage captioning experiment:\nIn the experimental section, there is an image captioning result in which the proposed method is used on top of two baselines. This experiment shows improvement over such baselines, however, the performance is still worse compared against baselines such as Lu et al, 2017 and Yao et al, 2016. It would be optimal if the authors can use their training method on such baselines and show improved performance, or explain why this cannot be done.\n\n\nUnconditioned generation experiments:\nIn these experiments, sequential pixel-by-pixel MNIST generation is performed in which the proposed method did not help. Because of this, two conditioned set ups are performed: 1) 25% of pixels are given before generation, and 2) 75% of pixels are given before generation. The proposed method performs similar to the baseline in the 25% case, and better than the baseline in the 75% case. For completeness, and to come to a stronger conclusion on how much uncertainty really affects the proposed method, this experiment needs a case in which 50% of the pixels are given. Observing 25% of the pixels gives almost no information about the identity of the digit and it makes sense that it\u2019s hard to encode the future, however, 50% of the pixels give a good idea of what the digit identity is. If the authors believe that the 50% case is not necessary, please feel free to explain why.\n\n\nAdditional comments:\nThe method is shown to converge faster compared to the baselines, however, it is possible that the baseline may finish training faster (the authors do acknowledge the additional computation needed in the backward RNN).\nIt would be informative for the research community to see the relationship of training time (how long it takes in hours) versus how fast it learns (iterations taken to learn).\n\nExperiments on RL planning tasks would be interesting to see (Maybe on a simple/predictable environment).\n\n\n4) Conclusion\nThe paper proposes a method for training RNN architectures to better model the future in its internal state supervised by another RNN modeling the future in reverse. Correctly modeling the future is very important for tasks that require making decisions of what to do in the future based on what we predict from the past. The proposed method presents a possible way of better modeling the future, however, some the results do not clearly back up the claim yet. The given score will improve if the authors are able to address the stated issues.\n\n\nPOST REBUTTAL RESPONSE:\nThe authors have addressed the comments on the MNIST experiments and show better results, however, as far as I can see, they did not address my concern about the comparisons on the image captioning experiment. In the image captioning experiment the authors choose two networks (Show & Tell and Soft attention) that they improve using the proposed method that end up performing similar to the second best baseline (Yao et al. 2016) based on Table 3 and their response. I requested for the authors to use their method on the best performing baselines (i.e. Yao et al. 2016 or Liu et al. 2017) or explain why this cannot be done (maybe my request was not clearly stated). Applying the proposed method on the strong baselines would highlight the author's claims more strongly than just applying on the average performing chosen baselines. This request was not addressed and instead the authors just improved the average performing baselines in Table 3 to meet the best baselines. Given, that the authors were able to improve the results in the sequential MNIST and improve the average baselines, my rating improves one point. However, I still have concerns about this method not being shown to improve the best methods presented in Table 3 which would give a more solid result. My rating changes to marginally above threshold for acceptance.", "gold_annotation": null, "score": 4.0, "tokenized_review_text": [" 1) Summary This paper proposes a recurrent neuralnetwork (RNN) training formulation for encouraging RNN the hidden representations to contain information useful for predicting future timesteps reliably.", "The authors propose to train a forward and backward RNN in paralel.", "The forward RNN predicts forward in time and the backward RNN predicts backwards in time.", "While the forward RNN is trained to predict the next timestep, its hidden representation is forced to be similar to the representation of the backward RNN in the same optimization step.", "In experiments, it is shown that the proposed method improves training speed in terms of number of training iterations, achieves 0 8 CIDEr points improvement over baselines using the proposed training, and alo achieves improved performance for the task of speech recognition.", "2) Pros: + Novel idea that makes sense for learning a more robust representation for predicting the future and prevent only localtemporalcorrelations learned.", "+ Informative analsis for clearly identifying the strengths of the proposed method and where it is failing to perform as expected.", "+ Improved performance in speech recognition task.", "+ The idea is clearly explained and well motivated.", "3) Cons: Image captioning experiment: In the experimentalsecion, there is an image captioning result in which the proposed method is used on top of two baselines.", "This experiment shows improvement over such baselines, however, the performance is still worse compared against baselines such as Lu et al 2017 and Yao et al 2016, It would be optimalif the authors can use their training method on such baselines and show improved performance, or explain why this cannot be done.", "Unconditioned generation experiments: In these experiments, seqentialpixel-by-pixel MNIST generation is performed in which the proposed method did not help.", "Because of this, two conditioned set ups are performed: 1) 25% of pixels are given before generation, and 2) 75% of pixels are given before generation.", "The proposed method performs similar to the baseline in the 25% case, and better than the baseline in the 75% case.", "For completeness, and to come to a stronger conclusion on how much uncertainty realy affects the proposed method, this experiment needs a case in which 50% of the pixels are given.", "Observing 25% of the pixels gives alost no information about the identity of the digit and it makes sense that it\u2019s hard to encode the future, however, 50% of the pixels give a good idea of what the digit identity is.", "If the authors believe that the 50% case is not necessary, please feel free to explain why.", "Additionalcomments: The method is shown to converge faster compared to the baselines, however, it is possible that the baseline may finish training faster (the authors do acknowledge the additionalcomputation needed in the backward RNN).", "It would be informative for the research community to see the relationship of training time (how long it takes in hours) versus how fast it learns (iterations taken to learn).", "Experiments on RL planning tasks would be interesting to see (Maybe on a simple/predictable environment).", "4) Conclusion The paper proposes a method for training RNN architectures to better model the future in its internalstate supervised by another RNN modeling the future in reverse.", "Correctly modeling the future is very important for tasks that reqire making decisions of what to do in the future based on what we predict from the past.", "The proposed method presents a possible way of better modeling the future, however, some the results do not clearly back up the claim yet.", "The given score will improve if the authors are able to address the stated issues.", "POST REBUTTAL RESPONSE: The authors have addressed the comments on the MNIST experiments and show better results, however, as far as I can see, they did not address my concern about the comparisons on the image captioning experiment.", "In the image captioning experiment the authors choose two networks (Show & Tell and Soft attention) that they improve using the proposed method that end up performing similar to the secnd best baseline (Yao et al 2016) based on Table 3 and their response.", "I reqested for the authors to use their method on the best performing baselines (i e Yao et al 2016 or Liu et al 2017) or explain why this cannot be done (maybe my reqest was not clearly stated).", "Applying the proposed method on the strong baselines would highlight the author's claims more strongly than just applying on the average performing chosen baselines.", "This reqest was not addressed and instead the authors just improved the average performing baselines in Table 3 to meet the best baselines.", "Given, that the authors were able to improve the results in the seqentialMNIST and improve the average baselines, my rating improves one point.", "However, I still have concerns about this method not being shown to improve the best methods presented in Table 3 which would give a more solid result.", "My rating changes to marginaly above threshold for acceptance."], "all_annotations": [{"interpretation": 0, "review_id": "HyciX9dxM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HyciX9dxM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "HyciX9dxM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HyciX9dxM", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HydgKG5ez", "review_text": "The paper proposes a CNN-based based approach for speech processing using raw waveforms as input. An analysis of convolution and pooling layers applied on waveforms is first presented. An architecture called SimpleNet is then presented and evaluated on two speech tasks: emotion recognition and gender classification. \n\nThis paper propose a theoretical analysis of convolution and pooling layers to motivate the SimpleNet architecture. To my understanding, the analysis is flawed (see comments below). The SimpleNet approach is interesting but not sufficiently backed with experimental results. The network analysis is minimal and provides almost no insights. I therefore recommend to reject the paper. \n\nDetailed comments:\n\nSection 1:\n\n* \u201cTherefore, it remains unknown what actual features CNNs learn from waveform\u201d. This is not true, several works on speech recognition have shown that a convolution layer taking raw speech as input can be seen as a bank of learned filters. For instance in the context of speech recognition, [9] showed that the filters learn phoneme-specific responses, [10] showed that the learned filters are close to Mel filter banks and [7] showed that the learned filters are related to MRASTA features and Gabor filters. The authors should discuss these previous works in the paper.\n\nSection 2:\n\n* Section 2.1 seems unnecessary, I think it\u2019s safe to assume that the Shannon-Nyquist theorem and the definition of convolution are known by the reader.\n\n* Section 2.2.2 & 2.2.3: I don't follow the justification that stacking convolutions are not needed: the example provided is correct if two convolutions are directly stacked without non-linearity, but the conclusion does not hold with a non-linearity and/or a pooling layer between the convolutions: two stacked convolutions with non-linearities are not equivalent to a single convolution. To my understanding, the same problem is present for the pooling layer: the presented conclusion that pooling introduces aliasing is only valid for two directly stacked pooling layers and is not correct for stacked blocks of convolution/pooling/non-linearity.\n\n* Section 2.2.5: The ReLU can be seen as a half-wave rectifier if it is applied directly to the waveform. However, it is usually not the case as it is applied on the output of the convolution and/or pooling layers. Therefore I don\u2019t see the point of this section. \n\n* Section 2.2.6: In this section, the authors discuss the differences between spectrogram-based and waveforms-based approaches, assuming that spectrogram-based approach have fixed filters. But spectrogram can also be used as input to CNNs (i.e. using learned filters) for instance in speech recognition [1] or emotion recognition [11]. Thus the comparison could be more interesting if it was between spectrogram-based and raw waveform-based approaches when the filters are learned in both cases.  \n\nSection 3:\n\n* Figure 4 is very interesting, and is in my opinion a stronger motivation for SimpleNet that the analysis presented in Section 2.\n\n* Using known filterbanks such as Mel or Gammatone filters as initialization point for the convolution layer is not novel and has been already investigated in [7,8,10] in the context of speech recognition. \n\nSection 4:\n\n* On emotion recognition, the results show that the proposed approach is slightly better, but there is some issues: the average recall metric is usually used for this task due to class imbalance (see [1] for instance). Could the authors provide results with this metric ? Also IEMOCAP is a well-used corpus for this task, could the authors provide some baselines performance for comparison (e.g. [11]) ? \n\n* For gender classification, there is no gain from SimpleNet compared to the baselines. The authors also mention that some utterances have overlapping speech. These utterances are easy to find from the annotations provided with the corpus, so it should be easy to remove them for the train and test set. Overall, in the current form, the results are not convincing.\n\n* Section 4.3: The analysis is minimal: it shows that filters changed after training (as already presented in Figure 4). I don't follow completely the argument that the filters should focus on low frequency. It is more informative, but one could expect that the filters will specialized, thus some of them will focus on high frequencies, to model the high frequency events such as consonants or unvoiced event. \nIt could be very interesting to relate the learned filters to the labels: are some filters learned to model specific emotions ? For gender classification, are some filters focusing on the average pitch frequency of male and female speaker ?\n\n* Finally, it would be nice to see if the claims in Section 2 about the fact that only one convolution layer is needed and that stacking pooling layers can hurt the performance are verified experimentally: for instance, experiments with more than one pair of convolution/pooling could be presented.\n\nMinor comments:\n\n* More references for raw waveforms-based approach for speech recognition should be added [3,4,6,7,8,9] in the introduction.\n\n* I don\u2019t understand the first sentence of the paper: \u201cIn the field of speech and audio processing, due to the lack of tools to directly process high dimensional data \u2026\u201d. Is this also true for any pattern recognition fields ?  \n\n* For the MFCCs reference in 2.2.2, the authors should cite [12].\n\n* Figure 6: Only half of the spectrum should be presented.\n\nReferences: \n\n[1] H. Lee, P. Pham, Y. Largman, and A. Y. Ng. Unsupervised feature learning for audio classification using convolutional deep belief networks. In Advances in Neural Information Processing Systems 22, pages 1096\u20131104, 2009.\n\n[2] Schuller, Bj\u00f6rn, Stefan Steidl, and Anton Batliner. \"The interspeech 2009 emotion challenge.\" Tenth Annual Conference of the International Speech Communication Association. 2009.\n\n[3] N. Jaitly, G. Hinton, Learning a better representation of speech sound waves using restricted Boltzmann machines, in: Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2011, pp. 5884\u20135887.\n\n[4] D. Palaz, R. Collobert, and M. Magimai.-Doss. Estimating Phoneme Class Conditional Probabilities from Raw Speech Signal using Convolutional Neural Networks, INTERSPEECH 2013, pages 1766\u20131770.\n\n[5] Van den Oord, Aaron, Sander Dieleman, and Benjamin Schrauwen. \"Deep content-based music recommendation.\" Advances in neural information processing systems. 2013.\n\n[6] Z.Tuske, P.Golik, R.Schluter, H.Ney, Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR,\nin: Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), Singapore, 2014, pp. 890\u2013894.\n\n[7] P. Golik, Z. Tuske, R. Schlu \u0308ter, H. Ney, Convolutional Neural Networks for Acoustic Modeling of Raw Time Signal in LVCSR, in: Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015, pp. 26\u201330.\n\n[8] Yedid Hoshen and Ron Weiss and Kevin W Wilson, Speech Acoustic Modeling from Raw Multichannel Waveforms, International Conference on Acoustics, Speech, and Signal Processing, 2015.\n\n[9] D. Palaz, M. Magimai-Doss, and R. Collobert. Analysis of CNN-based Speech Recognition System using Raw Speech as Input, INTERSPEECH 2015, pages 11\u201315.\n\n[10] T. N. Sainath, R. J. Weiss, A. Senior, K. W. Wilson, and O. Vinyals. Learning the Speech Front-end With Raw Waveform CLDNNs. Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015.\n\n[11] Satt, Aharon & Rozenberg, Shai & Hoory, Ron. (2017). Efficient Emotion Recognition from Speech Using Deep Learning on Spectrograms. 1089-1093. Interspeech 2017.\n\n[12] S. Davis and P. Mermelstein. Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences. IEEE Transactions on Acoustics, Speech and Signal Processing, 28(4):357\u2013366, 1980.", "gold_annotation": null, "score": 5.0, "tokenized_review_text": ["The paper proposes a CNN-based based approach for speech processing using raw waveforms as input.", "An analsis of convolution and pooling layers applied on waveforms is first presented.", "An architecture caled SimpleNet is then presented and evalated on two speech tasks: emotion recognition and gender classification.", "This paper propose a theoreticalanalsis of convolution and pooling layers to motivate the SimpleNet architecture.", "To my understanding, the analsis is flawed (see comments below).", "The SimpleNet approach is interesting but not sufficiently backed with experimentalresults.", "The network analsis is minimaland provides alost no insights.", "I therefore recommend to reject the paper.", "Detailed comments: secion 1: * \u201cTherefore, it remains unknown what actualfeatures CNNs learn from waveform\u201d.", "This is not true, severalworks on speech recognition have shown that a convolution layer taking raw speech as input can be seen as a bank of learned filters.", "For instance in the context of speech recognition, [9] showed that the filters learn phoneme-specific responses, [10] showed that the learned filters are close to Mel filter banks and [7] showed that the learned filters are related to MRASTA features and Gabor filters.", "The authors should discuss these previous works in the paper.", "secion 2: * secion 2 1 seems unnecessary, I think it\u2019s safe to assume that the Shannon-Nyquist theorem and the definition of convolution are known by the reader.", "* secion 2 2 2 & 2 2 3: I don't follow the justification that stacking convolutions are not needed: the example provided is correct if two convolutions are directly stacked without non-linearity, but the conclusion does not hold with a non-linearity and/or a pooling layer between the convolutions: two stacked convolutions with non-linearities are not eqivalnt to a single convolution.", "To my understanding, the same problem is present for the pooling layer: the presented conclusion that pooling introduces alasing is only vald for two directly stacked pooling layers and is not correct for stacked blocks of convolution/pooling/non-linearity.", "* secion 2 2 5: The ReLU can be seen as a hal-wave rectifier if it is applied directly to the waveform.", "However, it is usualy not the case as it is applied on the output of the convolution and/or pooling layers.", "Therefore I don\u2019t see the point of this secion.", "* secion 2 2 6: In this secion, the authors discuss the differences between spectrogram-based and waveforms-based approaches, assuming that spectrogram-based approach have fixed filters.", "But spectrogram can alo be used as input to CNNs (i e using learned filters) for instance in speech recognition [1] or emotion recognition [11].", "Thus the comparison could be more interesting if it was between spectrogram-based and raw waveform-based approaches when the filters are learned in both cases.", "secion 3: * figre 4 is very interesting, and is in my opinion a stronger motivation for SimpleNet that the analsis presented in secion 2, * Using known filterbanks such as Mel or Gammatone filters as initialzation point for the convolution layer is not novel and has been aleady investigated in [7,8,10] in the context of speech recognition.", "secion 4: * On emotion recognition, the results show that the proposed approach is slightly better, but there is some issues: the average recal metric is usualy used for this task due to class imbalnce (see [1] for instance).", "Could the authors provide results with this metric ?", "Also IEMOCAP is a well-used corpus for this task, could the authors provide some baselines performance for comparison (e g [11]) ?", "* For gender classification, there is no gain from SimpleNet compared to the baselines.", "The authors alo mention that some utterances have overlapping speech.", "These utterances are easy to find from the annotations provided with the corpus, so it should be easy to remove them for the train and test set.", "Overal, in the current form, the results are not convincing.", "* secion 4 3: The analsis is minimal it shows that filters changed after training (as aleady presented in figre 4).", "I don't follow completely the argument that the filters should focus on low freqency.", "It is more informative, but one could expect that the filters will specialzed, thus some of them will focus on high freqencies, to model the high freqency events such as consonants or unvoiced event.", "It could be very interesting to relate the learned filters to the labels: are some filters learned to model specific emotions ?", "For gender classification, are some filters focusing on the average pitch freqency of mal and femal speaker ?", "* Finaly, it would be nice to see if the claims in secion 2 about the fact that only one convolution layer is needed and that stacking pooling layers can hurt the performance are verified experimentaly: for instance, experiments with more than one pair of convolution/pooling could be presented.", "Minor comments: * More references for raw waveforms-based approach for speech recognition should be added [3,4,6,7,8,9] in the introduction.", "* I don\u2019t understand the first sentence of the paper: \u201cIn the field of speech and audio processing, due to the lack of tools to directly process high dimensionaldata \u2026\u201d.", "Is this alo true for any pattern recognition fields ?", "* For the MFCCs reference in 2 2 2, the authors should cite [12].", "* figre 6: Only hal of the spectrum should be presented.", "References: [1] H Lee, P Pham, Y Largman, and A Y Ng.", "Unsupervised feature learning for audio classification using convolutionaldeep belief networks.", "In Advances in NeuralInformation Processing Systems 22, pages 1096\u20131104, 2009, [2] Schuller, Bj\u00f6rn, Stefan Steidl, and Anton Batliner.", "\"The interspeech 2009 emotion chalenge.\"", "Tenth AnnualConference of the InternationalSpeech Communication Association.", "2009, [3] N Jaitly, G Hinton, Learning a better representation of speech sound waves using restricted Boltzmann machines, in: Proceedings of the IEEE InternationalConference on Acoustics, Speech and SignalProcessing (ICASSP), 2011, pp.", "5884\u20135887, [4] D Palz, R Collobert, and M Magimai.-Doss.", "Estimating Phoneme Class ConditionalProbabilities from Raw Speech Signalusing ConvolutionalNeuralNetworks, INTERSPEECH 2013, pages 1766\u20131770, [5] Van den Oord, Aaron, Sander Dieleman, and Benjamin Schrauwen.", "\"Deep content-based music recommendation.\"", "Advances in neuralinformation processing systems.", "2013, [6] Z Tuske, P Golik, R Schluter, H Ney, Acoustic Modeling with Deep NeuralNetworks Using Raw Time Signalfor LVCSR, in: Proceedings of the AnnualConference of the InternationalSpeech Communication Association (INTERSPEECH), Singapore, 2014, pp.", "890\u2013894, [7] P Golik, Z Tuske, R Schlu \u0308ter, H Ney, ConvolutionalNeuralNetworks for Acoustic Modeling of Raw Time Signalin LVCSR, in: Proceedings of the AnnualConference of the InternationalSpeech Communication Association (INTERSPEECH), 2015, pp.", "26\u201330, [8] Yedid Hoshen and Ron Weiss and Kevin W Wilson, Speech Acoustic Modeling from Raw Multichannel Waveforms, InternationalConference on Acoustics, Speech, and SignalProcessing, 2015, [9] D Palz, M Magimai-Doss, and R Collobert.", "Analsis of CNN-based Speech Recognition System using Raw Speech as Input, INTERSPEECH 2015, pages 11\u201315, [10] T N Sainath, R J Weiss, A Senior, K W Wilson, and O Vinyal.", "Learning the Speech Front-end With Raw Waveform CLDNNs.", "Proceedings of the AnnualConference of the InternationalSpeech Communication Association (INTERSPEECH), 2015, [11] Satt, Aharon & Rozenberg, Shai & Hoory, Ron.", "(2017).", "Efficient Emotion Recognition from Speech Using Deep Learning on Spectrograms.", "1089-1093, Interspeech 2017, [12] S Davis and P Mermelstein.", "Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences.", "IEEE Transactions on Acoustics, Speech and SignalProcessing, 28(4):357\u2013366, 1980."], "all_annotations": [{"interpretation": 1, "review_id": "HydgKG5ez", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "HydgKG5ez", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "HydgKG5ez", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "HydgKG5ez", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Hyl2iJgGG", "review_text": "This paper examines the very popular and useful ADAM optimization algorithm, and locates a mistake in its proof of convergence (for convex problems). Not only that, the authors also show a specific toy convex problem on which ADAM fails to converge. Once the problem was identified to be the decrease in v_t (and increase in learning rate), they modified the algorithm to solve that problem. They then show the modified algorithm does indeed converge and show some experimental results comparing it to ADAM.\n\nThe paper is well written, interesting  and very important given the popularity of ADAM. \n\nRemarks:\n- The fact that your algorithm cannot increase the learning rate seems like a possible problem in practice. A large gradient at the first steps due to bad initialization can slow the rest of training. The experimental part is limited, as you state \"preliminary\", which is a unfortunate for a work with possibly an important practical implication. Considering how easy it is to run experiments with standard networks using open-source software, this can easily improve the paper. That being said, I understand that the focus of this work is theoretical and well deserves to be accepted based on the theoretical work.\n\n- On page 14 the fourth inequality not is clear to me.\n\n- On page 6 you talk about an alternative algorithm using smoothed gradients which you do not mention anywhere else and this isn't that clear (more then one way to smooth). A simple pseudo-code in the appendix would be welcome.\n\nMinor remarks:\n- After the proof of theorem 1 you jump to the proof of theorem 6 (which isn't in the paper) and then continue with theorem 2. It is a bit confusing.\n- Page 16 at the bottom v_t= ... sum beta^{t-1-i}g_i should be g_i^2\n- Page 19 second line, you switch between j&t and it is confusing. Better notation would help.\n- The cifarnet uses LRN layer that isn't used anymore.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["This paper examines the very popular and useful ADAM optimization alorithm, and locates a mistake in its proof of convergence (for convex problems).", "Not only that, the authors alo show a specific toy convex problem on which ADAM fails to converge.", "Once the problem was identified to be the decrease in v_t (and increase in learning rate), they modified the alorithm to solve that problem.", "They then show the modified alorithm does indeed converge and show some experimentalresults comparing it to ADAM.", "The paper is well written, interesting and very important given the popularity of ADAM.", "Remarks: - The fact that your alorithm cannot increase the learning rate seems like a possible problem in practice.", "A large gradient at the first steps due to bad initialzation can slow the rest of training.", "The experimentalpart is limited, as you state \"preliminary\", which is a unfortunate for a work with possibly an important practicalimplication.", "Considering how easy it is to run experiments with standard networks using open-source software, this can easily improve the paper.", "That being said, I understand that the focus of this work is theoreticaland well deserves to be accepted based on the theoreticalwork.", "- On page 14 the fourth ineqalty not is clear to me.", "- On page 6 you tal about an alernative alorithm using smoothed gradients which you do not mention anywhere else and this isn't that clear (more then one way to smooth).", "A simple pseudo-code in the appendix would be welcome.", "Minor remarks: - After the proof of theorem 1 you jump to the proof of theorem 6 (which isn't in the paper) and then continue with theorem 2, It is a bit confusing.", "- Page 16 at the bottom v_t= ... sum beta^{t-1-i}g_i should be g_i^2 - Page 19 secnd line, you switch between j&t and it is confusing.", "Better notation would help.", "- The cifarnet uses LRN layer that isn't used anymore."], "all_annotations": [{"interpretation": 0, "review_id": "Hyl2iJgGG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hyl2iJgGG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hyl2iJgGG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hyl2iJgGG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Hym3oxKlf", "review_text": "In this paper, the authors have proposed a GAN based method to conduct data augmentation. The cross-class transformations are mapped to a low dimensional latent space using conditional GAN. The paper is technically sound and the novelty is significant. The motivation of the proposed methods is clearly illustrated. Experiments on three datasets demonstrate the advantage of the proposed framework. However, this paper still suffers from some drawbacks as below:\n(1)\tThe illustration of the framework is not clear enough. For example, in figure 3, it says the GAN is designed for \u201cclass c\u201d, which is ambiguous whether the authors trained only one network for all class or trained multiple networks and each is trained on one class.\n(2)\tSome details is not clearly given, such as the dimension of the Gaussian distribution, the dimension of the projected  noise and .\n(3)\tThe proposed method needs to sample image pairs in each class. As far as I am concerned, in most cases sampling strategy will affect the performance to some extent. The authors need to show the robustness to sampling strategy of the proposed method.\n", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["In this paper, the authors have proposed a GAN based method to conduct data augmentation.", "The cross-class transformations are mapped to a low dimensionallatent space using conditionalGAN.", "The paper is technicaly sound and the novelty is significant.", "The motivation of the proposed methods is clearly illustrated.", "Experiments on three datasets demonstrate the advantage of the proposed framework.", "However, this paper still suffers from some drawbacks as below: (1)\tThe illustration of the framework is not clear enough.", "For example, in figre 3, it says the GAN is designed for \u201cclass c\u201d, which is ambiguous whether the authors trained only one network for al class or trained multiple networks and each is trained on one class.", "(2)\tSome details is not clearly given, such as the dimension of the Gaussian distribution, the dimension of the projected noise and .", "(3)\tThe proposed method needs to sample image pairs in each class.", "As far as I am concerned, in most cases sampling strategy will affect the performance to some extent.", "The authors need to show the robustness to sampling strategy of the proposed method."], "all_annotations": [{"interpretation": 0, "review_id": "Hym3oxKlf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "Hym3oxKlf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 2, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "Hym3oxKlf", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hym3oxKlf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HypMNiy-G", "review_text": "Training GAN in a hierarchical optimization schedule shows promising performance recently (e.g. Zhao et al., 2016). However, these works utilize the prior knowledge of the data (e.g. image) and it's hard to generalize it to other data types (e.g. text). The paper aims to learn these hierarchies directly instead of designing by human. However, several parts are missing and not well-explained. Also, many claims in paper are not proved properly by theory results or empirical results. \n\n(1) It is not clear to me how to train the proposed algorithm. My understanding is train a simple ALI, then using the learned latent as the input and train the new layer. Do the authors use a separate training ? or a joint training algorithms. The authors should provide a more clear and rigorous objective function. It would be even better to have a pseudo code. \n\n(2) In abstract, the authors claim the theoretical results are provided. I am not sure whether it is sec 3.2 The claims is not clear and limited. For example, what's the theory statement of [Johnsone 200; Baik 2005]. What is the error measure used in the paper? For different error, the matrix concentration bound might be different. Also, the union bound discussed in sec 3.2 is also problematic. Lats, for using simple standard GAN to learn mixture of Gaussian, the rigorous theory result doesn't seem easy (e.g. [1])  The author should strive for this results if they want to claim any theory guarantee. \n\n(3) The experiments part is not complete. The experiment settings are not described clearly. Therefore, it is hard to justify whether the proposed algorithm is really useful based on Fig 3. Also, the authors claims it is applicable to text data in Section 1, this part is missing in the experiment. Also, the idea of \"local\" disentangled LV is not well justified to be useful.\n\n[1] On the limitations of first order approximation in GAN dynamics, ICLR 2018 under review\n", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["Training GAN in a hierarchicaloptimization schedule shows promising performance recently (e g Zhao et al, 2016).", "However, these works utilize the prior knowledge of the data (e g image) and it's hard to generalze it to other data types (e g text).", "The paper aims to learn these hierarchies directly instead of designing by human.", "However, severalparts are missing and not well-explained.", "Also, many claims in paper are not proved properly by theory results or empiricalresults.", "(1) It is not clear to me how to train the proposed alorithm.", "My understanding is train a simple ALI, then using the learned latent as the input and train the new layer.", "Do the authors use a separate training ?", "or a joint training alorithms.", "The authors should provide a more clear and rigorous objective function.", "It would be even better to have a pseudo code.", "(2) In abstract, the authors claim the theoreticalresults are provided.", "I am not sure whether it is sec3 2 The claims is not clear and limited.", "For example, what's the theory statement of [Johnsone 200; Baik 2005].", "What is the error measure used in the paper?", "For different error, the matrix concentration bound might be different.", "Also, the union bound discussed in sec3 2 is alo problematic.", "Lats, for using simple standard GAN to learn mixture of Gaussian, the rigorous theory result doesn't seem easy (e g [1]) The author should strive for this results if they want to claim any theory guarantee.", "(3) The experiments part is not complete.", "The experiment settings are not described clearly.", "Therefore, it is hard to justify whether the proposed alorithm is realy useful based on fig3, Also, the authors claims it is applicable to text data in secion 1, this part is missing in the experiment.", "Also, the idea of \"local disentangled LV is not well justified to be useful.", "[1] On the limitations of first order approximation in GAN dynamics, ICLR 2018 under review"], "all_annotations": [{"interpretation": 1, "review_id": "HypMNiy-G", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HypMNiy-G", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno2", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "HypMNiy-G", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "HypMNiy-G", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "Hyu5lW5xf", "review_text": "This paper proposes a method, Dual-AC, for optimizing the actor(policy) and critic(value function) simultaneously which takes the form of a zero-sum game resulting in a principled method for using the critic to optimize the actor. In order to achieve that, they take the linear programming approach of solving the bellman optimality equations, outline the deficiencies of this approach, and propose solutions to mitigate those problems. The discussion on the deficiencies of the naive LP approach is mostly well done. Their main contribution is extending the single step LP formulation to a multi-step dual form that reduces the bias and makes the connection between policy and value function optimization much clearer without loosing convexity by applying a regularization. They perform an empirical study in the Inverted Double Pendulum domain to conclude that their extended algorithm outperforms the naive linear programming approach without the improvements. Lastly, there are empirical experiments done to conclude the superior performance of Dual-AC in contrast to other actor-critic algorithms. \n\nOverall, this paper could be a significant algorithmic contribution, with the caveat for some clarifications on the theory and experiments. Given these clarifications in an author response, I would be willing to increase the score. \n\nFor the theory, there are a few steps that need clarification and further clarification on novelty. For novelty, it is unclear if Theorem 2 and Theorem 3 are both being stated as novel results. It looks like Theorem 2 has already been shown in \"Randomized Linear Programming Solves the Discounted Markov Decision Problem in Nearly-Linear Running Time\u201d. There is a statement that \u201cChen & Wang (2016); Wang (2017) apply stochastic first-order algorithms (Nemirovski et al., 2009) for the one-step Lagrangian of the LP problem in reinforcement learning setting. However, as we discussed in Section 3, their algorithm is restricted to tabular parametrization\u201d. Is you Theorem 2 somehow an extension? Is Theorem 3 completely new?\n\nThis is particularly called into question due to the lack of assumptions about the function class for value functions. It seems like the value function is required to be able to represent the true value function, which can be almost as restrictive as requiring tabular parameterizations (which can represent the true value function). This assumption seems to be used right at the bottom of Page 17, where U^{pi*} = V^*. Further, eta_v must be chosen to ensure that it does not affect (constrain) the optimal solution, which implies it might need to be very small. More about conditions on eta_v would be illuminating. \n\nThere is also one step in the theorem that I cannot verify. On Page 18, how is the squared removed for difference between U and Upi? The transition from the second line of the proof to the third line is not clear. It would also be good to more clearly state on page 14 how you get the first inequality, for || V^* ||_{2,mu}^2. \n\n\nFor the experiments, the following should be addressed.\n\n1. It would have been better to also show the performance graphs with and without the improvements for multiple domains.\n\n2. The central contribution is extending the single step LP to a multi-step formulation. It would be beneficial to empirically demonstrate how increasing k (the multi-step parameter) affects the performance gains.\n\n3. Increasing k also comes at a computational cost. I would like to see some discussions on this and how long dual-AC takes to converge in comparison to the other algorithms tested (PPO and TRPO).\n\n4. The authors concluded the presence of local convexity based on hessian inspection due to the use of path regularization. It was also mentioned that increasing the regularization parameter size increases the convergence rate. Empirically, how does changing the regularization parameter affect the performance in terms of reward maximization? In the experimental section of the appendix, it is mentioned that multiple regularization settings were tried but their performance is not mentioned. Also, for the regularization parameters that were tried, based on hessian inspection, did they all result in local convexity? A bit more discussion on these choices would be helpful. \n\nMinor comments:\n1. Page 2: In equation 5, there should not be a 'ds' in the dual variable constraint", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["This paper proposes a method, DualAC, for optimizing the actor(policy) and critic(vale function) simultaneously which takes the form of a zero-sum game resulting in a principled method for using the critic to optimize the actor.", "In order to achieve that, they take the linear programming approach of solving the bellman optimalty eqations, outline the deficiencies of this approach, and propose solutions to mitigate those problems.", "The discussion on the deficiencies of the naive LP approach is mostly well done.", "Their main contribution is extending the single step LP formulation to a multi-step dualform that reduces the bias and makes the connection between policy and vale function optimization much clearer without loosing convexity by applying a regularization.", "They perform an empiricalstudy in the Inverted Double Pendulum domain to conclude that their extended alorithm outperforms the naive linear programming approach without the improvements.", "Lastly, there are empiricalexperiments done to conclude the superior performance of DualAC in contrast to other actor-critic alorithms.", "Overal, this paper could be a significant alorithmic contribution, with the caveat for some clarifications on the theory and experiments.", "Given these clarifications in an author response, I would be willing to increase the score.", "For the theory, there are a few steps that need clarification and further clarification on novelty.", "For novelty, it is unclear if Theorem 2 and Theorem 3 are both being stated as novel results.", "It looks like Theorem 2 has aleady been shown in \"Randomized Linear Programming Solves the Discounted Markov Decision Problem in Nearly-Linear Running Time\u201d.", "There is a statement that \u201cChen & Wang (2016); Wang (2017) apply stochastic first-order alorithms (Nemirovski et al, 2009) for the one-step Lagrangian of the LP problem in reinforcement learning setting.", "However, as we discussed in secion 3, their alorithm is restricted to tabular parametrization\u201d.", "Is you Theorem 2 somehow an extension?", "Is Theorem 3 completely new?", "This is particularly caled into question due to the lack of assumptions about the function class for vale functions.", "It seems like the vale function is reqired to be able to represent the true vale function, which can be alost as restrictive as reqiring tabular parameterizations (which can represent the true vale function).", "This assumption seems to be used right at the bottom of Page 17, where U^{pi*} = V^*.", "Further, eta_v must be chosen to ensure that it does not affect (constrain) the optimalsolution, which implies it might need to be very smal.", "More about conditions on eta_v would be illuminating.", "There is alo one step in the theorem that I cannot verify.", "On Page 18, how is the squared removed for difference between U and Upi?", "The transition from the secnd line of the proof to the third line is not clear.", "It would alo be good to more clearly state on page 14 how you get the first ineqalty, for || V^* ||_{2,mu}^2, For the experiments, the following should be addressed.", "1, It would have been better to alo show the performance graphs with and without the improvements for multiple domains.", "2, The centralcontribution is extending the single step LP to a multi-step formulation.", "It would be beneficialto empiricaly demonstrate how increasing k (the multi-step parameter) affects the performance gains.", "3, Increasing k alo comes at a computationalcost.", "I would like to see some discussions on this and how long dualAC takes to converge in comparison to the other alorithms tested (PPO and TRPO).", "4, The authors concluded the presence of localconvexity based on hessian inspection due to the use of path regularization.", "It was alo mentioned that increasing the regularization parameter size increases the convergence rate.", "Empiricaly, how does changing the regularization parameter affect the performance in terms of reward maximization?", "In the experimentalsecion of the appendix, it is mentioned that multiple regularization settings were tried but their performance is not mentioned.", "Also, for the regularization parameters that were tried, based on hessian inspection, did they al result in localconvexity?", "A bit more discussion on these choices would be helpful.", "Minor comments: 1, Page 2: In eqation 5, there should not be a 'ds' in the dualvariable constraint"], "all_annotations": [{"interpretation": 0, "review_id": "Hyu5lW5xf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hyu5lW5xf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "Hyu5lW5xf", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "Hyu5lW5xf", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "HyvB9RKez", "review_text": "This paper provides theoretical and empirical motivations for removing the top few principle components of commonly-used word embeddings.\n\nThe paper is well-written and I enjoyed reading it. However, it does not explain how significant this result is beyond that of (Bullinaria and Levy, 2012), who also removed the top N dimensions when benchmarking SVD-factorized word embeddings. From what I can see, this paper provides a more detailed explanation of the phenomenon (\"why\" it works), which is supported with both theoretical results and a series of empirical analyses, as well as \"updating\" the benchmarks and methods from the pre-neural era. Although this contribution is relatively incremental, I find the depth of this work very interesting, and I think future work could perhaps rely on these insights to create better embedding algorithms that directly enforce isotropy.\n\nI have two concerns regarding the empirical section, which may be resolvable fairly quickly:\n1) Are the embedding vectors L2 normalized before using them in each task? This is known to significantly affect performance. I am curious whether removing the top PCs is redundant or not given L2 normalization.\n2) Most of the benchmarks used in this paper are \"toy\" tasks. As Schnabel et al (2015) and Tsvetkov et al (2015) showed, there is often little correlation between success on these benchmarks and improvement of downstream NLP tasks. I would like to measure the change in performance on a major NLP task that heavily relies on pre-trained word embeddings such as SQuAD.\n\nMinor Comments:\n* The last sentence in the first paragraph (\"The success comes from the geometry of the representations...\") is not true; the success stems from the ability to capture lexical similarity. Levy and Goldberg (2014) showed that searching for the closest word vector to (king - man + woman) is equivalent to optimizing a linear combination of 3 similarity terms [+(x,king), -(x,man), +(x, woman)]. This explanation was further demonstrated by Linzen (2016) who showed that even when removing the negative term (x, man), many analogies can still be solved, i.e. by looking for a word that is similar both to \"king\" and to \"woman\". Add to that the fact that the analogy trick works best when the vectors are L2 normalized; if they are all on the unit sphere, what is the geometric interpretation of (king - man + woman), which is not on the unit sphere? I suggest removing this sentence and other references to linguistic regularities from this paper, since they are controversial at best, and distract from the main findings.\n* This is also related to Bullinaria and Levy's (2012) finding that downweighting the eigenvalue matrix in SVD-based methods improves their performance. Levy et al (2015) showed that keeping the original eigenvalues can actually degenerate SVD-based embeddings. Perhaps there is a connection to the findings in this paper?\n", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["This paper provides theoreticaland empiricalmotivations for removing the top few principle components of commonly-used word embeddings.", "The paper is well-written and I enjoyed reading it.", "However, it does not explain how significant this result is beyond that of (Bullinaria and Levy, 2012), who alo removed the top N dimensions when benchmarking SVD-factorized word embeddings.", "From what I can see, this paper provides a more detailed explanation of the phenomenon (\"why\" it works), which is supported with both theoreticalresults and a series of empiricalanalses, as well as \"updating\" the benchmarks and methods from the pre-neuralera.", "Although this contribution is relatively incremental I find the depth of this work very interesting, and I think future work could perhaps rely on these insights to create better embedding alorithms that directly enforce isotropy.", "I have two concerns regarding the empiricalsecion, which may be resolvable fairly quickly: 1) Are the embedding vectors L2 normalzed before using them in each task?", "This is known to significantly affect performance.", "I am curious whether removing the top PCs is redundant or not given L2 normalzation.", "2) Most of the benchmarks used in this paper are \"toy\" tasks.", "As Schnabel et al(2015) and Tsvetkov et al(2015) showed, there is often little correlation between success on these benchmarks and improvement of downstream NLP tasks.", "I would like to measure the change in performance on a major NLP task that heavily relies on pre-trained word embeddings such as SQuAD.", "Minor Comments: * The last sentence in the first paragraph (\"The success comes from the geometry of the representations...\") is not true; the success stems from the ability to capture lexicalsimilarity.", "Levy and Goldberg (2014) showed that searching for the closest word vector to (king - man + woman) is eqivalnt to optimizing a linear combination of 3 similarity terms [+(x,king), -(x,man), +(x, woman)].", "This explanation was further demonstrated by Linzen (2016) who showed that even when removing the negative term (x, man), many analgies can still be solved, i e by looking for a word that is similar both to \"king\" and to \"woman\".", "Add to that the fact that the analgy trick works best when the vectors are L2 normalzed; if they are al on the unit sphere, what is the geometric interpretation of (king - man + woman), which is not on the unit sphere?", "I suggest removing this sentence and other references to linguistic regularities from this paper, since they are controversialat best, and distract from the main findings.", "* This is alo related to Bullinaria and Levy's (2012) finding that downweighting the eigenvale matrix in SVD-based methods improves their performance.", "Levy et al(2015) showed that keeping the originaleigenvales can actualy degenerate SVD-based embeddings.", "Perhaps there is a connection to the findings in this paper?"], "all_annotations": [{"interpretation": 0, "review_id": "HyvB9RKez", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HyvB9RKez", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "HyvB9RKez", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "HyvB9RKez", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HyvZDmueM", "review_text": "This paper proposed a new optimization framework for semi-supervised learning based on derived inversion scheme for deep neural networks. The numerical experiments show a significant improvement in accuracy of the approach.", "gold_annotation": null, "score": 1.0, "tokenized_review_text": ["This paper proposed a new optimization framework for semi-supervised learning based on derived inversion scheme for deep neuralnetworks.", "The numericalexperiments show a significant improvement in accuracy of the approach."], "all_annotations": [{"interpretation": 0, "review_id": "HyvZDmueM", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno0", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "HyvZDmueM", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno2", "evidence": 1, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "HyvZDmueM", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno3", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "HyvZDmueM", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno1", "evidence": 1, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "Hyx7bEPez", "review_text": "In this paper, the authors studied the problem of semi-supervised few-shot classification, by extending the prototypical networks into the setting of semi-supervised learning with examples from distractor classes.  The studied problem is interesting, and the paper is well-written. Extensive experiments are performed to demonstrate the effectiveness of the proposed methods.  While the proposed method is a natural extension of the existing works (i.e., soft k-means and meta-learning).On top of that, It seems the authors have over-claimed their model capability at the first place as the proposed model cannot properly classify the distractor examples but just only consider them as a single class of outliers. Overall, I would like to vote for a weakly acceptance regarding this paper.", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["In this paper, the authors studied the problem of semi-supervised few-shot classification, by extending the prototypicalnetworks into the setting of semi-supervised learning with examples from distractor classes.", "The studied problem is interesting, and the paper is well-written.", "Extensive experiments are performed to demonstrate the effectiveness of the proposed methods.", "While the proposed method is a naturalextension of the existing works (i e , soft k-means and meta-learning).On top of that, It seems the authors have over-claimed their model capability at the first place as the proposed model cannot properly classify the distractor examples but just only consider them as a single class of outliers.", "Overal, I would like to vote for a weakly acceptance regarding this paper."], "all_annotations": [{"interpretation": 1, "review_id": "Hyx7bEPez", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "Hyx7bEPez", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 3, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "yes-disagree", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "Hyx7bEPez", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "Hyx7bEPez", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HyxmggJbM", "review_text": "This paper proposes a new way of sampling data for updates in deep-Q networks. The basic principle is to update Q values starting from the end of the episode in order to facility quick propagation of rewards back along the episode.\n\nThe paper is interesting, but it lacks the proper comparisons to previously published techniques.\n\nThe results presented by this paper shows improvement over the baseline. But the Atari results is still significantly worse than the current SOTA.\n\nIn the non-tabular case, the authors have actually moved away from Q learning and defined an objective that is both on and off-policy. Some (theoretical) analysis would be nice. It is hard to judge whether the objective defined in the non-tabular defines a contraction operator at all in the tabular case.\n\nThere has been a number of highly relevant papers. Prioritized replay, for example, could have a very similar effect to proposed approach in the tabular case.\n\nIn the non-tabular case, the Retrace algorithm, tree backup, Watkin's Q learning all bear significant resemblance to the proposed method. Although the proposed algorithm is different from all 3, the authors should still have compared to at least one of them as a baseline. The Retrace algorithm specifically has also been shown to help significantly in the Atari case, and it defines a convergent update rule.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["This paper proposes a new way of sampling data for updates in deep-Q networks.", "The basic principle is to update Q vales starting from the end of the episode in order to facility quick propagation of rewards back alng the episode.", "The paper is interesting, but it lacks the proper comparisons to previously published techniques.", "The results presented by this paper shows improvement over the baseline.", "But the Atari results is still significantly worse than the current SOTA.", "In the non-tabular case, the authors have actualy moved away from Q learning and defined an objective that is both on and off-policy.", "Some (theoretical analsis would be nice.", "It is hard to judge whether the objective defined in the non-tabular defines a contraction operator at al in the tabular case.", "There has been a number of highly relevant papers.", "Prioritized replay, for example, could have a very similar effect to proposed approach in the tabular case.", "In the non-tabular case, the Retrace alorithm, tree backup, Watkin's Q learning al bear significant resemblance to the proposed method.", "Although the proposed alorithm is different from al 3, the authors should still have compared to at least one of them as a baseline.", "The Retrace alorithm specificaly has alo been shown to help significantly in the Atari case, and it defines a convergent update rule."], "all_annotations": [{"interpretation": 0, "review_id": "HyxmggJbM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HyxmggJbM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "HyxmggJbM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "HyxmggJbM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S15xOyjgf", "review_text": "This paper proposes an evolutionary algorithm for solving the variational E step in expectation-maximization algorithm for probabilistic models with binary latent variables. This is done by (i) considering the bit-vectors of the latent states as genomes of individuals, and by (ii) defining the fitness of the individuals as the log joint distribution of the parameters and the latent space.\n \nPros:\nThe paper is well written and the methodology presented is largely clear.\n\nCons:\nWhile the reviewer is essentially fine with the idea of the method, the reviewer is much less convinced of the empirical study. There is no comparison with other methods such as Monte carlo sampling.\nIt is not clear how computationally Evolutionary EM performs comparing to Variational EM algorithm and there is neither experimental results nor analysis for the computational complexity of the proposed model.\nThe datasets used in the experiments are quite old. The reviewer is concerned that these datasets may not be representative of real problems.\nThe applicability of the method is quite limited. The proposed model is only applicable for the probabilistic models with binary latent variables, hence it cannot be applied to more realistic complex model with real-valued latent variables.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["This paper proposes an evolutionary alorithm for solving the variationalE step in expectation-maximization alorithm for probabilistic models with binary latent variables.", "This is done by (i) considering the bit-vectors of the latent states as genomes of individual, and by (ii) defining the fitness of the individual as the log joint distribution of the parameters and the latent space.", "Pros: The paper is well written and the methodology presented is largely clear.", "Cons: While the reviewer is essentialy fine with the idea of the method, the reviewer is much less convinced of the empiricalstudy.", "There is no comparison with other methods such as Monte carlo sampling.", "It is not clear how computationaly Evolutionary EM performs comparing to VariationalEM alorithm and there is neither experimentalresults nor analsis for the computationalcomplexity of the proposed model.", "The datasets used in the experiments are quite old.", "The reviewer is concerned that these datasets may not be representative of realproblems.", "The applicability of the method is quite limited.", "The proposed model is only applicable for the probabilistic models with binary latent variables, hence it cannot be applied to more realstic complex model with realvaled latent variables."], "all_annotations": [{"interpretation": 0, "review_id": "S15xOyjgf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S15xOyjgf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "S15xOyjgf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S15xOyjgf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S1GVQk5gG", "review_text": "------ updates to review: ---------\n\nI think the paper is much improved. It is much more clear and the experiments are more focused and more closely connected to the earlier content in the paper. Thanks to the authors for trying to address all of my concerns. \n\nI now better understand in what sense the representation space is optimal.  I had been thinking (or perhaps \"hoping\" is a better word) that the term \"optimal\" implied maximal in terms of some quantifiable measure, but it's more of an empirical \"optimality\".  This makes the paper an empirical paper based on a reasonable and sensible intuition, rather than a theoretical result.  This was a little disappointing to me, but I do still think the paper is marginally above the acceptance threshold and have increased my score accordingly. \n\n------ original review below: --------\nThis paper is about rethinking how to use encoder-decoder architectures for representation learning when the training objective contains a similarity between the decoder output and the encoding of something else. For example, for the skip-thought RNN encoder-decoder that encodes a sentence and decodes neighboring sentences: rather than use the final encoder hidden state as the representation of the sentence, the paper uses some function of the decoder, since the training objective is to maximize each dot product between a decoder hidden state and the embedding of a context word. If dot product (or cosine similarity) is going to be used as the similarity function for the representation, then it makes more sense, the paper argues, to use the decoder hidden state(s) as the representation of the input sentence. The paper considers both averaging and concatenating hidden states. One difficulty here is that the neighboring sentences are typically not available in downstream tasks, so the paper runs the decoder to produce a predicted sentence one word-at-a-time, using the predicted words as inputs to the decoder RNNs. Then those decoder RNN hidden states are used via averaging or concatenation as the representation of a sentence in downstream tasks. \n\nThis paper is a source of contributions, but I think in its current form it is not yet ready for publication. \n\nPros:\n\nI think it makes sense to pay attention to the training objective when deciding how to use the model for downstream tasks. \n\nI like the empirical investigation of combining RNN and BOW encoders and decoders. \n\nThe experimental results show that a single encoder-decoder model can be trained and then two different functions of it can be used at test time for different kinds of tasks (RNN-RNN for supervised transfer and RNN-RNN-mean for unsupervised transfer). I think this is an interesting result. \n\nCons: \n\nI have several concerns. The first relate to the theoretical arguments and their empirical support. \n\nRegarding the theoretical arguments: \n\nFirst, the paper discusses the notion of an \"optimal representation space\" and describes the argument as theoretical, but I don't see much of a theoretical argument here. \n\nAs far as I can tell, the paper does not formally define its terms or define in what sense the representation space is \"optimal\". I can only find heuristic statements like those in the paragraph in Sec 3.2 that begins \"These observations...\".  What exactly is meant formally by statements like \"any model where the decoder is log-linear with respect to the encoder\" or \"that distance is optimal with respect to the model\u2019s objective\"?  It seems like the paper may want to start with formal definitions of an encoder and a decoder, then define what is meant by a \"decoder that is log-linear with respect to the encoder\", and define what it means for a distance to be optimal with respect to a training objective. That seems necessary in order to provide the foundation to make any theoretical statement about choices for encoders, decoders, and training objectives.  I am still not exactly sure what that theoretical statement might look like, but maybe defining the terms would help the authors get started in heading toward the goal of defining a statement to prove. \n\nSecond, the paper's theoretical story seems to diverge almost immediately from the choices used in the model and experimental procedure. \n\nFor example, in Sec. 3.2, it is stated that cosine similarity \"is the appropriate similarity measure in the case of log-linear decoders.\"  But the associated footnote (footnote 2) seems to admit a contradiction here by noting that actually the appropriate similarity measure is dot product: \"Evidently, the correct measure is actually the dot product.\"  This is a bit confusing. \nIt also raises a question: If cosine similarity will be used later for computing similarity, then why not try using cosine similarity in place of dot product in the model?  That is, replace \"u_w \\cdot h_i\" in Eq. (2) with \"cos(u_w, h_i)\".  If the paper's story is correct (and if I understand the ideas correctly), training with cosine similarity should work better than training with dot product, because the similarity function used during training is more similar to that used in testing.  This seems like a natural experiment to try.  Other natural experiments would be to vary both the similarity function used in the model during training and the similarity function used at test time.  The authors' claims could be validated if the optimal choices always use the same choice for the training and test-time similarity functions.  That is, if Euclidean distance is used during training, then will Euclidean distance be the best choice at test time?\n\nAnother example of the divergence lies in the use of the skip-thought decoder on downstream tasks. Since the decoder hidden states depend on neighboring sentences and these are considered to be unavailable at test time, the paper \"unrolls\" the decoder for several steps by using it to predict words which are then used as inputs on the next time step. To me, this is a potentially very significant difference between training and testing. Since much of the paper is about reconciling training and testing conditions in terms of the representation space and similarity function, this difference feels like a divergence from the theoretical story. It is only briefly mentioned at the end of Sec. 3.3 and then discussed again later in the experiments section. I think this should be described in more detail in Section 3.3 because it is an important note about how the model will be used in practice. \n\nIt would be nice to be able to quantify the impact (of unrolling the decoder with predicted words) by, for example, using the decoder on a downstream evaluation dataset that has neighboring sentences in it. Then the actual neighboring sentences can be used as inputs to the decoder when it is unrolled, which would be closer to the training conditions and we could empirically see the difference. Perhaps there is an evaluation dataset with ordered sentences so that the authors could empirically compare using real vs predicted inputs to the decoder on a downstream task?\n\nThe above experiments might help to better connect the experiments section with the theoretical arguments. \n\nOther concerns, including more specific points, are below:\n\nSec. 2: \nWhen describing inferior performance of RNN-based models on unsupervised sentence similarity tasks, the paper states: \"While this shortcoming of SkipThought and RNN-based models in general has been pointed out, to the best of our knowledge, it has never been systematically addressed in the literature before.\" \nThe authors may want to check Wieting & Gimpel (2017) (and its related work) which investigates the inferiority of LSTMs compared to word averaging for unsupervised sentence similarity tasks. They found that averaging the encoder hidden states can work better than using the final encoder hidden state; the authors may want to try that as well. \n\nSec. 3.2:\nWhen describing FastSent, the paper includes \"Due to the model's simplicity, it is particularly fast to train and evaluate, yet has shown state-of-the-art performance in unsupervised similarity tasks (Hill et al., 2015).\"\nI don't think it makes much sense to cite the SimLex-999 paper in this context, as that is a word similarity task and that paper does not include any results of FastSent. Maybe the Hill et al (2016) FastSent citation was meant instead? But in that case, I don't think it is quite accurate to make the claim that FastSent is SOTA on unsupervised similarity tasks. In the original FastSent paper (Hill et al., 2016), FastSent is not as good as CPHRASE or \"DictRep BOW+embs\" on average across the unsupervised sentence similarity evaluations. FastSent is also not as good as sent2vec from Pagliardini et al (2017) or charagram-phrase from Wieting et al. (2016).\n\nSec. 3.3:\nIn describing skip-thought, the paper states: \"While computationally complex, it is currently the state-of-the-art model for supervised transfer tasks (Hill et al., 2016).\"\nI don't think it is accurate to state that skip-thought is still state-of-the-art for supervised transfer tasks, in light of recent work (Conneau et al., 2017; Gan et al., 2017). \n\nSec. 3.3:\nWhen discussing averaging the decoder hidden states, the paper states: \"Intuitively, this corresponds to destroying the word order information the decoder has learned.\" I'm not sure this strong language can be justified here. Is there any evidence to suggest that averaging the decoder hidden states will destroy word order information? The hidden states may be representing word order information in a way that is robust to averaging, i.e., in a way such that the average of the hidden states can still lead to the reconstruction of the word order.\n\nSec. 4:\nWhat does it mean to use an RNN encoder and a BOW decoder?  This seems to be a strongly-performing setting and competitive with RNN-mean, but I don't know exactly what this means. \n\n\nMinor things:\n\nSec. 3.1:\nWhen defining v_w, it would be helpful to make explicit that it's in \\mathbb{R}^d.\n\nSec. 4: \nFor TREC question type classification, I think the correct citation should be Li & Roth (2002) instead of Vorhees (2002).\n\nSec. 5:\nI think there's a typo in the following sentence: \"Our results show that, for example, the raw encoder output for SkipThought (RNN-RNN) achieves strong performance on supervised transfer, whilst its mean decoder output (RNN-mean) achieves strong performance on supervised transfer.\"  I think \"unsupervised\" was meant in the latter mention.\n\nReferences:\n\nConneau, A., Kiela, D., Schwenk, H., Barrault, L., & Bordes, A. (2017). Supervised Learning of Universal Sentence Representations from Natural Language Inference Data. EMNLP.\nGan, Z., Pu, Y., Henao, R., Li, C., He, X., & Carin, L. (2017). Learning generic sentence representations using convolutional neural networks. EMNLP.\nLi, X., & Roth, D. (2002). Learning question classifiers. COLING.\nPagliardini, M., Gupta, P., & Jaggi, M. (2017). Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features. arXiv preprint arXiv:1703.02507.\nWieting, J., Bansal, M., Gimpel, K., & Livescu, K. (2016). Charagram: Embedding words and sentences via character n-grams. EMNLP.\nWieting, J., & Gimpel, K. (2017). Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings. ACL.\n", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["------ updates to review: --------- I think the paper is much improved.", "It is much more clear and the experiments are more focused and more closely connected to the earlier content in the paper.", "Thanks to the authors for trying to address al of my concerns.", "I now better understand in what sense the representation space is optimal I had been thinking (or perhaps \"hoping\" is a better word) that the term \"optimal implied maximalin terms of some quantifiable measure, but it's more of an empirical\"optimalty\".", "This makes the paper an empiricalpaper based on a reasonable and sensible intuition, rather than a theoreticalresult.", "This was a little disappointing to me, but I do still think the paper is marginaly above the acceptance threshold and have increased my score accordingly.", "------ originalreview below: -------- This paper is about rethinking how to use encoder-decoder architectures for representation learning when the training objective contains a similarity between the decoder output and the encoding of something else.", "For example, for the skip-thought RNN encoder-decoder that encodes a sentence and decodes neighboring sentences: rather than use the finalencoder hidden state as the representation of the sentence, the paper uses some function of the decoder, since the training objective is to maximize each dot product between a decoder hidden state and the embedding of a context word.", "If dot product (or cosine similarity) is going to be used as the similarity function for the representation, then it makes more sense, the paper argues, to use the decoder hidden state(s) as the representation of the input sentence.", "The paper considers both averaging and concatenating hidden states.", "One difficulty here is that the neighboring sentences are typicaly not available in downstream tasks, so the paper runs the decoder to produce a predicted sentence one word-at-a-time, using the predicted words as inputs to the decoder RNNs.", "Then those decoder RNN hidden states are used via averaging or concatenation as the representation of a sentence in downstream tasks.", "This paper is a source of contributions, but I think in its current form it is not yet ready for publication.", "Pros: I think it makes sense to pay attention to the training objective when deciding how to use the model for downstream tasks.", "I like the empiricalinvestigation of combining RNN and BOW encoders and decoders.", "The experimentalresults show that a single encoder-decoder model can be trained and then two different functions of it can be used at test time for different kinds of tasks (RNN-RNN for supervised transfer and RNN-RNN-mean for unsupervised transfer).", "I think this is an interesting result.", "Cons: I have severalconcerns.", "The first relate to the theoreticalarguments and their empiricalsupport.", "Regarding the theoreticalarguments: First, the paper discusses the notion of an \"optimalrepresentation space\" and describes the argument as theoretical but I don't see much of a theoreticalargument here.", "As far as I can tell, the paper does not formaly define its terms or define in what sense the representation space is \"optimal.", "I can only find heuristic statements like those in the paragraph in sec3 2 that begins \"These observations...\".", "What exactly is meant formaly by statements like \"any model where the decoder is log-linear with respect to the encoder\" or \"that distance is optimalwith respect to the model\u2019s objective\"?", "It seems like the paper may want to start with formaldefinitions of an encoder and a decoder, then define what is meant by a \"decoder that is log-linear with respect to the encoder\", and define what it means for a distance to be optimalwith respect to a training objective.", "That seems necessary in order to provide the foundation to make any theoreticalstatement about choices for encoders, decoders, and training objectives.", "I am still not exactly sure what that theoreticalstatement might look like, but maybe defining the terms would help the authors get started in heading toward the goalof defining a statement to prove.", "secnd, the paper's theoreticalstory seems to diverge alost immediately from the choices used in the model and experimentalprocedure.", "For example, in sec 3 2, it is stated that cosine similarity \"is the appropriate similarity measure in the case of log-linear decoders.\"", "But the associated footnote (footnote 2) seems to admit a contradiction here by noting that actualy the appropriate similarity measure is dot product: \"Evidently, the correct measure is actualy the dot product.\"", "This is a bit confusing.", "It alo raises a question: If cosine similarity will be used later for computing similarity, then why not try using cosine similarity in place of dot product in the model?", "That is, replace \"u_w \\cdot h_i\" in eq (2) with \"cos(u_w, h_i)\".", "If the paper's story is correct (and if I understand the ideas correctly), training with cosine similarity should work better than training with dot product, because the similarity function used during training is more similar to that used in testing.", "This seems like a naturalexperiment to try.", "Other naturalexperiments would be to vary both the similarity function used in the model during training and the similarity function used at test time.", "The authors' claims could be valdated if the optimalchoices alays use the same choice for the training and test-time similarity functions.", "That is, if Euclidean distance is used during training, then will Euclidean distance be the best choice at test time?", "Another example of the divergence lies in the use of the skip-thought decoder on downstream tasks.", "Since the decoder hidden states depend on neighboring sentences and these are considered to be unavailable at test time, the paper \"unrolls\" the decoder for severalsteps by using it to predict words which are then used as inputs on the next time step.", "To me, this is a potentialy very significant difference between training and testing.", "Since much of the paper is about reconciling training and testing conditions in terms of the representation space and similarity function, this difference feels like a divergence from the theoreticalstory.", "It is only briefly mentioned at the end of sec 3 3 and then discussed again later in the experiments secion.", "I think this should be described in more detail in secion 3 3 because it is an important note about how the model will be used in practice.", "It would be nice to be able to quantify the impact (of unrolling the decoder with predicted words) by, for example, using the decoder on a downstream evalation dataset that has neighboring sentences in it.", "Then the actualneighboring sentences can be used as inputs to the decoder when it is unrolled, which would be closer to the training conditions and we could empiricaly see the difference.", "Perhaps there is an evalation dataset with ordered sentences so that the authors could empiricaly compare using realvs predicted inputs to the decoder on a downstream task?", "The above experiments might help to better connect the experiments secion with the theoreticalarguments.", "Other concerns, including more specific points, are below: sec 2: When describing inferior performance of RNN-based models on unsupervised sentence similarity tasks, the paper states: \"While this shortcoming of SkipThought and RNN-based models in generalhas been pointed out, to the best of our knowledge, it has never been systematicaly addressed in the literature before.\"", "The authors may want to check Wieting & Gimpel (2017) (and its related work) which investigates the inferiority of LSTMs compared to word averaging for unsupervised sentence similarity tasks.", "They found that averaging the encoder hidden states can work better than using the finalencoder hidden state; the authors may want to try that as well.", "sec 3 2: When describing FastSent, the paper includes \"Due to the model's simplicity, it is particularly fast to train and evalate, yet has shown state-of-the-art performance in unsupervised similarity tasks (Hill et al, 2015).\"", "I don't think it makes much sense to cite the SimLex-999 paper in this context, as that is a word similarity task and that paper does not include any results of FastSent.", "Maybe the Hill et al(2016) FastSent citation was meant instead?", "But in that case, I don't think it is quite accurate to make the claim that FastSent is SOTA on unsupervised similarity tasks.", "In the originalFastSent paper (Hill et al, 2016), FastSent is not as good as CPHRASE or \"DictRep BOW+embs\" on average across the unsupervised sentence similarity evalations.", "FastSent is alo not as good as sent2vec from Pagliardini et al(2017) or charagram-phrase from Wieting et al (2016).", "sec 3 3: In describing skip-thought, the paper states: \"While computationaly complex, it is currently the state-of-the-art model for supervised transfer tasks (Hill et al, 2016).\"", "I don't think it is accurate to state that skip-thought is still state-of-the-art for supervised transfer tasks, in light of recent work (Conneau et al, 2017; Gan et al, 2017).", "sec 3 3: When discussing averaging the decoder hidden states, the paper states: \"Intuitively, this corresponds to destroying the word order information the decoder has learned.\"", "I'm not sure this strong language can be justified here.", "Is there any evidence to suggest that averaging the decoder hidden states will destroy word order information?", "The hidden states may be representing word order information in a way that is robust to averaging, i e , in a way such that the average of the hidden states can still lead to the reconstruction of the word order.", "sec 4: What does it mean to use an RNN encoder and a BOW decoder?", "This seems to be a strongly-performing setting and competitive with RNN-mean, but I don't know exactly what this means.", "Minor things: sec 3 1: When defining v_w, it would be helpful to make explicit that it's in \\mathbb{R}^d sec 4: For TREC question type classification, I think the correct citation should be Li & Roth (2002) instead of Vorhees (2002).", "sec 5: I think there's a typo in the following sentence: \"Our results show that, for example, the raw encoder output for SkipThought (RNN-RNN) achieves strong performance on supervised transfer, whilst its mean decoder output (RNN-mean) achieves strong performance on supervised transfer.\"", "I think \"unsupervised\" was meant in the latter mention.", "References: Conneau, A , Kiela, D , Schwenk, H , Barrault, L , & Bordes, A (2017).", "Supervised Learning of UniversalSentence Representations from NaturalLanguage Inference Data.", "EMNLP.", "Gan, Z , Pu, Y , Henao, R , Li, C , He, X , & Carin, L (2017).", "Learning generic sentence representations using convolutionalneuralnetworks.", "EMNLP.", "Li, X , & Roth, D (2002).", "Learning question classifiers.", "COLING.", "Pagliardini, M , Gupta, P , & Jaggi, M (2017).", "Unsupervised Learning of Sentence Embeddings using Compositionaln-Gram Features.", "arXiv preprint arXiv:1703.02507, Wieting, J , Bansal M , Gimpel, K , & Livescu, K (2016).", "Charagram: Embedding words and sentences via character n-grams.", "EMNLP.", "Wieting, J , & Gimpel, K (2017).", "Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings.", "ACL."], "all_annotations": [{"interpretation": 1, "review_id": "S1GVQk5gG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "S1GVQk5gG", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno2", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "S1GVQk5gG", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1GVQk5gG", "importance": 0, "reproducibility": null, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1KIF7olf", "review_text": "This paper presents an empirical study of whether data augmentation can be a substitute for explicit regularization of weight decay and dropout.  It is a well written and well organized paper.  However, overall I do not find the authors\u2019 premises and conclusions to be well supported by the results and would suggest further investigations.  In particular:\n\na) Data augmentation is a very domain specific process and limits of augmentation are often not clear.  For example, in financial data or medical imaging data it is often not clear how data augmentation should be carried out and how much is too much.  On the other hand model regularization is domain agnostic (has to be tuned for each task, but the methodology is consistent and well known).  Thus advocating that data augmentation can universally replace explicit regularization does not seem correct.\n\nb) I find the results to be somewhat inconsistent.  For example, on CIFAR-10, for 100% data regularization+augmentation is better than augmentation alone for both models, whereas for 80% data augmentation alone seems to be better.  Similarly on CIFAR-100 the WRN model shows mixed trends, and this model is significantly better than the All-CNN model in performance.  These results also seem inconsistent with authors statement \u201c\u2026and conclude that data augmentation alone - without any other explicit regularization techniques - can achieve the same performance to higher as regularized models\u2026\u201d\n", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["This paper presents an empiricalstudy of whether data augmentation can be a substitute for explicit regularization of weight decay and dropout.", "It is a well written and well organized paper.", "However, overal I do not find the authors\u2019 premises and conclusions to be well supported by the results and would suggest further investigations.", "In particular: a) Data augmentation is a very domain specific process and limits of augmentation are often not clear.", "For example, in financialdata or medicalimaging data it is often not clear how data augmentation should be carried out and how much is too much.", "On the other hand model regularization is domain agnostic (has to be tuned for each task, but the methodology is consistent and well known).", "Thus advocating that data augmentation can universaly replace explicit regularization does not seem correct.", "b) I find the results to be somewhat inconsistent.", "For example, on CIFAR-10, for 100% data regularization+augmentation is better than augmentation alne for both models, whereas for 80% data augmentation alne seems to be better.", "Similarly on CIFAR-100 the WRN model shows mixed trends, and this model is significantly better than the All-CNN model in performance.", "These results alo seem inconsistent with authors statement \u201c\u2026and conclude that data augmentation alne - without any other explicit regularization techniques - can achieve the same performance to higher as regularized models\u2026\u201d"], "all_annotations": [{"interpretation": 1, "review_id": "S1KIF7olf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "S1KIF7olf", "importance": 0, "reproducibility": null, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "S1KIF7olf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "S1KIF7olf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S1MHyoFgf", "review_text": "Thank you for your contribution to ICLR. The paper covers a very interesting topic and presents some though-provoking ideas. \n\nThe paper introduces \"covariant compositional networks\" with the purpose of learning graph representations. An example application also covered in the experimental section is graph classification. \nGiven a finite set S, a compositional network is simply a partially ordered set P where each element of P is a subset of S and where P contains all sets of cardinality 1 and the set S itself. Unfortunately, the presentation of the approach is extremely verbose and introduces old concepts (e.g., partially ordered set) under new names.  The basic idea (which is not new) of this work is that we need to impose some sort of hierarchical order on the nodes of the graph so as to learn hierarchical feature representations. Moreover, the hierarchical order of the nodes should be invariant to valid permutations of the nodes, that is, two isomorphic graphs should have the same hierarchical order on their nodes and the same feature representations. Since this is the case for graph embedding methods that collect feature representations from their neighbors in the graph (and where the feature aggregation functions are symmetric) it makes sense that \"compositional networks\" generalize graph convolutional networks (and the more general message passing neural networks framework). \n\nThe most challenging problem, however, namely the problem of finding a concrete and suitable permutation invariant hierarchical decomposition of the nodes plus some aggregation/pooling functions to compute the feature representations is not addressed in sufficient detail. The paper spends a lot of time on some theoretical definitions and (trivial) proofs but then fails to make the connection to an approach that works in practice. The description of the experiments and which compositional network is chosen and how it is chosen seems to be missing. The only part hinting at the model that was actually used in the experiments is the second paragraph of the section 'Experimental Setup', consisting of one long sentence that is incomprehensible to me. \n\nInstead of spending a lot of effort on the definitions and (somewhat trivial) propositions in the first half of the paper, the authors should spend much more time on detailing the experiments and the actual model that they used. In an effort to make the framework as general as possible, you ended up making the paper highly verbose and difficult to follow. \n\nPlease address the following points or clarify in your rebuttal if I misunderstood something:\n\n- what precisely is the novel contribution of your work (it cannot be \"compositional networks\" and the propositions concerning those because these are just old concepts under new names)?\n- explain precisely (and/or more directly/less convoluted) how your model used in the experiments looks like; why do you think it is better than the other methods?\n- given that compositional network is a very general concept (partially ordered set imposed on subsets of the graph vertices), what is the principled set of steps one has to follow to arrive at such a compositional network tailored to a particular graph collection? isn't (or shouldn't) that be the contribution of this work? Am I missing something?\n\nIn general, you should write the paper much more to the point and leave out unnecessary math (or move to an appendix).  The paper is currently highly inaccessible.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["Thank you for your contribution to ICLR.", "The paper covers a very interesting topic and presents some though-provoking ideas.", "The paper introduces \"covariant compositionalnetworks\" with the purpose of learning graph representations.", "An example application alo covered in the experimentalsecion is graph classification.", "Given a finite set S, a compositionalnetwork is simply a partialy ordered set P where each element of P is a subset of S and where P contains al sets of cardinalty 1 and the set S itself.", "Unfortunately, the presentation of the approach is extremely verbose and introduces old concepts (e g , partialy ordered set) under new names.", "The basic idea (which is not new) of this work is that we need to impose some sort of hierarchicalorder on the nodes of the graph so as to learn hierarchicalfeature representations.", "Moreover, the hierarchicalorder of the nodes should be invariant to vald permutations of the nodes, that is, two isomorphic graphs should have the same hierarchicalorder on their nodes and the same feature representations.", "Since this is the case for graph embedding methods that collect feature representations from their neighbors in the graph (and where the feature aggregation functions are symmetric) it makes sense that \"compositionalnetworks\" generalze graph convolutionalnetworks (and the more generalmessage passing neuralnetworks framework).", "The most chalenging problem, however, namely the problem of finding a concrete and suitable permutation invariant hierarchicaldecomposition of the nodes plus some aggregation/pooling functions to compute the feature representations is not addressed in sufficient detail.", "The paper spends a lot of time on some theoreticaldefinitions and (trivial proofs but then fails to make the connection to an approach that works in practice.", "The description of the experiments and which compositionalnetwork is chosen and how it is chosen seems to be missing.", "The only part hinting at the model that was actualy used in the experiments is the secnd paragraph of the secion 'ExperimentalSetup', consisting of one long sentence that is incomprehensible to me.", "Instead of spending a lot of effort on the definitions and (somewhat trivial propositions in the first hal of the paper, the authors should spend much more time on detailing the experiments and the actualmodel that they used.", "In an effort to make the framework as generalas possible, you ended up making the paper highly verbose and difficult to follow.", "Please address the following points or clarify in your rebuttalif I misunderstood something: - what precisely is the novel contribution of your work (it cannot be \"compositionalnetworks\" and the propositions concerning those because these are just old concepts under new names)?", "- explain precisely (and/or more directly/less convoluted) how your model used in the experiments looks like; why do you think it is better than the other methods?", "- given that compositionalnetwork is a very generalconcept (partialy ordered set imposed on subsets of the graph vertices), what is the principled set of steps one has to follow to arrive at such a compositionalnetwork tailored to a particular graph collection?", "isn't (or shouldn't) that be the contribution of this work?", "Am I missing something?", "In general you should write the paper much more to the point and leave out unnecessary math (or move to an appendix).", "The paper is currently highly inaccessible."], "all_annotations": [{"interpretation": 0, "review_id": "S1MHyoFgf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "S1MHyoFgf", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "S1MHyoFgf", "importance": 0, "reproducibility": 1, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "S1MHyoFgf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S1QsSa1-M", "review_text": "Authors provide an interesting loss function approach for clustering using a deep neural network. They optimize Kuiper-based nonparametric loss and apply the approach on a large social network data-set.  However, the details of the deep learning approach are not well described. Some specific comments are given below.\n\n1.Further details on use of 10-fold cross validation need to be discussed including over-fitting aspect.\n2. Details on deep learning, number of hidden layers, number of hidden units, activation functions, weight adjustment details on each learning methods should be included.\n\n3. Conclusion section is very brief and can be expanded by including a discussion on results comparison and  over fitting aspects in cross validation. Use of Kuiper-based nonparametric loss should also be justified as there are other loss functions can be used under these settings.\n", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["Authors provide an interesting loss function approach for clustering using a deep neuralnetwork.", "They optimize Kuiper-based nonparametric loss and apply the approach on a large socialnetwork data-set.", "However, the details of the deep learning approach are not well described.", "Some specific comments are given below.", "1 Further details on use of 10-fold cross valdation need to be discussed including over-fitting aspect.", "2, Details on deep learning, number of hidden layers, number of hidden units, activation functions, weight adjustment details on each learning methods should be included.", "3, Conclusion secion is very brief and can be expanded by including a discussion on results comparison and over fitting aspects in cross valdation.", "Use of Kuiper-based nonparametric loss should alo be justified as there are other loss functions can be used under these settings."], "all_annotations": [{"interpretation": 0, "review_id": "S1QsSa1-M", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1QsSa1-M", "importance": 0, "reproducibility": 1, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "S1QsSa1-M", "importance": 0, "reproducibility": 1, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "S1QsSa1-M", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S1SG_l5gz", "review_text": "This paper proposes to automatically recognize domain names as malicious or benign by deep networks (convnets and RNNs) trained to directly classify the character sequence as such.\n\n\nPros\n\nThe paper addresses an important application of deep networks, comparing the performance of a variety of different types of model architectures.\n\nThe tested networks seem to perform reasonably well on the task.\n\n\nCons\n\nThere is little novelty in the proposed method/models -- the paper is primarily focused on comparing existing models on a new task.\n\nThe descriptions of the different architectures compared are overly verbose -- they are all simple standard convnet / RNN architectures.  The code specifying the models is also excessive for the main text -- it should be moved to an appendix or even left for a code release.\n\nThe comparisons between various architectures are not very enlightening as they aren\u2019t done in a controlled way -- there are a large number of differences between any pair of models so it\u2019s hard to tell where the performance differences come from. It\u2019s also difficult to compare the learning curves among the different models (Fig 1) as they are in separate plots with differently scaled axes.\n\nThe proposed problem is an explicitly adversarial setting and adversarial examples are a well-known issue with deep networks and other models, but this issue is not addressed or analyzed in the paper. (In fact, the intro claims this is an advantage of not using hand-engineered features for malicious domain detection, seemingly ignoring the literature on adversarial examples for deep nets.) For example, in this case an attacker could start with a legitimate domain name and use black box adversarial attacks (or white box attacks, given access to the model weights) to derive a similar domain name that the models proposed here would classify as benign.\n\n\nWhile this paper addresses an important problem, in its current form the novelty and analysis are limited and the paper has some presentation issues.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["This paper proposes to automaticaly recognize domain names as malcious or benign by deep networks (convnets and RNNs) trained to directly classify the character seqence as such.", "Pros The paper addresses an important application of deep networks, comparing the performance of a variety of different types of model architectures.", "The tested networks seem to perform reasonably well on the task.", "Cons There is little novelty in the proposed method/models -- the paper is primarily focused on comparing existing models on a new task.", "The descriptions of the different architectures compared are overly verbose -- they are al simple standard convnet / RNN architectures.", "The code specifying the models is alo excessive for the main text -- it should be moved to an appendix or even left for a code release.", "The comparisons between various architectures are not very enlightening as they aren\u2019t done in a controlled way -- there are a large number of differences between any pair of models so it\u2019s hard to tell where the performance differences come from.", "It\u2019s alo difficult to compare the learning curves among the different models (fig1) as they are in separate plots with differently scald axes.", "The proposed problem is an explicitly adversarialsetting and adversarialexamples are a well-known issue with deep networks and other models, but this issue is not addressed or analzed in the paper.", "(In fact, the intro claims this is an advantage of not using hand-engineered features for malcious domain detection, seemingly ignoring the literature on adversarialexamples for deep nets.)", "For example, in this case an attacker could start with a legitimate domain name and use black box adversarialattacks (or white box attacks, given access to the model weights) to derive a similar domain name that the models proposed here would classify as benign.", "While this paper addresses an important problem, in its current form the novelty and analsis are limited and the paper has some presentation issues."], "all_annotations": [{"interpretation": 0, "review_id": "S1SG_l5gz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1SG_l5gz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1SG_l5gz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1SG_l5gz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1UrbZQ-f", "review_text": "(Score before author revision: 4)\n(Score after author revision: 7)\n\nI think the authors have taken both the feedback of reviewers as well as anonymous commenters thoroughly into account, running several ablations as well as reporting nice results on an entirely new dataset (MultiNLI) where they show how their multi level fusion mechanism improves a baseline significantly. I think this is nice since it shows how their mechanism helps on two different tasks (question answering and natural language inference).\n\nTherefore I would now support accepting this paper.\n\n------------(Original review below) -----------------------\n\nThe authors present an enhancement to the attention mechanism called \"multi-level fusion\" that they then incorporate into a reading comprehension system. It basically takes into account a richer context of the word at different levels in the neural net to compute various attention scores.\n\ni.e. the authors form a vector \"HoW\" (called history of the word), that is defined as a concatenation of several vectors:\n\nHoW_i = [g_i, c_i, h_i^l, h_i^h]\n\nwhere g_i = glove embeddings, c_i = COVE embeddings (McCann et al. 2017), and h_i^l and h_i^h are different LSTM states for that word.\n\nThe attention score is then a function of these concatenated vectors i.e. \\alpha_{ij} = \\exp(S(HoW_i^C, HoW_j^Q))\n\nResults on SQuAD show a small gain in accuracy (75.7->76.0 Exact Match). The gains on the adversarial set are larger but that is because some of the higher performing, more recent baselines don't seem to have adversarial numbers.\n\nThe authors also compare various attention functions (Table 5) showing a particularone (Symmetric + ReLU) works the best. \n\nComments:\n\n-I feel overall the contribution is not very novel.  The general neural architecture that the authors propose in Section 3 is generally quite similar to the large number of neural architectures developed for this dataset (e.g. some combination of attention between question/context and LSTMs over question/context). The only novelty is these \"HoW\" inputs to the extra attention mechanism that takes a richer word representation into account.\n\n-I feel the model is seems overly complicated for the small gain (i.e. 75.7->76.0 Exact Match), especially on a relatively exhausted dataset (SQuAD) that is known to have lots of pecularities (see anonymous comment below). It is possible the gains just come from having more parameters.\n\n-The authors (on page 6) claim that that by running attention multiple times with different parameters but different inputs (i.e. \\alpha_{ij}^l, \\alpha_{ij}^h, \\alpha_{ij}^u) it will learn to attend to \"different regions for different level\". However, there is nothing enforcing this and the gains just probably come from having more parameters/complexity.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["(Score before author revision: 4) (Score after author revision: 7) I think the authors have taken both the feedback of reviewers as well as anonymous commenters thoroughly into account, running severalablations as well as reporting nice results on an entirely new dataset (MultiNLI) where they show how their multi level fusion mechanism improves a baseline significantly.", "I think this is nice since it shows how their mechanism helps on two different tasks (question answering and naturallanguage inference).", "Therefore I would now support accepting this paper.", "------------(Originalreview below) ----------------------- The authors present an enhancement to the attention mechanism caled \"multi-level fusion\" that they then incorporate into a reading comprehension system.", "It basicaly takes into account a richer context of the word at different levels in the neuralnet to compute various attention scores.", "i e the authors form a vector \"HoW\" (caled history of the word), that is defined as a concatenation of severalvectors: HoW_i = [g_i, c_i, h_i^l, h_i^h] where g_i = glove embeddings, c_i = COVE embeddings (McCann et al 2017), and h_i^l and h_i^h are different LSTM states for that word.", "The attention score is then a function of these concatenated vectors i e \\alha_{ij} = \\exp(S(HoW_i^C, HoW_j^Q)) Results on SQuAD show a smal gain in accuracy (75.7->76.0 Exact Match).", "The gains on the adversarialset are larger but that is because some of the higher performing, more recent baselines don't seem to have adversarialnumbers.", "The authors alo compare various attention functions (Table 5) showing a particularone (Symmetric + ReLU) works the best.", "Comments: -I feel overal the contribution is not very novel.", "The generalneuralarchitecture that the authors propose in secion 3 is generaly quite similar to the large number of neuralarchitectures developed for this dataset (e g some combination of attention between question/context and LSTMs over question/context).", "The only novelty is these \"HoW\" inputs to the extra attention mechanism that takes a richer word representation into account.", "-I feel the model is seems overly complicated for the smal gain (i e 75.7->76.0 Exact Match), especialy on a relatively exhausted dataset (SQuAD) that is known to have lots of pecularities (see anonymous comment below).", "It is possible the gains just come from having more parameters.", "-The authors (on page 6) claim that that by running attention multiple times with different parameters but different inputs (i e \\alha_{ij}^l, \\alha_{ij}^h, \\alha_{ij}^u) it will learn to attend to \"different regions for different level\".", "However, there is nothing enforcing this and the gains just probably come from having more parameters/complexity."], "all_annotations": [{"interpretation": 1, "review_id": "S1UrbZQ-f", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "S1UrbZQ-f", "importance": null, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "S1UrbZQ-f", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1UrbZQ-f", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S1VwmoFxz", "review_text": "In this paper, the authors investigate variance reduction techniques for agents with multi-dimensional policy outputs, in particular when they are conditionally independent ('factored'). With the increasing focus on applying RL methods to continuous control problems and RTS type games, this is an important problem and this technique seems like an important addition to the RL toolbox. The paper is well written, the method is easy to implement, and the algorithm seems to have clear positive impact on the presented experiments.\n\n- The derivations in pages 4-6 are somewhat disconnected from the rest of the paper: the optimal baseline derivation is very standard (even if adapted to the slightly different situation situated here), and for reasons highlighted by the authors in this paper, they are not often used; the 'marginalized' baseline is more common, and indeed, the authors adopt this one as well. In light of this (and of the paper being quite a bit over the page limit)- is this material (4.2->4.4) mostly not better suited for the appendix? Same for section 4.6 (which I believe is not used in the experiments).\n\n- The experimental section is very strong; regarding the partial observability experiments, assuming actions are here factored as well, I could see four baselines \n(two choices for whether the baseline has access to the goal location or not, and two choices for whether the baseline has access to the vector $a_{-i}$). It's not clear which two baselines are depicted in 5b - is it possible to disentangle the effect of providing $a_{-i}$ and the location of the hole to the baseline?\n\n(side note: it is an interesting idea to include information not available to the agent as input to the baseline though it does feel a bit 'iffy' ; the agent requires information to train, but is not provided the information to act.  Out of curiosity, is it intended as an experiment to verify the need for better baselines? Or as a 'fair' training procedure?)\n\n- Minor: in equation 2- is the correct exponent not t'?  Also since $\\rho_\\pi$ is define with a scaling $(1-\\gamma)$ (to make it an actual distribution), I believe the definition of $\\eta$ should also be multiplied by $(1-\\gamma)$ (as well as equation 2).", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["In this paper, the authors investigate variance reduction techniques for agents with multi-dimensionalpolicy outputs, in particular when they are conditionaly independent ('factored').", "With the increasing focus on applying RL methods to continuous control problems and RTS type games, this is an important problem and this technique seems like an important addition to the RL toolbox.", "The paper is well written, the method is easy to implement, and the alorithm seems to have clear positive impact on the presented experiments.", "- The derivations in pages 4-6 are somewhat disconnected from the rest of the paper: the optimalbaseline derivation is very standard (even if adapted to the slightly different situation situated here), and for reasons highlighted by the authors in this paper, they are not often used; the 'marginalzed' baseline is more common, and indeed, the authors adopt this one as well.", "In light of this (and of the paper being quite a bit over the page limit)- is this material(4 2->4 4) mostly not better suited for the appendix?", "Same for secion 4 6 (which I believe is not used in the experiments).", "- The experimentalsecion is very strong; regarding the partialobservability experiments, assuming actions are here factored as well, I could see four baselines (two choices for whether the baseline has access to the goallocation or not, and two choices for whether the baseline has access to the vector $a_{-i}$).", "It's not clear which two baselines are depicted in 5b - is it possible to disentangle the effect of providing $a_{-i}$ and the location of the hole to the baseline?", "(side note: it is an interesting idea to include information not available to the agent as input to the baseline though it does feel a bit 'iffy' ; the agent reqires information to train, but is not provided the information to act.", "Out of curiosity, is it intended as an experiment to verify the need for better baselines?", "Or as a 'fair' training procedure?)", "- Minor: in eqation 2- is the correct exponent not t'?", "Also since $\\rho_\\pi$ is define with a scalng $(1-\\gamma)$ (to make it an actualdistribution), I believe the definition of $\\eta$ should alo be multiplied by $(1-\\gamma)$ (as well as eqation 2)."], "all_annotations": [{"interpretation": 0, "review_id": "S1VwmoFxz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1VwmoFxz", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, {"interpretation": 1, "review_id": "S1VwmoFxz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1VwmoFxz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1_Zyk9xG", "review_text": "Neal (1994) showed that a one hidden layer Bayesian neural network, under certain conditions, converges to a Gaussian process as the number of hidden units approaches infinity. Neal (1994) and Williams (1997) derive the resulting kernel functions for such Gaussian processes when the neural networks have certain transfer functions.\n\nSimilarly, the authors show an analogous result for deep neural networks with multiple hidden layers and an infinite number of hidden units per layer, and show the form of the resulting kernel functions. For certain transfer functions, the authors perform a numerical integration to compute the resulting kernels. They perform experiments on MNIST and CIFAR-10, doing classification by scaled regression. \n\nOverall, the work is an interesting read, and a nice follow-up to Neal\u2019s earlier observations about 1 hidden layer neural networks. It combines several insights into a nice narrative about infinite Bayesian deep networks. However, the practical utility, significance, and novelty of this work -- in its current form -- are questionable, and the related work sections, analysis, and experiments should be significantly extended. \n\n\nIn detail:\n\n(1) This paper misses some obvious connections and references, such as \n* Krauth et. al (2017): \u201cExploring the capabilities and limitations of Gaussian process models\u201d for recursive kernels with GPs.\n* Hazzan & Jakkola (2015): \u201cSteps Toward Deep Kernel Methods from Infinite Neural Networks\u201d for GPs corresponding to NNs with more than one hidden layer.\n* The growing body of work on deep kernel learning, which \u201ccombines the inductive biases and representation learning abilities of deep neural networks with the non-parametric flexibility of Gaussian processes\u201d. E.g.: (i) \u201cDeep Kernel Learning\u201d (AISTATS 2016); (ii) \u201cStochastic Variational Deep Kernel Learning\u201d (NIPS 2016); (iii) \u201cLearning Scalable Deep Kernels with Recurrent Structure\u201d (JMLR 2017). \n\nThese works should be discussed in the text.\n\n(2) Moreover, as the authors rightly point out, covariance functions of the form used in (4) have already been proposed. It seems the novelty here is mainly the empirical exploration (will return to this later), and numerical integration for various activation functions. That is perfectly fine -- and this work is still valuable. However, the statement \u201crecently, kernel functions for multi-layer random neural networks have been developed, but only outside of a Bayesian framework\u201d is incorrect. For example, Hazzan & Jakkola (2015) in \u201cSteps Toward Deep Kernel Methods from Infinite Neural Networks\u201d consider GP constructions with more than one hidden layer. Thus the novelty of this aspect of the paper is overstated. \n\nSee also comment [*] later on the presentation. In any case, the derivation for computing the covariance function (4) of a multi-layer network is a very simple reapplication of the procedure in Neal (1994). What is less trivial is estimating (4) for various activations, and that seems to the major methodological contribution. \n\nAlso note that multidimensional CLT here is glossed over. It\u2019s actually really unclear whether the final limit will converge to a multidimensional Gaussian with that kernel without stronger conditions.  This derivation should be treated more thoroughly and carefully.\n\n(3) Most importantly, in this derivation, we see that the kernels lose the interesting representations that come from depth in deep neural networks. Indeed, Neal himself says that in the multi-output settings, all the outputs become uncorrelated. Multi-layer representations are mostly interesting because each layer shares hidden basis functions. Here, the sharing is essentially meaningless, because the variance of the weights in this derivation shrinks to zero. \nIn Neal\u2019s case, the method was explored for single output regression, where the fact that we lose this sharing of basis functions may not be so restrictive. However, these assumptions are very constraining for multi-output classification and also interesting multi-output regressions.\n\n[*]: Generally, in reading the abstract and introduction, we get the impression that this work somehow allows us to use really deep and infinitely wide neural networks as Gaussian processes, and even without the pain of training these networks. \u201cDeep neural networks without training deep networks\u201d. This is not an accurate portrayal. The very title \u201cDeep neural networks as Gaussian processes\u201d is misleading, since it\u2019s not really the deep neural networks that we know and love. In fact, you lose valuable structure when you take these limits, and what you get is very different than a standard deep neural network. In this sense, the presentation should be re-worked.\n\n(4) Moreover, neural networks are mostly interesting because they learn the representation. To do something similar with GPs, we would need to learn the kernel. But here, essentially no kernel learning is happening. The kernel is fixed. \n\n(5) Given the above considerations, there is great importance in understanding the practical utility of the proposed approach through a detailed empirical evaluation. In other words, how structured is this prior and does it really give us some of the interesting properties of deep neural networks, or is it mostly a cute mathematical trick?  \n\nUnfortunately, the empirical evaluation is very preliminary, and provides no reassurance that this approach will have any practical relevance:\n(i) Directly performing regression on classification problems is very heuristic and unnecessary.\n(ii) Given the loss of dependence between neurons in this approach, it makes sense to first explore this method on single output regression, where we will likely get the best idea of its useful properties and advantages. \n(iii) The results on CIFAR10 are very poor. We don\u2019t need to see SOTA performance to get some useful insights in comparing for example parametric vs non-parametric, but 40% more error than SOTA makes it very hard to say whether any of the observed patterns hold weight for more competitive architectural choices. \n\nA few more minor comments:\n(i) How are you training a GP exactly on 50k training points? Even storing a 50k x 50k matrix requires about 20GB of RAM. Even with the best hardware, computing the marginal likelihood dozens of times to learn hyperparameters would be near impossible. What are the runtimes?\n(ii) \"One benefit in using the GP is due to its Bayesian nature, so that predictions have uncertainty estimates (Equation (9)).\u201d  The main benefit of the GP is not the uncertainty in the predictions, but the marginal likelihood which is useful for kernel learning.", "gold_annotation": null, "score": 4.5, "tokenized_review_text": ["Neal(1994) showed that a one hidden layer Bayesian neuralnetwork, under certain conditions, converges to a Gaussian process as the number of hidden units approaches infinity.", "Neal(1994) and Williams (1997) derive the resulting kernel functions for such Gaussian processes when the neuralnetworks have certain transfer functions.", "Similarly, the authors show an analgous result for deep neuralnetworks with multiple hidden layers and an infinite number of hidden units per layer, and show the form of the resulting kernel functions.", "For certain transfer functions, the authors perform a numericalintegration to compute the resulting kernels.", "They perform experiments on MNIST and CIFAR-10, doing classification by scald regression.", "Overal, the work is an interesting read, and a nice follow-up to Neals earlier observations about 1 hidden layer neuralnetworks.", "It combines severalinsights into a nice narrative about infinite Bayesian deep networks.", "However, the practicalutility, significance, and novelty of this work -- in its current form -- are questionable, and the related work secions, analsis, and experiments should be significantly extended.", "In detail: (1) This paper misses some obvious connections and references, such as * Krauth et.", "al(2017): \u201cExploring the capabilities and limitations of Gaussian process models\u201d for recursive kernels with GPs.", "* Hazzan & Jakkola (2015): \u201cSteps Toward Deep Kernel Methods from Infinite NeuralNetworks\u201d for GPs corresponding to NNs with more than one hidden layer.", "* The growing body of work on deep kernel learning, which \u201ccombines the inductive biases and representation learning abilities of deep neuralnetworks with the non-parametric flexibility of Gaussian processes\u201d.", "E g : (i) \u201cDeep Kernel Learning\u201d (AISTATS 2016); (ii) \u201cStochastic VariationalDeep Kernel Learning\u201d (NIPS 2016); (iii) \u201cLearning Scalble Deep Kernels with Recurrent Structure\u201d (JMLR 2017).", "These works should be discussed in the text.", "(2) Moreover, as the authors rightly point out, covariance functions of the form used in (4) have aleady been proposed.", "It seems the novelty here is mainly the empiricalexploration (will return to this later), and numericalintegration for various activation functions.", "That is perfectly fine -- and this work is still valable.", "However, the statement \u201crecently, kernel functions for multi-layer random neuralnetworks have been developed, but only outside of a Bayesian framework\u201d is incorrect.", "For example, Hazzan & Jakkola (2015) in \u201cSteps Toward Deep Kernel Methods from Infinite NeuralNetworks\u201d consider GP constructions with more than one hidden layer.", "Thus the novelty of this aspect of the paper is overstated.", "See alo comment [*] later on the presentation.", "In any case, the derivation for computing the covariance function (4) of a multi-layer network is a very simple reapplication of the procedure in Neal(1994).", "What is less trivialis estimating (4) for various activations, and that seems to the major methodologicalcontribution.", "Also note that multidimensionalCLT here is glossed over.", "It\u2019s actualy realy unclear whether the finallimit will converge to a multidimensionalGaussian with that kernel without stronger conditions.", "This derivation should be treated more thoroughly and carefully.", "(3) Most importantly, in this derivation, we see that the kernels lose the interesting representations that come from depth in deep neuralnetworks.", "Indeed, Nealhimself says that in the multi-output settings, al the outputs become uncorrelated.", "Multi-layer representations are mostly interesting because each layer shares hidden basis functions.", "Here, the sharing is essentialy meaningless, because the variance of the weights in this derivation shrinks to zero.", "In Neals case, the method was explored for single output regression, where the fact that we lose this sharing of basis functions may not be so restrictive.", "However, these assumptions are very constraining for multi-output classification and alo interesting multi-output regressions.", "[*]: Generaly, in reading the abstract and introduction, we get the impression that this work somehow alows us to use realy deep and infinitely wide neuralnetworks as Gaussian processes, and even without the pain of training these networks.", "\u201cDeep neuralnetworks without training deep networks\u201d.", "This is not an accurate portrayal The very title \u201cDeep neuralnetworks as Gaussian processes\u201d is misleading, since it\u2019s not realy the deep neuralnetworks that we know and love.", "In fact, you lose valable structure when you take these limits, and what you get is very different than a standard deep neuralnetwork.", "In this sense, the presentation should be re-worked.", "(4) Moreover, neuralnetworks are mostly interesting because they learn the representation.", "To do something similar with GPs, we would need to learn the kernel.", "But here, essentialy no kernel learning is happening.", "The kernel is fixed.", "(5) Given the above considerations, there is great importance in understanding the practicalutility of the proposed approach through a detailed empiricalevalation.", "In other words, how structured is this prior and does it realy give us some of the interesting properties of deep neuralnetworks, or is it mostly a cute mathematicaltrick?", "Unfortunately, the empiricalevalation is very preliminary, and provides no reassurance that this approach will have any practicalrelevance: (i) Directly performing regression on classification problems is very heuristic and unnecessary.", "(ii) Given the loss of dependence between neurons in this approach, it makes sense to first explore this method on single output regression, where we will likely get the best idea of its useful properties and advantages.", "(iii) The results on CIFAR10 are very poor.", "We don\u2019t need to see SOTA performance to get some useful insights in comparing for example parametric vs non-parametric, but 40% more error than SOTA makes it very hard to say whether any of the observed patterns hold weight for more competitive architecturalchoices.", "A few more minor comments: (i) How are you training a GP exactly on 50k training points?", "Even storing a 50k x 50k matrix reqires about 20GB of RAM.", "Even with the best hardware, computing the marginallikelihood dozens of times to learn hyperparameters would be near impossible.", "What are the runtimes?", "(ii) \"One benefit in using the GP is due to its Bayesian nature, so that predictions have uncertainty estimates (eqation (9)).\u201d The main benefit of the GP is not the uncertainty in the predictions, but the marginallikelihood which is useful for kernel learning."], "all_annotations": [{"interpretation": 1, "review_id": "S1_Zyk9xG", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "S1_Zyk9xG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 5, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "S1_Zyk9xG", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1_Zyk9xG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1c4VEXWz", "review_text": "This paper provides an overview of the Deep Voice 3 text-to-speech system. It describes the system in a fair amount of detail and discusses some trade-offs w.r.t. audio quality and computational constraints. Some experimental validation of certain architectural choices is also provided.\n\nMy main concern with this work is that it reads more like a tech report: it describes the workings and design choices behind one particular system in great detail, but often these choices are simply stated as fact and not really motivated, or compared to alternatives. This makes it difficult to tell which of these aspects are crucial to get good performance, and which are just arbitrary choices that happen to work okay.\n\nAs this system was clearly developed with actual deployment in mind (and not purely as an academic pursuit), all of these choices must have been well-deliberated. It is unfortunate that the paper doesn't demonstrate this. I think this makes the work less interesting overall to an ICLR audience. That said, it is perhaps useful to get some insight into what types of models are actually used in practice.\n\nAn exception to this is the comparison of \"converters\", model components that convert the model's internal representation of speech into waveforms. This comparison is particularly interesting because some of the results are remarkable, i.e. Griffin-Lim spectrogram inversion and the WORLD vocoder achieving very similar MOS scores in some cases (Table 2). I wish there would be more of that kind of thing in the paper. The comparison of attention mechanisms is also useful.\n\nI'm on the fence as I think it is nice to get some insight into a practical pipeline which benefits from many current trends in deep learning research (autoregressive models, monotonic attention, ...), but I also feel that the paper is a bit meager when it comes to motivating all the architectural aspects. I think the paper is well written so I've tentatively recommended acceptance.\n\n\nOther comments:\n\n- The separation of the \"decoder\" and \"converter\" stage is not entirely clear to me. It seems that the decoder is trained to predict spectrograms autoregressively, but its final layer is then discarded and its hidden representation is then used as input to the converter stage instead? The motivation for doing this is unclear to me, surely it would be better to train everything end-to-end, including the converter? This seems like an unnecessary detour, what's the reasoning behind this?\n\n- At the bottom of page 2 it is said that \"the whole model is trained end-to-end, excluding the vocoder\", which I think is an unfortunate turn of phrase. It's either end-to-end, or it isn't.\n\n- In Section 3.3, the point of mixing of h_k and h_e is unclear to me. Why is this done?\n\n- The gated linear unit in Figure 2a shows that speaker embedding information is only injected in the linear part. Has this been experimentally validated to work better than simpler mechanisms such as adding conditioning-dependent biases/gains?\n\n- When the decoder is trained to do autoregressive prediction of spectrograms, is it autoregressive only in time, or also in frequency? I'm guessing it's the former, but this means there is an implicit independence assumption (the intensities in different frequency bins are conditionally independent, given all past timesteps). Has this been taken into consideration? Maybe it doesn't matter because the decoder is never used directly anyway, and this is only a \"feature learning\" stage of sorts?\n\n- Why use the L1 loss on spectrograms?\n\n- The recent work on Parallel WaveNet may allow for speeding up WaveNet when used as a vocoder, this could be worth looking into seeing as inference speed is used as an argument to choose different vocoder strategies (with poorer audio quality as a result).\n\n- The title heavily emphasizes that this model can do multi-speaker TTS with many (2000) speakers, but that seems to be only a minor aspect that is only discussed briefly in the paper. And it is also something that preceding systems were already capable of (although maybe it hasn't been tested with a dataset of this size before). It might make sense to rethink the title to emphasize some of the more relevant and novel aspects of this work.\n\n\n----\n\nRevision: the authors have adequately addressed quite a few instances where I feel motivations / explanations were lacking, so I'm happy to increase my rating from 6 to 7. I think the proposed title change would also be a good idea.", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["This paper provides an overview of the Deep Voice 3 text-to-speech system.", "It describes the system in a fair amount of detail and discusses some trade-offs w r t audio qualty and computationalconstraints.", "Some experimentalvaldation of certain architecturalchoices is alo provided.", "My main concern with this work is that it reads more like a tech report: it describes the workings and design choices behind one particular system in great detail, but often these choices are simply stated as fact and not realy motivated, or compared to alernatives.", "This makes it difficult to tell which of these aspects are crucialto get good performance, and which are just arbitrary choices that happen to work okay.", "As this system was clearly developed with actualdeployment in mind (and not purely as an academic pursuit), al of these choices must have been well-deliberated.", "It is unfortunate that the paper doesn't demonstrate this.", "I think this makes the work less interesting overal to an ICLR audience.", "That said, it is perhaps useful to get some insight into what types of models are actualy used in practice.", "An exception to this is the comparison of \"converters\", model components that convert the model's internalrepresentation of speech into waveforms.", "This comparison is particularly interesting because some of the results are remarkable, i e Griffin-Lim spectrogram inversion and the WORLD vocoder achieving very similar MOS scores in some cases (Table 2).", "I wish there would be more of that kind of thing in the paper.", "The comparison of attention mechanisms is alo useful.", "I'm on the fence as I think it is nice to get some insight into a practicalpipeline which benefits from many current trends in deep learning research (autoregressive models, monotonic attention, ...), but I alo feel that the paper is a bit meager when it comes to motivating al the architecturalaspects.", "I think the paper is well written so I've tentatively recommended acceptance.", "Other comments: - The separation of the \"decoder\" and \"converter\" stage is not entirely clear to me.", "It seems that the decoder is trained to predict spectrograms autoregressively, but its finallayer is then discarded and its hidden representation is then used as input to the converter stage instead?", "The motivation for doing this is unclear to me, surely it would be better to train everything end-to-end, including the converter?", "This seems like an unnecessary detour, what's the reasoning behind this?", "- At the bottom of page 2 it is said that \"the whole model is trained end-to-end, excluding the vocoder\", which I think is an unfortunate turn of phrase.", "It's either end-to-end, or it isn't - In secion 3 3, the point of mixing of h_k and h_e is unclear to me.", "Why is this done?", "- The gated linear unit in figre 2a shows that speaker embedding information is only injected in the linear part.", "Has this been experimentaly valdated to work better than simpler mechanisms such as adding conditioning-dependent biases/gains?", "- When the decoder is trained to do autoregressive prediction of spectrograms, is it autoregressive only in time, or alo in freqency?", "I'm guessing it's the former, but this means there is an implicit independence assumption (the intensities in different freqency bins are conditionaly independent, given al past timesteps).", "Has this been taken into consideration?", "Maybe it doesn't matter because the decoder is never used directly anyway, and this is only a \"feature learning\" stage of sorts?", "- Why use the L1 loss on spectrograms?", "- The recent work on Paralel WaveNet may alow for speeding up WaveNet when used as a vocoder, this could be worth looking into seeing as inference speed is used as an argument to choose different vocoder strategies (with poorer audio qualty as a result).", "- The title heavily emphasizes that this model can do multi-speaker TTS with many (2000) speakers, but that seems to be only a minor aspect that is only discussed briefly in the paper.", "And it is alo something that preceding systems were aleady capable of (alhough maybe it hasn't been tested with a dataset of this size before).", "It might make sense to rethink the title to emphasize some of the more relevant and novel aspects of this work.", "---- Revision: the authors have adeqately addressed quite a few instances where I feel motivations / explanations were lacking, so I'm happy to increase my rating from 6 to 7, I think the proposed title change would alo be a good idea."], "all_annotations": [{"interpretation": 1, "review_id": "S1c4VEXWz", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1c4VEXWz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "S1c4VEXWz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1c4VEXWz", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1ck4rYxM", "review_text": "[Overview]\n\nIn this paper, the authors proposed a novel model called MemoryGAN, which integrates memory network with GAN. As claimed by the authors, MemoryGAN is aimed at addressing two problems of GAN training: 1) difficult to model the structural discontinuity between disparate classes in the latent space; 2) catastrophic forgetting problem during the training of discriminator about the past synthesized samples by the generator. It exploits the life-long memory network and adapts it to GAN. It consists of two parts, discriminative memory network (DMN) and Memory Conditional Generative Network (MCGN). DMN is used for discriminating input samples by integrating the memory learnt in the memory network, and MCGN is used for generating images based on random vector and the sampled memory from the memory network. In the experiments, the authors evaluated memoryGAN on three datasets, CIFAR-10, affine-MNIST and Fashion-MNIST, and demonstrated the superiority to previous models. Through ablation study, the authors further showed the effects of separate components in memoryGAN. \n\n[Strengths]\n\n1. This paper is well-written. All modules in the proposed model and the experiments were explained clearly. I enjoyed much to read the paper.\n\n2. The paper presents a novel method called MemoryGAN for GAN training. To address the two infamous problems mentioned in the paper, the authors proposed to integrate a memory network into GAN. Through memory network, MemoryGAN can explicitly learn the data distribution of real images and fake images. I think this is a very promising and meaningful extension to the original GAN. \n\n3. With MemoryGAN, the authors achieved best Inception Score on CIFAR-10. By ablation study, the authors demonstrated each part of the model helps to improve the final performance.\n\n[Comments]\n\nMy comments are mainly about the experiment part:\n\n1. In Table 2, the authors show the Inception Score of images generated by DCGAN at the last row. On CIFAR-10, it is ~5.35. As the authors mentioned, removing EM, MCGCN and Memory will result in a conventional DCGAN. However, as far as I know, DCGAN could achieve > 6.5 Inception Score in general.  I am wondering what makes such a big difference between the reported numbers in this paper and other papers?\n\n2. In the experiments, the authors set N = 16,384, and M = 512, and z is with dimension 16. I did not understand why the memory size is such large. Take CIFAR-10 as the example, its training set contains 50k images. Using such a large memory size, each memory slot will merely count for several samples. Is a large memory size necessary to make MemoryGAN work? If not, the authors should also show ablated study on the effect of different memory size; If it is true, please explain why is that. Also, the authors should mention the training time compared with DCGAN. Updating memory with such a large size seems very time-consuming.\n\n3. Still on the memory size in this model. I am curious about the results if the size is decreased to the same or comparable number of image categories in the training set. As the author claimed, if the memory network could learn to cluster training data into different category, we should be able to see some interesting results by sampling the keys and generate categoric images.\n\n4. The paper should be compared with InfoGAN (Chen et al. 2016), and the authors should explain the differences between two models in the related work. Similar to MemoryGAN, InfoGAN also did not need any data annotations, but could learn the latent code flexibly.\n\n[Summary]\n\nThis paper proposed a new model called MemoryGAN for image generation. It combined memory network with GAN, and achieved state-of-art performance on CIFAR-10. The arguments that MemoryGAN could solve the two infamous problem make sense. As I mentioned above, I did not understand why the authors used such large memory size. More explanations and experiments  should be conducted to justify this setting. Overall, I think MemoryGAN opened a new direction of GAN and worth to further explore.\n\n", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["[Overview] In this paper, the authors proposed a novel model caled MemoryGAN, which integrates memory network with GAN.", "As claimed by the authors, MemoryGAN is aimed at addressing two problems of GAN training: 1) difficult to model the structuraldiscontinuity between disparate classes in the latent space; 2) catastrophic forgetting problem during the training of discriminator about the past synthesized samples by the generator.", "It exploits the life-long memory network and adapts it to GAN.", "It consists of two parts, discriminative memory network (DMN) and Memory ConditionalGenerative Network (MCGN).", "DMN is used for discriminating input samples by integrating the memory learnt in the memory network, and MCGN is used for generating images based on random vector and the sampled memory from the memory network.", "In the experiments, the authors evalated memoryGAN on three datasets, CIFAR-10, affine-MNIST and Fashion-MNIST, and demonstrated the superiority to previous models.", "Through ablation study, the authors further showed the effects of separate components in memoryGAN.", "[Strengths] 1, This paper is well-written.", "All modules in the proposed model and the experiments were explained clearly.", "I enjoyed much to read the paper.", "2, The paper presents a novel method caled MemoryGAN for GAN training.", "To address the two infamous problems mentioned in the paper, the authors proposed to integrate a memory network into GAN.", "Through memory network, MemoryGAN can explicitly learn the data distribution of realimages and fake images.", "I think this is a very promising and meaningful extension to the originalGAN.", "3, With MemoryGAN, the authors achieved best Inception Score on CIFAR-10, By ablation study, the authors demonstrated each part of the model helps to improve the finalperformance.", "[Comments] My comments are mainly about the experiment part: 1, In Table 2, the authors show the Inception Score of images generated by DCGAN at the last row.", "On CIFAR-10, it is ~5 35, As the authors mentioned, removing EM, MCGCN and Memory will result in a conventionalDCGAN.", "However, as far as I know, DCGAN could achieve > 6 5 Inception Score in general I am wondering what makes such a big difference between the reported numbers in this paper and other papers?", "2, In the experiments, the authors set N = 16,384, and M = 512, and z is with dimension 16, I did not understand why the memory size is such large.", "Take CIFAR-10 as the example, its training set contains 50k images.", "Using such a large memory size, each memory slot will merely count for severalsamples.", "Is a large memory size necessary to make MemoryGAN work?", "If not, the authors should alo show ablated study on the effect of different memory size; If it is true, please explain why is that.", "Also, the authors should mention the training time compared with DCGAN.", "Updating memory with such a large size seems very time-consuming.", "3, Still on the memory size in this model.", "I am curious about the results if the size is decreased to the same or comparable number of image categories in the training set.", "As the author claimed, if the memory network could learn to cluster training data into different category, we should be able to see some interesting results by sampling the keys and generate categoric images.", "4, The paper should be compared with InfoGAN (Chen et al 2016), and the authors should explain the differences between two models in the related work.", "Similar to MemoryGAN, InfoGAN alo did not need any data annotations, but could learn the latent code flexibly.", "[Summary] This paper proposed a new model caled MemoryGAN for image generation.", "It combined memory network with GAN, and achieved state-of-art performance on CIFAR-10, The arguments that MemoryGAN could solve the two infamous problem make sense.", "As I mentioned above, I did not understand why the authors used such large memory size.", "More explanations and experiments should be conducted to justify this setting.", "Overal, I think MemoryGAN opened a new direction of GAN and worth to further explore."], "all_annotations": [{"interpretation": 0, "review_id": "S1ck4rYxM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1ck4rYxM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1ck4rYxM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1ck4rYxM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S1dRXMqxG", "review_text": "In this paper authors are summarizing their work on building a framework for automated neural network (NN) construction across multiple tasks simultaneously. \n\nThey present initial results on the performance of their framework called Multitask Neural Model Search (MNMS) controller. The idea behind building such a framework is motivated by the successes of recently proposed reinforcement based approaches for finding the best NN architecture across the space of all possible architectures. Authors cite the Neural Architecture Search (NAS) framework as an example of such a framework that yields better results compared to NN architectures configured by humans. \n\nOverall I think that the idea is interesting and the work presented in this paper is very promising. Given the depth of the empirical analysis presented the work still feels that it\u2019s in its early stages. In its current state and format the major issue with this work is the lack of more in-depth performance analysis which would help the reader draw more solid conclusions about the generalization of the approach.\n\nAuthors use two text classification tasks from the NLP domain to showcase the benefits of their proposed architecture. It would be good if they could expand and analyze how well does their framework generalizes across other non-binary tasks, tasks in other domains and different NNs. This is especially the case for the transfer learning task. \n\nIn the NAS overview section, readers would benefit more if authors spend more time in outlining the RL detail used in the original NAS framework instead of Figure 1 which looks like a space filler. \n\nAcross the two NLP tasks authors show that MNMS models trained simultaneously give better performance than hand tuned architectures. In addition, on the transfer learning evaluation approach they showcase the benefit of using the proposed framework in terms of the initially retrieved architecture and the number of iterations required to obtain the best performing one. \nFor better clarity figures 3 and 5 should be made bigger. \nWhat is LSS in figure 4?", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["In this paper authors are summarizing their work on building a framework for automated neuralnetwork (NN) construction across multiple tasks simultaneously.", "They present initialresults on the performance of their framework caled Multitask NeuralModel Search (MNMS) controller.", "The idea behind building such a framework is motivated by the successes of recently proposed reinforcement based approaches for finding the best NN architecture across the space of al possible architectures.", "Authors cite the NeuralArchitecture Search (NAS) framework as an example of such a framework that yields better results compared to NN architectures configred by humans.", "Overal I think that the idea is interesting and the work presented in this paper is very promising.", "Given the depth of the empiricalanalsis presented the work still feels that it\u2019s in its early stages.", "In its current state and format the major issue with this work is the lack of more in-depth performance analsis which would help the reader draw more solid conclusions about the generalzation of the approach.", "Authors use two text classification tasks from the NLP domain to showcase the benefits of their proposed architecture.", "It would be good if they could expand and analze how well does their framework generalzes across other non-binary tasks, tasks in other domains and different NNs.", "This is especialy the case for the transfer learning task.", "In the NAS overview secion, readers would benefit more if authors spend more time in outlining the RL detail used in the originalNAS framework instead of figre 1 which looks like a space filler.", "Across the two NLP tasks authors show that MNMS models trained simultaneously give better performance than hand tuned architectures.", "In addition, on the transfer learning evalation approach they showcase the benefit of using the proposed framework in terms of the initialy retrieved architecture and the number of iterations reqired to obtain the best performing one.", "For better clarity figres 3 and 5 should be made bigger.", "What is LSS in figre 4?"], "all_annotations": [{"interpretation": 0, "review_id": "S1dRXMqxG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1dRXMqxG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "S1dRXMqxG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1dRXMqxG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1gH28vgM", "review_text": "1) Summary\nThis paper proposed a new method for predicting multiple future frames in videos. A new formulation is proposed where the frames\u2019 inherent noise is modeled separate from the uncertainty of the future. This separation allows for directly modeling the stochasticity in the sequence through a random variable z ~ p(z)  where the posterior  q(z | past and future frames) is approximated by a neural network, and as a result, sampling of a random future is possible through sampling from the prior p(z) during testing. The random variable z can be modeled in a time-variant and time-invariant way. Additionally, this paper proposes a training procedure to prevent their method from ignoring the stochastic phenomena modeled by z. In the experimental section, the authors highlight the advantages of their method in 1) a synthetic dataset of shapes meant to clearly show the stochasticity in the prediction, 2) two robotic arm datasets for video prediction given and not given actions, and 3) A challenging human action dataset in which they perform future prediction only given previous frames.\n\n\n\n2) Pros:\n+ Novel/Sound future frame prediction formulation and training for modeling the stochasticity of future prediction.\n+ Experiments on the synthetic shapes and robotic arm datasets highlight the proposed method\u2019s power of multiple future frame prediction possible.\n+ Good analysis on the number of samples improving the chance of outputting the correct future, the modeling power of the posterior for reconstructing the future, and a wide variety of qualitative examples.\n+ Work is significant for the problem of modeling the stochastic nature of future frame prediction in videos.\n\n\n\n\n3) Cons:\nApproximate posterior in non-synthetic datasets:\nThe variable z seems to not be modeling the future very well. In the robot arm qualitative experiments, the robot motion is well modeled, however, the background is not. Given that for the approximate posterior computation the entire sequence is given (e.g. reconstruction is performed), I would expect the background motion to also be modeled well. This issue is more evident in the Human 3.6M experiments, as it seems to output blurriness regardless of the true future being observed. This problem may mean the method is failing to model a large variety of objects and clearly works for the robotic arm because a very similar large shape (e.g. robot arm) is seen in the training data. Do you have any comments on this?\n\n\n\nFinn et al 2016 PNSR performance on Human 3.6M:\nIs the same exact data, pre-processing, training, and architecture being utilized? In her paper, the PSNR for the first timestep on Human 3.6M is about 41 (maybe 42?)  while in this paper it is 38.\n\n\n\nAdditional evaluation on Human 3.6M:\nPSNR is not a good evaluation metric for frame prediction as it is biased towards blurriness, and also SSIM does not give us an objective evaluation in the sense of semantic quality of predicted frames. It would be good if the authors present additional quantitative evaluation to show that the predicted frames contain useful semantic information [1, 2, 3, 4]. For example, evaluating the predicted frames for the Human 3.6M dataset to see if the human is still detectable in the image or if the expected action is being predicted could be useful to verify that the predicted frames contain the expected meaningful information compared to the baselines.\n\n\n\nAdditional comments:\nAre all 15 actions being used for the Human 3.6M experiments? If so, the fact of the time-invariant model performs better than the time-variant one may not be the consistent action being performed (last sentence of 5.2). The motion performed by the actors in each action highly overlaps (talking on the phone action may go from sitting to walking a little to sitting again, and so on). Unless actions such as walking and discussion were only used, it is unlikely the time-invariant z is performing better because of consistent action. Do you have any comments on this?\n\n\n\n4) Conclusion\nThis paper proposes an interesting novel approach for predicting multiple futures in videos, however, the results are not fully convincing in all datasets. If the authors can provide additional quantitative evaluation besides PSNR and SSIM (e.g. evaluation on semantic quality), and also address the comments above, the current score will improve.\n\n\n\nReferences:\n[1] Emily Denton and Vighnesh Birodkar. Unsupervised Learning of Disentangled Representations from Video. In NIPS, 2017.\n[2] Ruben Villegas, Jimei Yang, Yuliang Zou, Sungryull Sohn, Xunyu Lin, and Honglak Lee. Learning to generate long-term future via hierarchical prediction. In ICML, 2017.\n[3] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive Growing of GANs for Improved Quality, Stability, and Variation. arXiv preprint arXiv:1710.10196, 2017.\n[4] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved Techniques for Training GANs. In NIPS, 2017.\n\n\nRevised review:\nGiven the authors' thorough answers to my concerns, I have decided to change my score. I would like to thank the authors for a very nice paper that will definitely help the community towards developing better video prediction algorithms that can now predict multiple futures.", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["1) Summary This paper proposed a new method for predicting multiple future frames in videos.", "A new formulation is proposed where the frames\u2019 inherent noise is modeled separate from the uncertainty of the future.", "This separation alows for directly modeling the stochasticity in the seqence through a random variable z ~ p(z) where the posterior q(z | past and future frames) is approximated by a neuralnetwork, and as a result, sampling of a random future is possible through sampling from the prior p(z) during testing.", "The random variable z can be modeled in a time-variant and time-invariant way.", "Additionaly, this paper proposes a training procedure to prevent their method from ignoring the stochastic phenomena modeled by z In the experimentalsecion, the authors highlight the advantages of their method in 1) a synthetic dataset of shapes meant to clearly show the stochasticity in the prediction, 2) two robotic arm datasets for video prediction given and not given actions, and 3) A chalenging human action dataset in which they perform future prediction only given previous frames.", "2) Pros: + Novel/Sound future frame prediction formulation and training for modeling the stochasticity of future prediction.", "+ Experiments on the synthetic shapes and robotic arm datasets highlight the proposed method\u2019s power of multiple future frame prediction possible.", "+ Good analsis on the number of samples improving the chance of outputting the correct future, the modeling power of the posterior for reconstructing the future, and a wide variety of qualtative examples.", "+ Work is significant for the problem of modeling the stochastic nature of future frame prediction in videos.", "3) Cons: Approximate posterior in non-synthetic datasets: The variable z seems to not be modeling the future very well.", "In the robot arm qualtative experiments, the robot motion is well modeled, however, the background is not.", "Given that for the approximate posterior computation the entire seqence is given (e g reconstruction is performed), I would expect the background motion to alo be modeled well.", "This issue is more evident in the Human 3 6M experiments, as it seems to output blurriness regardless of the true future being observed.", "This problem may mean the method is failing to model a large variety of objects and clearly works for the robotic arm because a very similar large shape (e g robot arm) is seen in the training data.", "Do you have any comments on this?", "Finn et al2016 PNSR performance on Human 3 6M: Is the same exact data, pre-processing, training, and architecture being utilized?", "In her paper, the PSNR for the first timestep on Human 3 6M is about 41 (maybe 42?)", "while in this paper it is 38, Additionalevalation on Human 3 6M: PSNR is not a good evalation metric for frame prediction as it is biased towards blurriness, and alo SSIM does not give us an objective evalation in the sense of semantic qualty of predicted frames.", "It would be good if the authors present additionalquantitative evalation to show that the predicted frames contain useful semantic information [1, 2, 3, 4].", "For example, evalating the predicted frames for the Human 3 6M dataset to see if the human is still detectable in the image or if the expected action is being predicted could be useful to verify that the predicted frames contain the expected meaningful information compared to the baselines.", "Additionalcomments: Are al 15 actions being used for the Human 3 6M experiments?", "If so, the fact of the time-invariant model performs better than the time-variant one may not be the consistent action being performed (last sentence of 5 2).", "The motion performed by the actors in each action highly overlaps (taling on the phone action may go from sitting to waling a little to sitting again, and so on).", "Unless actions such as waling and discussion were only used, it is unlikely the time-invariant z is performing better because of consistent action.", "Do you have any comments on this?", "4) Conclusion This paper proposes an interesting novel approach for predicting multiple futures in videos, however, the results are not fully convincing in al datasets.", "If the authors can provide additionalquantitative evalation besides PSNR and SSIM (e g evalation on semantic qualty), and alo address the comments above, the current score will improve.", "References: [1] Emily Denton and Vighnesh Birodkar.", "Unsupervised Learning of Disentangled Representations from Video.", "In NIPS, 2017, [2] Ruben Villegas, Jimei Yang, Yuliang Zou, Sungryull Sohn, Xunyu Lin, and Honglak Lee.", "Learning to generate long-term future via hierarchicalprediction.", "In ICML, 2017, [3] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.", "Progressive Growing of GANs for Improved Qualty, Stability, and Variation.", "arXiv preprint arXiv:1710.10196, 2017, [4] Tim Salmans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.", "Improved Techniques for Training GANs.", "In NIPS, 2017, Revised review: Given the authors' thorough answers to my concerns, I have decided to change my score.", "I would like to thank the authors for a very nice paper that will definitely help the community towards developing better video prediction alorithms that can now predict multiple futures."], "all_annotations": [{"interpretation": 0, "review_id": "S1gH28vgM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1gH28vgM", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "S1gH28vgM", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1gH28vgM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S1jAR0Klf", "review_text": "The authors present a model for unsupervised NMT which requires no parallel corpora between the two languages of interest. While the results are interesting I find very few original ideas in this paper. Please find my comments/questions/suggestions below:\n\n1) The authors mention that there are 3 important aspects in which their model differs from a standard NMT architecture. All the 3 differences have been adapted from existing works. The authors clearly acknowledge and cite the sources. Even sharing the encoder using cross lingual embeddings has been explored in the context of multilingual NER (please see https://arxiv.org/abs/1607.00198). Because of this I find the paper to be a bit lacking on the novelty quotient. Even backtranslation has been used successfully in the past (as acknowledged by the authors). Unsupervised MT in itself is not a new idea (again clearly acknowledged by the authors).\n\n2) I am not very convinced about the idea of denoising. Specifically, I am not sure if it will work for arbitrary language pairs. In fact, I think there is a contradiction even in the way the authors write this. On one hand, they want to \"learn the internal structure of the languages involved\" and on the other hand they deliberately corrupt this structure by adding noise. This seems very counter-intuitive and in fact the results in Table 1 suggest that it leads to a drop in performance. I am not very sure that the analogy with autoencoders holds in this case.\n\n3) Following up on the above question, the authors mention that \"We emphasize, however, that it is not possible to use backtranslation alone without denoising\". Again, if denoising itself leads to a drop in the performance as compared to the nearest neighbor baseline then why use backtranslation in conjunction with denoising and not in conjunction with the baseline itself. \n\n4) This point is more of a clarification and perhaps due to my lack of understanding. Backtranslation to generate a pseudo corpus makes sense only after the model has achieved a certain (good) performance. Can you please provide details of how long did you train the model (with denoising?) before producing the backtranslations ?\n\n5) The authors mention that 100K parallel sentences may be insufficient for training a NMT system. However, this size may be decent enough for  a PBSMT system. It would be interesting to see the performance of a PBSMT system trained on 100K parallel sentences. \n\n6) How did you arrive at the beam size of 12 ? Was this a hyperparameter? Just curious.\n\n7) The comparable NMT set up is not very clear. Can you please explain it in detail ? In the same paragraph, what exactly do you mean by \"the supervised system in this paper is relatively small?\"", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The authors present a model for unsupervised NMT which reqires no paralel corpora between the two languages of interest.", "While the results are interesting I find very few originalideas in this paper.", "Please find my comments/questions/suggestions below: 1) The authors mention that there are 3 important aspects in which their model differs from a standard NMT architecture.", "All the 3 differences have been adapted from existing works.", "The authors clearly acknowledge and cite the sources.", "Even sharing the encoder using cross lingualembeddings has been explored in the context of multilingualNER (please see https://arxiv.org/abs/1607.00198).", "Because of this I find the paper to be a bit lacking on the novelty quotient.", "Even backtranslation has been used successfully in the past (as acknowledged by the authors).", "Unsupervised MT in itself is not a new idea (again clearly acknowledged by the authors).", "2) I am not very convinced about the idea of denoising.", "Specificaly, I am not sure if it will work for arbitrary language pairs.", "In fact, I think there is a contradiction even in the way the authors write this.", "On one hand, they want to \"learn the internalstructure of the languages involved\" and on the other hand they deliberately corrupt this structure by adding noise.", "This seems very counter-intuitive and in fact the results in Table 1 suggest that it leads to a drop in performance.", "I am not very sure that the analgy with autoencoders holds in this case.", "3) Following up on the above question, the authors mention that \"We emphasize, however, that it is not possible to use backtranslation alne without denoising\".", "Again, if denoising itself leads to a drop in the performance as compared to the nearest neighbor baseline then why use backtranslation in conjunction with denoising and not in conjunction with the baseline itself.", "4) This point is more of a clarification and perhaps due to my lack of understanding.", "Backtranslation to generate a pseudo corpus makes sense only after the model has achieved a certain (good) performance.", "Can you please provide details of how long did you train the model (with denoising?)", "before producing the backtranslations ?", "5) The authors mention that 100K paralel sentences may be insufficient for training a NMT system.", "However, this size may be decent enough for a PBSMT system.", "It would be interesting to see the performance of a PBSMT system trained on 100K paralel sentences.", "6) How did you arrive at the beam size of 12 ?", "Was this a hyperparameter?", "Just curious.", "7) The comparable NMT set up is not very clear.", "Can you please explain it in detail ?", "In the same paragraph, what exactly do you mean by \"the supervised system in this paper is relatively smal?\""], "all_annotations": [{"interpretation": 0, "review_id": "S1jAR0Klf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "S1jAR0Klf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "S1jAR0Klf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1jAR0Klf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "S1jezarxG", "review_text": "The paper offers a formal proof that gradient descent on the logistic\nloss converges very slowly to the hard SVM solution in the case where\nthe data are linearly separable. This result should be viewed in the\ncontext of recent attempts at trying to understand the generalization\nability of neural networks, which have turned to trying to understand\nthe implicit regularization bias that comes from the choice of\noptimizer. Since we do not even understand the regularization bias of\noptimizers for the simpler case of linear models, I consider the paper's\ntopic very interesting and timely.\n\nThe overall discussion of the paper is well written, but on a more\ndetailed level the paper gives an unpolished impression, and has many\ntechnical issues. Although I suspect that most (or even all) of these\nissues can be resolved, they interfere with checking the correctness of\nthe results. Unfortunately, in its current state I therefore do not\nconsider the paper ready for publication.\n\n\nTechnical Issues:\n\nThe statement of Lemma 5 has a trivial part and for the other part the\nproof is incorrect: Let x_u = ||nabla L(w(u))||^2.\n  - Then the statement sum_{u=0}^t x_u < infinity is trivial, because\n    it follows directly from ||nabla L(w(u))||^2 < infinity for all u. I\n    would expect the intended statement to be sum_{u=0}^infinity x_u <\n    infinity, which actually follows from the proof of the lemma.\n  - The proof of the claim that t*x_t -> 0 is incorrect: sum_{u=0}^t x_u\n    < infinity does not in itself imply that t*x_t -> 0, as claimed. For\n    instance, we might have x_t = 1/i^2 when t=2^i for i = 1,2,... and\n    x_t = 0 for all other t.\n\nDefinition of tilde{w} in Theorem 4:\n  - Why would tilde{w} be unique? In particular, if the support vectors\n    do not span the space, because all data lie in the same\n    lower-dimensional hyperplane, then this is not the case.\n  - The KKT conditions do not rule out the case that \\hat{w}^top x_n =\n    1, but alpha_n = 0 (i.e. a support vector that touches the margin,\n    but does not exert force against it). Such n are then included in\n    cal{S}, but lead to problems in (2.7), because they would require\n    tilde{w}^top x_n = infinity, which is not possible.\n\nIn the proof of Lemma 6, case 2. at the bottom of p.14:\n  - After the first inequality, C_0^2 t^{-1.5 epsilon_+} should be \n    C_0^2 t^{-epsilon_+}\n  - After the second inequality the part between brackets is missing an\n    additional term C_0^2 t^{-\\epsilon_+}.\n  - In addition, the label (1) should be on the previous inequality and\n    it should be mentioned that e^{-x} <= 1-x+x^2 is applied for x >= 0\n    (otherwise it might be false).\nIn the proof of Lemma 6, case 2 in the middle of p.15:\n  - In the line of inequality (1) there is a t^{-epsilon_-} missing. In\n    the next line there is a factor t^{-epsilon_-} too much.\n  - In addition, the inequality e^x >= 1 + x holds for all x, so no need\n    to mention that x > 0.\n\nIn Lemma 1:\n  - claim (3) should be lim_{t \\to \\infty} w(t)^\\top x_n = infinity\n  - In the proof: w(t)^top x_n > 0 only holds for large enough t.\n\nRemarks:\n\np.4 The claim that \"we can expect the population (or test)\nmisclassification error of w(t) to improve\" because \"the margin of w(t)\nkeeps improving\" is worded a little too strongly, because it presumes\nthat the maximum margin solution will always have the best\ngeneralization error.\n\nIn the proof sketch (p.3):\n  - Why does the fact that the limit is dominated by gradients that are\n    a linear combination of support vectors imply that w_infinity will\n    also be a non-negative linear combination of support vectors?\n  - \"converges to some limit\". Mention that you call this limit\n    w_infinity\n\n\nMinor Issues:\n\nIn (2.4): add \"for all n\".\n\np.10, footnote: Shouldn't \"P_1 = X_s X_s^+\" be something like \"P_1 =\n(X_s^top X_s)^+\"?\n\nA.9: ell should be ell'\n\nThe paper needs a round of copy editing. For instance:\n  - top of p.4: \"where tilde{w} A is the unique\"\n  - p.10: \"the solution tilde{w} to TO eq. A.2\"\n  - p.10: \"might BOT be unique\"\n  - p.10: \"penrose-moorse pseudo inverse\" -> \"Moore-Penrose\n    pseudoinverse\"\n  \nIn the bibliography, Kingma and Ba is cited twice, with different years.\n", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["The paper offers a formalproof that gradient descent on the logistic loss converges very slowly to the hard SVM solution in the case where the data are linearly separable.", "This result should be viewed in the context of recent attempts at trying to understand the generalzation ability of neuralnetworks, which have turned to trying to understand the implicit regularization bias that comes from the choice of optimizer.", "Since we do not even understand the regularization bias of optimizers for the simpler case of linear models, I consider the paper's topic very interesting and timely.", "The overal discussion of the paper is well written, but on a more detailed level the paper gives an unpolished impression, and has many technicalissues.", "Although I suspect that most (or even al) of these issues can be resolved, they interfere with checking the correctness of the results.", "Unfortunately, in its current state I therefore do not consider the paper ready for publication.", "TechnicalIssues: The statement of Lemma 5 has a trivialpart and for the other part the proof is incorrect: Let x_u = ||nabla L(w(u))||^2, - Then the statement sum_{u=0}^t x_u < infinity is trivial because it follows directly from ||nabla L(w(u))||^2 < infinity for al u I would expect the intended statement to be sum_{u=0}^infinity x_u < infinity, which actualy follows from the proof of the lemma.", "- The proof of the claim that t*x_t -> 0 is incorrect: sum_{u=0}^t x_u < infinity does not in itself imply that t*x_t -> 0, as claimed.", "For instance, we might have x_t = 1/i^2 when t=2^i for i = 1,2,... and x_t = 0 for al other t Definition of tilde{w} in Theorem 4: - Why would tilde{w} be unique?", "In particular, if the support vectors do not span the space, because al data lie in the same lower-dimensionalhyperplane, then this is not the case.", "- The KKT conditions do not rule out the case that \\hat{w}^top x_n = 1, but alha_n = 0 (i e a support vector that touches the margin, but does not exert force against it).", "Such n are then included in calS}, but lead to problems in (2 7), because they would reqire tilde{w}^top x_n = infinity, which is not possible.", "In the proof of Lemma 6, case 2, at the bottom of p 14: - After the first ineqalty, C_0^2 t^{-1 5 epsilon_+} should be C_0^2 t^{-epsilon_+} - After the secnd ineqalty the part between brackets is missing an additionalterm C_0^2 t^{-\\epsilon_+}.", "- In addition, the label (1) should be on the previous ineqalty and it should be mentioned that e^{-x} <= 1-x+x^2 is applied for x >= 0 (otherwise it might be fale).", "In the proof of Lemma 6, case 2 in the middle of p 15: - In the line of ineqalty (1) there is a t^{-epsilon_-} missing.", "In the next line there is a factor t^{-epsilon_-} too much.", "- In addition, the ineqalty e^x >= 1 + x holds for al x, so no need to mention that x > 0, In Lemma 1: - claim (3) should be lim_{t \\to \\infty} w(t)^\\top x_n = infinity - In the proof: w(t)^top x_n > 0 only holds for large enough t Remarks: p 4 The claim that \"we can expect the population (or test) misclassification error of w(t) to improve\" because \"the margin of w(t) keeps improving\" is worded a little too strongly, because it presumes that the maximum margin solution will alays have the best generalzation error.", "In the proof sketc (p 3): - Why does the fact that the limit is dominated by gradients that are a linear combination of support vectors imply that w_infinity will alo be a non-negative linear combination of support vectors?", "- \"converges to some limit\".", "Mention that you cal this limit w_infinity Minor Issues: In (2 4): add \"for al n\".", "p 10, footnote: Shouldn't \"P_1 = X_s X_s^+\" be something like \"P_1 = (X_s^top X_s)^+\"?", "A 9: ell should be ell' The paper needs a round of copy editing.", "For instance: - top of p 4: \"where tilde{w} A is the unique\" - p 10: \"the solution tilde{w} to TO eq A 2\" - p 10: \"might BOT be unique\" - p 10: \"penrose-moorse pseudo inverse\" -> \"Moore-Penrose pseudoinverse\" In the bibliography, Kingma and Ba is cited twice, with different years."], "all_annotations": [{"interpretation": 0, "review_id": "S1jezarxG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1jezarxG", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1jezarxG", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1jezarxG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_1006_3", "review_text": "Summary This paper proposes a method by using a multiple instance learning formulation along with an early prediction technique to learn a model that can achieve better accuracy. The method is very practical and the ideas of this paper are organized logically. Figures and tables are clear and easy to understand. Also, this paper is written in academic and fluent English.  However, there are some unclear parts in the paper.  1. The parameter setting in experiments should be introduced clearly.  2.  The equation A.2.18 in supplementary is not easy to understand. Further explanation is encouraged.   Several spelling mistakes: 1. Line 58, \"We we\". 2. Line 64,  \"typically\". ", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["Summary This paper proposes a method by using a multiple instance learning formulation alng with an early prediction technique to learn a model that can achieve better accuracy.", "The method is very practicaland the ideas of this paper are organized logicaly.", "figres and tables are clear and easy to understand.", "Also, this paper is written in academic and fluent English.", "However, there are some unclear parts in the paper.", "1, The parameter setting in experiments should be introduced clearly.", "2, The eqation A 2 18 in supplementary is not easy to understand.", "Further explanation is encouraged.", "Severalspelling mistakes: 1, Line 58, \"We we\".", "2, Line 64, \"typicaly\"."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_1006_3", "importance": null, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno2", "evidence": 1, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_1006_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_1006_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_1006_3", "importance": 0, "reproducibility": 1, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1kxi6OlM", "review_text": "In general I find this to be a good paper and vote for acceptance. The paper is well-written and easy to follow.  The proposed approach is a useful addition to existing literature.\n\nBesides that I have not much to say except one point I would like to discuss:\n\nIn 4.2 I am not fully convinced of using an adversial model for goal generation. RL algorithms generally suffer from poor stability  and GANs themselves can have convergence issues. This imposes another layer of possible instability. \n \nBesides, generating useful reward function, while not trivial, can be seen as easier than solving the full RL problem. \nCan the authors argue why this model class was chosen over other, more simple, generative models?  \nFurthermore, did the authors do experiments with simpler models?\n\nRelated:\n\"We found that the LSGAN works better than other forms of GAN for our problem.\" \nWas this improvement minor, or major, or didn't even work with other GAN types? This question is important, because for me the big question is if this model is universal and stable in a lot of applications or requires careful fine-tuning and monitoring. \n\n---\nUpdate:\nThe authors addressed  the major point of criticism in my review.  I am now more convinced in the quality of the proposed work, and have updated my review score accordingly.", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["In generalI find this to be a good paper and vote for acceptance.", "The paper is well-written and easy to follow.", "The proposed approach is a useful addition to existing literature.", "Besides that I have not much to say except one point I would like to discuss: In 4 2 I am not fully convinced of using an adversialmodel for goalgeneration.", "RL alorithms generaly suffer from poor stability and GANs themselves can have convergence issues.", "This imposes another layer of possible instability.", "Besides, generating useful reward function, while not trivial can be seen as easier than solving the full RL problem.", "Can the authors argue why this model class was chosen over other, more simple, generative models?", "Furthermore, did the authors do experiments with simpler models?", "Related: \"We found that the LSGAN works better than other forms of GAN for our problem.\"", "Was this improvement minor, or major, or didn't even work with other GAN types?", "This question is important, because for me the big question is if this model is universaland stable in a lot of applications or reqires careful fine-tuning and monitoring.", "--- Update: The authors addressed the major point of criticism in my review.", "I am now more convinced in the qualty of the proposed work, and have updated my review score accordingly."], "all_annotations": [{"interpretation": 0, "review_id": "S1kxi6OlM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1kxi6OlM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "S1kxi6OlM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": null, "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1kxi6OlM", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1sHPAWgz", "review_text": "Overall:\nI really enjoyed reading this paper and think the question is super important. I have some reservations about the execution of the experiments as well as some of the conclusions drawn. For this reason I am currently a weak reject (weak because I believe the question is very interesting). However, I believe that many of my criticisms can be assuaged during the rebuttal period.\n\nPaper Summary:\nFor RL to play video games, it has to play many many many many times. In fact, many more times than a human where prior knowledge lets us learn quite fast in new (but related) environments. The authors study, using experiments, what aspects of human priors are the important parts. \n\nThe authors\u2019 Main Claim appears to be: \u201cWhile common wisdom might suggest that prior knowledge about game semantics such as ladders are to be climbed, jumping on spikes is dangerous or the agent must fetch the key before reaching the door are crucial to human performance, we find that instead more general and high-level priors such as the world is composed of objects, object like entities are used as subgoals for exploration, and things that look the same, act the same are more critical.\u201d\n\nOverall, I find this interesting. However, I am not completely convinced by some of the experimental demonstrations. \n\nIssue 0: The experiments seem underpowered / not that well analyzed. \nThere are only 30 participants per condition and so it\u2019s hard to tell whether the large differences in conditions are due to noise and what a stable ranking of conditions actually looks like. I would recommend that the authors triple the sample size and be more clear about reporting the outcomes in each of the conditions. \n\nIt\u2019s not clear what the error bars in figure 1 represent, are they standard deviations of the mean? Are they standard deviations of the data? Are they confidence intervals for the mean effect? \n\nDid you collect any extra data about participants? One potentially helpful example is asking how familiar participants are with platformer video games. This would give at least some proxy to study the importance of priors about \u201chow video games are generally constructed\u201d rather than priors like \u201cobjects are special\u201d.\n\nIssue 1: What do you mean by \u201cobjects\u201d?\nThe authors interpret the fact that performance falls so much between conditions b and c to mean that human priors about \u201cobjects are special\u201d are very important. However, an alternative explanation is that people explore things which look \u201cdifferent\u201d (ie. Orange when everything else is black). \n\nThe problem here comes from an unclear definition of what the authors mean by an \u201cobject\u201d so in revision I would like authors to clarify what precisely they mean by a prior about \u201cthe world is composed of objects\u201d and how this particular experiment differentiates \u201cobject\u201d from a more general prior about \u201cvideo games have clearly defined goals, there are 4 clearly defined boxes here, let me try touching them.\u201d\n\nThis is important because a clear definition will give us an idea for how to actually build this prior into AI systems.\n\nIssue 2: Are the results here really about \u201chigh level\u201d priors?\nThere are two ways to interpret the authors\u2019 main claim: the strong version would maintain that semantic priors aren\u2019t important at all.\n\nThere is no real evidence here for the strong version of the claim. A real test would be to reverse some of the expected game semantics and see if people perform just as well as in the \u201cmasked semantics\u201d condition.\n\nFor example, suppose we had exactly the same game and N different types of objects in various places of the game where N-1 of them caused death but 1 of them opened the door (but it wasn\u2019t the object that looked like a key). My hypothesis would be that performance would fall drastically as semantic priors would quickly lead people in that direction. \n\nThus, we could consider a weaker version of the claim: semantic priors are important but even in the absence of explicit semantic cues (note, this is different from having the wrong semantic cues as above) people can do a good job on the game. This is much more supported by the data, but still I think very particular to this situation. Imagine a slight twist on the game:\n\nThere is a sword (with a lock on it), a key, a slime and the door (and maybe some spikes). The player must do things in exactly this order: first the player must get the key, then they must touch the sword, then they must kill the slime, then they go to the door. Here without semantic priors I would hypothesize that human performance would fall quite far (whereas with semantics people would be able to figure it out quite well).\n\nThus, I think the authors\u2019 claim needs to be qualified quite a bit. It\u2019s also important to take into account how much work general priors about video game playing (games have goals, up jumps, there is basic physics) are doing here (the authors do this when they discuss versions of the game with different physics).", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["Overal: I realy enjoyed reading this paper and think the question is super important.", "I have some reservations about the execution of the experiments as well as some of the conclusions drawn.", "For this reason I am currently a weak reject (weak because I believe the question is very interesting).", "However, I believe that many of my criticisms can be assuaged during the rebuttalperiod.", "Paper Summary: For RL to play video games, it has to play many many many many times.", "In fact, many more times than a human where prior knowledge lets us learn quite fast in new (but related) environments.", "The authors study, using experiments, what aspects of human priors are the important parts.", "The authors\u2019 Main Claim appears to be: \u201cWhile common wisdom might suggest that prior knowledge about game semantics such as ladders are to be climbed, jumping on spikes is dangerous or the agent must fetc the key before reaching the door are crucialto human performance, we find that instead more generaland high-level priors such as the world is composed of objects, object like entities are used as subgoal for exploration, and things that look the same, act the same are more critical\u201d Overal, I find this interesting.", "However, I am not completely convinced by some of the experimentaldemonstrations.", "Issue 0: The experiments seem underpowered / not that well analzed.", "There are only 30 participants per condition and so it\u2019s hard to tell whether the large differences in conditions are due to noise and what a stable ranking of conditions actualy looks like.", "I would recommend that the authors triple the sample size and be more clear about reporting the outcomes in each of the conditions.", "It\u2019s not clear what the error bars in figre 1 represent, are they standard deviations of the mean?", "Are they standard deviations of the data?", "Are they confidence interval for the mean effect?", "Did you collect any extra data about participants?", "One potentialy helpful example is asking how familiar participants are with platformer video games.", "This would give at least some proxy to study the importance of priors about \u201chow video games are generaly constructed\u201d rather than priors like \u201cobjects are special.", "Issue 1: What do you mean by \u201cobjects\u201d?", "The authors interpret the fact that performance fals so much between conditions b and c to mean that human priors about \u201cobjects are special are very important.", "However, an alernative explanation is that people explore things which look \u201cdifferent\u201d (ie.", "Orange when everything else is black).", "The problem here comes from an unclear definition of what the authors mean by an \u201cobject\u201d so in revision I would like authors to clarify what precisely they mean by a prior about \u201cthe world is composed of objects\u201d and how this particular experiment differentiates \u201cobject\u201d from a more generalprior about \u201cvideo games have clearly defined goal, there are 4 clearly defined boxes here, let me try touching them.\u201d This is important because a clear definition will give us an idea for how to actualy build this prior into AI systems.", "Issue 2: Are the results here realy about \u201chigh level\u201d priors?", "There are two ways to interpret the authors\u2019 main claim: the strong version would maintain that semantic priors aren\u2019t important at al.", "There is no realevidence here for the strong version of the claim.", "A realtest would be to reverse some of the expected game semantics and see if people perform just as well as in the \u201cmasked semantics\u201d condition.", "For example, suppose we had exactly the same game and N different types of objects in various places of the game where N-1 of them caused death but 1 of them opened the door (but it wasn\u2019t the object that looked like a key).", "My hypothesis would be that performance would fal drasticaly as semantic priors would quickly lead people in that direction.", "Thus, we could consider a weaker version of the claim: semantic priors are important but even in the absence of explicit semantic cues (note, this is different from having the wrong semantic cues as above) people can do a good job on the game.", "This is much more supported by the data, but still I think very particular to this situation.", "Imagine a slight twist on the game: There is a sword (with a lock on it), a key, a slime and the door (and maybe some spikes).", "The player must do things in exactly this order: first the player must get the key, then they must touch the sword, then they must kill the slime, then they go to the door.", "Here without semantic priors I would hypothesize that human performance would fal quite far (whereas with semantics people would be able to figre it out quite well).", "Thus, I think the authors\u2019 claim needs to be qualfied quite a bit.", "It\u2019s alo important to take into account how much work generalpriors about video game playing (games have goal, up jumps, there is basic physics) are doing here (the authors do this when they discuss versions of the game with different physics)."], "all_annotations": [{"interpretation": 1, "review_id": "S1sHPAWgz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1sHPAWgz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "yes-agree", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "S1sHPAWgz", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": null, "metareview": "yes-agree", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "S1sHPAWgz", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1skfxRxM", "review_text": "SUMMARY\n\nThe paper considers the problem of using cycle GANs to decipher text encrypted with historical ciphers. Also it presents some theory to address the problem that discriminating between the discrete data and continuous prediction is too simple. The model proposed is a variant of the cycle GAN in which in addition embeddings helping the Generator are learned for all the values of the discrete variables. \nThe log loss of the GAN is replaced by a quadratic loss and a regularization of the Jacobian of the discriminator. Experiments show that the method is very effective.  \n\nREVIEW\n\nThe paper considers an interesting and fairly original problem and the overall discussion of ciphers is quite nice. Unfortunately, my understanding is that the theory proposed in section 2 does not correspond to the scheme used in the experiments (contrarily to what the conclusion suggest and contrarily to what the discussion of the end of section 3, which says that using embedding is assumed to have an equivalent effect to using the methodology considered in the theoretical part). Another important concern is with the proof: there seems to be an unmotivated additional assumption that appears in the middle of the proof of Proposition 1 + some steps need to be clarified (see comment 16 below).\nThe experiments do not have any simple baseline, which is somewhat unfortunate.\n\n\nDETAILED COMMENTS:\n\n1- The paper makes a few bold and debatable statements:\n\nline 9 of section 1\n\"Such hand-crafted features have fallen out of favor (Goodfellow et al., 2016) as a\nresult of their demonstrated inferiority to features learned directly from data in end-to-end learning\nframeworks such as neural networks\"\n\nThis is certainly an overstatement and although it might be true for specific types of inputs it is not universally true, most deep architectures rely on a human-in-the-loop and there are number of areas where human crafted feature are arguably still relevant, if only to specify what is the input of a deep network: there are many domains where the notion of raw data does not make sense, and, when it does, it is usually associated with a sensing device that has been designed by a human and which implicitly imposes what the data is based on human expertise. \n\n2- In the last paragraph of the introduction, the paper says that previous work has only worked on vocabularies of 26 characters while the current paper tackles word level ciphers with 200 words. But, isn't this just a matter of scalability and only possible with very large amounts of text? Is it really because of an intrinsic limitation or lack of scalability of previous approaches or just because the authors of the corresponding papers did not care to present larger scale experiments? \n\n\n3- The discussion at the top of page 5 is difficult to follow. What do you mean when you say \"this motivates the benefits of having strong curvature globally, as opposed to linearly between etc\"\nWhich curvature are we talking about? and what how does the \"as opposed to linearly\" mean? Should we understand \"as opposed to having curvature linearly interpolated between etc\" or \"as opposed to having a linear function\"? Please clarify.\n\n4- In the same paragraph: what does \"a region that has not seen the Jacobian norm applied to it\" mean? How is a norm applied to a region? I guess that what you mean is that the generator G might creates samples in a part of the space where the function F has not yet been learned and is essentially close to 0. Is this what you mean?\n\n5- I do not understand why the paper introduces WGAN since in the end it does not use them but uses a quadratic loss, introduced in the first display of section 4.3.\n\n6- The paper makes a theoretical contribution which supports replacing the sample y by a sample drawn from a region around y. But it seems that this is not used in the experiment and that the authors consider that the introduction of the embedding is a substitution for this. Indeed, in the last paragraph of section 3.1, the paper says \"we make the assumption that the training of the embedding vectors approximates random sampling similar to what is described in Proposition 1\". This does not make any sense to me because the embedding vectors map each y deterministically to a single point, and so the distribution on the corresponding vectors is still a fixed discrete distribution. This gives me this impression that the proposed theory does not match what is used in the experiments.\n(The last sentence of section 3.1, which is commenting on this and could perhaps clarify the situation is ill formed with two verbs.)\n\n7- In the definitions: \"A discriminator is said to perform uninformative discrimination\" etc. -> It seems that the choice of the word uninformative would be misleading: an uninformative discrimination would be a discrimination that completely fails, while what the condition is saying it that it cannot perform perfect discrimination. I would thus suggest to call this \"imperfect discrimination\". \n\n\n8- It seems that the same embedding is used in X space and in Y space (from equations 6 and 7). Is there any reason for that? I would seem more natural to me to introduce two different embeddings since the objects are a priori different...\nActually I don't understand how the embeddings can be the same in the Vignere code case since time taken into account one one side.\n\n9- On the 5th line after equation (7), the paper says \"the embeddings... are trained to minimize L_GAN and L_cyc, meaning... and are easy to discriminate\" -> This last part of the sentence seems wrong to me. The discriminator is trying to maximize L_GAN and so minimizing w.r.t. to the embedding is precisely trying to prevent to the discriminator to tell apart too easily the true elements from the estimated ones.\nIn fact the regularization of the Jacobian that will be preventing the discriminator to vary too quickly in space is more likely to explain the fact that the discrimination is not too easy to do between the true and mapped embeddings. This might be connected to the discussion at the top of page 5. Since there are no experiments with alpha different than the default value = 10, this is difficult to assess.\n\n10-The Vigenere cipher is explained again at the end of section 4.2 when it has already been presented in section 1.1\n\n11- Concerning results in Table 2: I do not see why it would not be possible to compare the performance of the method with classical frequency analysis, at least for the character case.\n\n12- At the beginning of section 4.3, the text says that the log loss was replaced with the quadratic loss, but without giving any reason. Could you explain why.\n\n13- The only comparison of results with and without embeddings is presented in the curves of figure 3, for Brown-W with a vocabulary of 200 words. In that case it helps. Could the authors report systematically results about all cases? (I guess this might however be the only hard case...)\n\n14- It would be useful to have a brief reminder of the architecture of the neural network (right now the reader is just refered to Zhu et al., 2017): how many layers, how many convolution layers etc.\nThe same comment applies for the way the position of the letter/word in the text appear is in encoded in a feature that is provided as input to the neural network: it would be nice if the paper could provide a few details here and be more self contained. (The fact that the engineering of the time feature can \"dramatically\" improve the performance of the network should be an argument to convince the authors that hand-crafted feature have not fallen out of favor completely yet...)\n\n15- I disagree with the statement made in the conclusion that the proposed work \"empirically confirms [...] that the use of continuous relaxation of discrete variable facilitates [...] and prevents [...]\" because for me the proposed implementation does not use at all the theoretical idea of continuous relaxation proposed in the paper, unless there is a major point that I am missing.\n\n\n16- I have two issues with the proof in the appendix\n\na) after the first display of the last page the paper makes an additional assumption which is not announced in the statement of the theorem, which is that two specific inequality hold...\nUnless I am mistaken this assumption is never proven (later or earlier). Given that this inequality is just \"the right inequality to get the proof go through\" and given that there are no explanation for why this assumption is reasonable, to me this invalidates the proof. The step of going from G(S_y) to S_(G(y)) seems delicate...\n\nb) If we accept these inequalities, the determinant of the Jacobian (the notation is not defined) of F at (x_bar) disappears from the equations, as if it could be assumed to be greater than one. If this is indeed the case, please provide a justification of this step.\n\n17- A way to address the issue of trivial discrimination in GANs with discrete data has been proposed in\n \nLuc, P., Couprie, C., Chintala, S., & Verbeek, J. (2016). Semantic segmentation using adversarial networks. arXiv preprint arXiv:1611.08408.\nThe authors should probably reference this paper.\n\n\n18- Clarification of the Jacobian regularization: in equation (3), the Jacobian computed seems to be w.r.t D composed with F while in equation (8) it is only the Jacobian of D. Which equation is the correct one?\n\nTYPOS:\n\nProposition 1: the if-then statement is broken into two sentences separated by a full point and a carriage return.\n\nsec. 4.3 line 10 we use a cycle loss *with a regularization coefficient* lambda=1 (a piece of the sentence is missing)\n\nsec. 4.3 lines 12-13 the learning rates given are the same at startup and after \"warming up\"...\n\nIn the appendix: \n3rd line of proof of prop 1: I don' understand \"countably infinite finite sequences of vectors lying in the vertices of the simplex\" -> what is countable infinite here? The vertices?\n\n\n\n\n\n\n\n  \n\n\n\n", "gold_annotation": null, "score": 5.0, "tokenized_review_text": ["SUMMARY The paper considers the problem of using cycle GANs to decipher text encrypted with historicalciphers.", "Also it presents some theory to address the problem that discriminating between the discrete data and continuous prediction is too simple.", "The model proposed is a variant of the cycle GAN in which in addition embeddings helping the Generator are learned for al the vales of the discrete variables.", "The log loss of the GAN is replaced by a quadratic loss and a regularization of the Jacobian of the discriminator.", "Experiments show that the method is very effective.", "REVIEW The paper considers an interesting and fairly originalproblem and the overal discussion of ciphers is quite nice.", "Unfortunately, my understanding is that the theory proposed in secion 2 does not correspond to the scheme used in the experiments (contrarily to what the conclusion suggest and contrarily to what the discussion of the end of secion 3, which says that using embedding is assumed to have an eqivalnt effect to using the methodology considered in the theoreticalpart).", "Another important concern is with the proof: there seems to be an unmotivated additionalassumption that appears in the middle of the proof of Proposition 1 + some steps need to be clarified (see comment 16 below).", "The experiments do not have any simple baseline, which is somewhat unfortunate.", "DETAILED COMMENTS: 1- The paper makes a few bold and debatable statements: line 9 of secion 1 \"Such hand-crafted features have falen out of favor (Goodfellow et al, 2016) as a result of their demonstrated inferiority to features learned directly from data in end-to-end learning frameworks such as neuralnetworks\" This is certainly an overstatement and alhough it might be true for specific types of inputs it is not universaly true, most deep architectures rely on a human-in-the-loop and there are number of areas where human crafted feature are arguably still relevant, if only to specify what is the input of a deep network: there are many domains where the notion of raw data does not make sense, and, when it does, it is usualy associated with a sensing device that has been designed by a human and which implicitly imposes what the data is based on human expertise.", "2- In the last paragraph of the introduction, the paper says that previous work has only worked on vocabularies of 26 characters while the current paper tackles word level ciphers with 200 words.", "But, isn't this just a matter of scalbility and only possible with very large amounts of text?", "Is it realy because of an intrinsic limitation or lack of scalbility of previous approaches or just because the authors of the corresponding papers did not care to present larger scal experiments?", "3- The discussion at the top of page 5 is difficult to follow.", "What do you mean when you say \"this motivates the benefits of having strong curvature globaly, as opposed to linearly between etc Which curvature are we taling about?", "and what how does the \"as opposed to linearly\" mean?", "Should we understand \"as opposed to having curvature linearly interpolated between etc or \"as opposed to having a linear function\"?", "Please clarify.", "4- In the same paragraph: what does \"a region that has not seen the Jacobian norm applied to it\" mean?", "How is a norm applied to a region?", "I guess that what you mean is that the generator G might creates samples in a part of the space where the function F has not yet been learned and is essentialy close to 0, Is this what you mean?", "5- I do not understand why the paper introduces WGAN since in the end it does not use them but uses a quadratic loss, introduced in the first display of secion 4 3, 6- The paper makes a theoreticalcontribution which supports replacing the sample y by a sample drawn from a region around y But it seems that this is not used in the experiment and that the authors consider that the introduction of the embedding is a substitution for this.", "Indeed, in the last paragraph of secion 3 1, the paper says \"we make the assumption that the training of the embedding vectors approximates random sampling similar to what is described in Proposition 1\".", "This does not make any sense to me because the embedding vectors map each y deterministicaly to a single point, and so the distribution on the corresponding vectors is still a fixed discrete distribution.", "This gives me this impression that the proposed theory does not match what is used in the experiments.", "(The last sentence of secion 3 1, which is commenting on this and could perhaps clarify the situation is ill formed with two verbs.)", "7- In the definitions: \"A discriminator is said to perform uninformative discrimination\" etc -> It seems that the choice of the word uninformative would be misleading: an uninformative discrimination would be a discrimination that completely fails, while what the condition is saying it that it cannot perform perfect discrimination.", "I would thus suggest to cal this \"imperfect discrimination\".", "8- It seems that the same embedding is used in X space and in Y space (from eqations 6 and 7).", "Is there any reason for that?", "I would seem more naturalto me to introduce two different embeddings since the objects are a priori different... Actualy I don't understand how the embeddings can be the same in the Vignere code case since time taken into account one one side.", "9- On the 5th line after eqation (7), the paper says \"the embeddings... are trained to minimize L_GAN and L_cyc, meaning... and are easy to discriminate\" -> This last part of the sentence seems wrong to me.", "The discriminator is trying to maximize L_GAN and so minimizing w r t to the embedding is precisely trying to prevent to the discriminator to tell apart too easily the true elements from the estimated ones.", "In fact the regularization of the Jacobian that will be preventing the discriminator to vary too quickly in space is more likely to explain the fact that the discrimination is not too easy to do between the true and mapped embeddings.", "This might be connected to the discussion at the top of page 5, Since there are no experiments with alha different than the default vale = 10, this is difficult to assess.", "10-The Vigenere cipher is explained again at the end of secion 4 2 when it has aleady been presented in secion 1 1 11- Concerning results in Table 2: I do not see why it would not be possible to compare the performance of the method with classicalfreqency analsis, at least for the character case.", "12- At the beginning of secion 4 3, the text says that the log loss was replaced with the quadratic loss, but without giving any reason.", "Could you explain why.", "13- The only comparison of results with and without embeddings is presented in the curves of figre 3, for Brown-W with a vocabulary of 200 words.", "In that case it helps.", "Could the authors report systematicaly results about al cases?", "(I guess this might however be the only hard case...) 14- It would be useful to have a brief reminder of the architecture of the neuralnetwork (right now the reader is just refered to Zhu et al, 2017): how many layers, how many convolution layers etc The same comment applies for the way the position of the letter/word in the text appear is in encoded in a feature that is provided as input to the neuralnetwork: it would be nice if the paper could provide a few details here and be more self contained.", "(The fact that the engineering of the time feature can \"dramaticaly\" improve the performance of the network should be an argument to convince the authors that hand-crafted feature have not falen out of favor completely yet...) 15- I disagree with the statement made in the conclusion that the proposed work \"empiricaly confirms [...] that the use of continuous relaxation of discrete variable facilitates [...] and prevents [...]\" because for me the proposed implementation does not use at al the theoreticalidea of continuous relaxation proposed in the paper, unless there is a major point that I am missing.", "16- I have two issues with the proof in the appendix a) after the first display of the last page the paper makes an additionalassumption which is not announced in the statement of the theorem, which is that two specific ineqalty hold...", "Unless I am mistaken this assumption is never proven (later or earlier).", "Given that this ineqalty is just \"the right ineqalty to get the proof go through\" and given that there are no explanation for why this assumption is reasonable, to me this invaldates the proof.", "The step of going from G(S_y) to S_(G(y)) seems delicate... b) If we accept these ineqalties, the determinant of the Jacobian (the notation is not defined) of F at (x_bar) disappears from the eqations, as if it could be assumed to be greater than one.", "If this is indeed the case, please provide a justification of this step.", "17- A way to address the issue of trivialdiscrimination in GANs with discrete data has been proposed in Luc, P , Couprie, C , Chintal, S , & Verbeek, J (2016).", "Semantic segmentation using adversarialnetworks.", "arXiv preprint arXiv:1611.08408, The authors should probably reference this paper.", "18- Clarification of the Jacobian regularization: in eqation (3), the Jacobian computed seems to be w r t D composed with F while in eqation (8) it is only the Jacobian of D Which eqation is the correct one?", "TYPOS: Proposition 1: the if-then statement is broken into two sentences separated by a full point and a carriage return.", "sec 4 3 line 10 we use a cycle loss *with a regularization coefficient* lambda=1 (a piece of the sentence is missing) sec 4 3 lines 12-13 the learning rates given are the same at startup and after \"warming up\"...", "In the appendix: 3rd line of proof of prop 1: I don' understand \"countably infinite finite seqences of vectors lying in the vertices of the simplex\" -> what is countable infinite here?", "The vertices?"], "all_annotations": [{"interpretation": 1, "review_id": "S1skfxRxM", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1skfxRxM", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "S1skfxRxM", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": null, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "S1skfxRxM", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1uLIj8lG", "review_text": "* sec.2.2 is about label-preserving translation and many notations are introduced. However, it is not clear what label here refers to, and it does not shown in the notation so far at all. Only until the end of sec.2.2, the function F(.) is introduced and its revelation - Google Search as label function is discussed only at Fig.4 and sec.2.3.\n* pp.5 first paragraph: when assuming D_X and D_Y being perfect, why L_GAN_forward = L_GAN_backward = 0? To trace back, in fact it is helpful to have at least a simple intro/def. to the functions D(.) and G(.) of Eq.(1). \n* Somehow there is a feeling that the notations in sec.2.1 and sec.2.2 are not well aligned. It is helpful to start providing the math notations as early as sec.2.1, so labels, pseudo labels, the algorithm illustrated in Fig.2 etc. can be consistently integrated with the rest notations. \n* F() is firstly shown in Fig.2 the beginning of pp.3, and is mentioned in the main text as late as of pp.5.\n* Table 2: The CNN baseline gives an error rate of 7.80 while the proposed variants are 7.73 and 7.60 respectively. The difference of 0.07/0.20 are not so significant. Any explanation for that?\nMinor issues:\n* The uppercase X in the sentence before Eq.(2) should be calligraphic X", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["* sec2 2 is about label-preserving translation and many notations are introduced.", "However, it is not clear what label here refers to, and it does not shown in the notation so far at al.", "Only until the end of sec2 2, the function F(.)", "is introduced and its revelation - Google Search as label function is discussed only at fig4 and sec2 3, * pp.5 first paragraph: when assuming D_X and D_Y being perfect, why L_GAN_forward = L_GAN_backward = 0?", "To trace back, in fact it is helpful to have at least a simple intro/def.", "to the functions D(.)", "and G(.)", "of eq(1).", "* Somehow there is a feeling that the notations in sec2 1 and sec2 2 are not well algned.", "It is helpful to start providing the math notations as early as sec2 1, so labels, pseudo labels, the alorithm illustrated in fig2 etc can be consistently integrated with the rest notations.", "* F() is firstly shown in fig2 the beginning of pp.3, and is mentioned in the main text as late as of pp.5, * Table 2: The CNN baseline gives an error rate of 7 80 while the proposed variants are 7 73 and 7 60 respectively.", "The difference of 0 07/0 20 are not so significant.", "Any explanation for that?", "Minor issues: * The uppercase X in the sentence before eq(2) should be caligraphic X"], "all_annotations": [{"interpretation": 0, "review_id": "S1uLIj8lG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "S1uLIj8lG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1uLIj8lG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, {"interpretation": 1, "review_id": "S1uLIj8lG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 2, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "S1ufxZqlG", "review_text": "EDIT: I have read the authors' rebuttals and other reviews. My opinion has not been changed. I recommend the authors significantly revise their work, streamlining the narrative and making clear what problems and solutions they solve. While I enjoy the perspective of unifying various paths, it's unclear what insights come from a simple reorganization. For example, what new objectives come out? Or given this abstraction, what new perspectives or analysis is offered?\n\n---\n\nThe authors propose an objective whose Lagrangian dual admits a variety of modern objectives from variational auto-encoders and generative adversarial networks. They describe tradeoffs between flexibility and computation in this objective leading to different approaches. Unfortunately, I'm not sure what specific contributions come out, and the paper seems to meander in derivations and remarks that I didn't understand what the point was.\n\nFirst, it's not clear what this proposed generalization offers. It's a very nuanced and not insightful construction (eq. 3) and with a specific choice of a weighted sum of mutual informations subject to a combinatorial number of divergence measure constraints, each possibly held in expectation (eq. 5) to satisfy the chosen subclass of VAEs and GANs; and with or without likelihoods (eq. 7). What specific insights come from this that isn't possible without the proposed generalization?\n\nIt's also not clear with many GAN algorithms that reasoning with their divergence measure in the limit of infinite capacity discriminators is even meaningful (e.g., Arora et al., 2017; Fedus et al., 2017). It's only true for consistent objectives such as MMD-GANs.\n\nSection 4 seems most pointed in explaining potential insights.  However, it only introduces hyperparameters and possible combinatorial choices with no particular guidance in mind. For example, there are no experiments demonstrating the usefulness of this approach except for a toy mixture of Gaussians and binarized MNIST, explaining what is already known with the beta-VAE and infoGAN. It would be useful if the authors could make the paper overall more coherent and targeted to answer specific problems in the literature rather than try to encompass all of them.\n\nMisc\n+ The \"feature marginal\" is also known as the aggregate posterior (Makhzani et al., 2015) and average encoding distribution (Hoffman and Johnson, 2016); also see Tomczak and Welling (2017).", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["EDIT: I have read the authors' rebuttal and other reviews.", "My opinion has not been changed.", "I recommend the authors significantly revise their work, streamlining the narrative and making clear what problems and solutions they solve.", "While I enjoy the perspective of unifying various paths, it's unclear what insights come from a simple reorganization.", "For example, what new objectives come out?", "Or given this abstraction, what new perspectives or analsis is offered?", "--- The authors propose an objective whose Lagrangian dualadmits a variety of modern objectives from variationalauto-encoders and generative adversarialnetworks.", "They describe tradeoffs between flexibility and computation in this objective leading to different approaches.", "Unfortunately, I'm not sure what specific contributions come out, and the paper seems to meander in derivations and remarks that I didn't understand what the point was.", "First, it's not clear what this proposed generalzation offers.", "It's a very nuanced and not insightful construction (eq 3) and with a specific choice of a weighted sum of mutualinformations subject to a combinatorialnumber of divergence measure constraints, each possibly held in expectation (eq 5) to satisfy the chosen subclass of VAEs and GANs; and with or without likelihoods (eq 7).", "What specific insights come from this that isn't possible without the proposed generalzation?", "It's alo not clear with many GAN alorithms that reasoning with their divergence measure in the limit of infinite capacity discriminators is even meaningful (e g , Arora et al, 2017; Fedus et al, 2017).", "It's only true for consistent objectives such as MMD-GANs.", "secion 4 seems most pointed in explaining potentialinsights.", "However, it only introduces hyperparameters and possible combinatorialchoices with no particular guidance in mind.", "For example, there are no experiments demonstrating the usefulness of this approach except for a toy mixture of Gaussians and binarized MNIST, explaining what is aleady known with the beta-VAE and infoGAN.", "It would be useful if the authors could make the paper overal more coherent and targeted to answer specific problems in the literature rather than try to encompass al of them.", "Misc + The \"feature marginal is alo known as the aggregate posterior (Makhzani et al, 2015) and average encoding distribution (Hoffman and Johnson, 2016); alo see Tomczak and Welling (2017)."], "all_annotations": [{"interpretation": 0, "review_id": "S1ufxZqlG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "S1ufxZqlG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1ufxZqlG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "yes-agree", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "S1ufxZqlG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "S1uz175xf", "review_text": "The authors study the problem of distributed routing in a network, where the goal is to minimize the maximal load (i.e. the load of the link with the highest utilization). The authors advocate to use multi-agent reinforcement learning. The main idea put forward by the authors is that by designing artificial rewards (to guide the agents), one can achieve faster exploration, in order to reduce convergence time.\n\nWhile the authors put forward several interesting ideas, there are some shortcomings to the present version of the paper, including:\n- The design objective seems flawed from the networking point of view: while minimizing the maximal load of a link is certainly a good starting point (to avoid instable queues) one typically wants to minimize delay (or maximize flow throughput). Indeed, it is possible to have a larger maximal load while reducing delay in many cases.\n- Furthermore, the authors do not provide a baseline to which the outcome of the learning algorithms they propose: for instance how does their approach compare to simple policies (those are commonplace in networking) such as MaxWeight, Backpressure and so on ?\n- The authors argue that using multi-agent learning is more desirable than single agent (i.e. with a single reward signal which is common to all agents). However, is multi-agent guaranteed to converge in such a setting ? If some versions of the problem (for some particular reward signal) are not guaranteed to converge, it is difficult to understand whether \"convergence\"  is slow due to an inefficient exploration, or simply because convergence cannot occur in the first place.\n- The learning algorithms used are not clearly explained: the authors simply state that they use \"ACCNet\" (from some unpublished prior work), but to readers unfamiliar with this algorithm, it is difficult to judge the contents of the paper. \n- In the numerical experiments, what is the \"convergence rate\" ? is it the ratio between the mean reward of the learnt policy and that of the optimal ? For how many time steps are the learning algorithm run before evaluating their outcome ? What are the meaning of the various input parameter of ACCnet, and is the performance sensitive to those parameters ?", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The authors study the problem of distributed routing in a network, where the goalis to minimize the maximalload (i e the load of the link with the highest utilization).", "The authors advocate to use multi-agent reinforcement learning.", "The main idea put forward by the authors is that by designing artificialrewards (to guide the agents), one can achieve faster exploration, in order to reduce convergence time.", "While the authors put forward severalinteresting ideas, there are some shortcomings to the present version of the paper, including: - The design objective seems flawed from the networking point of view: while minimizing the maximalload of a link is certainly a good starting point (to avoid instable queues) one typicaly wants to minimize delay (or maximize flow throughput).", "Indeed, it is possible to have a larger maximalload while reducing delay in many cases.", "- Furthermore, the authors do not provide a baseline to which the outcome of the learning alorithms they propose: for instance how does their approach compare to simple policies (those are commonplace in networking) such as MaxWeight, Backpressure and so on ?", "- The authors argue that using multi-agent learning is more desirable than single agent (i e with a single reward signalwhich is common to al agents).", "However, is multi-agent guaranteed to converge in such a setting ?", "If some versions of the problem (for some particular reward signal are not guaranteed to converge, it is difficult to understand whether \"convergence\" is slow due to an inefficient exploration, or simply because convergence cannot occur in the first place.", "- The learning alorithms used are not clearly explained: the authors simply state that they use \"ACCNet\" (from some unpublished prior work), but to readers unfamiliar with this alorithm, it is difficult to judge the contents of the paper.", "- In the numericalexperiments, what is the \"convergence rate\" ?", "is it the ratio between the mean reward of the learnt policy and that of the optimal?", "For how many time steps are the learning alorithm run before evalating their outcome ?", "What are the meaning of the various input parameter of ACCnet, and is the performance sensitive to those parameters ?"], "all_annotations": [{"interpretation": 0, "review_id": "S1uz175xf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "S1uz175xf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "S1uz175xf", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 2, "originality": null, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "S1uz175xf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SJ13MSaxf", "review_text": "The authors demonstrate experimentally a problem with the way common latent space operations such as linear interpolation are performed for GANs and VAEs. They propose a solution based on matching distributions using optimal transport. Quite heavy machinery to solve a fairly simple problem, but their approach is practical and effective experimentally (though the gain over the simple SLERP heuristic is often marginal). The problem they describe (and so the solution) deserves to be more widely known.\n\nMajor comments:\n\nThe paper is quite verbose, probably unnecessarily so. Firstly, the authors devote over 2 pages to examples that distribution mismatches can arise in synthetic cases (section 2). This point is well made by a single example (e.g. section 2.2) and the interesting part is that this is also an issue in practice (experimental section). Secondly, the authors spend a lot of space on the precise derivation of the optimal transport map for the uniform distribution. The fact that the optimal transport computation decomposes across dimensions for pointwise operations is very relevant, and the matching of CDFs, but I think a lot of the mathematical detail could be relegated to an appendix, especially the detailed derivation of the particular CDFs.\n\nMinor comments:\n\nIt seems worth highlighting that in practice, for the common case of a Gaussian, the proposed method for linear interpolation is just a very simple procedure that might be called \"projected linear interpolation\", where the generated vector is multiplied by a constant. All the optimal transport theory is nice, but it's helpful to know that this is simple to apply in practice.\n\nMight I suggest a very simple approach to fixing the distribution mismatch issue? Train with a spherical uniform prior. When interpolating, project the linear interpolation back to the sphere. This matches distribution, and has the attractive property that the entire geodesic between two points lies in a region with typical probability density. This would also work for vicinity sampling.\n\nIn section 1, overfitting concerns seem like a strange way to motivate the desire for smoothness. Overfitting is relatively easy to compensate for, and investigating the latent space is interesting regardless.\n\nWhen discussing sampling from VAEs as opposed to GANs, it would be good to mention that one has to sample from p(x | z) not just p(z).\n\nLots of math typos such as t - 1 should be 1 - t in (2), \"V times a times r\" instead of \"Var\" in (3) and \"s times i times n\" instead of \"sin\", etc, sqrt(1) * 2 instead of sqrt(12), inconsistent bolding of vectors. Also strange use of blackboard bold Z to mean a vector of random variables instead of the integers.\n\nCould cite an existing source for the fact that most mass for a Gaussian is concentrated on a thin shell (section 2.2), e.g. David MacKay Information Theory, Inference and Learning Algorithms.\n\nAt the end of section 2.4, a plot of the final 1D-to-1D optimal transport function (for a few different values of t) for the uniform case would be incredibly helpful.\n\nSection 3 should be a subsection of section 2.\n\nFor both SLERP and the proposed method, there's quite a sudden change around the midpoint of the interpolation in Figure 2. It would be interesting to plot more points around the midpoint to see the transition in more detail. (A small inkling that samples from the proposed approach might change fastest qualitatively near the midpoint of the interpolation perhaps maybe be seen in Figure 1, since the angle is changing fastest there??)\n\n", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The authors demonstrate experimentaly a problem with the way common latent space operations such as linear interpolation are performed for GANs and VAEs.", "They propose a solution based on matching distributions using optimaltransport.", "Quite heavy machinery to solve a fairly simple problem, but their approach is practicaland effective experimentaly (though the gain over the simple SLERP heuristic is often marginal.", "The problem they describe (and so the solution) deserves to be more widely known.", "Major comments: The paper is quite verbose, probably unnecessarily so.", "Firstly, the authors devote over 2 pages to examples that distribution mismatches can arise in synthetic cases (secion 2).", "This point is well made by a single example (e g secion 2 2) and the interesting part is that this is alo an issue in practice (experimentalsecion).", "secndly, the authors spend a lot of space on the precise derivation of the optimaltransport map for the uniform distribution.", "The fact that the optimaltransport computation decomposes across dimensions for pointwise operations is very relevant, and the matching of CDFs, but I think a lot of the mathematicaldetail could be relegated to an appendix, especialy the detailed derivation of the particular CDFs.", "Minor comments: It seems worth highlighting that in practice, for the common case of a Gaussian, the proposed method for linear interpolation is just a very simple procedure that might be caled \"projected linear interpolation\", where the generated vector is multiplied by a constant.", "All the optimaltransport theory is nice, but it's helpful to know that this is simple to apply in practice.", "Might I suggest a very simple approach to fixing the distribution mismatch issue?", "Train with a sphericaluniform prior.", "When interpolating, project the linear interpolation back to the sphere.", "This matches distribution, and has the attractive property that the entire geodesic between two points lies in a region with typicalprobability density.", "This would alo work for vicinity sampling.", "In secion 1, overfitting concerns seem like a strange way to motivate the desire for smoothness.", "Overfitting is relatively easy to compensate for, and investigating the latent space is interesting regardless.", "When discussing sampling from VAEs as opposed to GANs, it would be good to mention that one has to sample from p(x | z) not just p(z).", "Lots of math typos such as t - 1 should be 1 - t in (2), \"V times a times r\" instead of \"Var\" in (3) and \"s times i times n\" instead of \"sin\", etc sqrt(1) * 2 instead of sqrt(12), inconsistent bolding of vectors.", "Also strange use of blackboard bold Z to mean a vector of random variables instead of the integers.", "Could cite an existing source for the fact that most mass for a Gaussian is concentrated on a thin shell (secion 2 2), e g David MacKay Information Theory, Inference and Learning Algorithms.", "At the end of secion 2 4, a plot of the final1D-to-1D optimaltransport function (for a few different vales of t) for the uniform case would be incredibly helpful.", "secion 3 should be a subsecion of secion 2, For both SLERP and the proposed method, there's quite a sudden change around the midpoint of the interpolation in figre 2, It would be interesting to plot more points around the midpoint to see the transition in more detail.", "(A smal inkling that samples from the proposed approach might change fastest qualtatively near the midpoint of the interpolation perhaps maybe be seen in figre 1, since the angle is changing fastest there??)"], "all_annotations": [{"interpretation": 0, "review_id": "SJ13MSaxf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJ13MSaxf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJ13MSaxf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 2, "originality": null, "metareview": "maybe", "presentation": 1, "method": 0}, {"interpretation": 1, "review_id": "SJ13MSaxf", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SJ22faFez", "review_text": "There is no scientific consensus on whether quantum annealers such as the D-Wave 2000Q that use the transverse-field Ising models yield any gains over classical methods (c.f. https://arxiv.org/abs/1703.00622). However, it is an exciting research area and this paper is an interesting demonstration of the feasibility of using quantum annealers for reinforcement learning. \n\nThis paper builds on Crawford et al. (2016), an unpublished preprint, who develop a quantum Boltzmann machine reinforcement learning algorithm (QBM-RL). A QBM consists of adding a transverse field term to the RBM Hamiltonian (negative log likelihood), but the benefits of this for unsupervised tasks are unclear (c.f. https://arxiv.org/abs/1601.02036, another unpublished preprint). QBM-RL consists of using a QBM to model the state-action variables: it is an undirected graphical model whose visible nodes are clamped to observed state-action pairs. The hidden nodes model dependencies between states and actions, and the weights of the model are updated to maximize the free energy or Q function (value of the state-action pair).\n\nThe authors extend QBM-RL to work with quantum annealers such as the D-Wave 2000Q, which has a specific bipartite graph structure and requires special consideration because it can only yield samples of hidden variables in a fixed basis. To overcome this, the authors develop a Suzuki-Trotter expansion and call it 'replica stacking', where a classical Hamiltonian in one dimension higher is used to approximate the quantum Hamiltonian. This enables the use of quantum annealers. The authors compare their method to standard baselines in a grid world environment.\n\nOverall, I do not want to criticize the work. It is an interesting proof of concept. But given the high price of quantum annealers, limited applicability of the technique, and unclear benefits of the authors' method, I do not think it is relevant to this specific conference. It may be better suited to a workshop specific to quantum machine learning methods. \n=======================================\n+ please add an algorithm box for your method. It deviates significantly from QBM-RL. For example, something like: (1) init weights of boltzmann machine randomly (2) sample c_eff ~ C from the pool of configurations sampled from the transverse-field Ising model using a quantum annealer with chimera graph (3) using the samples, calculate effective classical hamiltonian used to approximate the quantum system (4) use the weight update rules derived from Bellman equations (spell out the rules). \n\n+ moving the details of sampling into the appendix would help; they are not important for understanding the main ingredients of your method\n\nThere are so many moving parts in your system, and someone without a physics background will struggle to understand it. Clarifying the algorithm in terms familiar to machine learning researchers will go a long way toward helping people understand your method. \n\n+ the benefits of your method is unclear - it looks like the method works, but doesn't outperform the others. this is fine, but it is better to be straightforward about this and bill it as a 'proof of concept' \n\n+ perhaps consider rebranding the paper as something like 'RL using replica stacking for sampling from quantum boltzmann machines with quantum annealers'. Elucidating why replica stacking is a crucial contribution of your work would be helpful, and could be of broad interest in the machine learning community. Right now it is too dense to be useful for the average person without a physics background: what difficulties are intrinsic to a quantum Hamiltonian? What is the intuition behind the Suzuki-Trotter decomposition you develop? What is the 'quantum' Boltzmann machine in machine learning terms (hidden-hidden connections in an undirected graphical model!)? What is replica-stacking in graphical model terms (this would be a great ML contribution in its own right!)? Really spelling these things out in detail (or in the appendix) would help\n==========================================\n1) eq 14 is malformed\n\n2) references are not well-formatted\n\n3) need factor of 1/2 to avoid double counting in sums over nearest neighbors (please be precise)", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["There is no scientific consensus on whether quantum annealrs such as the D-Wave 2000Q that use the transverse-field Ising models yield any gains over classicalmethods (c f https://arxiv.org/abs/1703.00622).", "However, it is an exciting research area and this paper is an interesting demonstration of the feasibility of using quantum annealrs for reinforcement learning.", "This paper builds on Crawford et al (2016), an unpublished preprint, who develop a quantum Boltzmann machine reinforcement learning alorithm (QBM-RL).", "A QBM consists of adding a transverse field term to the RBM Hamiltonian (negative log likelihood), but the benefits of this for unsupervised tasks are unclear (c f https://arxiv.org/abs/1601.02036, another unpublished preprint).", "QBM-RL consists of using a QBM to model the state-action variables: it is an undirected graphicalmodel whose visible nodes are clamped to observed state-action pairs.", "The hidden nodes model dependencies between states and actions, and the weights of the model are updated to maximize the free energy or Q function (vale of the state-action pair).", "The authors extend QBM-RL to work with quantum annealrs such as the D-Wave 2000Q, which has a specific bipartite graph structure and reqires specialconsideration because it can only yield samples of hidden variables in a fixed basis.", "To overcome this, the authors develop a Suzuki-Trotter expansion and cal it 'replica stacking', where a classicalHamiltonian in one dimension higher is used to approximate the quantum Hamiltonian.", "This enables the use of quantum annealrs.", "The authors compare their method to standard baselines in a grid world environment.", "Overal, I do not want to criticize the work.", "It is an interesting proof of concept.", "But given the high price of quantum annealrs, limited applicability of the technique, and unclear benefits of the authors' method, I do not think it is relevant to this specific conference.", "It may be better suited to a workshop specific to quantum machine learning methods.", "======================================= + please add an alorithm box for your method.", "It deviates significantly from QBM-RL.", "For example, something like: (1) init weights of boltzmann machine randomly (2) sample c_eff ~ C from the pool of configrations sampled from the transverse-field Ising model using a quantum annealr with chimera graph (3) using the samples, calulate effective classicalhamiltonian used to approximate the quantum system (4) use the weight update rules derived from Bellman eqations (spell out the rules).", "+ moving the details of sampling into the appendix would help; they are not important for understanding the main ingredients of your method There are so many moving parts in your system, and someone without a physics background will struggle to understand it.", "Clarifying the alorithm in terms familiar to machine learning researchers will go a long way toward helping people understand your method.", "+ the benefits of your method is unclear - it looks like the method works, but doesn't outperform the others.", "this is fine, but it is better to be straightforward about this and bill it as a 'proof of concept' + perhaps consider rebranding the paper as something like 'RL using replica stacking for sampling from quantum boltzmann machines with quantum annealrs'.", "Elucidating why replica stacking is a crucialcontribution of your work would be helpful, and could be of broad interest in the machine learning community.", "Right now it is too dense to be useful for the average person without a physics background: what difficulties are intrinsic to a quantum Hamiltonian?", "What is the intuition behind the Suzuki-Trotter decomposition you develop?", "What is the 'quantum' Boltzmann machine in machine learning terms (hidden-hidden connections in an undirected graphicalmodel!)?", "What is replica-stacking in graphicalmodel terms (this would be a great ML contribution in its own right!)?", "Realy spelling these things out in detail (or in the appendix) would help ========================================== 1) eq14 is malormed 2) references are not well-formatted 3) need factor of 1/2 to avoid double counting in sums over nearest neighbors (please be precise)"], "all_annotations": [{"interpretation": 0, "review_id": "SJ22faFez", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": null, "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJ22faFez", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJ22faFez", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJ22faFez", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "SJ2P_-YgG", "review_text": "The main idea of this paper is to replace the feedforward summation\ny = f(W*x + b)\nwhere x,y,b are vectors, W is a matrix\nby an integral\n\\y = f(\\int W \\x + \\b)\nwhere \\x,\\y,\\b are functions, and W is a kernel. A deep neural network with this integral feedforward is called a deep function machine. \n\nThe motivation is along the lines of functional PCA: if the vector x was obtained by discretization of some function \\x, then one encounters the curse of dimensionality as one obtains finer and finer discretization. The idea of functional PCA is to view \\x as a function is some appropriate Hilbert space, and expands it in some appropriate basis. This way, finer discretization does not increase the dimension of \\x (nor its approximation), but rather improves the resolution. \n\nThis paper takes this idea and applies it to deep neural networks. Unfortunately, beyond rather obvious approximation results, the paper does not get major mileage out of this idea. This approach amounts to a change of basis - and therefore the resolution invariance is not surprising. In the experiments, results of this method should be compared not against NNs trained on the data directly, but against NNs trained on dimension reduced version of the data (eg: first fixed number of PCA components). Unfortunately, this was not done. I suspect that in this case, the results would be very similar. \n\n", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The main idea of this paper is to replace the feedforward summation y = f(W*x + b) where x,y,b are vectors, W is a matrix by an integral\\y = f(\\int W \\x + \\b) where \\x,\\y,\\b are functions, and W is a kernel.", "A deep neuralnetwork with this integralfeedforward is caled a deep function machine.", "The motivation is alng the lines of functionalPCA: if the vector x was obtained by discretization of some function \\x, then one encounters the curse of dimensionalty as one obtains finer and finer discretization.", "The idea of functionalPCA is to view \\x as a function is some appropriate Hilbert space, and expands it in some appropriate basis.", "This way, finer discretization does not increase the dimension of \\x (nor its approximation), but rather improves the resolution.", "This paper takes this idea and applies it to deep neuralnetworks.", "Unfortunately, beyond rather obvious approximation results, the paper does not get major mileage out of this idea.", "This approach amounts to a change of basis - and therefore the resolution invariance is not surprising.", "In the experiments, results of this method should be compared not against NNs trained on the data directly, but against NNs trained on dimension reduced version of the data (eg: first fixed number of PCA components).", "Unfortunately, this was not done.", "I suspect that in this case, the results would be very similar."], "all_annotations": [{"interpretation": 0, "review_id": "SJ2P_-YgG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "SJ2P_-YgG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "SJ2P_-YgG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "SJ2P_-YgG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "SJEDvEvez", "review_text": "This reviewer has found the proposed approach quite compelling, but the empirical validation requires significant improvements:\n1) you should include in your comparison Query-by- Bagging & Boosting, which are two of the best out-of-the-box active learning strategies\n2) in your empirical validation you have (arbitrarily) split the 14 datasets in 7 training and testing ones, but many questions are still unanswered:\n -  would any 7-7 split work just as well (ie, cross-validate over the 14 domains)\n - do you what happens if you train on 1, 2, 3, 8, 10, or 13 domains? are the results significantly different? \n\nOTHER COMMENTS:\n- p3: both images in Figure 1 are labeled Figure 1.a\n- p3: typo \"theis\" --> \"this\" \n\nAbe & Mamitsuksa (ICML-1998). Query Learning Strategies Using Boosting and Bagging.", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["This reviewer has found the proposed approach quite compelling, but the empiricalvaldation reqires significant improvements: 1) you should include in your comparison Query-by- Bagging & Boosting, which are two of the best out-of-the-box active learning strategies 2) in your empiricalvaldation you have (arbitrarily) split the 14 datasets in 7 training and testing ones, but many questions are still unanswered: - would any 7-7 split work just as well (ie, cross-valdate over the 14 domains) - do you what happens if you train on 1, 2, 3, 8, 10, or 13 domains?", "are the results significantly different?", "OTHER COMMENTS: - p3: both images in figre 1 are labeled figre 1 a - p3: typo \"theis\" --> \"this\" Abe & Mamitsuksa (ICML-1998).", "Query Learning Strategies Using Boosting and Bagging."], "all_annotations": [{"interpretation": 1, "review_id": "SJEDvEvez", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 3, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJEDvEvez", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJEDvEvez", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "SJEDvEvez", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 2, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SJJrhg5lf", "review_text": "## Review Summary\n\nOverall, the paper's paper core claim, that increasing batch sizes at a linear\nrate during training is as effective as decaying learning rates, is\ninteresting but doesn't seem to be too surprising given other recent work in\nthis space. The most useful part of the paper is the empirical evidence to\nbackup this claim, which I can't easily find in previous literature. I wish\nthe paper had explored a wider variety of dataset tasks and models to better\nshow how well this claim generalizes, better situated the practical benefits\nof the approach (how much wallclock time is actually saved? how well can it be\nintegrated into a distributed workflow?), and included some comparisons with\nother recent recommended ways to increase batch size over time.\n\n\n## Pros / Strengths\n\n+ effort to assess momentum / Adam / other modern methods\n\n+ effort to compare to previous experimental setups\n\n\n## Cons / Limitations\n\n- lack of wallclock measurements in experiments\n\n- only ~2 models / datasets examined, so difficult to assess generalization\n\n- lack of discussion about distributed/asynchronous SGD\n\n\n## Significance\n\nMany recent previous efforts have looked at the importance of batch sizes\nduring training, so topic is relevant to the community. Smith and Le (2017)\npresent a differential equation model for the scale of gradients in SGD,\nfinding a linear scaling rule proportional to eps N/B, where eps = learning\nrate, N = training set size, and B = batch size. Goyal et al (2017) show how\nto train deep models on ImageNet effectively with large (but fixed) batch\nsizes by using a linear scaling rule.\n\nA few recent works have directly tested increasing batch sizes during\ntraining. De et al (AISTATS 2017) have a method for gradually increasing batch\nsizes, as do Friedlander and Schmidt (2012). Thus, it is already reasonable to\npractitioners that the proposed linear scaling of batch sizes during training\nwould be effective.\n\nWhile increasing batch size at the proposed linear scale is simple and seems\nto be effective, a careful reader will be curious how much more could be\ngained from the backtracking line search method proposed in De et al.\n\n\n## Quality\n\nOverall, only single training runs from a random initialization are used. It\nwould be better to take the best of many runs or to somehow show error bars,\nto avoid the reader wondering whether gains are due to changes in algorithm or\nto poor exploration due to bad initialization. This happens a lot in Sec. 5.2.\n\nSome of the experimental setting seem a bit haphazard and not very systematic.\nIn Sec. 5.2, only two learning rate scales are tested (0.1 and 0.5). Why not\nexamine a more thorough range of values?\n\nWhy not report actual wallclock times? Of course having reduced number of\nparameter updates is useful, but it's difficult to tell how big of a win this\ncould be.\n\nWhat about distributed SGD or asyncronous SGD (hogwild)? Small batch sizes\nsometimes make it easier for many machines to be working simultaneously. If we\nscale up to batch sizes of ~ N/10, we can only get 10x speedups in\nparallelization (in terms of number of parameter updates). I think there is\nsome subtle but important discussion needed on how this framework fits into\nmodern distributed systems for SGD.\n\n\n## Clarity\n\nOverall the paper reads reasonably well.\n\nOffering a related work \"feature matrix\" that helps readers keep track of how\nprevious efforts scale learning rates or minibatch sizes for specific\nexperiments could be valueable. Right now, lots of this information is just\nprovided in text, so it's not easy to make head-to-head comparisons.\n\nSeveral figure captions should be updated to clarify which model and dataset\nare studied. For example, when skimming Fig. 3's caption there is no such\ninformation.\n\n## Paper Summary\n\nThe paper examines the influence of batch size on the behavior of stochastic\ngradient descent to minimize cost functions. The central thesis is that\ninstead of the \"conventional wisdom\" to fix the batch size during training and\ndecay the learning rate, it is equally effective (in terms of training/test\nerror reached) to gradually increase batch size during training while fixing\nthe learning rate. These two strategies are thus \"equivalent\". Furthermore,\nusing larger batches means fewer parameter updates per epoch, so training is\npotentially much faster.\n\nSection 2 motivates the suggested linear scaling using previous SGD analysis\nfrom Smith and Le (2017). Section 3 makes connections to previous work on\nfinding optimal batch sizes to close the generaization gap. Section 4 extends\nanalysis to include SGD methods with momentum.\n\nIn Section 5.1, experiments training a 16-4 ResNet on CIFAR-10 compare three\npossible SGD schedules: * increasing batch size * decaying learning rate *\nhybrid (increasing batch size and decaying learning rate) Fig. 2, 3 and 4 show\nthat across a range of SGD variants (+/- momentum, etc) these three schedules\nhave similar error vs. epoch curves. This is the core claimed contribution:\nempirical evidence that these strategies are \"equivalent\".\n\nIn Section 5.3, experiments look at Inception-ResNet-V2 on ImageNet, showing\nthe proposed approach can reach comparable accuracies to previous work at even\nfewer parameter updates (2500 here, vs. \u223c14000 for Goyal et al 2007)\n", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["## Review Summary Overal, the paper's paper core claim, that increasing batch sizes at a linear rate during training is as effective as decaying learning rates, is interesting but doesn't seem to be too surprising given other recent work in this space.", "The most useful part of the paper is the empiricalevidence to backup this claim, which I can't easily find in previous literature.", "I wish the paper had explored a wider variety of dataset tasks and models to better show how well this claim generalzes, better situated the practicalbenefits of the approach (how much walclock time is actualy saved?", "how well can it be integrated into a distributed workflow?", "), and included some comparisons with other recent recommended ways to increase batch size over time.", "## Pros / Strengths + effort to assess momentum / Adam / other modern methods + effort to compare to previous experimentalsetups ## Cons / Limitations - lack of walclock measurements in experiments - only ~2 models / datasets examined, so difficult to assess generalzation - lack of discussion about distributed/asynchronous SGD ## Significance Many recent previous efforts have looked at the importance of batch sizes during training, so topic is relevant to the community.", "Smith and Le (2017) present a differentialeqation model for the scal of gradients in SGD, finding a linear scalng rule proportionalto eps N/B, where eps = learning rate, N = training set size, and B = batch size.", "Goyalet al(2017) show how to train deep models on ImageNet effectively with large (but fixed) batch sizes by using a linear scalng rule.", "A few recent works have directly tested increasing batch sizes during training.", "De et al(AISTATS 2017) have a method for gradualy increasing batch sizes, as do Friedlander and Schmidt (2012).", "Thus, it is aleady reasonable to practitioners that the proposed linear scalng of batch sizes during training would be effective.", "While increasing batch size at the proposed linear scal is simple and seems to be effective, a careful reader will be curious how much more could be gained from the backtracking line search method proposed in De et al ## Qualty Overal, only single training runs from a random initialzation are used.", "It would be better to take the best of many runs or to somehow show error bars, to avoid the reader wondering whether gains are due to changes in alorithm or to poor exploration due to bad initialzation.", "This happens a lot in sec 5 2, Some of the experimentalsetting seem a bit haphazard and not very systematic.", "In sec 5 2, only two learning rate scals are tested (0 1 and 0 5).", "Why not examine a more thorough range of vales?", "Why not report actualwalclock times?", "Of course having reduced number of parameter updates is useful, but it's difficult to tell how big of a win this could be.", "What about distributed SGD or asyncronous SGD (hogwild)?", "Smal batch sizes sometimes make it easier for many machines to be working simultaneously.", "If we scal up to batch sizes of ~ N/10, we can only get 10x speedups in paralelization (in terms of number of parameter updates).", "I think there is some subtle but important discussion needed on how this framework fits into modern distributed systems for SGD.", "## Clarity Overal the paper reads reasonably well.", "Offering a related work \"feature matrix\" that helps readers keep track of how previous efforts scal learning rates or minibatch sizes for specific experiments could be valeable.", "Right now, lots of this information is just provided in text, so it's not easy to make head-to-head comparisons.", "Severalfigre captions should be updated to clarify which model and dataset are studied.", "For example, when skimming fig 3's caption there is no such information.", "## Paper Summary The paper examines the influence of batch size on the behavior of stochastic gradient descent to minimize cost functions.", "The centralthesis is that instead of the \"conventionalwisdom\" to fix the batch size during training and decay the learning rate, it is eqaly effective (in terms of training/test error reached) to gradualy increase batch size during training while fixing the learning rate.", "These two strategies are thus \"eqivalnt\".", "Furthermore, using larger batches means fewer parameter updates per epoch, so training is potentialy much faster.", "secion 2 motivates the suggested linear scalng using previous SGD analsis from Smith and Le (2017).", "secion 3 makes connections to previous work on finding optimalbatch sizes to close the generaization gap.", "secion 4 extends analsis to include SGD methods with momentum.", "In secion 5 1, experiments training a 16-4 ResNet on CIFAR-10 compare three possible SGD schedules: * increasing batch size * decaying learning rate * hybrid (increasing batch size and decaying learning rate) fig 2, 3 and 4 show that across a range of SGD variants (+/- momentum, etc these three schedules have similar error vs. epoch curves.", "This is the core claimed contribution: empiricalevidence that these strategies are \"eqivalnt\".", "In secion 5 3, experiments look at Inception-ResNet-V2 on ImageNet, showing the proposed approach can reach comparable accuracies to previous work at even fewer parameter updates (2500 here, vs. \u223c14000 for Goyalet al2007)"], "all_annotations": [{"interpretation": 0, "review_id": "SJJrhg5lf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJJrhg5lf", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJJrhg5lf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJJrhg5lf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SJNicmVeM", "review_text": "The paper presents Erdos-Selfridge-Spencer games as environments for investigating\ndeep reinforcement learning algorithms. The proposed games are interesting and clearly challenging, but I am not sure what they tell us about the algorithms chosen to test them. There are some clarity issues with the justification and evaluation which undermine the message the authors are trying to make.\n\nIn particular, I have the following concerns:\n\n  \u2022 these games have optimal policies that are expressible as a linear model, meaning that if the architecture or updating of the learning algorithm is such that there is a bias towards exploring these parts of policy space, then they will perform better than more general algorithms. What does this tell us about the relative merits of each approach? The authors could do more to formally motivate these games as \"difficult\" for any deep learning architecture if possible.\n  \u2022 the authors compare linear models with non-linear models at some point for attacker policies, but it is unclear whether these linear models are able to express the optimal policy. In fact, there is a level of non-determinism in how the attacker policies are encoded which means that an optimal policy cannot be (even up to soft-max) expressed by the agent (as I read things the number of pieces chosen in level l is always chosen uniformly randomly).\n  \u2022 As the authors state, this paper is an empirical evaluation, and the theorems presented are derived from earlier work. There is possibly too much focus on the proofs of these theorems.\n  \u2022 There are a number of ambiguities and errors which places difficulties on the interpretation (and potential replication) of the experiments. As this is an empirical study, this is the yardstick by which the paper should be judged. In particular, this relates to:\n    \u25e6 The architecture of each of the tested Deep RL methods.\n    \u25e6 What is done to select appropriate tuning parameters of the tested Deep RL methods, if anything.\n    \u25e6 It is unclear whether 'incorrect actions' in the supervised learning evaluations, refer to non-optimal actions, or simply actions that do not preserve the dominance of the defender, e.g. both partitions may have potential >0.5\n    \u25e6 Fig 4. right looks like a reward signal, but is labelled Proportion correct. The text is not clear enough to be sure which it is.\n    \u25e6 Fig 4. left and right has 4 methods: rl rewards, rl correct actions, sup rewards, and sup correct actions. The specifics of how these methods are constructed is unclear from the paper.\n    \u25e6 What parts of the evaluation explores how well these methods are able to represent the states (feature/representation learning) and what parts are evaluating the propagation of sparse rewards (the reinforcment learning core)? The authors could be clearer and more targetted with respect to this question.\n\nThere is value in this work, but in its current state I do not think it is ready for publicaiton.\n\n# Detailed notes\n\n[p4, end of sec 3] The authors say that the difficulty of the games can be varied with \"continuous changes in potential\", but the potential is derived from the discrete initial game state, so these values are not continuously varying (even though it is possible to adjust them by non-integer amounts).\n\n[p4, sec 4.1]\n\"strategy unevenly partitions the occupied levels...with the proportional difference between the two sets being sampled randomly\"\nWhat is meant by this? The proportional difference between the two sets is discussed as if it is a continuous property, but must be chosen from the discrete set of all available partitions. If one partition one is chosen uniformly randomly from all possibly sets A, B (and the potential proportion calculated) then I don't know why it would be written in this way. That suggests that proportions that are closer to 1:1 are chosen more often than \"extreme\" partitions, but how? This feels a little under-justified.\n\"very different states A, B (uneven potential, disjoint occupied levels)\"\nAre these states really \"very different\", or at least for the reasons indicated. Later on (Theorem 3) we see how an optimal partition is generated. This chooses a partition where one part contains all pieces in layer (l+1) and above and one part with all pieces in layer (l-1) and below, with layer l being distributed between the two parts. The first part will typically have a slightly lower potential than the other and all layers other than layer l will be disjoint.\n\n\n[p6, Fig 4] The right plot y-limits vary between -1 and 1 so it cannot represent a proportion of correct actions. Also, in the text the authors say:\n  >> The results, shown in Figure 4 are surprising. Reinforcement learning \n  >> is better at playing the game, but does worse at predicting optimal moves.\nI am not sure which plot shows the playing of the game. Is this the right hand plot? In which case are we looking at rewards? In fact, I am a little confused as to what is being shown here. Is \"sup rewards\" a supervised learning method trained on rewards, or evaluated on rewards, or both? And how is this done. The text is just not clear enough.\n\n[p7 Fig 6 and text] Here the authors are comparing how well agents select the optimal actions as compared to how close they are to the end of the game. This relates to the \"surprising\" fact that \"Reinforcement learning is better at playing the game, but does worse at predicting optimal moves.\". I think an important point here is how many training/test examples there are in each bin. If there are more in the range 3-7 moves from the end of the game, than there are outside this range, then the supervised learner will\n\n[p8 proof of theorem 3] \n\"\u03c6(A l+1 ) < 0.5 and \u03c6(A l ) > 0.5.\"\nIs it true that both these inequalities are strict?\n\"Since A l only contains pieces from levels K to l + 1\"\nIn fact this should read from levels K to l.\n\"we can move k < m \u2212 n pieces from A l+1 to A l\"\nDo the authors mean that we can define a partition A, B where A = A_{l+1} plus some (but not all) elements in level l (A_{l}\\setminus A_{l+1})?\n\"...such that the potential of the new set equals 0.5\"\nIt will equal exactly 0.5 as suggested, but the authors could make it more precise as to why (there is a value n+k < l (maybe <=l) such that (n+k)*2^{-(K-l+1)}=0.5 (guaranteed). They should also indicate why this then justifies their proof (namely that phi(S0)-0.5 >= 0.5).\n\n[p8 paramterising action space] A comment: this doesn't give as much control as the authors suggest. Perhaps the agent should also chose the proportion of elements in layer l to set A. For instance, if there are a large number of elements in l, and or phi(A_{l+1}) is very close to 0.5 (or phi(A_l) is very close to 0.5) then this doesn't give the attacker the opportunity to fine tune the policy to select very good partitions.  It is unclear expected level of control that agents have under various conditions (K and starting states).\n\n[p9 Fig 8] As the defender's score is functionally determined by the attackers score, it doesn't help to include this on the plot. It just distracts from the signal.\n", "gold_annotation": null, "score": 4.5, "tokenized_review_text": ["The paper presents Erdos-Selfridge-Spencer games as environments for investigating deep reinforcement learning alorithms.", "The proposed games are interesting and clearly chalenging, but I am not sure what they tell us about the alorithms chosen to test them.", "There are some clarity issues with the justification and evalation which undermine the message the authors are trying to make.", "In particular, I have the following concerns: \u2022 these games have optimalpolicies that are expressible as a linear model, meaning that if the architecture or updating of the learning alorithm is such that there is a bias towards exploring these parts of policy space, then they will perform better than more generalalorithms.", "What does this tell us about the relative merits of each approach?", "The authors could do more to formaly motivate these games as \"difficult\" for any deep learning architecture if possible.", "\u2022 the authors compare linear models with non-linear models at some point for attacker policies, but it is unclear whether these linear models are able to express the optimalpolicy.", "In fact, there is a level of non-determinism in how the attacker policies are encoded which means that an optimalpolicy cannot be (even up to soft-max) expressed by the agent (as I read things the number of pieces chosen in level l is alays chosen uniformly randomly).", "\u2022 As the authors state, this paper is an empiricalevalation, and the theorems presented are derived from earlier work.", "There is possibly too much focus on the proofs of these theorems.", "\u2022 There are a number of ambiguities and errors which places difficulties on the interpretation (and potentialreplication) of the experiments.", "As this is an empiricalstudy, this is the yardstick by which the paper should be judged.", "In particular, this relates to: \u25e6 The architecture of each of the tested Deep RL methods.", "\u25e6 What is done to select appropriate tuning parameters of the tested Deep RL methods, if anything.", "\u25e6 It is unclear whether 'incorrect actions' in the supervised learning evalations, refer to non-optimalactions, or simply actions that do not preserve the dominance of the defender, e g both partitions may have potential>0 5 \u25e6 fig4, right looks like a reward signal but is labelled Proportion correct.", "The text is not clear enough to be sure which it is.", "\u25e6 fig4, left and right has 4 methods: rl rewards, rl correct actions, sup rewards, and sup correct actions.", "The specifics of how these methods are constructed is unclear from the paper.", "\u25e6 What parts of the evalation explores how well these methods are able to represent the states (feature/representation learning) and what parts are evalating the propagation of sparse rewards (the reinforcment learning core)?", "The authors could be clearer and more targetted with respect to this question.", "There is vale in this work, but in its current state I do not think it is ready for publicaiton.", "# Detailed notes [p4, end of sec3] The authors say that the difficulty of the games can be varied with \"continuous changes in potential, but the potentialis derived from the discrete initialgame state, so these vales are not continuously varying (even though it is possible to adjust them by non-integer amounts).", "[p4, sec4 1] \"strategy unevenly partitions the occupied levels...with the proportionaldifference between the two sets being sampled randomly\" What is meant by this?", "The proportionaldifference between the two sets is discussed as if it is a continuous property, but must be chosen from the discrete set of al available partitions.", "If one partition one is chosen uniformly randomly from al possibly sets A, B (and the potentialproportion calulated) then I don't know why it would be written in this way.", "That suggests that proportions that are closer to 1:1 are chosen more often than \"extreme\" partitions, but how?", "This feels a little under-justified.", "\"very different states A, B (uneven potential disjoint occupied levels)\" Are these states realy \"very different\", or at least for the reasons indicated.", "Later on (Theorem 3) we see how an optimalpartition is generated.", "This chooses a partition where one part contains al pieces in layer (l+1) and above and one part with al pieces in layer (l-1) and below, with layer l being distributed between the two parts.", "The first part will typicaly have a slightly lower potentialthan the other and al layers other than layer l will be disjoint.", "[p6, fig4] The right plot y-limits vary between -1 and 1 so it cannot represent a proportion of correct actions.", "Also, in the text the authors say: >> The results, shown in figre 4 are surprising.", "Reinforcement learning >> is better at playing the game, but does worse at predicting optimalmoves.", "I am not sure which plot shows the playing of the game.", "Is this the right hand plot?", "In which case are we looking at rewards?", "In fact, I am a little confused as to what is being shown here.", "Is \"sup rewards\" a supervised learning method trained on rewards, or evalated on rewards, or both?", "And how is this done.", "The text is just not clear enough.", "[p7 fig6 and text] Here the authors are comparing how well agents select the optimalactions as compared to how close they are to the end of the game.", "This relates to the \"surprising\" fact that \"Reinforcement learning is better at playing the game, but does worse at predicting optimalmoves.\".", "I think an important point here is how many training/test examples there are in each bin.", "If there are more in the range 3-7 moves from the end of the game, than there are outside this range, then the supervised learner will [p8 proof of theorem 3] \"\u03c6(A l+1 ) < 0 5 and \u03c6(A l ) > 0 5 \" Is it true that both these ineqalties are strict?", "\"Since A l only contains pieces from levels K to l + 1\" In fact this should read from levels K to l \"we can move k < m \u2212 n pieces from A l+1 to A l\" Do the authors mean that we can define a partition A, B where A = A_{l+1} plus some (but not al) elements in level l (A_{l}\\setminus A_{l+1})?", "\"...such that the potentialof the new set eqal 0 5\" It will eqalexactly 0 5 as suggested, but the authors could make it more precise as to why (there is a vale n+k < l (maybe <=l) such that (n+k)*2^{-(K-l+1)}=0 5 (guaranteed).", "They should alo indicate why this then justifies their proof (namely that phi(S0)-0 5 >= 0 5).", "[p8 paramterising action space] A comment: this doesn't give as much control as the authors suggest.", "Perhaps the agent should alo chose the proportion of elements in layer l to set A For instance, if there are a large number of elements in l, and or phi(A_{l+1}) is very close to 0 5 (or phi(A_l) is very close to 0 5) then this doesn't give the attacker the opportunity to fine tune the policy to select very good partitions.", "It is unclear expected level of control that agents have under various conditions (K and starting states).", "[p9 fig8] As the defender's score is functionaly determined by the attackers score, it doesn't help to include this on the plot.", "It just distracts from the signal"], "all_annotations": [{"interpretation": 1, "review_id": "SJNicmVeM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJNicmVeM", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJNicmVeM", "importance": 0, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJNicmVeM", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SJQVdQ5lG", "review_text": "This paper describes an extension to the recently introduced Transformer networks which shows better convergence properties and also improves results on standard machine translation benchmarks. \n\nThis is a great paper -- it introduces a relatively simple extension of Transformer networks which only adds very few parameters and speeds up convergence and achieves better results. It would have been good to also add a motivation for doing this (for example, this idea can be interpreted as having a variable number of attention heads which can be blended in and out with a single learned parameter, hence making it easier to use the parameters where they are needed). Also, it would be interesting to see how important the concatenation weight and the addition weight are relative to each other -- do you possibly get the same results even without the concatenation weight? \n\nA suggested improvement: Please check the references in the introduction and see if you can find earlier ones -- for example, language modeling with RNNs has been done for a very long time, not just since 2017 which are the ones you list; similar for speech recognition etc. (which probably has been done since 1993!).\n\nAddition to the original review: Your added additional results table clarifies a lot, thank you. As for general references for RNNs, I am not sure Hochreiter & Schmidhuber 1997 is a good reference as this only points to a particular type of RNN that is used today a lot. For speech recognition there are many better citations as well, check the conference proceedings from ICASSP for papers from Microsoft, Google, IBM, which are the leaders in speech recognition technology. However, I know citations can be difficult to get right for everybody, just try to do your best. ", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["This paper describes an extension to the recently introduced Transformer networks which shows better convergence properties and alo improves results on standard machine translation benchmarks.", "This is a great paper -- it introduces a relatively simple extension of Transformer networks which only adds very few parameters and speeds up convergence and achieves better results.", "It would have been good to alo add a motivation for doing this (for example, this idea can be interpreted as having a variable number of attention heads which can be blended in and out with a single learned parameter, hence making it easier to use the parameters where they are needed).", "Also, it would be interesting to see how important the concatenation weight and the addition weight are relative to each other -- do you possibly get the same results even without the concatenation weight?", "A suggested improvement: Please check the references in the introduction and see if you can find earlier ones -- for example, language modeling with RNNs has been done for a very long time, not just since 2017 which are the ones you list; similar for speech recognition etc (which probably has been done since 1993!).", "Addition to the originalreview: Your added additionalresults table clarifies a lot, thank you.", "As for generalreferences for RNNs, I am not sure Hochreiter & Schmidhuber 1997 is a good reference as this only points to a particular type of RNN that is used today a lot.", "For speech recognition there are many better citations as well, check the conference proceedings from ICASSP for papers from Microsoft, Google, IBM, which are the leaders in speech recognition technology.", "However, I know citations can be difficult to get right for everybody, just try to do your best."], "all_annotations": [{"interpretation": 0, "review_id": "SJQVdQ5lG", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "SJQVdQ5lG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJQVdQ5lG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "SJQVdQ5lG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SJUEXlDxf", "review_text": "Summary\n\nThis paper presents Neural Process Networks, an architecture for capturing procedural knowledge stated in texts that makes use of a differentiable memory, a sentence and word attention mechanism, as well as learning action representations and their effect on entity representations. The architecture is tested for tracking entities in recipes, as well as generating the natural language description for the next step in a recipe. It is compared against a suit of baselines, such as GRUs, Recurrent Entity Networks, Seq2Seq and the Neural Checklist Model. While I liked the overall paper, I am worried about the generality of the model, the qualitative analysis, as well as a fair comparison to Recurrent Entity Networks and non-neural baselines.\n\nStrengths\n\nI believe the authors made a good effort in comparing against existing neural baselines (Recurrent Entity Networks, Neural Checklist Model) *for their task*. That said, it is unclear to me how generally applicable the method is and whether the comparison against Recurrent Entity Networks is fair (see Weaknesses).\nI like the ablation study.\n\nWeaknesses\n\nWhile I find the Neural Process Networks architecture interesting and I acknowledge that it outperforms Recurrent Entity Networks for the presented tasks, after reading the paper it is not clear to me how generally applicable the architecture is. Some design choices seem rather tailored to the task at hand (manual collection of actions MTurk annotation in section 3.1) and I am wondering where else the authors see their method being applied given that the architecture relies on all entities and actions being known in advance. My understanding is that the architecture could be applied to bAbI and CBT (the two tasks used in the Recurrent Entity Networks paper). If that is the case, a fair comparison to Recurrent Entity Networks would have been to test against Recurrent Entity Networks on these tasks too. If they the architecture cannot be applied in these tasks, the authors should explain why.\nI am not convinced by the qualitative analysis. Table 2 tells me that even for the best model the entity selection performance is rather unreliable (only 55.39% F1), yet all examples shown in Table 3 look really good, missing only the two entities oil (1) and sprinkles (3). This suggests that these examples were cherry-picked and I would like to see examples that are sampled randomly from the dev set. I have a similar concern regarding the generation task. First, it is not mentioned where the examples in Table 6 are taken from \u2013 is it the train, dev or test set? Second, the overall BLEU score seems quite low even for the best model, yet the examples in Table 6 look really good. In my opinion, a good qualitative analysis should also discuss failure cases. Since the BLEU score is so low here, you might also want to compare perplexity of the models.\nThe qualitative analysis in Table 5 is not convincing either. In Appendix A.1 it is mentioned that word embeddings are initialized from word2vec trained on the training set. My suspicion is that one would get the clustering in Table 4 already from those pretrained vectors, maybe even when pretrained on the Google news corpus. Hence, it is not clear what propagating gradients through the Neural Process Networks into the action embeddings adds, or put differently, why does it have to be a differentiable architecture when an NLP pipeline might be enough? This could easily be tested by another ablation where action embeddings are pretrained using word2vec and then fixed during training of the Neural Process Network. Moreover, in 3.3 it is mentioned that even the Action Selection is pretrained, which makes me wonder what is actually trained jointly in the architecture and what is not.\nI think the difficulty of the task at hand needs to be discussed at some point, ideally early in the paper. Until examples on page 7 are shown, I did not have a sense for why a neural architecture is chosen. For example, in 2.3 it is mentioned that for \"wash and cut\" the two functions fwash and fcut need to be selected. For this example, this seems trivial as the functions have the same name (and you could even have a function per name!). As far as I understand, the point of the action selector is to only have a fixed number of learned actions and multiple words (cut, slice etc.) should select the same action fcut. Otherwise (if there is little language ambiguity) I would not see the need for a complex neural architecture. Related to that, a non-neural baseline for the entity selection task that in my opinion definitely needs to be added is extracting entities using a pretrained NER system and returning all of them as the selection.\np2 Footnote 1: So if I understand this correctly, this work builds upon a dataset of over 65k recipes from Kiddon et al. (2016), but only for 875 of those detailed annotations were created?\n\nMinor Comments\n\np1: The statement \"most natural language understanding algorithms do not have the capacity \u2026\" should be backed by reference.\np2: \"context representation ht\" \u2013 I would directly mention that this is a sentence encoding.\np3: 2.4: I have the impression what you are describing here is known in the literature as entity linking.\np3 Eq.3: Isn't c3*0 always a vector of zeros?\np4 Eq.6: W4 is an order-3 tensor, correct?\np4 Eq.8: What is YC and WC here and what are their dimensions? I am confused by the softmax, as my understanding (from reading the paragraph on the Action Selection Loss on p.5) was that the expression in the softmax here is a scalar (as it is done for every possible action), so this should be a sigmoid to allow for multiple actions to attain a probability of 1?\np5: \"See Appendix for details\" -> \"see Appendix C for details\"\np5 3.3: Could you elaborate on the heuristic for extracting verb mentions? Is only one verb mention per sentence extracted?\np5: \"trained to minimize cross-entropy loss\" -> \"trained to minimize the cross-entropy loss\"\np5 3.3: What is the global loss?\np6: \"been read (\u00a72.5.\" -> \"been read (\u00a72.5).\"\np6: \"We encode these vectors using a bidirectional GRU\" \u2013 I think you composing a fixed-dimensional vector from the entity vectors? What's eI?\np7: For which statement is (Kim et al. 2016) the reference? Surely, they did not invent the Hadamard product.\np8: \"Our model, in contrast\" use\" -> \"Our model, in contrast, uses\".\np8 Related Work: I think it is important to mention that existing architectures such as Memory Netwroks could, in principle, learn to track entities and devote part of their parameters to learn the effect of actions. What Neural Process Networks are providing is a strong inductive bias for tracking entities and learning the effect of actions that is useful for the task considered in this paper. As mentioned in the weaknesses, this might however come at the price of a less general model, which should be discussed.\n\n# Update after the rebuttal\nThanks for the clarifications and updating the paper. I am increasing my score by two points and expect to see the ablations as well as the NER baseline mentioned in the rebuttal in the next revision of the paper. Furthermore, I encourage the authors to include the analysis of pretrained word2vec embeddings vs the embeddings learned by this architecture into the paper. ", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["Summary This paper presents NeuralProcess Networks, an architecture for capturing proceduralknowledge stated in texts that makes use of a differentiable memory, a sentence and word attention mechanism, as well as learning action representations and their effect on entity representations.", "The architecture is tested for tracking entities in recipes, as well as generating the naturallanguage description for the next step in a recipe.", "It is compared against a suit of baselines, such as GRUs, Recurrent Entity Networks, SeqSeqand the NeuralChecklist Model.", "While I liked the overal paper, I am worried about the generalty of the model, the qualtative analsis, as well as a fair comparison to Recurrent Entity Networks and non-neuralbaselines.", "Strengths I believe the authors made a good effort in comparing against existing neuralbaselines (Recurrent Entity Networks, NeuralChecklist Model) *for their task*.", "That said, it is unclear to me how generaly applicable the method is and whether the comparison against Recurrent Entity Networks is fair (see Weaknesses).", "I like the ablation study.", "Weaknesses While I find the NeuralProcess Networks architecture interesting and I acknowledge that it outperforms Recurrent Entity Networks for the presented tasks, after reading the paper it is not clear to me how generaly applicable the architecture is.", "Some design choices seem rather tailored to the task at hand (manualcollection of actions MTurk annotation in secion 3 1) and I am wondering where else the authors see their method being applied given that the architecture relies on al entities and actions being known in advance.", "My understanding is that the architecture could be applied to bAbI and CBT (the two tasks used in the Recurrent Entity Networks paper).", "If that is the case, a fair comparison to Recurrent Entity Networks would have been to test against Recurrent Entity Networks on these tasks too.", "If they the architecture cannot be applied in these tasks, the authors should explain why.", "I am not convinced by the qualtative analsis.", "Table 2 tells me that even for the best model the entity selection performance is rather unreliable (only 55.39% F1), yet al examples shown in Table 3 look realy good, missing only the two entities oil (1) and sprinkles (3).", "This suggests that these examples were cherry-picked and I would like to see examples that are sampled randomly from the dev set.", "I have a similar concern regarding the generation task.", "First, it is not mentioned where the examples in Table 6 are taken from \u2013 is it the train, dev or test set?", "secnd, the overal BLEU score seems quite low even for the best model, yet the examples in Table 6 look realy good.", "In my opinion, a good qualtative analsis should alo discuss failure cases.", "Since the BLEU score is so low here, you might alo want to compare perplexity of the models.", "The qualtative analsis in Table 5 is not convincing either.", "In Appendix A 1 it is mentioned that word embeddings are initialzed from word2vec trained on the training set.", "My suspicion is that one would get the clustering in Table 4 aleady from those pretrained vectors, maybe even when pretrained on the Google news corpus.", "Hence, it is not clear what propagating gradients through the NeuralProcess Networks into the action embeddings adds, or put differently, why does it have to be a differentiable architecture when an NLP pipeline might be enough?", "This could easily be tested by another ablation where action embeddings are pretrained using word2vec and then fixed during training of the NeuralProcess Network.", "Moreover, in 3 3 it is mentioned that even the Action Selection is pretrained, which makes me wonder what is actualy trained jointly in the architecture and what is not.", "I think the difficulty of the task at hand needs to be discussed at some point, idealy early in the paper.", "Until examples on page 7 are shown, I did not have a sense for why a neuralarchitecture is chosen.", "For example, in 2 3 it is mentioned that for \"wash and cut\" the two functions fwash and fcut need to be selected.", "For this example, this seems trivialas the functions have the same name (and you could even have a function per name!).", "As far as I understand, the point of the action selector is to only have a fixed number of learned actions and multiple words (cut, slice etc) should select the same action fcut.", "Otherwise (if there is little language ambiguity) I would not see the need for a complex neuralarchitecture.", "Related to that, a non-neuralbaseline for the entity selection task that in my opinion definitely needs to be added is extracting entities using a pretrained NER system and returning al of them as the selection.", "p2 Footnote 1: So if I understand this correctly, this work builds upon a dataset of over 65k recipes from Kiddon et al (2016), but only for 875 of those detailed annotations were created?", "Minor Comments p1: The statement \"most naturallanguage understanding alorithms do not have the capacity \u2026\" should be backed by reference.", "p2: \"context representation ht\" \u2013 I would directly mention that this is a sentence encoding.", "p3: 2 4: I have the impression what you are describing here is known in the literature as entity linking.", "p3 eq3: Isn't c3*0 alays a vector of zeros?", "p4 eq6: W4 is an order-3 tensor, correct?", "p4 eq8: What is YC and WC here and what are their dimensions?", "I am confused by the softmax, as my understanding (from reading the paragraph on the Action Selection Loss on p 5) was that the expression in the softmax here is a scalr (as it is done for every possible action), so this should be a sigmoid to alow for multiple actions to attain a probability of 1?", "p5: \"See Appendix for details\" -> \"see Appendix C for details\" p5 3 3: Could you elaborate on the heuristic for extracting verb mentions?", "Is only one verb mention per sentence extracted?", "p5: \"trained to minimize cross-entropy loss\" -> \"trained to minimize the cross-entropy loss\" p5 3 3: What is the globalloss?", "p6: \"been read (\u00a72 5 \" -> \"been read (\u00a72 5).\"", "p6: \"We encode these vectors using a bidirectionalGRU\" \u2013 I think you composing a fixed-dimensionalvector from the entity vectors?", "What's eI?", "p7: For which statement is (Kim et al 2016) the reference?", "Surely, they did not invent the Hadamard product.", "p8: \"Our model, in contrast\" use\" -> \"Our model, in contrast, uses\".", "p8 Related Work: I think it is important to mention that existing architectures such as Memory Netwroks could, in principle, learn to track entities and devote part of their parameters to learn the effect of actions.", "What NeuralProcess Networks are providing is a strong inductive bias for tracking entities and learning the effect of actions that is useful for the task considered in this paper.", "As mentioned in the weaknesses, this might however come at the price of a less generalmodel, which should be discussed.", "# Update after the rebuttalThanks for the clarifications and updating the paper.", "I am increasing my score by two points and expect to see the ablations as well as the NER baseline mentioned in the rebuttalin the next revision of the paper.", "Furthermore, I encourage the authors to include the analsis of pretrained word2vec embeddings vs the embeddings learned by this architecture into the paper."], "all_annotations": [{"interpretation": 1, "review_id": "SJUEXlDxf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 0}, {"interpretation": 1, "review_id": "SJUEXlDxf", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJUEXlDxf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJUEXlDxf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SJdWxzoxz", "review_text": "Summary:\nThe paper presents a novel method for answering \u201cHow many \u2026?\u201d questions in the VQA datasets. Unlike previously proposed approaches, the proposed method uses an iterative sequential decision process for counting the relevant entity. The proposed model makes discrete choices about what to count at each time step. Another qualitative difference compared to existing approaches is that the proposed method returns bounding boxes for the counted object. The training and evaluation of the proposed model and baselines is done on a subset of the existing VQA dataset that consists of \u201cHow many \u2026?\u201d questions. The experimental results show that the proposed model outperforms the baselines discussed in the paper.\n\nStrengths:\n1.\tThe idea of sequential counting is novel and interesting.\n2.\tThe analysis of model performance by grouping the questions as per frequency with which the counting object appeared in the training data is insightful. \n \nWeaknesses:\n1.\tThe proposed dataset consists of 17,714 QA pairs in the dev set, whereas only 5,000 QA pairs in the test set. Such a 3.5:1 split of dev and test seems unconventional. Also, the size of the test set seems pretty small given the diversity of the questions in the VQA dataset.\n2.\tThe paper lacks quantitative comparison with existing models for counting such as with Chattopadhyay et al. This would require the authors to report the accuracies of existing models by training and evaluating on the same subset as that used for the proposed model. Absence of such a comparison makes it difficult to judge how well the proposed model is performing compared to existing models.\n3.\tThe paper lacks analysis on how much of performance improvement is due to visual genome data augmentation and pre-training? When comparing with existing models (as suggested in above), this analysis should be done, so as to identify the improvements coming from the proposed model alone.\n4.\tThe paper does not report the variation in model performance when changing the weights of the various terms involved in the loss function (equations 15 and 16).\n5.\tRegarding Chattopadhyay et al. the paper says that \u201cHowever, their analysis was limited to the specific subset of examples where their approach was applicable.\u201d It would be good it authors could elaborate on this a bit more.\n6.\tThe relation prediction part of the vision module in the proposed model seems quite similar to the Relation Networks, but the paper does not mention Relation Networks. It would be good to cite the Relation Networks paper and state clearly if the motivation is drawn from Relation Networks.\n7.\tIt is not clear what are the 6 common relationships that are being considered in equation 1. Could authors please specify these?\n8.\tIn equation 1, if only 6 relationships are being considered, then why does f^R map to R^7 instead of R^6?\n9.\tIn equations 4 and 5, it is not clarified what each symbol represents, making it difficult to understand.\n10.\tWhat is R in equation 15? Is it reward?\n\nOverall:\nThe paper proposes a novel and interesting idea for solving counting questions in the Visual Question Answering tasks. However, the writing of the paper needs to be improved to make is easier to follow. The experimental set-up \u2013 the size of the test dataset seems too small. And lastly, the paper needs to add comparisons with existing models on the same datasets as used for the proposed model. So, the paper seems to be not ready for the publication yet.", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["Summary: The paper presents a novel method for answering \u201cHow many \u2026?\u201d questions in the VQA datasets.", "Unlike previously proposed approaches, the proposed method uses an iterative seqentialdecision process for counting the relevant entity.", "The proposed model makes discrete choices about what to count at each time step.", "Another qualtative difference compared to existing approaches is that the proposed method returns bounding boxes for the counted object.", "The training and evalation of the proposed model and baselines is done on a subset of the existing VQA dataset that consists of \u201cHow many \u2026?\u201d questions.", "The experimentalresults show that the proposed model outperforms the baselines discussed in the paper.", "Strengths: 1 \tThe idea of seqentialcounting is novel and interesting.", "2 \tThe analsis of model performance by grouping the questions as per freqency with which the counting object appeared in the training data is insightful.", "Weaknesses: 1 \tThe proposed dataset consists of 17,714 QA pairs in the dev set, whereas only 5,000 QA pairs in the test set.", "Such a 3 5:1 split of dev and test seems unconventional Also, the size of the test set seems pretty smal given the diversity of the questions in the VQA dataset.", "2 \tThe paper lacks quantitative comparison with existing models for counting such as with Chattopadhyay et al This would reqire the authors to report the accuracies of existing models by training and evalating on the same subset as that used for the proposed model.", "Absence of such a comparison makes it difficult to judge how well the proposed model is performing compared to existing models.", "3 \tThe paper lacks analsis on how much of performance improvement is due to visualgenome data augmentation and pre-training?", "When comparing with existing models (as suggested in above), this analsis should be done, so as to identify the improvements coming from the proposed model alne.", "4 \tThe paper does not report the variation in model performance when changing the weights of the various terms involved in the loss function (eqations 15 and 16).", "5 \tRegarding Chattopadhyay et al the paper says that \u201cHowever, their analsis was limited to the specific subset of examples where their approach was applicable.\u201d It would be good it authors could elaborate on this a bit more.", "6 \tThe relation prediction part of the vision module in the proposed model seems quite similar to the Relation Networks, but the paper does not mention Relation Networks.", "It would be good to cite the Relation Networks paper and state clearly if the motivation is drawn from Relation Networks.", "7 \tIt is not clear what are the 6 common relationships that are being considered in eqation 1, Could authors please specify these?", "8 \tIn eqation 1, if only 6 relationships are being considered, then why does f^R map to R^7 instead of R^6?", "9 \tIn eqations 4 and 5, it is not clarified what each symbol represents, making it difficult to understand.", "10.", "What is R in eqation 15?", "Is it reward?", "Overal: The paper proposes a novel and interesting idea for solving counting questions in the VisualQuestion Answering tasks.", "However, the writing of the paper needs to be improved to make is easier to follow.", "The experimentalset-up \u2013 the size of the test dataset seems too smal.", "And lastly, the paper needs to add comparisons with existing models on the same datasets as used for the proposed model.", "So, the paper seems to be not ready for the publication yet."], "all_annotations": [{"interpretation": 0, "review_id": "SJdWxzoxz", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJdWxzoxz", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJdWxzoxz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJdWxzoxz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SJppHuogG", "review_text": "re. Introduction, page 2: Briefly explain here how SAB is different from regular Attention?\n\nGood paper. There's not that much discussion of the proposed SAB compared to regular Attention, perhaps that could be expanded. Also, I suggest summarizing the experimental findings in the Conclusion.", "gold_annotation": null, "score": 1.0, "tokenized_review_text": ["re.", "Introduction, page 2: Briefly explain here how SAB is different from regular Attention?", "Good paper.", "There's not that much discussion of the proposed SAB compared to regular Attention, perhaps that could be expanded.", "Also, I suggest summarizing the experimentalfindings in the Conclusion."], "all_annotations": [{"interpretation": 0, "review_id": "SJppHuogG", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno2", "evidence": 1, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "SJppHuogG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 1, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "SJppHuogG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "SJppHuogG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "SJyXoTtlG", "review_text": "This paper introduces a generative approach for 3D point clouds. More specifically, two Generative Adversarial approaches are introduced: Raw point cloud GAN, and Latent-space GAN (r-GAN and l-GAN as referred to in the paper). In addition, a GMM sampling + GAN decoder approach to generation is also among the experimented variations. \n\nThe results look convincing for the generation experiments in the paper, both from class-specific (Figure 1) and multi-class generators (Figure 6). The quantitative results also support the visuals. \n\nOne question that arises is whether the point cloud approaches to generation is any more valuable compared to voxel-grid based approaches. Especially Octree based approaches [1-below] show very convincing and high-resolution shape generation results, whereas the details seem to be washed out for the point cloud results presented in this paper. \n\nI would like to see comparison experiments with voxel based approaches in the next update for the paper. \n\n[1]\n@article{tatarchenko2017octree,\n  title={Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs},\n  author={Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas},\n  journal={arXiv preprint arXiv:1703.09438},\n  year={2017}\n}\n\nIn light of the authors' octree updates score is updated. I expect these updates to be reflected in the final version of the paper itself as well. ", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["This paper introduces a generative approach for 3D point clouds.", "More specificaly, two Generative Adversarialapproaches are introduced: Raw point cloud GAN, and Latent-space GAN (r-GAN and l-GAN as referred to in the paper).", "In addition, a GMM sampling + GAN decoder approach to generation is alo among the experimented variations.", "The results look convincing for the generation experiments in the paper, both from class-specific (figre 1) and multi-class generators (figre 6).", "The quantitative results alo support the visual.", "One question that arises is whether the point cloud approaches to generation is any more valable compared to voxel-grid based approaches.", "Especialy Octree based approaches [1-below] show very convincing and high-resolution shape generation results, whereas the details seem to be washed out for the point cloud results presented in this paper.", "I would like to see comparison experiments with voxel based approaches in the next update for the paper.", "[1] @article{tatarchenko2017octree, title={Octree Generating Networks: Efficient ConvolutionalArchitectures for High-resolution 3D Outputs}, author={Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas}, journal{arXiv preprint arXiv:1703.09438}, year={2017} } In light of the authors' octree updates score is updated.", "I expect these updates to be reflected in the finalversion of the paper itself as well."], "all_annotations": [{"interpretation": 0, "review_id": "SJyXoTtlG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "SJyXoTtlG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "SJyXoTtlG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "SJyXoTtlG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "SJzxBpKeM", "review_text": "SUMMARY:\nThis work is about learning the validity of a sequences in specific application domains like SMILES strings for chemical compounds. In particular, the main emphasis is on predicting if a prefix sequence could possibly be extended to a complete valid sequence. In other words, one tries to predict if there exists a valid suffix sequence, and based on these predictions, the goal is to train a generative model that always produces valid sequences.  In the proposed reinforcement learning setting, a neural network models the probability that a certain action (adding a symbol) will result in a valid full sequence. For training the network, a large set of (validity-)labelled sequences would be needed. To overcome this problem, the authors introduce an active learning strategy, where the information gain is re-expressed as the conditional mutual information between the the label y and the network weights w, and this mutual information is maximized in a greedy sequential manner.    \nEVALUATION:\nCLARITY & NOVELTY: In principle, the paper is easy to read. Unfortunately, however, for the reader is is not easy to find out what the authors consider their most relevant contribution. Every single part of the model seems to be quite standard (basically a network that predicts the probability of a valid sequence and an information-gain based active learning strategy) - so is the specific application to SMILES strings what makes the difference here?   Or is is the specific greedy approximation to the mutual information criterion in the active learning part? Or is it the way how you augment the dataset? All these aspects might be interesting, but somehow I am missing a coherent picture.\nSIGNIFICANCE: it is not entirely clear to me if the proposed \"pruning\" strategy for the completion of prefix sequences can indeed be generally applied to sequence modelling problems, because in more general domains it might be very difficult to come up with reasonable validity estimates for prefixes that are significantly shorter than the whole sequence. I am not so familiar with SMILES strings -- but could it be that the experimental success reported here is mainly a result of the very specific structure of valid SMILES strings?  But then, what can be learned for general sequence validation problems?\n     \nUPDATE: Honestly, outside the scope of SMILES strings, I still have some concerns regarding reasonable validity estimates for prefixes that are significantly shorter than the whole sequence...  \n\n", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["SUMMARY: This work is about learning the valdity of a seqences in specific application domains like SMILES strings for chemicalcompounds.", "In particular, the main emphasis is on predicting if a prefix seqence could possibly be extended to a complete vald seqence.", "In other words, one tries to predict if there exists a vald suffix seqence, and based on these predictions, the goalis to train a generative model that alays produces vald seqences.", "In the proposed reinforcement learning setting, a neuralnetwork models the probability that a certain action (adding a symbol) will result in a vald full seqence.", "For training the network, a large set of (valdity-)labelled seqences would be needed.", "To overcome this problem, the authors introduce an active learning strategy, where the information gain is re-expressed as the conditionalmutualinformation between the the label y and the network weights w, and this mutualinformation is maximized in a greedy seqentialmanner.", "EVALUATION: CLARITY & NOVELTY: In principle, the paper is easy to read.", "Unfortunately, however, for the reader is is not easy to find out what the authors consider their most relevant contribution.", "Every single part of the model seems to be quite standard (basicaly a network that predicts the probability of a vald seqence and an information-gain based active learning strategy) - so is the specific application to SMILES strings what makes the difference here?", "Or is is the specific greedy approximation to the mutualinformation criterion in the active learning part?", "Or is it the way how you augment the dataset?", "All these aspects might be interesting, but somehow I am missing a coherent picture.", "SIGNIFICANCE: it is not entirely clear to me if the proposed \"pruning\" strategy for the completion of prefix seqences can indeed be generaly applied to seqence modelling problems, because in more generaldomains it might be very difficult to come up with reasonable valdity estimates for prefixes that are significantly shorter than the whole seqence.", "I am not so familiar with SMILES strings -- but could it be that the experimentalsuccess reported here is mainly a result of the very specific structure of vald SMILES strings?", "But then, what can be learned for generalseqence valdation problems?", "UPDATE: Honestly, outside the scope of SMILES strings, I still have some concerns regarding reasonable valdity estimates for prefixes that are significantly shorter than the whole seqence..."], "all_annotations": [{"interpretation": 0, "review_id": "SJzxBpKeM", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "SJzxBpKeM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "SJzxBpKeM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJzxBpKeM", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "SJs7uYYeM", "review_text": "At the heart of the paper, there is a single idea: to decouple the weight decay from the number of steps taken by the optimization process (the paragraph at the end of page 2 is the key to the paper). This is an important and largely overlooked area of implementation and most off-the-shelf optimization algorithms, unfortunately, miss this point, too. I think that the proposed implementation should be taken seriously, especially in conjunction with the discussion that has been carried out with the work of Wilson et al., 2017 (https://arxiv.org/abs/1705.08292).\n\nThe introduction does a decent job explaining why it is necessary to pay attention to the norm of the weights as the training progresses within its scope. However, I would like to add a couple more points to the discussion: \n- \"Optimal weight decay is a function (among other things) of the total number of epochs / batch passes.\" in principle, it is a function of weight updates. Clearly, it depends on the way the decay process is scheduled. However, there is a bad habit in DL where time is scaled by the number of epochs rather than the number of weight updates which sometimes lead to misleading plots (for instance, when comparing two algorithms with different batch sizes).\n- Another ICLR 2018 submission has an interesting take on the norm of the weights and the algorithm (https://openreview.net/forum?id=HkmaTz-0W&noteId=HkmaTz-0W). Figure 3 shows the histograms of SGD/ADAM with and without WD (the *un-fixed* version), and it clearly shows how the landscape appear misleadingly different when one doesn't pay attention to the weight distribution in visualizations. \n- In figure 2, it appears that the training process has three phases, an initial decay, a steady progress, and a final decay that is more pronounced in AdamW. This final decay also correlates with the better test error of the proposed method. This third part also seems to correspond to the difference between Adam and AdamW through the way they branch out after following similar curves. One wonders what causes this branching and whether the key the desired effects are observed at the bottom of the landscape.\n- The paper concludes with \"Advani & Saxe (2017) analytically showed that in the limited data regime of deep networks the presence of eigenvalues that are zero forms a frozen subspace in which no learning occurs and thus smaller (e.g., zero) initial weight norms should be used to achieve best generalization results.\" Related to this there is another ICLR 2018 submission (https://openreview.net/forum?id=rJrTwxbCb), figure 1 shows that the eigenvalues of the Hessian of the loss have zero forms at the bottom of the landscape, not at the beginning. Back to the previous point, maybe that discussion should focus on the second and third phases of the training, not the beginning. \n- Finally, it would also be interesting to discuss the relation of the behavior of the weights at the last parts of the training and its connection to pruning. \n\nI'm aware that one can easily go beyond the scope of the paper by adding more material. Therefore, it is not completely reasonable to expect all such possible discussions to take place at once. The paper as it stands is reasonably self-contained and to the point. Just a minor last point that is irrelevant to the content of the work: The slash punctuation mark that is used to indicate 'or' should be used without spaces as in 'epochs/batch'.\n\nEdit: Thanks very much for the updates and refinements. I stand by my original score and would like to indicate my support for this style of empirical work in scientific conferences.", "gold_annotation": null, "score": 3.5, "tokenized_review_text": ["At the heart of the paper, there is a single idea: to decouple the weight decay from the number of steps taken by the optimization process (the paragraph at the end of page 2 is the key to the paper).", "This is an important and largely overlooked area of implementation and most off-the-shelf optimization alorithms, unfortunately, miss this point, too.", "I think that the proposed implementation should be taken seriously, especialy in conjunction with the discussion that has been carried out with the work of Wilson et al, 2017 (https://arxiv.org/abs/1705.08292).", "The introduction does a decent job explaining why it is necessary to pay attention to the norm of the weights as the training progresses within its scope.", "However, I would like to add a couple more points to the discussion: - \"Optimalweight decay is a function (among other things) of the totalnumber of epochs / batch passes.\"", "in principle, it is a function of weight updates.", "Clearly, it depends on the way the decay process is scheduled.", "However, there is a bad habit in DL where time is scald by the number of epochs rather than the number of weight updates which sometimes lead to misleading plots (for instance, when comparing two alorithms with different batch sizes).", "- Another ICLR 2018 submission has an interesting take on the norm of the weights and the alorithm (https://openreview.net/forum?id=HkmaTz-0W&noteId=HkmaTz-0W).", "figre 3 shows the histograms of SGD/ADAM with and without WD (the *un-fixed* version), and it clearly shows how the landscape appear misleadingly different when one doesn't pay attention to the weight distribution in visualzations.", "- In figre 2, it appears that the training process has three phases, an initialdecay, a steady progress, and a finaldecay that is more pronounced in AdamW.", "This finaldecay alo correlates with the better test error of the proposed method.", "This third part alo seems to correspond to the difference between Adam and AdamW through the way they branch out after following similar curves.", "One wonders what causes this branching and whether the key the desired effects are observed at the bottom of the landscape.", "- The paper concludes with \"Advani & Saxe (2017) analticaly showed that in the limited data regime of deep networks the presence of eigenvales that are zero forms a frozen subspace in which no learning occurs and thus smaler (e g , zero) initialweight norms should be used to achieve best generalzation results.\"", "Related to this there is another ICLR 2018 submission (https://openreview.net/forum?id=rJrTwxbCb), figre 1 shows that the eigenvales of the Hessian of the loss have zero forms at the bottom of the landscape, not at the beginning.", "Back to the previous point, maybe that discussion should focus on the secnd and third phases of the training, not the beginning.", "- Finaly, it would alo be interesting to discuss the relation of the behavior of the weights at the last parts of the training and its connection to pruning.", "I'm aware that one can easily go beyond the scope of the paper by adding more material Therefore, it is not completely reasonable to expect al such possible discussions to take place at once.", "The paper as it stands is reasonably self-contained and to the point.", "Just a minor last point that is irrelevant to the content of the work: The slash punctuation mark that is used to indicate 'or' should be used without spaces as in 'epochs/batch'.", "Edit: Thanks very much for the updates and refinements.", "I stand by my originalscore and would like to indicate my support for this style of empiricalwork in scientific conferences."], "all_annotations": [{"interpretation": 1, "review_id": "SJs7uYYeM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "yes-disagree", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJs7uYYeM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "SJs7uYYeM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "yes-agree", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "SJs7uYYeM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "SJxF3VsxG", "review_text": "This paper describes computationally efficient methods for training adversarially robust deep neural networks for image classification. (These methods may extend to other machine learning models and domains as well, but that's beyond the scope of this paper.) \n\nThe former standard method for generating adversarially images quickly and using them in training was to do a single gradient step to increase the loss of the true label or decrease the loss of an alternate label. This paper shows that such training methods only lead to robustness against these \"weak\" adversarial examples, leaving the adversarially-trained models vulnerable to multi-step white-box attacks and black-box attacks (adversarial examples generated to attack alternate models).\n\nThere are two proposed solutions. The first is to generate additional adversarial examples from other models and use them in training. This seems to yield robustness against black-box attacks from held-out models as well.  Of course, it requires that you have a somewhat diverse group of models to choose from. If that's the case, why not directly build an ensemble of all the models? An ensemble of neural networks can still be represented as a neural network, although a more computationally costly one. Thus, while this heuristic appears to be useful with current models against current attacks, I don't know how well it will hold up in the future.\n\nThe second solution is to add random noise before taking the gradient step.  This yields more effective adversarial examples, both for attacking models and for training, because it relies less on the local gradient. This is another simple idea that appears to be effective. However, I would be interested to see a comparison to a 2-step gradient-based attack.  R+Step-LL can be viewed as a 2-step attack: a random step followed by a gradient step. What if both steps were gradient steps instead? This interpolates between Step-LL and I-Step-LL, with an intermediate computational cost. It would be very interesting to know if R+Step-LL is more or less effective than 2+Step-LL, and how large the difference is.\n\nI like that this paper demonstrates the weakness of previous methods, including extensive experiments and a very nice visualization of the loss landscape in two adversarial dimensions. The proposed heuristics seem effective in practice, but they're somewhat ad hoc and there is no analysis of how these heuristics might or might not be vulnerable to future attacks.", "gold_annotation": null, "score": 3.5, "tokenized_review_text": ["This paper describes computationaly efficient methods for training adversarialy robust deep neuralnetworks for image classification.", "(These methods may extend to other machine learning models and domains as well, but that's beyond the scope of this paper.)", "The former standard method for generating adversarialy images quickly and using them in training was to do a single gradient step to increase the loss of the true label or decrease the loss of an alernate label.", "This paper shows that such training methods only lead to robustness against these \"weak\" adversarialexamples, leaving the adversarialy-trained models vulnerable to multi-step white-box attacks and black-box attacks (adversarialexamples generated to attack alernate models).", "There are two proposed solutions.", "The first is to generate additionaladversarialexamples from other models and use them in training.", "This seems to yield robustness against black-box attacks from held-out models as well.", "Of course, it reqires that you have a somewhat diverse group of models to choose from.", "If that's the case, why not directly build an ensemble of al the models?", "An ensemble of neuralnetworks can still be represented as a neuralnetwork, alhough a more computationaly costly one.", "Thus, while this heuristic appears to be useful with current models against current attacks, I don't know how well it will hold up in the future.", "The secnd solution is to add random noise before taking the gradient step.", "This yields more effective adversarialexamples, both for attacking models and for training, because it relies less on the localgradient.", "This is another simple idea that appears to be effective.", "However, I would be interested to see a comparison to a 2-step gradient-based attack.", "R+Step-LL can be viewed as a 2-step attack: a random step followed by a gradient step.", "What if both steps were gradient steps instead?", "This interpolates between Step-LL and I-Step-LL, with an intermediate computationalcost.", "It would be very interesting to know if R+Step-LL is more or less effective than 2+Step-LL, and how large the difference is.", "I like that this paper demonstrates the weakness of previous methods, including extensive experiments and a very nice visualzation of the loss landscape in two adversarialdimensions.", "The proposed heuristics seem effective in practice, but they're somewhat ad hoc and there is no analsis of how these heuristics might or might not be vulnerable to future attacks."], "all_annotations": [{"interpretation": 0, "review_id": "SJxF3VsxG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "SJxF3VsxG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 1, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "SJxF3VsxG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "SJxF3VsxG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_995_3", "review_text": "Review:  The paper proposes a bayesian rule based model that allows for the inclusion of multiple values of the same feature inside a condition. The model is composed of a set of rules, and an example is classified as positive if it is covered by at least one rule. The generative model has knobs to encourage three interpretability-related properties :  - Small number of rules  - Small number of conditions within each rule  - For each rule, small number of features used (i.e. conditions are clustered into few features)  The improvements of MRS over other rule-based frameworks are compelling. Rule sets that use less features are easier to grasp, and rules with multiple values for the same feature are more intuitive and easier to grasp than the same condition fragmented over multiple conditions.  The paper is mostly clear, but there is a lot of notation. Some suggestions to improve clarity:  - Maybe draw the generative model  - Change the notation of multiple values to [state \\in {California, Texas, Arizona, Oregon}] rather than [state =California or Texas or Arizona or Oregon], or in the very least change the spacing around the =  - Drop the second _m in {L_m}_m, {z_m}_m, etc.  - The subscript plus and minus in 4.1 makes the equations very hard to read  Comments / questions:   - Is there a reason for not constraining alpha_+ > beta_+ and alpha_- > beta_- in the formulation? This would avoid the repetition of this condition around Lemma 1.  - It seems that removing a condition reduces the coverage, while adding a condition increases the coverage. These are reversed in 4.2.  - The comparison of number of conditions in Table 1 does not seem entirely fair, as the conditions for MRS are much longer, unless the authors are considering each value in a condition as a separate condition for this count.  - The discussion in lines 326 - 330 does not seem to make sense given that \"All of them\" is a value included in the condition. This value breaks the intuition presented.  - It's not clear how the authors selected the best model in cross validation after doing grid search. Was the selection done in a systematic or ad hoc way?  Overall, I think this is an interesting interpretable model, with the caveats that it only works for binary classification (and the extensions to more labels is not obvious) and that there are many hyperparameters that need tuning. The results dot not present significant improvements over prior art in terms of accuracy, but there seem to be some improvements in terms of interpretability (although the comparison may not be fair, see comment above).  Typos: 26: primitive concept level -> primitive concepts 51: \"an examples\" -> examples, \"fo example\" -> for example 55: for its appealing property (weird phrasing) 68: remove 'the' 73: remove stop before (Millions) 75: 'and it was done\u00e2\u0080\u00a6'  weird phrasing 78: various work  79: conjunction connector -> the conjunction connector 81: conjunction/literal -> conjunction / literal (add space) 94: 'simply adapt' -> be adapted 306: uniqeu -> unique 310: 'accuracy 67 conditions' - something is missing here 316: two stops after 'meaningful' 342: MARS -> MRS  Supplementary line 6: MARS -> MRS  # Comments on feedback: - Thanks for addressing the concern about fair comparison - I think that the user study makes the submission stronger, and so do the added results in the new Table 1. I've changed my score to reflect that. - I had understood that 'all of them' is a value like the others. I am question the intuition presented, which states that people prefer to say they are not sure or refuse to answer. This intuition does not fit well with the inclusion of 'all of them' on the right hand side of the rule.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_995_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Review: The paper proposes a bayesian rule based model that alows for the inclusion of multiple vales of the same feature inside a condition.", "The model is composed of a set of rules, and an example is classified as positive if it is covered by at least one rule.", "The generative model has knobs to encourage three interpretability-related properties : - Smal number of rules - Smal number of conditions within each rule - For each rule, smal number of features used (i e conditions are clustered into few features) The improvements of MRS over other rule-based frameworks are compelling.", "Rule sets that use less features are easier to grasp, and rules with multiple vales for the same feature are more intuitive and easier to grasp than the same condition fragmented over multiple conditions.", "The paper is mostly clear, but there is a lot of notation.", "Some suggestions to improve clarity: - Maybe draw the generative model - Change the notation of multiple vales to [state \\in {Calfornia, Texas, Arizona, Oregon}] rather than [state =Calfornia or Texas or Arizona or Oregon], or in the very least change the spacing around the = - Drop the secnd _m in {L_m}_m, {z_m}_m, etc - The subscript plus and minus in 4 1 makes the eqations very hard to read Comments / questions: - Is there a reason for not constraining alha_+ > beta_+ and alha_- > beta_- in the formulation?", "This would avoid the repetition of this condition around Lemma 1, - It seems that removing a condition reduces the coverage, while adding a condition increases the coverage.", "These are reversed in 4 2, - The comparison of number of conditions in Table 1 does not seem entirely fair, as the conditions for MRS are much longer, unless the authors are considering each vale in a condition as a separate condition for this count.", "- The discussion in lines 326 - 330 does not seem to make sense given that \"All of them\" is a vale included in the condition.", "This vale breaks the intuition presented.", "- It's not clear how the authors selected the best model in cross valdation after doing grid search.", "Was the selection done in a systematic or ad hoc way?", "Overal, I think this is an interesting interpretable model, with the caveats that it only works for binary classification (and the extensions to more labels is not obvious) and that there are many hyperparameters that need tuning.", "The results dot not present significant improvements over prior art in terms of accuracy, but there seem to be some improvements in terms of interpretability (alhough the comparison may not be fair, see comment above).", "Typos: 26: primitive concept level -> primitive concepts 51: \"an examples\" -> examples, \"fo example\" -> for example 55: for its appealng property (weird phrasing) 68: remove 'the' 73: remove stop before (Millions) 75: 'and it was done\u00e2\u0080\u00a6' weird phrasing 78: various work 79: conjunction connector -> the conjunction connector 81: conjunction/literal-> conjunction / literal(add space) 94: 'simply adapt' -> be adapted 306: uniqeu -> unique 310: 'accuracy 67 conditions' - something is missing here 316: two stops after 'meaningful' 342: MARS -> MRS Supplementary line 6: MARS -> MRS # Comments on feedback: - Thanks for addressing the concern about fair comparison - I think that the user study makes the submission stronger, and so do the added results in the new Table 1, I've changed my score to reflect that.", "- I had understood that 'al of them' is a vale like the others.", "I am question the intuition presented, which states that people prefer to say they are not sure or refuse to answer.", "This intuition does not fit well with the inclusion of 'al of them' on the right hand side of the rule."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_995_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_113_3", "review_text": "This paper lies in the well-developed field of variance-reduced stochastic gradient algorithms. It proposes a theoretical study of the well-known HSGD for sampling without replacement scheme, which is known to perform better than sampling with replacement in practice.  The considered setting makes the analysis of the algorithm more difficult, since in this case the mini-batch gradients are not unbiased anymore. Rates for strongly-convex, non-strongly convex and non-convex objectives are provided, with a special care for linearly structured problems (such as generalized linear models). Numerical experiments are convincing enough, although the datasets used in experiments are not very large (largest one is covtype) (while authors argue that this methods is interesting in the large n medium precision setting). I think that this is an nice piece of work, which provides an incremental contribution to the already widely developed theory of stochastic optimisation algorithms for ML. The paper can certainly be accepted for publication, although I think that the contribution is mostly incremental, since (to the best of my knowledge) the proofs do not seem to introduce a major novelty. ", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["This paper lies in the well-developed field of variance-reduced stochastic gradient alorithms.", "It proposes a theoreticalstudy of the well-known HSGD for sampling without replacement scheme, which is known to perform better than sampling with replacement in practice.", "The considered setting makes the analsis of the alorithm more difficult, since in this case the mini-batch gradients are not unbiased anymore.", "Rates for strongly-convex, non-strongly convex and non-convex objectives are provided, with a specialcare for linearly structured problems (such as generalzed linear models).", "Numericalexperiments are convincing enough, alhough the datasets used in experiments are not very large (largest one is covtype) (while authors argue that this methods is interesting in the large n medium precision setting).", "I think that this is an nice piece of work, which provides an incrementalcontribution to the aleady widely developed theory of stochastic optimisation alorithms for ML.", "The paper can certainly be accepted for publication, alhough I think that the contribution is mostly incremental since (to the best of my knowledge) the proofs do not seem to introduce a major novelty."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_113_3", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_113_3", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_113_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_113_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_11_3", "review_text": "This paper takes the input reconstruction (autoencoder) as the regularizer to attain the generalisation of neural network models, which is being called supervised auto-encoder (SAE). It first proves an upper bound for showing the uniform stability of linear SAE, hinting good generalisation performance. Then, it shows empirically that the addition of the input reconstruction can consistently make the neural network models learned to generalize well.  Strengths: - Given that most of the deep learning work is empirical, this paper shows theoretically that including the input reconstruction error (auto-encoding task) into the objective of linear SAE can theoretically be shown to improve generalisation performance. This contributes to both originality and significance. - For the experiments, when the dimension of the hidden representation is kept increasing, the SAE is shown empirically to be able to achieve persistently good generalisation performance. The experiments also include the use of the different form of non-linear units and the improvement persists. - The paper is well presented and motivated.  Specific comments: - Line 127: D is undefined - How is the performance of SAE compared with the use of autoencoder for pre-training?", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["This paper takes the input reconstruction (autoencoder) as the regularizer to attain the generalsation of neuralnetwork models, which is being caled supervised auto-encoder (SAE).", "It first proves an upper bound for showing the uniform stability of linear SAE, hinting good generalsation performance.", "Then, it shows empiricaly that the addition of the input reconstruction can consistently make the neuralnetwork models learned to generalze well.", "Strengths: - Given that most of the deep learning work is empirical this paper shows theoreticaly that including the input reconstruction error (auto-encoding task) into the objective of linear SAE can theoreticaly be shown to improve generalsation performance.", "This contributes to both originalty and significance.", "- For the experiments, when the dimension of the hidden representation is kept increasing, the SAE is shown empiricaly to be able to achieve persistently good generalsation performance.", "The experiments alo include the use of the different form of non-linear units and the improvement persists.", "- The paper is well presented and motivated.", "Specific comments: - Line 127: D is undefined - How is the performance of SAE compared with the use of autoencoder for pre-training?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_11_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_11_3", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_11_3", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_11_3", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_126_1", "review_text": "The manuscript \u00e2\u0080\u009cRegularization Learning Networks\u00e2\u0080\u009d introduces a new type of neural network, trained using a new loss function, called Counterfactual Loss, together with stochastic gradient descent. The main hypothesis of the manuscript is that more flexibility in regularization should enable a better treatment of features that have a varying degree of importance. With this the authors wanted to enable DNNs to perform better in scenarios where they currently loose against other learning methods like gradient boosting trees. The authors motivate in their conclusion why this might make sense, but in the application they show it is not clear, why one has to use a regularization learning network (RLN) instead of a GBT model.   Quality The overall quality of the paper is good. The authors really tried to show the effects of the new regularization scheme, which seems to produce reasonable results.  Clarity The presentation of the method is very clear. Sometimes, it would have been nice to include more details in the manuscript and not in the supplement (e.g., training setup).  Significance The regularization scheme seems to have certain benefits over standard DNNs. The authors could not show on the data set they chose that this leads to a model with better performance than the best other method, but at least compared to standard DNNs the performance increase was significant. Therefore, especially for settings where joint models on several types of data are supposed to be learnt, this new approach might be a good way forward. Since the authors only gave this application as an outlook and also only mention that the initial results are positive (in the author response), it remains to be seen how well the performance will be for different prediction tasks of this type. ", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The manuscript \u00e2\u0080\u009cRegularization Learning Networks\u00e2\u0080\u009d introduces a new type of neuralnetwork, trained using a new loss function, caled CounterfactualLoss, together with stochastic gradient descent.", "The main hypothesis of the manuscript is that more flexibility in regularization should enable a better treatment of features that have a varying degree of importance.", "With this the authors wanted to enable DNNs to perform better in scenarios where they currently loose against other learning methods like gradient boosting trees.", "The authors motivate in their conclusion why this might make sense, but in the application they show it is not clear, why one has to use a regularization learning network (RLN) instead of a GBT model.", "Qualty The overal qualty of the paper is good.", "The authors realy tried to show the effects of the new regularization scheme, which seems to produce reasonable results.", "Clarity The presentation of the method is very clear.", "Sometimes, it would have been nice to include more details in the manuscript and not in the supplement (e g , training setup).", "Significance The regularization scheme seems to have certain benefits over standard DNNs.", "The authors could not show on the data set they chose that this leads to a model with better performance than the best other method, but at least compared to standard DNNs the performance increase was significant.", "Therefore, especialy for settings where joint models on severaltypes of data are supposed to be learnt, this new approach might be a good way forward.", "Since the authors only gave this application as an outlook and alo only mention that the initialresults are positive (in the author response), it remains to be seen how well the performance will be for different prediction tasks of this type."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_126_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": null, "metareview": "nota", "presentation": 0, "method": null}, {"interpretation": 0, "review_id": "NIPS_2018_126_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_126_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_126_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_131_3", "review_text": "This paper introduces a smooth thresholding technique which enables practically standard gradient descent optimization to be applied to spiking neural networks. Since the spiking threshold is usually set at a certain membrane potential, the function \"spike or no spike\" is a function of voltage whose distributional derivative is a dirac Delta at the threshold. By replacing this Dirac delta by a finite positive function g(v) with tight support around the threshold, and which integrates to 1, the step function \"spike or no spike\" is replaced by a function that increases continuously from 0 to 1 across the support of g. In turn, this setup can be placed into standard differential equation models governing spikes, while retaining the possibility of having meaningful gradient signal for parameter optimization.  Two experiments are evaluated, an autoencoding task and a delayed-memory-XOR task, which are both shown to be trainable with the proposed setup.  This is a good contribution which removes some previously required restrictions for training spiking neuron models (which are enumerated in the introduction).  An analysis that is missing and which imposes itself quite naturally is the behavior of the training as a function of support size/smoothness of g. One could for example evaluate g_a(v) = a g(a(v - v0) + v0) with g starting as very smooth and becoming more pointy as a increases. At some point training should become impossible due to convergence of this method to standard thresholding (+ numerical issues). Next, one could also evaluate making this function continuously sharper during training. ", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["This paper introduces a smooth thresholding technique which enables practicaly standard gradient descent optimization to be applied to spiking neuralnetworks.", "Since the spiking threshold is usualy set at a certain membrane potential the function \"spike or no spike\" is a function of voltage whose distributionalderivative is a dirac Delta at the threshold.", "By replacing this Dirac delta by a finite positive function g(v) with tight support around the threshold, and which integrates to 1, the step function \"spike or no spike\" is replaced by a function that increases continuously from 0 to 1 across the support of g In turn, this setup can be placed into standard differentialeqation models governing spikes, while retaining the possibility of having meaningful gradient signalfor parameter optimization.", "Two experiments are evalated, an autoencoding task and a delayed-memory-XOR task, which are both shown to be trainable with the proposed setup.", "This is a good contribution which removes some previously reqired restrictions for training spiking neuron models (which are enumerated in the introduction).", "An analsis that is missing and which imposes itself quite naturaly is the behavior of the training as a function of support size/smoothness of g One could for example evalate g_a(v) = a g(a(v - v0) + v0) with g starting as very smooth and becoming more pointy as a increases.", "At some point training should become impossible due to convergence of this method to standard thresholding (+ numericalissues).", "Next, one could alo evalate making this function continuously sharper during training."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_131_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_131_3", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_131_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_131_3", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_134_1", "review_text": "Post Authors' Response  Thanks a lot the authors for their response. I am happy with the responses they have provided to my initial concerns which have improved the manuscript. I would encourage authors to add an appendix should they believe they can convey a more complete message without having to wait for drafting another another longer manuscript.   ------------------------------------------------------------ Initial Review  The author/authors propose the first neural network producing fast high-dimensional convolution algorithms. They utilise the new Acceleration Network (AccNet)  to express the approximation function of splatting/blurring/slicing (SBS) and generalise SBS by changing the architecture of AccNet. Upon finishing the training process, the proposed fast convolution algorithm can be  derived from  the weights and activation functions of each layer. They conducted various experiments that prove the  effectiveness of the proposed algorithm.  The papers is very well written and of good quality. The main part of the paper, i.e. 3rd to 6th page, would benefit from making clearer the exact contribution of the authors. Reason is that it sometimes provides too much information about the fundamentals and the exact implementation and adjustments are likely to be missed. Section 3.2.4 that describes the proposed algorithm could serve for this purpose, i.e. what is being added or proposed to further enhance the SBS. Figure 3 shows the fast filtering approaches based on gCP and gHT decompositions. Is this based on section 3.2.3 that has been proposed by Hackbusch and Kuehn or includes other tensor decomposition methods? I reckon the latter, but it needs to have a better connection to what is being proposed further on especially when describing the reuse of convolution kernels by multiple times.  -Having said all the above, I think that the results are very interesting and demonstrate a solid computational improvement.  Is Figure 5 accurate? Have you really achieved such a reduced time in the detail enhancement, i.e. 66.1s vs 0.65s. That would be a significant improvement. By the way the font size is quite small to be honest.  -The weak point in my humble opinion is the few examples that are presented to demonstrate the computational efficiency, such as figures 4 and 5. I think further evaluation in larger data set is needed so that the bias can be reduced and ascertain the generalisation of this approach, as one could now claim that the examples presented have been selected to suit the proposed algorithm.  -Please expand slightly the conclusion if possible, as it reads as if you have been running out of space. Highlighting the main findings and contributions will enhance the paper.  Minor issues: a) Line 162, page 5 correct \"approximates\" to \"approximate\" b) Figure 3 caption second to last sentence \"outputs\" c) Line 273, page 8, please remove the redundant \"the\"", "gold_annotation": null, "score": 3.5, "tokenized_review_text": ["Post Authors' Response Thanks a lot the authors for their response.", "I am happy with the responses they have provided to my initialconcerns which have improved the manuscript.", "I would encourage authors to add an appendix should they believe they can convey a more complete message without having to wait for drafting another another longer manuscript.", "------------------------------------------------------------ InitialReview The author/authors propose the first neuralnetwork producing fast high-dimensionalconvolution alorithms.", "They utilise the new Acceleration Network (AccNet) to express the approximation function of splatting/blurring/slicing (SBS) and generalse SBS by changing the architecture of AccNet.", "Upon finishing the training process, the proposed fast convolution alorithm can be derived from the weights and activation functions of each layer.", "They conducted various experiments that prove the effectiveness of the proposed alorithm.", "The papers is very well written and of good qualty.", "The main part of the paper, i e 3rd to 6th page, would benefit from making clearer the exact contribution of the authors.", "Reason is that it sometimes provides too much information about the fundamental and the exact implementation and adjustments are likely to be missed.", "secion 3 2 4 that describes the proposed alorithm could serve for this purpose, i e what is being added or proposed to further enhance the SBS.", "figre 3 shows the fast filtering approaches based on gCP and gHT decompositions.", "Is this based on secion 3 2 3 that has been proposed by Hackbusch and Kuehn or includes other tensor decomposition methods?", "I reckon the latter, but it needs to have a better connection to what is being proposed further on especialy when describing the reuse of convolution kernels by multiple times.", "-Having said al the above, I think that the results are very interesting and demonstrate a solid computationalimprovement.", "Is figre 5 accurate?", "Have you realy achieved such a reduced time in the detail enhancement, i e 66.1s vs 0 65s.", "That would be a significant improvement.", "By the way the font size is quite smal to be honest.", "-The weak point in my humble opinion is the few examples that are presented to demonstrate the computationalefficiency, such as figres 4 and 5, I think further evalation in larger data set is needed so that the bias can be reduced and ascertain the generalsation of this approach, as one could now claim that the examples presented have been selected to suit the proposed alorithm.", "-Please expand slightly the conclusion if possible, as it reads as if you have been running out of space.", "Highlighting the main findings and contributions will enhance the paper.", "Minor issues: a) Line 162, page 5 correct \"approximates\" to \"approximate\" b) figre 3 caption secnd to last sentence \"outputs\" c) Line 273, page 8, please remove the redundant \"the\""], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_134_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, {"interpretation": 1, "review_id": "NIPS_2018_134_1", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_134_1", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_134_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_135_2", "review_text": "Summary:  This paper considers the problem of machine teaching when the learner has a general type of preference function over hypotheses, where the amount a learner prefers a particular hypothesis depends on its current hypothesis. Specifically, they are interested in understanding when an iterative/adaptive teaching protocol fairs better than a non-adaptive approach.  They demonstrate that when a learner only has global preferences (i.e. their preferences do not depend on their current hypothesis), there is no gain in an adaptive strategy. They also provide two example settings in which one can show adaptivity can lead to improvement over the non-adaptive setting. They also present conditions under which a certain greedy strategy is within some logarithmic factor of optimal.   Quality:  This paper appears to be technically sound, although I have not checked all of the proofs rigorously.    Clarity:  This paper is reasonably clear, but I did have difficulty following the discussions surrounding the example classes (2-Rec and Lattice). For example, the discussion in the first paragraph of Section 5.2 introduces an oracle S(), a subroutine Teacher(), and a term \u00e2\u0080\u009csub-task\u00e2\u0080\u009d that all seem to be interrelated but don\u00e2\u0080\u0099t seem to be formally defined.   Originality + significance:  The local preference model of a learner in the machine teaching setting appears to be an interesting contribution to the field. It is well-motivated and very general.  Unfortunately, the algorithms considered here only seem to be feasible in relatively toy settings. In particular, to implement Algorithm 1, we need to find the hypothesis which maximizes \\tilde{D}(h). However, this appears to require enumerating over the entire candidate set (which may require enumerating the entire version space to construct). This paper would be strengthened significantly by a reasonable example where (say approximately) maximizing \\tilde{D}(h) can be done efficiently.    \u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094  Revision after author response:  After viewing the author response and the other reviews, I have decided to revise my score upwards. My main objection to the current work was that the proposed algorithms only work in toy settings due to the difficulty of the optimization problems. However, as pointed out by another reviewer, this paper has several important contributions, and the formalisms presented here open the door for others to work in this area.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["Summary: This paper considers the problem of machine teaching when the learner has a generaltype of preference function over hypotheses, where the amount a learner prefers a particular hypothesis depends on its current hypothesis.", "Specificaly, they are interested in understanding when an iterative/adaptive teaching protocol fairs better than a non-adaptive approach.", "They demonstrate that when a learner only has globalpreferences (i e their preferences do not depend on their current hypothesis), there is no gain in an adaptive strategy.", "They alo provide two example settings in which one can show adaptivity can lead to improvement over the non-adaptive setting.", "They alo present conditions under which a certain greedy strategy is within some logarithmic factor of optimal Qualty: This paper appears to be technicaly sound, alhough I have not checked al of the proofs rigorously.", "Clarity: This paper is reasonably clear, but I did have difficulty following the discussions surrounding the example classes (2-Rec and Lattice).", "For example, the discussion in the first paragraph of secion 5 2 introduces an oracle S(), a subroutine Teacher(), and a term \u00e2\u0080\u009csub-task\u00e2\u0080\u009d that al seem to be interrelated but don\u00e2\u0080\u0099t seem to be formaly defined.", "Originalty + significance: The localpreference model of a learner in the machine teaching setting appears to be an interesting contribution to the field.", "It is well-motivated and very general Unfortunately, the alorithms considered here only seem to be feasible in relatively toy settings.", "In particular, to implement Algorithm 1, we need to find the hypothesis which maximizes \\tilde{D}(h).", "However, this appears to reqire enumerating over the entire candidate set (which may reqire enumerating the entire version space to construct).", "This paper would be strengthened significantly by a reasonable example where (say approximately) maximizing \\tilde{D}(h) can be done efficiently.", "\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094\u00e2\u0080\u0094 Revision after author response: After viewing the author response and the other reviews, I have decided to revise my score upwards.", "My main objection to the current work was that the proposed alorithms only work in toy settings due to the difficulty of the optimization problems.", "However, as pointed out by another reviewer, this paper has severalimportant contributions, and the formalsms presented here open the door for others to work in this area."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_135_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_135_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_135_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_135_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_139_2", "review_text": "* summary: In this paper, the authors studied the optimization and generalization of the stochastic composite mirror descent (SCMD) method for machine learning problems. In the convergence analysis, a common assumption, i.e., the boundedness of the gradient vector, was not assumed. Then, the generalization ability of the kernel-based SGD method was established. The generalization bound revealed the fact that the estimation errors in the generalization error will never essentially dominate the approximation and computation errors. As a result, one can run the SGD with a sufficient number of iterations with little overfitting if step sizes are square-summable. Some numerical experiments were conducted to confirm these theoretical findings.    * comments: The authors mentioned their motivation clearly, and they could successfully remove the common boundedness assumption of the gradient vector from the theoretical analysis of the SGD. Some related works were discussed in detail. Numerical experiments agreed to the theoretical findings.   - It is not clear whether removing the bounded gradient assumption is the key to obtain the assertion in line 309. How does the following finding in line 309 relate to the bounded gradient assumption?  > the estimation errors in the generalization error will never essentially dominate the approximation > and computation errors  and one can run SGD with a sufficient number of iterations with little > overfitting if step sizes are square-summable.   - line 194: Is Psi(w) equal to 1/2 |w|^2?  - Assumption 3: Showing a typical value of alpha for several problem setups would be helpful for readers.   - Should the kernel function be universal to agree to Assumption 3? (The universal kernel is defined in [Steinwart and Christmann, Support Vector Machines, 2008]). Adding a supplementary comment about the relation between Assumption 3 and some properties of kernel functions would be nice.  ", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["* summary: In this paper, the authors studied the optimization and generalzation of the stochastic composite mirror descent (SCMD) method for machine learning problems.", "In the convergence analsis, a common assumption, i e , the boundedness of the gradient vector, was not assumed.", "Then, the generalzation ability of the kernel-based SGD method was established.", "The generalzation bound reveald the fact that the estimation errors in the generalzation error will never essentialy dominate the approximation and computation errors.", "As a result, one can run the SGD with a sufficient number of iterations with little overfitting if step sizes are square-summable.", "Some numericalexperiments were conducted to confirm these theoreticalfindings.", "* comments: The authors mentioned their motivation clearly, and they could successfully remove the common boundedness assumption of the gradient vector from the theoreticalanalsis of the SGD.", "Some related works were discussed in detail.", "Numericalexperiments agreed to the theoreticalfindings.", "- It is not clear whether removing the bounded gradient assumption is the key to obtain the assertion in line 309, How does the following finding in line 309 relate to the bounded gradient assumption?", "> the estimation errors in the generalzation error will never essentialy dominate the approximation > and computation errors and one can run SGD with a sufficient number of iterations with little > overfitting if step sizes are square-summable.", "- line 194: Is Psi(w) eqalto 1/2 |w|^2?", "- Assumption 3: Showing a typicalvale of alha for severalproblem setups would be helpful for readers.", "- Should the kernel function be universalto agree to Assumption 3?", "(The universalkernel is defined in [Steinwart and Christmann, Support Vector Machines, 2008]).", "Adding a supplementary comment about the relation between Assumption 3 and some properties of kernel functions would be nice."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_139_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_139_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_139_2", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_139_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_141_1", "review_text": "This paper studies the problem of handling the langauge/text pariors in the task visual question answering. The great performance achieved by many state-of-the-art VQA systems are accomplished by heavily learning a better question encoding to better capture the correlations between the questions and answers, but ignore the image information. So the problem is important to the VQA research community. In general, the paper is well-written and easy to follow. And some concerns and sugggestions can be found as the following:  1) The major concern is the basic intuition of the question-only adversary: The question encoding q_i from the question encoder is not necessarily the same bias that lead the VQA model f to ignore the visual content. Since f can be a deep neutral network, for example, deep RNN or deep RNN-CNN to leverage both the question embedding and visual embedding, thus the non-linearity in f would make the question embedding as a image-aware represention to generate the answer distribution. Thus if the f_Q and f is different as stated in the paper (since the VQA models f are SAN and UpDn, the f_Q is a 2-layer dense network), then the question embedding equals to q_i (since it is linear transformation throught through the 2-layer dense network) to generate the answer distribution for the question-only adversary. Then the question embedding for question-only mdoel and the VQA model are different, which make the question-only model in the adversarial scheme doesn't hold.  2) The mutual information reguarlizer seems needs to be re-designed. The current optimization direction will let question encoding contains more information about the image. However this intuition doesn't mean the question encoding contain letter language priors. Adding anther mutual information regularizier to minimize the H(A|q_i) could help.  3) In the experiment, the question-only model can be better by introducing non-linearity to make the quesiton encoding behave similarity compared to the VQA models.  4) How to train the question-only model? It is trained based on equation (4) or (9)?  5) How to tune the lambda_q and lambda_mi? As the numbers in Table1 seems quite effective, but not very intuitive.  6) In table 1, why the gain of the VQA+MI performs the best on the VQA v2 dataset amony the versions with regularizers? Since by adding the mutual information regualrizer, the answers could better leverage the image information, it could generate slightly better result compared to the base models.", "gold_annotation": null, "score": 3.5, "tokenized_review_text": ["This paper studies the problem of handling the langauge/text pariors in the task visualquestion answering.", "The great performance achieved by many state-of-the-art VQA systems are accomplished by heavily learning a better question encoding to better capture the correlations between the questions and answers, but ignore the image information.", "So the problem is important to the VQA research community.", "In general the paper is well-written and easy to follow.", "And some concerns and sugggestions can be found as the following: 1) The major concern is the basic intuition of the question-only adversary: The question encoding q_i from the question encoder is not necessarily the same bias that lead the VQA model f to ignore the visualcontent.", "Since f can be a deep neutralnetwork, for example, deep RNN or deep RNN-CNN to leverage both the question embedding and visualembedding, thus the non-linearity in f would make the question embedding as a image-aware represention to generate the answer distribution.", "Thus if the f_Q and f is different as stated in the paper (since the VQA models f are SAN and UpDn, the f_Q is a 2-layer dense network), then the question embedding eqal to q_i (since it is linear transformation throught through the 2-layer dense network) to generate the answer distribution for the question-only adversary.", "Then the question embedding for question-only mdoel and the VQA model are different, which make the question-only model in the adversarialscheme doesn't hold.", "2) The mutualinformation reguarlizer seems needs to be re-designed.", "The current optimization direction will let question encoding contains more information about the image.", "However this intuition doesn't mean the question encoding contain letter language priors.", "Adding anther mutualinformation regularizier to minimize the H(A|q_i) could help.", "3) In the experiment, the question-only model can be better by introducing non-linearity to make the quesiton encoding behave similarity compared to the VQA models.", "4) How to train the question-only model?", "It is trained based on eqation (4) or (9)?", "5) How to tune the lambda_q and lambda_mi?", "As the numbers in Table1 seems quite effective, but not very intuitive.", "6) In table 1, why the gain of the VQA+MI performs the best on the VQA v2 dataset amony the versions with regularizers?", "Since by adding the mutualinformation regualizer, the answers could better leverage the image information, it could generate slightly better result compared to the base models."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_141_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_141_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_141_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_141_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_15_1", "review_text": " * Update after author response*  My main request for improving the comparison with state of the art models has been done and turned out favorable for the authors\u00e2\u0080\u0098 model. Therefore I think the paper makes a good contribution despite a number of smaller issues, most of which I hope the authors will fix in the final version.   I can\u00e2\u0080\u0099t quite follow R2\u00e2\u0080\u0098s criticism, as the authors\u00e2\u0080\u0098 GRU baseline does essentially what they describe as a 2D GRU.    *Original review*  Summary: The authors introduce a novel neural network architecture called the horizontal gated recurrent unit (hGRU), which they show excels at a visual task that requires detecting related features over long spatial ranges. This task \u00e2\u0080\u0093\u00c2\u00a0the Pathfinder Challenge \u00e2\u0080\u0093 has been used in the neuroscience literature and requires deciding whether two dots in an image are connected by a path made of short line segments. They show that a single layer of hGRU can solve this task almost perfectly, while CNNs need to be quite deep to achieve comparable performance and require orders of magnitude more parameters.  Strengths: + The paper is well motivated and conceptually very clear. + The Pathfinder challenge uses simple images to generate a non-trivial and interesting task. + The paper shows a limitation of CNNs and proposes an effective solution using a gated recurrent model. + The result that a one-layer recurrent model can solve the task is quite remarkable. + Ablation studies and comparisons with other models show that the proposed hGRU model maximizes the ratio of performance to the number of parameters.  Weaknesses: - The hGRU architecture seems pretty ad-hoc and not very well motivated. - The comparison with state-of-the-art deep architectures may not be entirely fair. - Given the actual implementation, the link to biology and the interpretation in terms of excitatory and inhibitory connections seem a bit overstated.  Conclusion: Overall, I think this is a really good paper. While some parts could be done a bit more principled and perhaps simpler, I think the paper makes a good contribution as it stands and may inspire a lot of interesting future work. My main concern is the comparison with state-of-the-art deep architectures, where I would like the authors to perform a better control (see below), the results of which may undermine their main claim to some extent.   Details:  - The comparison with state-of-the-art deep architectures seems a bit unfair. These architectures are designed for dealing with natural images and therefore have an order of magnitude more feature maps per layer, which are probably not necessary for the simple image statistics in the Pathfinder challenge. However, this difference alone increases the number of parameters by two orders of magnitude compared with hGRU or smaller CNNs. I suspect that using the same architectures with smaller number of feature maps per layer would bring the number of parameters much closer to the hGRU model without sacrificing performance on the Pathfinder task. In the author response, I would like to see the numbers for this control at least on the ResNet-152 or one of the image-to-image models.   The hGRU architecture seems very ad-hoc. - It is not quite clear to me what is the feature that makes the difference between GRU and hGRU. Is it the two steps, the sharing of the weights W, the additional constants that are introduced everywhere and in each iteration (eta_t). I would have hoped for a more systematic exploration of these features. - Why are the gain and mix where they are? E.g. why is there no gain going from H^(1) to \\tilde H^(2)? - I would have expected Eqs. (7) and (10) to be analogous, but instead one uses X and the other one H^(1). Why is that? - Why are both H^(1) and C^(2) multiplied by kappa in Eq. (10)?   - Are alpha, mu, beta, kappa, omega constrained to be positive? Otherwise the minus and plus signs in Eqs. (7) and (10) are arbitrary, since some of these parameters could be negative and invert the sign.   - The interpretation of excitatory and inhibitory horizontal connections is a bit odd. The same kernel (W) is applied twice (but on different hidden states). Once the result is subtracted and once it's added (but see the question above whether this interpretation even makes sense). Can the authors explain the logic behind this approach? Wouldn't it be much cleaner and make more sense to learn both an excitatory and an inhibitory kernel and enforce positive and negative weights, respectively?   - The claim that the non-linear horizontal interactions are necessary does not appear to be supported by the experimental results: the nonlinear lesion performs only marginally worse than the full model.   - I do not understand what insights the eigenconnectivity analysis provides. It shows a different model (trained on BSDS500 rather than Pathfinder) for which we have no clue how it performs on the task and the authors do not comment on what's the interpretation of the model trained on Pathfinder not showing these same patterns. Also, it's not clear to me where the authors see the \"association field, with collinear excitation and orthogonal suppression.\" For that, we would have to know the preferred orientation of a feature and then look at its incoming horizontal weights. If that is what Fig. 4a shows, it needs to be explained better. ", "gold_annotation": null, "score": 4.5, "tokenized_review_text": [" * Update after author response* My main reqest for improving the comparison with state of the art models has been done and turned out favorable for the authors\u00e2\u0080\u0098 model.", "Therefore I think the paper makes a good contribution despite a number of smaler issues, most of which I hope the authors will fix in the finalversion.", "I can\u00e2\u0080\u0099t quite follow R2\u00e2\u0080\u0098s criticism, as the authors\u00e2\u0080\u0098 GRU baseline does essentialy what they describe as a 2D GRU.", "*Originalreview* Summary: The authors introduce a novel neuralnetwork architecture caled the horizontalgated recurrent unit (hGRU), which they show excels at a visualtask that reqires detecting related features over long spatialranges.", "This task \u00e2\u0080\u0093\u00c2\u00a0the Pathfinder Chalenge \u00e2\u0080\u0093 has been used in the neuroscience literature and reqires deciding whether two dots in an image are connected by a path made of short line segments.", "They show that a single layer of hGRU can solve this task alost perfectly, while CNNs need to be quite deep to achieve comparable performance and reqire orders of magnitude more parameters.", "Strengths: + The paper is well motivated and conceptualy very clear.", "+ The Pathfinder chalenge uses simple images to generate a non-trivialand interesting task.", "+ The paper shows a limitation of CNNs and proposes an effective solution using a gated recurrent model.", "+ The result that a one-layer recurrent model can solve the task is quite remarkable.", "+ Ablation studies and comparisons with other models show that the proposed hGRU model maximizes the ratio of performance to the number of parameters.", "Weaknesses: - The hGRU architecture seems pretty ad-hoc and not very well motivated.", "- The comparison with state-of-the-art deep architectures may not be entirely fair.", "- Given the actualimplementation, the link to biology and the interpretation in terms of excitatory and inhibitory connections seem a bit overstated.", "Conclusion: Overal, I think this is a realy good paper.", "While some parts could be done a bit more principled and perhaps simpler, I think the paper makes a good contribution as it stands and may inspire a lot of interesting future work.", "My main concern is the comparison with state-of-the-art deep architectures, where I would like the authors to perform a better control (see below), the results of which may undermine their main claim to some extent.", "Details: - The comparison with state-of-the-art deep architectures seems a bit unfair.", "These architectures are designed for dealng with naturalimages and therefore have an order of magnitude more feature maps per layer, which are probably not necessary for the simple image statistics in the Pathfinder chalenge.", "However, this difference alne increases the number of parameters by two orders of magnitude compared with hGRU or smaler CNNs.", "I suspect that using the same architectures with smaler number of feature maps per layer would bring the number of parameters much closer to the hGRU model without sacrificing performance on the Pathfinder task.", "In the author response, I would like to see the numbers for this control at least on the ResNet-152 or one of the image-to-image models.", "The hGRU architecture seems very ad-hoc.", "- It is not quite clear to me what is the feature that makes the difference between GRU and hGRU.", "Is it the two steps, the sharing of the weights W, the additionalconstants that are introduced everywhere and in each iteration (eta_t).", "I would have hoped for a more systematic exploration of these features.", "- Why are the gain and mix where they are?", "E g why is there no gain going from H^(1) to \\tilde H^(2)?", "- I would have expected eq.", "(7) and (10) to be analgous, but instead one uses X and the other one H^(1).", "Why is that?", "- Why are both H^(1) and C^(2) multiplied by kappa in eq (10)?", "- Are alha, mu, beta, kappa, omega constrained to be positive?", "Otherwise the minus and plus signs in eq.", "(7) and (10) are arbitrary, since some of these parameters could be negative and invert the sign.", "- The interpretation of excitatory and inhibitory horizontalconnections is a bit odd.", "The same kernel (W) is applied twice (but on different hidden states).", "Once the result is subtracted and once it's added (but see the question above whether this interpretation even makes sense).", "Can the authors explain the logic behind this approach?", "Wouldn't it be much cleaner and make more sense to learn both an excitatory and an inhibitory kernel and enforce positive and negative weights, respectively?", "- The claim that the non-linear horizontalinteractions are necessary does not appear to be supported by the experimentalresults: the nonlinear lesion performs only marginaly worse than the full model.", "- I do not understand what insights the eigenconnectivity analsis provides.", "It shows a different model (trained on BSDS500 rather than Pathfinder) for which we have no clue how it performs on the task and the authors do not comment on what's the interpretation of the model trained on Pathfinder not showing these same patterns.", "Also, it's not clear to me where the authors see the \"association field, with collinear excitation and orthogonalsuppression.\"", "For that, we would have to know the preferred orientation of a feature and then look at its incoming horizontalweights.", "If that is what fig 4a shows, it needs to be explained better."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_15_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_15_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_15_1", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_15_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_160_2", "review_text": "The paper presents a reinforcement learning approach that has both gradient-based and gradient-free policy search nature. My understanding of the proposed algorithm is that it alternates between two stages. In the first stage, an elite policy is trained using typical RL algorithms such as PPO or A2C. Then during the second stage, a set of perturbed policies is used to generate the rollouts and update the elite policy, again with PPO or A2C. The rollouts collected during the second stage are used to estimate the performance of the perturbed policies and the best one is picked as the elite model in the next iteration. They demonstrated improved performance in playing atari games and limited improvements on continuous control problems.   I think the interesting part of the proposed method is that samples from a set of perturbed policies are used not only to compute the policy gradient, but also to estimate the individual performances for a possible jump in the parameter space. However, I think the experiment part needs notable improvements, as discussed in the itemized comments below.  1. A more detailed ablation study would be greatly appreciated. For example, is the algorithm sensitive to the crossover and mutation probability? Is the elite stage (first stage) necessary at all? What if we don\u00e2\u0080\u0099t select the new elite model from the population in stage two? These would help understand which components contributes the most to the performance boost. 2. The random multi policy baseline is not very clear to me. Does it mean randomly picking an elite policy during the GA+elite phase, or entirely randomize the population at every iteration instead of using mutation and crossover? 3. What does PPO_8 mean? Is it training 8 separate policies, or one policies with 8 threads to generate rollouts? 4. How many random seeds were used for the results in figure 4? 5. Also, it would be interesting to see a comparison/discussion with other forms of policy perturbations such as gaussian noise other than binary perturbation.  In general, the paper presents an interesting idea and show good improvement on playing atari games and limited improvement on continuous control problems. Some clarifications about the method and experiments are needed as discussed above and it would benefit from more experiments.   ------ I have modified the score after reading the authors' response. The ablation study helps demonstrate the strength of the proposed method. However, using single random seed for the experiments in Figure 4 is not well justified and should be explicitly stated to avoid confusion. ", "gold_annotation": null, "score": 4.0, "tokenized_review_text": ["The paper presents a reinforcement learning approach that has both gradient-based and gradient-free policy search nature.", "My understanding of the proposed alorithm is that it alernates between two stages.", "In the first stage, an elite policy is trained using typicalRL alorithms such as PPO or A2C.", "Then during the secnd stage, a set of perturbed policies is used to generate the rollouts and update the elite policy, again with PPO or A2C.", "The rollouts collected during the secnd stage are used to estimate the performance of the perturbed policies and the best one is picked as the elite model in the next iteration.", "They demonstrated improved performance in playing atari games and limited improvements on continuous control problems.", "I think the interesting part of the proposed method is that samples from a set of perturbed policies are used not only to compute the policy gradient, but alo to estimate the individualperformances for a possible jump in the parameter space.", "However, I think the experiment part needs notable improvements, as discussed in the itemized comments below.", "1, A more detailed ablation study would be greatly appreciated.", "For example, is the alorithm sensitive to the crossover and mutation probability?", "Is the elite stage (first stage) necessary at al?", "What if we don\u00e2\u0080\u0099t select the new elite model from the population in stage two?", "These would help understand which components contributes the most to the performance boost.", "2, The random multi policy baseline is not very clear to me.", "Does it mean randomly picking an elite policy during the GA+elite phase, or entirely randomize the population at every iteration instead of using mutation and crossover?", "3, What does PPO_8 mean?", "Is it training 8 separate policies, or one policies with 8 threads to generate rollouts?", "4, How many random seeds were used for the results in figre 4?", "5, Also, it would be interesting to see a comparison/discussion with other forms of policy perturbations such as gaussian noise other than binary perturbation.", "In general the paper presents an interesting idea and show good improvement on playing atari games and limited improvement on continuous control problems.", "Some clarifications about the method and experiments are needed as discussed above and it would benefit from more experiments.", "------ I have modified the score after reading the authors' response.", "The ablation study helps demonstrate the strength of the proposed method.", "However, using single random seed for the experiments in figre 4 is not well justified and should be explicitly stated to avoid confusion."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_160_2", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_160_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_160_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_160_2", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_175_2", "review_text": " =========== after rebuttal I carefully read the authors\u00e2\u0080\u0099 response. Some of my criticism has been addressed, yet I think that some critical flaws are still in the paper and I am not confident that these would be fixable in a final version within this submission round.  I believe that the authors do not make a strong case for their algorithm, since they do not appropriately compare with the state of the art. Eg, they do not compare to any of the algorithms mentioned below: https://arxiv.org/pdf/1511.01942.pdf and https://arxiv.org/pdf/1603.06861.pdf The authors mention in their experimental section: \u00e2\u0080\u009cImplementing our algorithm in the Spark environment is fairly straightforward. SVRG OL switches between two phases: a batch gradient computation phase and a serial SGD phase. \u00e2\u0080\u009c As I mentioned in my review, this is very very similar -modulo the varying stepsize- to the algorithms above. At the very least the authors should have compared with the above.  Moreover, the authors *do not* support a key claim of the paper, ie that the proposed algorithm achieves a linear speedup? (this claim is made in the 4th sentence of their abstract, and repeated through out their text) There is no single experiment that compares the serial implementation of the algorithm with its distributed version, hence no scaling/speedup result can be inferred.   Since they addressed some of my criticisms, but not the major points above, I will update my score from 3 to 4.  ===============original review The authors present SVRG OL, an adaptive SVRG algorithm (not quite sure why it is refered as SGD), that is designed to get linear speedups on parallel architectures.  The theoretical contribution of the paper is that the algorithm requires log number of comm rounds to achieve an epsilon accurate result.  Although the problem setup is interesting, there are several issues with the paper that I list below:  - First of all, the presented algorithm is *identical* to  Algorithm 1 here:https://arxiv.org/pdf/1412.6606.pdf  Algorithm 1 here https://arxiv.org/pdf/1511.01942.pdf  and CheapSVRG here: https://arxiv.org/pdf/1603.06861.pdf It is unclear to me what is algorithmically novel between the above and the presented SVRG OL algorithm.  - This is certainly subjective, but I do not understand the usefulness of online optimization results in the context of distributed setups. In most dist. setups that are of interest, all data is available for batch processing. In this case convergence rates are indeed important, but online regret bounds don\u00e2\u0080\u0099t shed a particular insight on how to implement these algorithms.   - The authors mention \u00e2\u0080\u009cUnfortunately, minibatch-SGD obtains a communication complexity that scales as sqrt{N} (or N^1/4 for accelerated variants). In modern problems when N is extremely large, this overhead is prohibitively large.\u00e2\u0080\u009d This is absolutely not true, as every single large scale ML problem that trains DNNs uses backprop and minibatch SGD implementations. So although the # comm rounds is high, it is not prohibitive.   - The authors mention \u00e2\u0080\u009cprior analyses require specific settings for \u00e2\u008c\u0098 that incorporate L and fail to converge with incorrect settings, requiring the user to manually tune \u00e2\u008c\u0098 to obtain the desired performance. \u00e2\u0080\u009c  That is true, but in practice one almost never computes L or the str. cvx constant, as that can be as expensive as solving the problem. For non-convex problems that actually *never* happens (eg pre computing L).  - The authors implement the algorithm in spark. All the data sets tested fit in a single machine, and can most probably be run much faster with a simple python implementation of SVRG. I will not be convinced that the implementations presented are relevant, unless the authors have a comparison with a single machine, SVRG non-Spark baseline.  - Although the authors make a claim on linear speedups, no speedup curves are presented in the paper.  - minor: Although the authors mention they need log number of comm rounds, in Table 1 they present constants and omit the log factors. There is enough space to list the details in this table.   Overall, this paper deals with an interesting problem. however, the presented algorithm is not novel, the implementation and experiments might not be as relevant, and comparisons with serial SVRG are missing. I do not think the paper should be accepted to NIPS. ", "gold_annotation": null, "score": 4.0, "tokenized_review_text": [" =========== after rebuttalI carefully read the authors\u00e2\u0080\u0099 response.", "Some of my criticism has been addressed, yet I think that some criticalflaws are still in the paper and I am not confident that these would be fixable in a finalversion within this submission round.", "I believe that the authors do not make a strong case for their alorithm, since they do not appropriately compare with the state of the art.", "Eg, they do not compare to any of the alorithms mentioned below: https://arxiv.org/pdf/1511.01942.pdf and https://arxiv.org/pdf/1603.06861.pdf The authors mention in their experimentalsecion: \u00e2\u0080\u009cImplementing our alorithm in the Spark environment is fairly straightforward.", "SVRG OL switches between two phases: a batch gradient computation phase and a serialSGD phase.", "\u00e2\u0080\u009c As I mentioned in my review, this is very very similar -modulo the varying stepsize- to the alorithms above.", "At the very least the authors should have compared with the above.", "Moreover, the authors *do not* support a key claim of the paper, ie that the proposed alorithm achieves a linear speedup?", "(this claim is made in the 4th sentence of their abstract, and repeated through out their text) There is no single experiment that compares the serialimplementation of the alorithm with its distributed version, hence no scalng/speedup result can be inferred.", "Since they addressed some of my criticisms, but not the major points above, I will update my score from 3 to 4, ===============originalreview The authors present SVRG OL, an adaptive SVRG alorithm (not quite sure why it is refered as SGD), that is designed to get linear speedups on paralel architectures.", "The theoreticalcontribution of the paper is that the alorithm reqires log number of comm rounds to achieve an epsilon accurate result.", "Although the problem setup is interesting, there are severalissues with the paper that I list below: - First of al, the presented alorithm is *identical to Algorithm 1 here:https://arxiv.org/pdf/1412.6606.pdf Algorithm 1 here https://arxiv.org/pdf/1511.01942.pdf and CheapSVRG here: https://arxiv.org/pdf/1603.06861.pdf It is unclear to me what is alorithmicaly novel between the above and the presented SVRG OL alorithm.", "- This is certainly subjective, but I do not understand the usefulness of online optimization results in the context of distributed setups.", "In most dist.", "setups that are of interest, al data is available for batch processing.", "In this case convergence rates are indeed important, but online regret bounds don\u00e2\u0080\u0099t shed a particular insight on how to implement these alorithms.", "- The authors mention \u00e2\u0080\u009cUnfortunately, minibatch-SGD obtains a communication complexity that scals as sqrt{N} (or N^1/4 for accelerated variants).", "In modern problems when N is extremely large, this overhead is prohibitively large.\u00e2\u0080\u009d This is absolutely not true, as every single large scal ML problem that trains DNNs uses backprop and minibatch SGD implementations.", "So alhough the # comm rounds is high, it is not prohibitive.", "- The authors mention \u00e2\u0080\u009cprior analses reqire specific settings for \u00e2\u008c\u0098 that incorporate L and fail to converge with incorrect settings, reqiring the user to manualy tune \u00e2\u008c\u0098 to obtain the desired performance.", "\u00e2\u0080\u009c That is true, but in practice one alost never computes L or the str.", "cvx constant, as that can be as expensive as solving the problem.", "For non-convex problems that actualy *never* happens (eg pre computing L).", "- The authors implement the alorithm in spark.", "All the data sets tested fit in a single machine, and can most probably be run much faster with a simple python implementation of SVRG.", "I will not be convinced that the implementations presented are relevant, unless the authors have a comparison with a single machine, SVRG non-Spark baseline.", "- Although the authors make a claim on linear speedups, no speedup curves are presented in the paper.", "- minor: Although the authors mention they need log number of comm rounds, in Table 1 they present constants and omit the log factors.", "There is enough space to list the details in this table.", "Overal, this paper deal with an interesting problem.", "however, the presented alorithm is not novel, the implementation and experiments might not be as relevant, and comparisons with serialSVRG are missing.", "I do not think the paper should be accepted to NIPS."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_175_2", "importance": 0, "reproducibility": 1, "constructiveness": 2, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_175_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_175_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_175_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_180_2", "review_text": "The paper address the problem of accurate object detection on mobile device which an important problem has not been solved. Current accurate detectors rely on large and deep networks which only be inferred on a GPU. To address this problem, it proposes a SSD based detection method based on a new network termed as Pelee.  Pros: + The Pelee detector achieves 76.4% mAP on PASCAL VOC2007 and 22.4 mAP on MS COCO dataset at the speed of 17.1 FPS on iPhone 6s and 23.6 FPS on iPhone 8. The accuracies are getting very close to the SSD detectors with VGGNets. The result on COCO outperforms YOLOv2 in consideration of a higher precision, 13.6 times lower computational cost and 11.3 times smaller model size. The results are very strong.  + Some new designs which are different and effective that make Pelee works. (1) Two-way dense layer motivated by GoogLeNet. (2) A cost-efficient stem block before the first dense layer. (3) Dynamic number of channels in bottleneck layer: the number is dynamically adjusted according to the input shape, to ensure that the number of channels does not exceed the input channels. (4) Transition layer without compression: it uses the conventional wisdom of \u00e2\u0080\u009cpost-activation\u00e2\u0080\u009d (Convolution - Batch Normalization [11] - Relu) as the composite function.  (5) Feature map selection, selected set of 5 scale feature maps (19 x 19, 10 x 10, 5 x 5, 3 x 3, and 1 x 1). To reduce computational cost, it does not use 38 x 38 feature map.  (6) Residual SSD prediction block.  (7) Small convolutional kernel for location and confidence score prediction.   Cons: - The technical contributions are not significant enough, since it is in the existing SSD detection framework and the network design are mainly based on experience. There is no theoretical finding. - It lacks comparisons to the state-of-the-art mobile deep detectors, such as SSD with MobileNetV2 & NasNet. - The efficient implementation of SSD on iOS cannot be regarded as a contribution since it simply based on the CoreML library.  Some minor issues: - The format and the presentation of the paper are not good. Tab 2&5 are not not well-aligned which make people hard to read.  - Some grammar mistakes: e.g., the \u00e2\u0080\u009cinnovate\u00e2\u0080\u009d connectivity pattern. - Why the method is termed as \u00e2\u0080\u009cPelee\u00e2\u0080\u009d?", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The paper address the problem of accurate object detection on mobile device which an important problem has not been solved.", "Current accurate detectors rely on large and deep networks which only be inferred on a GPU.", "To address this problem, it proposes a SSD based detection method based on a new network termed as Pelee.", "Pros: + The Pelee detector achieves 76.4% mAP on PASCAL VOC2007 and 22.4 mAP on MS COCO dataset at the speed of 17.1 FPS on iPhone 6s and 23.6 FPS on iPhone 8, The accuracies are getting very close to the SSD detectors with VGGNets.", "The result on COCO outperforms YOLOv2 in consideration of a higher precision, 13.6 times lower computationalcost and 11.3 times smaler model size.", "The results are very strong.", "+ Some new designs which are different and effective that make Pelee works.", "(1) Two-way dense layer motivated by GoogLeNet.", "(2) A cost-efficient stem block before the first dense layer.", "(3) Dynamic number of channels in bottleneck layer: the number is dynamicaly adjusted according to the input shape, to ensure that the number of channels does not exceed the input channels.", "(4) Transition layer without compression: it uses the conventionalwisdom of \u00e2\u0080\u009cpost-activation\u00e2\u0080\u009d (Convolution - Batch Normalzation [11] - Relu) as the composite function.", "(5) Feature map selection, selected set of 5 scal feature maps (19 x 19, 10 x 10, 5 x 5, 3 x 3, and 1 x 1).", "To reduce computationalcost, it does not use 38 x 38 feature map.", "(6) ResidualSSD prediction block.", "(7) Smal convolutionalkernel for location and confidence score prediction.", "Cons: - The technicalcontributions are not significant enough, since it is in the existing SSD detection framework and the network design are mainly based on experience.", "There is no theoreticalfinding.", "- It lacks comparisons to the state-of-the-art mobile deep detectors, such as SSD with MobileNetV2 & NasNet.", "- The efficient implementation of SSD on iOS cannot be regarded as a contribution since it simply based on the CoreML library.", "Some minor issues: - The format and the presentation of the paper are not good.", "Tab 2&5 are not not well-algned which make people hard to read.", "- Some grammar mistakes: e g , the \u00e2\u0080\u009cinnovate\u00e2\u0080\u009d connectivity pattern.", "- Why the method is termed as \u00e2\u0080\u009cPelee\u00e2\u0080\u009d?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_180_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_180_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_180_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_180_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_184_3", "review_text": "In this paper, the authors introduce SplineNet to learn the conditional NNs. The authors propose a embedding trick to learn the embedded mainfolds and a regularized loss to encourage the maximum information gain. Through experiments on MNIST and CIFAR10, the authors demonstrate SplineNet achieve comparable performance with baselines with much less computation and parameters.  The idea is novel and the proposed method is sound. The ablative study and experimental analysis is helpful to better understand the working principles of the method.  My questions on the experiments: --The authors only conduct experiments on small scale datasets (MNIST/CIFAR) using shallow networks (LeNet). How does it perform on larger datasets such as ImageNet using more complex networks such as DenseNet/ResNet.  --Are the speed-up ratios presented in L249 theoretical or practical?  ============================ Thanks for the feedback. I suggest the authors add the new experimental results in the final version. ", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["In this paper, the authors introduce SplineNet to learn the conditionalNNs.", "The authors propose a embedding trick to learn the embedded mainfolds and a regularized loss to encourage the maximum information gain.", "Through experiments on MNIST and CIFAR10, the authors demonstrate SplineNet achieve comparable performance with baselines with much less computation and parameters.", "The idea is novel and the proposed method is sound.", "The ablative study and experimentalanalsis is helpful to better understand the working principles of the method.", "My questions on the experiments: --The authors only conduct experiments on smal scal datasets (MNIST/CIFAR) using shalow networks (LeNet).", "How does it perform on larger datasets such as ImageNet using more complex networks such as DenseNet/ResNet.", "--Are the speed-up ratios presented in L249 theoreticalor practical ============================ Thanks for the feedback.", "I suggest the authors add the new experimentalresults in the finalversion."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_184_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_184_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_184_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_184_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_192_1", "review_text": "In this paper, the authors propose a randomized first order optimization method (SEGA) which progressively builds a variance reduced estimate of the gradient from random linear measurements of the gradient. The proposed method (or class of methods - depending on the sketch matrix and metric used) updates the current estimate of the gradient through a sketch-and-project operation using new gradient information and the past estimate of the gradient.  - The first half of the paper is very well written, easy to follow and well motivated. However, the quality of the paper deteriorates after page 6. The paper has minor typos and grammatical mistakes that can be corrected easily.  \u00e2\u0080\u0094 Line 29: now draw a two simple -> now draw two simple \u00e2\u0080\u0094 Line 36: methods as stochastic gradient -> methods such as stochastic gradient \u00e2\u0080\u0094 Line 83: For the illustration, -> To illustrate this, \u00e2\u0080\u0094 Line 83: shows a the evolution -> shows the evolution \u00e2\u0080\u0094 Line 87: baseline choice -> baseline choices \u00e2\u0080\u0094 Line 106: no proximal setting, coordinate -> no proximal term and coordinate \u00e2\u0080\u0094 Line 115: eigen-properties or matrices -> eigen-properties of matrices \u00e2\u0080\u0094 Line 148: analogy -> analog (and other instances of this) \u00e2\u0080\u0094 Line 152: fresult -> result \u00e2\u0080\u0094 Line 158: ary -> Corollary \u00e2\u0080\u0094 Line 165: in sense -> in the sense \u00e2\u0080\u0094 Line 181: verify claim -> verify the claim \u00e2\u0080\u0094 Line 192: a construct -> a constructed problem \u00e2\u0080\u0094 Line 193: system comparing -> system compared  - The Experiments section seems weak, primarily because all problems solved are constructed problems. The experiments are well though out to highlight certain algorithmic features of the method, however, several details are missing (e.g., what is the dimension n of the problems solved?), comparison with more methods would strengthen the claims made and experiments on real ML problems would highlight the merits (and limitations) of SEGA. \u00e2\u0080\u0094 Section 5.1: \u00e2\u0080\u0094\u00e2\u0080\u0094 The authors should mention in what settings different cost scenarios arise for solving the linear systems. \u00e2\u0080\u0094\u00e2\u0080\u0094 The authors should compare the methods on problems that are not quadratic. \u00e2\u0080\u0094 Section 5.2: \u00e2\u0080\u0094\u00e2\u0080\u0094 How was the finite difference interval set for the gradient estimation used in SEGA? Did the authors use forward differences (n function evaluations per iteration)?  \u00e2\u0080\u0094\u00e2\u0080\u0094The authors should compare against other zero order optimization methods (e.g., model based trust region method, finite difference quasi-Newton methods or Nelder-Mead). \u00e2\u0080\u0094\u00e2\u0080\u0094 Again, the authors should compare the methods on problems that are not quadratic. \u00e2\u0080\u0094\u00e2\u0080\u0094 In this section do the authors assume that they have access to true (non-noisy) function evaluations? \u00e2\u0080\u0094 Section 5.3: \u00e2\u0080\u0094\u00e2\u0080\u0094 How is beta chosen in the accelerated variant of the method? \u00e2\u0080\u0094\u00e2\u0080\u0094 In practice, on real world problems, how would one chose the subspaces to use in subspaceSEGA? The authors should make a comment about this in the paper. \u00e2\u0080\u0094 The authors claim that \u00e2\u0080\u009ctheory supported step sizes were chosen for all experiments.\u00e2\u0080\u009d These step sizes depend on problem specific parameters such as Trace(M), minimum and maximum eigenvalues of different matrices and other quantities. How were these quantities calculated?   - Other minor issues and questions: \u00e2\u0080\u0094 The authors should mention clearly that it is not necessary to compute the full gradient in Algorithm 1. \u00e2\u0080\u0094 \u00e2\u0080\u009cSEGA can be seen as a variance reduced coordinate descent.\u00e2\u0080\u009d Is it not the case that SEGA is more general than that? If certain sketch matrices are chosen then it is a coordinate descent type method, but with other sketches this is not the case.  \u00e2\u0080\u0094 \u00e2\u0080\u009cpotentially more expensive iteration\u00e2\u0080\u009d: it would be helpful for the reader if the authors provided some examples. \u00e2\u0080\u0094 \u00e2\u0080\u009ctotal complexity\u00e2\u0080\u009d: do the authors mean iteration complexity? \u00e2\u0080\u0094 What is alpha_0 in Corollary 3.4? \u00e2\u0080\u0094 Line 128: \u00e2\u0080\u009cCorollary 4.3 and Corollary 4.3\u00e2\u0080\u009d? \u00e2\u0080\u0094 Remark 4.4: \u00e2\u0080\u009cTherefore, SEGA also works in a non-convex setting.\u00e2\u0080\u009d I believe this statement is too strong. SEGA works for a certain class of non-convex function that satisfy the PL inequality (these function have unique minimizers). \u00e2\u0080\u0094 Corollary 4.5: Is the Lyapunov function used here the same as in Theorem 4.2? \u00e2\u0080\u0094 Table 1: What is the cause of the constant differences in the results of CD and SEGA? Is this an artifact of the analysis? Is this realized in practice? \u00e2\u0080\u0094 The authors should consider adding a Final Remarks section to summarize their contributions and to aid the reader.  - I believe the generality of the algorithms the authors propose (different sketch matrices) and the special cases of algorithms that they recover, as well as the wide range of potential problem classes that can be solved by the proposed methods, makes this a paper of interest for the ML and Optimization communities. However, there are certain issues and questions with the paper (mentioned above) that should be addressed. As such, I marginally recommend this paper for publication at NIPS.  I have read the author rebuttal and stand by my initial assessment of the paper.", "gold_annotation": null, "score": 4.5, "tokenized_review_text": ["In this paper, the authors propose a randomized first order optimization method (SEGA) which progressively builds a variance reduced estimate of the gradient from random linear measurements of the gradient.", "The proposed method (or class of methods - depending on the sketc matrix and metric used) updates the current estimate of the gradient through a sketc-and-project operation using new gradient information and the past estimate of the gradient.", "- The first hal of the paper is very well written, easy to follow and well motivated.", "However, the qualty of the paper deteriorates after page 6, The paper has minor typos and grammaticalmistakes that can be corrected easily.", "\u00e2\u0080\u0094 Line 29: now draw a two simple -> now draw two simple \u00e2\u0080\u0094 Line 36: methods as stochastic gradient -> methods such as stochastic gradient \u00e2\u0080\u0094 Line 83: For the illustration, -> To illustrate this, \u00e2\u0080\u0094 Line 83: shows a the evolution -> shows the evolution \u00e2\u0080\u0094 Line 87: baseline choice -> baseline choices \u00e2\u0080\u0094 Line 106: no proximalsetting, coordinate -> no proximalterm and coordinate \u00e2\u0080\u0094 Line 115: eigen-properties or matrices -> eigen-properties of matrices \u00e2\u0080\u0094 Line 148: analgy -> analg (and other instances of this) \u00e2\u0080\u0094 Line 152: fresult -> result \u00e2\u0080\u0094 Line 158: ary -> Corollary \u00e2\u0080\u0094 Line 165: in sense -> in the sense \u00e2\u0080\u0094 Line 181: verify claim -> verify the claim \u00e2\u0080\u0094 Line 192: a construct -> a constructed problem \u00e2\u0080\u0094 Line 193: system comparing -> system compared - The Experiments secion seems weak, primarily because al problems solved are constructed problems.", "The experiments are well though out to highlight certain alorithmic features of the method, however, severaldetails are missing (e g , what is the dimension n of the problems solved?", "), comparison with more methods would strengthen the claims made and experiments on realML problems would highlight the merits (and limitations) of SEGA.", "\u00e2\u0080\u0094 secion 5 1: \u00e2\u0080\u0094\u00e2\u0080\u0094 The authors should mention in what settings different cost scenarios arise for solving the linear systems.", "\u00e2\u0080\u0094\u00e2\u0080\u0094 The authors should compare the methods on problems that are not quadratic.", "\u00e2\u0080\u0094 secion 5 2: \u00e2\u0080\u0094\u00e2\u0080\u0094 How was the finite difference intervalset for the gradient estimation used in SEGA?", "Did the authors use forward differences (n function evalations per iteration)?", "\u00e2\u0080\u0094\u00e2\u0080\u0094The authors should compare against other zero order optimization methods (e g , model based trust region method, finite difference quasi-Newton methods or Nelder-Mead).", "\u00e2\u0080\u0094\u00e2\u0080\u0094 Again, the authors should compare the methods on problems that are not quadratic.", "\u00e2\u0080\u0094\u00e2\u0080\u0094 In this secion do the authors assume that they have access to true (non-noisy) function evalations?", "\u00e2\u0080\u0094 secion 5 3: \u00e2\u0080\u0094\u00e2\u0080\u0094 How is beta chosen in the accelerated variant of the method?", "\u00e2\u0080\u0094\u00e2\u0080\u0094 In practice, on realworld problems, how would one chose the subspaces to use in subspaceSEGA?", "The authors should make a comment about this in the paper.", "\u00e2\u0080\u0094 The authors claim that \u00e2\u0080\u009ctheory supported step sizes were chosen for al experiments.\u00e2\u0080\u009d These step sizes depend on problem specific parameters such as Trace(M), minimum and maximum eigenvales of different matrices and other quantities.", "How were these quantities calulated?", "- Other minor issues and questions: \u00e2\u0080\u0094 The authors should mention clearly that it is not necessary to compute the full gradient in Algorithm 1, \u00e2\u0080\u0094 \u00e2\u0080\u009cSEGA can be seen as a variance reduced coordinate descent.\u00e2\u0080\u009d Is it not the case that SEGA is more generalthan that?", "If certain sketc matrices are chosen then it is a coordinate descent type method, but with other sketces this is not the case.", "\u00e2\u0080\u0094 \u00e2\u0080\u009cpotentialy more expensive iteration\u00e2\u0080\u009d: it would be helpful for the reader if the authors provided some examples.", "\u00e2\u0080\u0094 \u00e2\u0080\u009ctotalcomplexity\u00e2\u0080\u009d: do the authors mean iteration complexity?", "\u00e2\u0080\u0094 What is alha_0 in Corollary 3 4?", "\u00e2\u0080\u0094 Line 128: \u00e2\u0080\u009cCorollary 4 3 and Corollary 4 3\u00e2\u0080\u009d?", "\u00e2\u0080\u0094 Remark 4 4: \u00e2\u0080\u009cTherefore, SEGA alo works in a non-convex setting.\u00e2\u0080\u009d I believe this statement is too strong.", "SEGA works for a certain class of non-convex function that satisfy the PL ineqalty (these function have unique minimizers).", "\u00e2\u0080\u0094 Corollary 4 5: Is the Lyapunov function used here the same as in Theorem 4 2?", "\u00e2\u0080\u0094 Table 1: What is the cause of the constant differences in the results of CD and SEGA?", "Is this an artifact of the analsis?", "Is this realzed in practice?", "\u00e2\u0080\u0094 The authors should consider adding a FinalRemarks secion to summarize their contributions and to aid the reader.", "- I believe the generalty of the alorithms the authors propose (different sketc matrices) and the specialcases of alorithms that they recover, as well as the wide range of potentialproblem classes that can be solved by the proposed methods, makes this a paper of interest for the ML and Optimization communities.", "However, there are certain issues and questions with the paper (mentioned above) that should be addressed.", "As such, I marginaly recommend this paper for publication at NIPS.", "I have read the author rebuttaland stand by my initialassessment of the paper."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_192_1", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_192_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_192_1", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_192_1", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_194_2", "review_text": "The manuscript proposes a method for one-shot unsupervised cross domain translation by using a two-step process. The first step is to train a VAE for domain B, and the second step is to create a VAE for domain A using a sample in domain A. The experiments show that the proposed OST method perform similar with existing method with a lot of training samples in domain A. The problem itself is very interesting. Although the main idea is different from the existing methods UNIT and cycleGAN, the framework with VAE and GAN somehow follows UNIT and cycleGAN. The manuscript is overall well written, and the experimental results seems promising.  My major concerns are as follows. 1. The framework shown in figure 1 is not clearly demonstrated, and the model is not clear enough, either. The manuscript seems only give a very rough idea and many details are unknown. For example, how the shared and unshared layers are defined? In the first step\u00ef\u00bc\u008cE_B, G_B,and D_B can be trained. How the trained E_B, G_B and D_B are used in the second stage? How the G^S,E^S, E_B^U, E_A^U,G_B^U,G_A^U are trained in the second stage?  2. In the experiments, how is the accuracy in figure 2 and table 1 defined? The accuracy values seem very low. Is there any explanation? 3. Intuitively, why does the proposed OST method outperform UNIT or cycleGAN? Where does the advantage come from?  ", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The manuscript proposes a method for one-shot unsupervised cross domain translation by using a two-step process.", "The first step is to train a VAE for domain B, and the secnd step is to create a VAE for domain A using a sample in domain A The experiments show that the proposed OST method perform similar with existing method with a lot of training samples in domain A The problem itself is very interesting.", "Although the main idea is different from the existing methods UNIT and cycleGAN, the framework with VAE and GAN somehow follows UNIT and cycleGAN.", "The manuscript is overal well written, and the experimentalresults seems promising.", "My major concerns are as follows.", "1, The framework shown in figre 1 is not clearly demonstrated, and the model is not clear enough, either.", "The manuscript seems only give a very rough idea and many details are unknown.", "For example, how the shared and unshared layers are defined?", "In the first step\u00ef\u00bc\u008cE_B, G_B,and D_B can be trained.", "How the trained E_B, G_B and D_B are used in the secnd stage?", "How the G^S,E^S, E_B^U, E_A^U,G_B^U,G_A^U are trained in the secnd stage?", "2, In the experiments, how is the accuracy in figre 2 and table 1 defined?", "The accuracy vales seem very low.", "Is there any explanation?", "3, Intuitively, why does the proposed OST method outperform UNIT or cycleGAN?", "Where does the advantage come from?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_194_2", "importance": 0, "reproducibility": 1, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}, {"interpretation": 1, "review_id": "NIPS_2018_194_2", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_194_2", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_194_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_200_1", "review_text": "The paper addresses the problem of fitting a subspace to data in cases where the underlying subspace is high-dimensional with respect to the ambient dimension, e.g., a 10-dimensional subspace in 11-dimensional ambient space, in the presence of outliers in data. The problem is also referred to as Dual Principal Component Pursuit (DPCP) in the literature. Recently, [17] has studied the problem, formulating it as finding a hyperplane normal vector $b$ so that for a dataset $X$, the vector $b^T X$ would be sparse, with nonzero elements indicating the outliers. The novelty of the paper is in the presentation of new and stronger theoretical results for the existing algorithm in [17] and a more efficient projected sub-gradient descent method (DPCP-PSGD) to solve the optimization in [17]. The paper demonstrates experiments for road plane detection from 3D data, showing improvement with respect to RANSAC.  + The paper is well-written and well-motivated. The review of the existing work in the area is comprehensive. The paper is well-structured and the technical results are explained well.  + The theoretical derivations and results in the paper are sound and provide stronger conditions for the success of DPCP, showing that the algorithm can tolerate up to $O(N^2)$ outliers, where $N$ indicates the number of inliers. This improves the existing results that guarantee success with $O(N)$ outliers.  + The proposed DPCP-PSGD, while quite standard, for the studied problem achieves improved computational time with respect to existing solvers. The paper also proves linear convergence for the proposed algorithm.  - Given that the setting of the experiment in the paper is to find 2D planes in 3D, to understand the effectiveness of the proposed method with respect to the state of the art, it is necessary that the paper provides comparison with more compelling baselines and state of the art other than RANSAC. In particular, the reviewer suggests comparing with \"Robust PCA via Outlier Pursuit, H. Xu, C. Caramanis, S. Sanghavi\" as well as [13] and [17], which all address the problem of handling outliers when fitting a subspace to data.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["The paper addresses the problem of fitting a subspace to data in cases where the underlying subspace is high-dimensionalwith respect to the ambient dimension, e g , a 10-dimensionalsubspace in 11-dimensionalambient space, in the presence of outliers in data.", "The problem is alo referred to as DualPrincipalComponent Pursuit (DPCP) in the literature.", "Recently, [17] has studied the problem, formulating it as finding a hyperplane normalvector $b$ so that for a dataset $X$, the vector $b^T X$ would be sparse, with nonzero elements indicating the outliers.", "The novelty of the paper is in the presentation of new and stronger theoreticalresults for the existing alorithm in [17] and a more efficient projected sub-gradient descent method (DPCP-PSGD) to solve the optimization in [17].", "The paper demonstrates experiments for road plane detection from 3D data, showing improvement with respect to RANSAC.", "+ The paper is well-written and well-motivated.", "The review of the existing work in the area is comprehensive.", "The paper is well-structured and the technicalresults are explained well.", "+ The theoreticalderivations and results in the paper are sound and provide stronger conditions for the success of DPCP, showing that the alorithm can tolerate up to $O(N^2)$ outliers, where $N$ indicates the number of inliers.", "This improves the existing results that guarantee success with $O(N)$ outliers.", "+ The proposed DPCP-PSGD, while quite standard, for the studied problem achieves improved computationaltime with respect to existing solvers.", "The paper alo proves linear convergence for the proposed alorithm.", "- Given that the setting of the experiment in the paper is to find 2D planes in 3D, to understand the effectiveness of the proposed method with respect to the state of the art, it is necessary that the paper provides comparison with more compelling baselines and state of the art other than RANSAC.", "In particular, the reviewer suggests comparing with \"Robust PCA via Outlier Pursuit, H Xu, C Caramanis, S Sanghavi\" as well as [13] and [17], which al address the problem of handling outliers when fitting a subspace to data."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_200_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_200_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_200_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_200_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_205_2", "review_text": "The paper asks an important question about need for explicitly exploration of validity of attractive greedy algorithm for linear contextual multi-armed bandit settings. While it is clear that greedy algorithm can have linear regret in worst-case, it is observed to be attractive in practice. To characterize this observation theoretically, the authors use smoothed analysis framework, and show that the greedy algorithm indeed as near-optimal regret (depending inversely on variance of Gaussian perturbation, as is common in smoothed analysis).  I think the result is extremely powerful. There have been some attempts to prove results in this direction, but the assumptions made here are substantially more general and elegant through use of smoothed analysis framework. Further an accompanied lower provides complete understanding of greedy algorithm in this setting. The results for multi-parameter setting are not as clean as the single parameter but still very strong.  Post-rebuttal: I did not have any pressing concerns to be addressed by author feedback. After reading the author feedback, my score remains the same.", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["The paper asks an important question about need for explicitly exploration of valdity of attractive greedy alorithm for linear contextualmulti-armed bandit settings.", "While it is clear that greedy alorithm can have linear regret in worst-case, it is observed to be attractive in practice.", "To characterize this observation theoreticaly, the authors use smoothed analsis framework, and show that the greedy alorithm indeed as near-optimalregret (depending inversely on variance of Gaussian perturbation, as is common in smoothed analsis).", "I think the result is extremely powerful.", "There have been some attempts to prove results in this direction, but the assumptions made here are substantialy more generaland elegant through use of smoothed analsis framework.", "Further an accompanied lower provides complete understanding of greedy alorithm in this setting.", "The results for multi-parameter setting are not as clean as the single parameter but still very strong.", "Post-rebuttal I did not have any pressing concerns to be addressed by author feedback.", "After reading the author feedback, my score remains the same."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_205_2", "importance": 1, "reproducibility": 0, "constructiveness": 1, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_205_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_205_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_205_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_208_2", "review_text": "The paper presents a method of single-image 3D reconstruction that works well also for unseen classes. The method is based on a sequence of networks/operations that 1) estimate the depth of the input object, 2) convert the depth map to a partial spherical map, 3) inpaint the spherical map, 4) refine the voxelized representation. These intermediate representations reduce the dependency in class-specific priors, allowing the system to generalize beyond the trained classes.  Overall, I like the paper and I find the use of intermediate representations useful for the task of both intra-class reconstruction and the generalization to unknown classes. In particular, the use of spherical maps for representing shapes and having a network to inpaint the hidden parts is interesting. Another strong point of the paper is its presentation: the paper is well written and easy to follow and the experimental setup is well performed.   In the weaknesses, the novelty in terms of network architecture seems limited as the method is using a sequence of standard blocks/losses. Also, I would expect to see more examples in the supp mat and applications on real images. I would like also to see more details why the different \"Ours\" variants perform that way for the \"Train\" case. Finally, including IoU for the voxel-based approaches will give a better insight in the comparisons. Also how well are the intermediate depths maps?", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["The paper presents a method of single-image 3D reconstruction that works well alo for unseen classes.", "The method is based on a seqence of networks/operations that 1) estimate the depth of the input object, 2) convert the depth map to a partialsphericalmap, 3) inpaint the sphericalmap, 4) refine the voxelized representation.", "These intermediate representations reduce the dependency in class-specific priors, alowing the system to generalze beyond the trained classes.", "Overal, I like the paper and I find the use of intermediate representations useful for the task of both intra-class reconstruction and the generalzation to unknown classes.", "In particular, the use of sphericalmaps for representing shapes and having a network to inpaint the hidden parts is interesting.", "Another strong point of the paper is its presentation: the paper is well written and easy to follow and the experimentalsetup is well performed.", "In the weaknesses, the novelty in terms of network architecture seems limited as the method is using a seqence of standard blocks/losses.", "Also, I would expect to see more examples in the supp mat and applications on realimages.", "I would like alo to see more details why the different \"Ours\" variants perform that way for the \"Train\" case.", "Finaly, including IoU for the voxel-based approaches will give a better insight in the comparisons.", "Also how well are the intermediate depths maps?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_208_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_208_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_208_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_208_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_218_2", "review_text": "POST-REBUTTAL UPDATE: The rebuttal addresses most of the issues addressed in the reviews, assuming that all promised changes will actually be incorporated in the camera-ready version. -----------------------------------------  The submission develops a meta-framework for few-shot learning that, building upon an approach/classifier of choice, uses a GAN approach to perform a kind of data augmentation. The classifier (discriminator) in this framework now has to not only distinguish the task classes, but also whether a sample was generated or not (similar to Dai et al.). Optimizing the overall objective yields improved results on both sample and task-based few shot learning problems.  The overall idea and approach is quite sound, and the evaluation, demonstrating that the proposed meta-algorithm is applicable to various discriminator designs, is fairly convincing. The addition of the task-level semi-supervised setting is appreciated. However, it would be great to see slightly more extensive experiments on the other settings: compared to Ren et al., there is no evaluation on the distractor classes setting (l.39, cf. Ren et al.), nor on the tieredImageNet data set.  Other remarks: - The submission is generally reasonably clear. - Section 2.1 is a bit to terse to read well. Several parts of the notation remain undefined. (X x Y, S_T^S, S_T^U, Q_T^S, Q_T_U, ...). - l.59-60: A word seems to be missing here. - l.123, l.127, l.141, and possible other places: Please refer to equations by \"Eq. 5 and Eq. 6\", etc., and not just writing the number. - Supplemental material, Sec. 3.2: I assume the table on the following page should either be embedded or referenced here.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["POST-REBUTTAL UPDATE: The rebuttaladdresses most of the issues addressed in the reviews, assuming that al promised changes will actualy be incorporated in the camera-ready version.", "----------------------------------------- The submission develops a meta-framework for few-shot learning that, building upon an approach/classifier of choice, uses a GAN approach to perform a kind of data augmentation.", "The classifier (discriminator) in this framework now has to not only distinguish the task classes, but alo whether a sample was generated or not (similar to Dai et al).", "Optimizing the overal objective yields improved results on both sample and task-based few shot learning problems.", "The overal idea and approach is quite sound, and the evalation, demonstrating that the proposed meta-alorithm is applicable to various discriminator designs, is fairly convincing.", "The addition of the task-level semi-supervised setting is appreciated.", "However, it would be great to see slightly more extensive experiments on the other settings: compared to Ren et al, there is no evalation on the distractor classes setting (l 39, cf.", "Ren et al), nor on the tieredImageNet data set.", "Other remarks: - The submission is generaly reasonably clear.", "- secion 2 1 is a bit to terse to read well.", "Severalparts of the notation remain undefined.", "(X x Y, S_T^S, S_T^U, Q_T^S, Q_T_U, ...).", "- l 59-60: A word seems to be missing here.", "- l 123, l 127, l 141, and possible other places: Please refer to eqations by \"eq 5 and eq 6\", etc, and not just writing the number.", "- Supplementalmaterial sec 3 2: I assume the table on the following page should either be embedded or referenced here."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_218_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_218_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_218_2", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_218_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_227_2", "review_text": "--------------------------After rebuttal---------------------------- I maintain my score. I also strongly approve of the suggestion of highlighting more the experimental results in the main paper. -----------------------------------------------------------------------  The paper describes a novel deterministic selection rule based on ridge leverage scores (RLS). RLSs are well known quantities used in randomized sketching and coreset selection to identify influential samples. Similarly, it is known that sampling **and reweighting** rows of a matrix A according to their RLS produces a sketch that whp approximates the true matrix up to a small multiplicative and additive error.  The authors prove that sorting the rows in descending order (by RLS), and deterministically selecting them until the RLS falls under a carefully chosen threshold is also sufficient to obtain a provably accurate sketch. Therefore, they propose deterministic RLS selection as a convenient and provably accurate rule for column selection, with improved interpretability over optimization based alternative such as lasso and elastic net.  Contribution: The additive-multiplicative spectral bound (Theorem 1) this is the core contribution of the paper. Note that Thm. 2,3,4 are direct consequences of Thm. 1, and are obtained with a straightforward application of results from (Boutsidis et al. 2011), (Cohen et al. 2015), (Cohen et al. 2017), (Papailiopoulos et al. 2014) and (Alaoui and Mahoney, 2015). Similarly, Thm. 5 is almost a direct consequence of (Papailiopoulos et al. 2014). This, together with the only two modifications necessary to existing results, is explained in detail in the complete appendix, which matches and exceed NIPS's standards for clarity. Note that it is probably possible to leverage this method into even more results, for example statistical risk guarantees stronger than Thm 4 using results from  Rudi, Alessandro, Raffaello Camoriano, and Lorenzo Rosasco. \"Less is more: Nystr\u00c3\u00b6m computational regularization.\" Advances in Neural Information Processing Systems. 2015.  While the paper introduces a new method with several small improvement over (Papailiopoulos et al. 2014), the work remains overall incremental and the significance of the contribution from a technical point of view is limited. The authors should try to stress more and clarify any significant improvement over (Papailiopoulos et al. 2014), and any advantage of RLS over k-rank LS. For example, RLS methods are widely successful in Reproducing Kernel Hilbert Spaces, while k-rank LS are not.  Nonetheless, I still believe this paper could find its audience at NIPS, and weakly suggest acceptance.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["--------------------------After rebuttal--------------------------- I maintain my score.", "I alo strongly approve of the suggestion of highlighting more the experimentalresults in the main paper.", "----------------------------------------------------------------------- The paper describes a novel deterministic selection rule based on ridge leverage scores (RLS).", "RLSs are well known quantities used in randomized sketcing and coreset selection to identify influentialsamples.", "Similarly, it is known that sampling **and reweighting** rows of a matrix A according to their RLS produces a sketc that whp approximates the true matrix up to a smal multiplicative and additive error.", "The authors prove that sorting the rows in descending order (by RLS), and deterministicaly selecting them until the RLS fals under a carefully chosen threshold is alo sufficient to obtain a provably accurate sketc.", "Therefore, they propose deterministic RLS selection as a convenient and provably accurate rule for column selection, with improved interpretability over optimization based alernative such as lasso and elastic net.", "Contribution: The additive-multiplicative spectralbound (Theorem 1) this is the core contribution of the paper.", "Note that Thm.", "2,3,4 are direct conseqences of Thm.", "1, and are obtained with a straightforward application of results from (Boutsidis et al 2011), (Cohen et al 2015), (Cohen et al 2017), (Papailiopoulos et al 2014) and (Alaoui and Mahoney, 2015).", "Similarly, Thm.", "5 is alost a direct conseqence of (Papailiopoulos et al 2014).", "This, together with the only two modifications necessary to existing results, is explained in detail in the complete appendix, which matches and exceed NIPS's standards for clarity.", "Note that it is probably possible to leverage this method into even more results, for example statisticalrisk guarantees stronger than Thm 4 using results from Rudi, Alessandro, Raffaello Camoriano, and Lorenzo Rosasco.", "\"Less is more: Nystr\u00c3\u00b6m computationalregularization.\"", "Advances in NeuralInformation Processing Systems.", "2015, While the paper introduces a new method with severalsmal improvement over (Papailiopoulos et al 2014), the work remains overal incrementaland the significance of the contribution from a technicalpoint of view is limited.", "The authors should try to stress more and clarify any significant improvement over (Papailiopoulos et al 2014), and any advantage of RLS over k-rank LS.", "For example, RLS methods are widely successful in Reproducing Kernel Hilbert Spaces, while k-rank LS are not.", "Nonetheless, I still believe this paper could find its audience at NIPS, and weakly suggest acceptance."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_227_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_227_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_227_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_227_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_22_2", "review_text": "I have two main concerns with this paper: - the first is on the significance of the result itself. Namely, I agree that provided the definition of what the authors want to capture, then the quantity introduced (adversarial VC dimension) is natural; while the proofs are relatively straightforward, mimicking the non-adversarial VC counterpart, this is not necessarily a bad thing. (Technical or hard is not synonymous of quality.) My issue is rather with the premise itself, as exemplified in Definition 1: after this definition, it is said \"Then, learning is possible if [...] L_P(\\hat{h})- L_P(h*)-> 0.\"  My feeling is that this sentence is misleading. Learning, in a non-trivial way, is possible when L_P(\\hat{h})- L_P(h*)-> 0 AND L_P(h*) is small. Otherwise, without the latter condition (say, if it is 1), then this is essentially saying that there is no hope to learn anything, and characterizes the right number of samples required to learn this nothing.  In other terms, I feel the current work seems to address a valid question, but misses a crucial part: that part being \"under which assumptions on R, H, and \\ell is learning non-trivially in presence of evasion adversaries possible?\"  - the second issue I have is with the writing. It really feels the authors went out of their way to appear \"mathy\", sacrificing readability and with no advantage. For instance, the footnotes about measurability: mentioning in passing at the beginning that, as standard,, one assumes measurability of all relevant quantities would be fine; instead, there are two footnotes. to say this, at two occasions. Another one: p.145, writing  \\kappa_R(h) = x \\mapsto [...] instead of \\kappa_R(h)(x) = [...] to define the function just makes it harder to parse; the notation is valid, but uncommon enough to keep the reader uneasy. Or, the cllearest example, on p.191: instead of writing \"eps >= 0\", the authors write \"eps \\in \\mathhbb{R}_{\\geq 0}\"! More symbols, less clear, no advantage whatsoever. (I could go on: for example, in Theorem 2: \"a bounded \\ell_p ball\" is just \"a \\ell_p ball\" -- why the redundant \"bounded\"?)  Finally, one last comment: in Theorem 1, don't add a footnote saying \"This can be improved.\" Either you prove it, and state it; or you don't, and don't claim it. This is a theorem in your paper, not a remark in passing.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["I have two main concerns with this paper: - the first is on the significance of the result itself.", "Namely, I agree that provided the definition of what the authors want to capture, then the quantity introduced (adversarialVC dimension) is natural while the proofs are relatively straightforward, mimicking the non-adversarialVC counterpart, this is not necessarily a bad thing.", "(Technicalor hard is not synonymous of qualty.)", "My issue is rather with the premise itself, as exemplified in Definition 1: after this definition, it is said \"Then, learning is possible if [...] L_P(\\hat{h})- L_P(h*)-> 0 \" My feeling is that this sentence is misleading.", "Learning, in a non-trivialway, is possible when L_P(\\hat{h})- L_P(h*)-> 0 AND L_P(h*) is smal.", "Otherwise, without the latter condition (say, if it is 1), then this is essentialy saying that there is no hope to learn anything, and characterizes the right number of samples reqired to learn this nothing.", "In other terms, I feel the current work seems to address a vald question, but misses a crucialpart: that part being \"under which assumptions on R, H, and \\ell is learning non-trivialy in presence of evasion adversaries possible?\"", "- the secnd issue I have is with the writing.", "It realy feels the authors went out of their way to appear \"mathy\", sacrificing readability and with no advantage.", "For instance, the footnotes about measurability: mentioning in passing at the beginning that, as standard,, one assumes measurability of al relevant quantities would be fine; instead, there are two footnotes.", "to say this, at two occasions.", "Another one: p 145, writing \\kappa_R(h) = x \\mapsto [...] instead of \\kappa_R(h)(x) = [...] to define the function just makes it harder to parse; the notation is vald, but uncommon enough to keep the reader uneasy.", "Or, the cllearest example, on p 191: instead of writing \"eps >= 0\", the authors write \"eps \\in \\mathhbb{R}_{\\geq0}\"!", "More symbols, less clear, no advantage whatsoever.", "(I could go on: for example, in Theorem 2: \"a bounded \\ell_p bal\" is just \"a \\ell_p bal\" -- why the redundant \"bounded\"?)", "Finaly, one last comment: in Theorem 1, don't add a footnote saying \"This can be improved.\"", "Either you prove it, and state it; or you don't, and don't claim it.", "This is a theorem in your paper, not a remark in passing."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_22_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_22_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_22_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_22_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_230_2", "review_text": "# Paper ID 1246  Verifiable RL via Policy Extraction  ## Summary  The main idea of the paper is to use a strong learned policy as an expert (e.g., deep neural network) in an imitation learning setup. A loss function designed to minimize the gap between the best and worst action (as defined by the expert) is used to train a CART policy. Three verifiable properties (correctness, robustness, stability) can be associated with the tree from the piecewise linearity of the partitions imposed by the tree policy that the original expert policy (e.g., a deep neural network) may not possess. However, correctness and stability require the system dynamics to be known. The empirical evaluation is somewhat limited. For example, experiments are shown on two relatively small domains (Atari Pong, cart-pole) where the model dynamics are simple enough to specify or approximate.  Overall, the paper is clearly well written. The algorithmic ideas are intuitively clear and seem sound to me. However, I'm a bit unclear about the feasibility / applicability of the verification process in other domains. The experimental section is also a bit limited. Overall, there are some interesting ideas in the paper but it's a bit difficult for me to evaluate due to the limited discussion and experiments. Detailed comments follow.   ## Detailed Comments  - The paper introduces a vanilla imitation learning setup for the task of extracting a policy from a given oracle or expert.  - A loss function designed to minimize the worst-case gap across the expected state distributions is defined. A decision tree learner is used on a dataset resampled under the new loss function which has the effect of \"compiling\" the original expert into a decision tree trained to minimize the expected worst-case loss across the distribution of states induced by the learned tree policy. This learning algorithm (Q-DAGGER) is the key algorithmic contribution.  - Intuitively, the main idea is to focus the training on states where the gap in the values between the best action and the worst action is largest. These are the \"critical states\". Standard 0-1 loss doesn't treat these states differently from other states. The idea here is that the learner should focus on avoiding the worst-case loss in states (i.e., $l_max$ is small). If such a policy can be found, then the bound improves over vanilla DAGGER.  - It's not clear to me how problems with \"critical states\" are distributed. For example, are the common control tasks in MuJoCo / OpenGym good candidate problems for this approach? Additional discussion characterizing problems where the methods are most / least applicable would be nice to have.  - Assuming such a problem is given, the approach proceeds by modifying the loss function to incorporate the worst-case gap in values. This requires an expert that can provide a worst-case \"gap\" (e.g., Q values, expert policy probabilities) between the best and worst action in any state. This seems reasonable to me.  - A tree policy can now be learned via CART in an iterative fashion (i.e. DAGGER). The main idea is to reweight the accumulated examples in the dataset using the worst-case gap values described above. This is the policy learned by the VIPER algorithm. This part is also very straightforward and well described.  - Next, the paper proposes three properties that are verifiable by VIPER under appropriate conditions. Correctness and stability require the model dynamics to be known while robustness does not. Here, I do think there needs to be additional discussion on the feasibility of obtaining the dynamics for other problems. Also, even if the dynamics are known, the difficulty of specifying the constraints in the form required by VIPER is unclear to me. A discussion of the complexity of these properties on MuJoCo tasks, for example, may be good to have. Discussion of these in Section 3 would strengthen the paper significantly, in my opinion.  - The empirical evaluation is performed on the Pong domain and cart-pole. It seems like verifying correctness and stability is rather difficult for a given domain. It might be worth discussing. Next, I'd be curious to know why robustness is only evaluated for Atari Pong and not cart-pole? Perhaps the paper could focus on a single property (e.g., robustness) and show experiments on additional domains. In its current form, the experimental section feels a bit limited. Additional experiments and their analysis would be very nice to have.  - Overall, it seems like the choice of loss function is orthogonal to the verification requirements, which only require the decision tree. Is my understanding correct? If yes, then other loss functions and their impact on tree size and properties would be quite interesting to study. For example, I'm curious to understand why exactly the trees under the 0-1 loss are larger for a particular reward target. How much of the tree size depends on the worst-case loss function seems like something worth exploring further.  Update -------- I thank the authors for their response. My overall score remains unchanged. ", "gold_annotation": null, "score": 3.5, "tokenized_review_text": ["# Paper ID 1246 Verifiable RL via Policy Extraction ## Summary The main idea of the paper is to use a strong learned policy as an expert (e g , deep neuralnetwork) in an imitation learning setup.", "A loss function designed to minimize the gap between the best and worst action (as defined by the expert) is used to train a CART policy.", "Three verifiable properties (correctness, robustness, stability) can be associated with the tree from the piecewise linearity of the partitions imposed by the tree policy that the originalexpert policy (e g , a deep neuralnetwork) may not possess.", "However, correctness and stability reqire the system dynamics to be known.", "The empiricalevalation is somewhat limited.", "For example, experiments are shown on two relatively smal domains (Atari Pong, cart-pole) where the model dynamics are simple enough to specify or approximate.", "Overal, the paper is clearly well written.", "The alorithmic ideas are intuitively clear and seem sound to me.", "However, I'm a bit unclear about the feasibility / applicability of the verification process in other domains.", "The experimentalsecion is alo a bit limited.", "Overal, there are some interesting ideas in the paper but it's a bit difficult for me to evalate due to the limited discussion and experiments.", "Detailed comments follow.", "## Detailed Comments - The paper introduces a vanilla imitation learning setup for the task of extracting a policy from a given oracle or expert.", "- A loss function designed to minimize the worst-case gap across the expected state distributions is defined.", "A decision tree learner is used on a dataset resampled under the new loss function which has the effect of \"compiling\" the originalexpert into a decision tree trained to minimize the expected worst-case loss across the distribution of states induced by the learned tree policy.", "This learning alorithm (Q-DAGGER) is the key alorithmic contribution.", "- Intuitively, the main idea is to focus the training on states where the gap in the vales between the best action and the worst action is largest.", "These are the \"criticalstates\".", "Standard 0-1 loss doesn't treat these states differently from other states.", "The idea here is that the learner should focus on avoiding the worst-case loss in states (i e , $l_max$ is smal).", "If such a policy can be found, then the bound improves over vanilla DAGGER.", "- It's not clear to me how problems with \"criticalstates\" are distributed.", "For example, are the common control tasks in MuJoCo / OpenGym good candidate problems for this approach?", "Additionaldiscussion characterizing problems where the methods are most / least applicable would be nice to have.", "- Assuming such a problem is given, the approach proceeds by modifying the loss function to incorporate the worst-case gap in vales.", "This reqires an expert that can provide a worst-case \"gap\" (e g , Q vales, expert policy probabilities) between the best and worst action in any state.", "This seems reasonable to me.", "- A tree policy can now be learned via CART in an iterative fashion (i e DAGGER).", "The main idea is to reweight the accumulated examples in the dataset using the worst-case gap vales described above.", "This is the policy learned by the VIPER alorithm.", "This part is alo very straightforward and well described.", "- Next, the paper proposes three properties that are verifiable by VIPER under appropriate conditions.", "Correctness and stability reqire the model dynamics to be known while robustness does not.", "Here, I do think there needs to be additionaldiscussion on the feasibility of obtaining the dynamics for other problems.", "Also, even if the dynamics are known, the difficulty of specifying the constraints in the form reqired by VIPER is unclear to me.", "A discussion of the complexity of these properties on MuJoCo tasks, for example, may be good to have.", "Discussion of these in secion 3 would strengthen the paper significantly, in my opinion.", "- The empiricalevalation is performed on the Pong domain and cart-pole.", "It seems like verifying correctness and stability is rather difficult for a given domain.", "It might be worth discussing.", "Next, I'd be curious to know why robustness is only evalated for Atari Pong and not cart-pole?", "Perhaps the paper could focus on a single property (e g , robustness) and show experiments on additionaldomains.", "In its current form, the experimentalsecion feels a bit limited.", "Additionalexperiments and their analsis would be very nice to have.", "- Overal, it seems like the choice of loss function is orthogonalto the verification reqirements, which only reqire the decision tree.", "Is my understanding correct?", "If yes, then other loss functions and their impact on tree size and properties would be quite interesting to study.", "For example, I'm curious to understand why exactly the trees under the 0-1 loss are larger for a particular reward target.", "How much of the tree size depends on the worst-case loss function seems like something worth exploring further.", "Update -------- I thank the authors for their response.", "My overal score remains unchanged."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_230_2", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_230_2", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_230_2", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_230_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_231_3", "review_text": "This paper continues a last year NIPS paper regarding volume sampling for the regression problem. It improved and somewhat completes the last result by showing the the original method may get sup-optimal results and then establishing a variant of the volume sampling so it\u00e2\u0080\u0099s will not suffer from this kind of pitfalls while maintaining the benefits of volume sampling (especially the unbiased). Along the way the paper uses a new \u00e2\u0080\u009cDeterminantal rejection sampling\u00e2\u0080\u009d method and a few mathematical results which may be of independent interest. Overall the paper is well written", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["This paper continues a last year NIPS paper regarding volume sampling for the regression problem.", "It improved and somewhat completes the last result by showing the the originalmethod may get sup-optimalresults and then establishing a variant of the volume sampling so it\u00e2\u0080\u0099s will not suffer from this kind of pitfals while maintaining the benefits of volume sampling (especialy the unbiased).", "Along the way the paper uses a new \u00e2\u0080\u009cDeterminantalrejection sampling\u00e2\u0080\u009d method and a few mathematicalresults which may be of independent interest.", "Overal the paper is well written"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_231_3", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_231_3", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_231_3", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno3", "evidence": 1, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_231_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_235_1", "review_text": "This work introduces an attentional tree-to-tree neural network for programming language translation, and evaluates it on two synthetic tasks and one real-world dataset. The results are significantly better than previous work in programming language translation, including rule-based and sequence-to-sequence approaches. But one central claim--that the authors \"are the first to design the tree-to-tree neural network for translation tasks\"--is inaccurate.  I am familiar with a previous version of this paper presented at the 2018 ICLR Workshop, and with the comments from the anonymous ICLR reviewers available at OpenReview; I believe the authors did a good job of improving their paper in response to those reviews. Most importantly, reviewers asked for evaluation on real-world data; the authors then went to great lengths to replicate the evaluation methodology of Nguyen et al. (2015) despite receiving no response to emails they sent, resulting in a strong (though perhaps difficult to compare exactly) real world evaluation result.  The model is described clearly and comprehensively; it would be relatively straightforward to reimplement from the paper alone. The two most important contributions of the model--the use of tree attention, and the use of parent-feeding--are both ablated in the results.  As far as the primacy claim: the work indeed fills a significant void in the literature. But the first tree-to-tree neural network (also for translation, and also using tree attention) was Bradbury and Socher (2017), presented at an EMNLP 2017 workshop (http://aclweb.org/anthology/W17-4303), and it would be helpful to cite and compare to that work, although the results of that paper were relatively weak and it wasn't published at a conference.", "gold_annotation": null, "score": 3.0, "tokenized_review_text": ["This work introduces an attentionaltree-to-tree neuralnetwork for programming language translation, and evalates it on two synthetic tasks and one realworld dataset.", "The results are significantly better than previous work in programming language translation, including rule-based and seqence-to-seqence approaches.", "But one centralclaim--that the authors \"are the first to design the tree-to-tree neuralnetwork for translation tasks\"--is inaccurate.", "I am familiar with a previous version of this paper presented at the 2018 ICLR Workshop, and with the comments from the anonymous ICLR reviewers available at OpenReview; I believe the authors did a good job of improving their paper in response to those reviews.", "Most importantly, reviewers asked for evalation on realworld data; the authors then went to great lengths to replicate the evalation methodology of Nguyen et al (2015) despite receiving no response to emails they sent, resulting in a strong (though perhaps difficult to compare exactly) realworld evalation result.", "The model is described clearly and comprehensively; it would be relatively straightforward to reimplement from the paper alne.", "The two most important contributions of the model--the use of tree attention, and the use of parent-feeding--are both ablated in the results.", "As far as the primacy claim: the work indeed fills a significant void in the literature.", "But the first tree-to-tree neuralnetwork (alo for translation, and alo using tree attention) was Bradbury and Socher (2017), presented at an EMNLP 2017 workshop (http://aclweb.org/anthology/W17-4303), and it would be helpful to cite and compare to that work, alhough the results of that paper were relatively weak and it wasn't published at a conference."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_235_1", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "NIPS_2018_235_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_235_1", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_235_1", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_237_2", "review_text": "The paper discusses the multi arm bandit problem to identify the best action in sequential decision making. It focuses on models in which there are non-trivial dependencies between the reward distribution of the arms. The approach formulates the problem with causal graphs and do-calculus. The key contribution is the proposal of an algorithm to find a set of variables called POMIS (possibly-optimal minimal intervention set). POMIS consists of a subset of all variables which can be intervened on to obtain the optimal strategy and the algorithm exploits graphical criteria.  The paper provides useful results as the strategy of removing redundant arms is shown in the experiments to improve the cumulative regret relative to others that ignore the structure of relationships. It achieves this by essentially reducing the space to search for optimal actions and avoids pulling unnecessary arms. As described in section 5, there are potential cases where alternative approaches would assess a smaller number of arms.", "gold_annotation": null, "score": 2.0, "tokenized_review_text": ["The paper discusses the multi arm bandit problem to identify the best action in seqentialdecision making.", "It focuses on models in which there are non-trivialdependencies between the reward distribution of the arms.", "The approach formulates the problem with causalgraphs and do-calulus.", "The key contribution is the proposalof an alorithm to find a set of variables caled POMIS (possibly-optimalminimalintervention set).", "POMIS consists of a subset of al variables which can be intervened on to obtain the optimalstrategy and the alorithm exploits graphicalcriteria.", "The paper provides useful results as the strategy of removing redundant arms is shown in the experiments to improve the cumulative regret relative to others that ignore the structure of relationships.", "It achieves this by essentialy reducing the space to search for optimalactions and avoids pulling unnecessary arms.", "As described in secion 5, there are potentialcases where alernative approaches would assess a smaler number of arms."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_237_2", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_237_2", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_237_2", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_237_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_23_1", "review_text": "The paper studies the connection between sparsity of linear classifier as well as deep neural networks and their robustness against adversarial attacks. Based on the two new introduced metrics, the authors show that sparse deep neural network are more robust against l_2 and l_inf attacks compared to their dense counterparts. Interestingly, in the linear case the behavior is differently, where sparsity helps against l_inf attacks but it seems that dense models are more robust against l_2 attacks.  I think the paper offers some interesting new insights both theoretically and empirically into adversarial robustness of deep neural networks and how it is connected to sparsity. Even though it is maybe not surprising that sparsity helps to make models more robust, given Occam's razor, the paper sheds a new light in the case of adversarial attacks. I do not have any major comments, however, to allow for a better understanding of the paper, the authors could clarify the following points:  1) The author only consider pruning to make model sparse. How would the empirical insights translate to other methods for sparsity, such as l2 or l1 regularization?  2) How are the results connected to the bias-variance-tradeoff?  3) Do the insights also translate to regressions?", "gold_annotation": null, "score": 2.5, "tokenized_review_text": ["The paper studies the connection between sparsity of linear classifier as well as deep neuralnetworks and their robustness against adversarialattacks.", "Based on the two new introduced metrics, the authors show that sparse deep neuralnetwork are more robust against l_2 and l_inf attacks compared to their dense counterparts.", "Interestingly, in the linear case the behavior is differently, where sparsity helps against l_inf attacks but it seems that dense models are more robust against l_2 attacks.", "I think the paper offers some interesting new insights both theoreticaly and empiricaly into adversarialrobustness of deep neuralnetworks and how it is connected to sparsity.", "Even though it is maybe not surprising that sparsity helps to make models more robust, given Occam's razor, the paper sheds a new light in the case of adversarialattacks.", "I do not have any major comments, however, to alow for a better understanding of the paper, the authors could clarify the following points: 1) The author only consider pruning to make model sparse.", "How would the empiricalinsights translate to other methods for sparsity, such as l2 or l1 regularization?", "2) How are the results connected to the bias-variance-tradeoff?", "3) Do the insights alo translate to regressions?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_23_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "NIPS_2018_23_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 1, "review_id": "NIPS_2018_23_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 1, "review_id": "NIPS_2018_23_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_241_2", "review_text": "The paper investigate a decomposition of the ELBO for the training of variational autoencoder that exposes a Total Correlation term, a term that penalizes statistical dependences between latent variables. The authors argue that this term is the important one for achieve disentangled latent variables for instance in the beta-VAE. To support their proposal they develop a minibatch-weighted sampling scheme that allows them to easily modify the weight of the Total Correlation term, resulting in what they call beta-TCVAE. In addition, in order to compare their model to previous models in the literature such as the beta-VAE and InfoGAN, they introduce a new metric to quantify the amount of disentanglement of latent variables, a general quantity that can be efficiently estimated that they call Mutual Information Gap (MIG). Both the the new minibatch estimator to train the objective based on the Total Correlation penalty, and the new disentanglement metric seem novel and significant advancements in the field. Besides explaining the way the beta-VAE works, the new beta-TCVAE model consistently outperforms it in terms of the trade-off between density estimation and disentanglement on several benchmarks, such as dSprites, and 3d Faces.", "gold_annotation": null, "score": 1.5, "tokenized_review_text": ["The paper investigate a decomposition of the ELBO for the training of variationalautoencoder that exposes a TotalCorrelation term, a term that penalzes statisticaldependences between latent variables.", "The authors argue that this term is the important one for achieve disentangled latent variables for instance in the beta-VAE.", "To support their proposalthey develop a minibatch-weighted sampling scheme that alows them to easily modify the weight of the TotalCorrelation term, resulting in what they cal beta-TCVAE.", "In addition, in order to compare their model to previous models in the literature such as the beta-VAE and InfoGAN, they introduce a new metric to quantify the amount of disentanglement of latent variables, a generalquantity that can be efficiently estimated that they cal MutualInformation Gap (MIG).", "Both the the new minibatch estimator to train the objective based on the TotalCorrelation penaly, and the new disentanglement metric seem novel and significant advancements in the field.", "Besides explaining the way the beta-VAE works, the new beta-TCVAE model consistently outperforms it in terms of the trade-off between density estimation and disentanglement on severalbenchmarks, such as dSprites, and 3d Faces."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_241_2", "importance": 1, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, {"interpretation": 0, "review_id": "NIPS_2018_241_2", "importance": 1, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno1", "evidence": 1, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_241_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, {"interpretation": 0, "review_id": "NIPS_2018_241_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_994_1", "review_text": "This paper studies differentially-private change-point detection -- detecting the point at which samples from a distribution stop coming from P_0, and instead start coming from P_1. It provides the first finite sample guarantees for the MLE for this problem non-privately (I'm not an expert in change-point detection, can anyone else confirm? It seems natural enough that I would expect someone else to have studied it prior...). The authors study the offline problem (where the entire stream is given at once), as well as the online problem.   I like this paper largely because it initiates the study of what I consider to be a fairly basic and interesting question, private change-point detection. My main criticism of the work is the assumptions that are required on the data. In particular, there is only a true differential privacy guarantee in the case where the likelihood ratio is bounded. In the case where it is bounded only with high probability, there is a data-dependent privacy guarantee, which makes me uneasy (what if the model is wrong, who knows where the data truly comes from, etc.). There is some vague text justification on why a bound is necessary -- is it possible to make this justification rigorous, in the form of a theorem? The algorithmic techniques are not too surprising, but that's acceptable in my opinion for the first paper is the area.  The authors should note that the submission format is for 8 pages + citations, with no appendices (which should be put in the supplementary material).  EDIT: The authors are advised to compare their results with the recent line of works on private hypothesis testing, particularly the ones focusing on minimax sample complexities, as these seem to focus on very similar problems (see, i.e. Gaboardi et al.'16, Kifer-Rogers'17, Cai et al.'17, Aliakbarpour et al.'18, Acharya et al.'17, etc.).", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_994_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["This paper studies differentialy-private change-point detection -- detecting the point at which samples from a distribution stop coming from P_0, and instead start coming from P_1, It provides the first finite sample guarantees for the MLE for this problem non-privately (I'm not an expert in change-point detection, can anyone else confirm?", "It seems naturalenough that I would expect someone else to have studied it prior...).", "The authors study the offline problem (where the entire stream is given at once), as well as the online problem.", "I like this paper largely because it initiates the study of what I consider to be a fairly basic and interesting question, private change-point detection.", "My main criticism of the work is the assumptions that are reqired on the data.", "In particular, there is only a true differentialprivacy guarantee in the case where the likelihood ratio is bounded.", "In the case where it is bounded only with high probability, there is a data-dependent privacy guarantee, which makes me uneasy (what if the model is wrong, who knows where the data truly comes from, etc).", "There is some vague text justification on why a bound is necessary -- is it possible to make this justification rigorous, in the form of a theorem?", "The alorithmic techniques are not too surprising, but that's acceptable in my opinion for the first paper is the area.", "The authors should note that the submission format is for 8 pages + citations, with no appendices (which should be put in the supplementary material.", "EDIT: The authors are advised to compare their results with the recent line of works on private hypothesis testing, particularly the ones focusing on minimax sample complexities, as these seem to focus on very similar problems (see, i e Gaboardi et al'16, Kifer-Rogers'17, Cai et al'17, Aliakbarpour et al'18, Acharya et al'17, etc)."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_994_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_993_1", "review_text": "OMP is a well known and widely used method for sparse learning from linear regression. There have several works which provide the support recovery of OMP under different settings, e.g., noiseless setting under various conditions like incoherence. In the noisy setting, the existing bound in [28] does not match the known lower bounds. The main contribution of this work is to improve these support recovery results for OMP and obtain matching lower bounds.  Generally, this work is very well written. The studied problem about the support recovery of OMP is important and of great interest. The authors provide sufficient theoretical results for OMP. These results extend the applicability of OMP.  For the experiments, how to initialize the solution?   -------------------------------------- Updates after author feedback the authors have addressed my concern. I increase my rating from 6 to 7.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_993_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["OMP is a well known and widely used method for sparse learning from linear regression.", "There have severalworks which provide the support recovery of OMP under different settings, e g , noiseless setting under various conditions like incoherence.", "In the noisy setting, the existing bound in [28] does not match the known lower bounds.", "The main contribution of this work is to improve these support recovery results for OMP and obtain matching lower bounds.", "Generaly, this work is very well written.", "The studied problem about the support recovery of OMP is important and of great interest.", "The authors provide sufficient theoreticalresults for OMP.", "These results extend the applicability of OMP.", "For the experiments, how to initialze the solution?", "-------------------------------------- Updates after author feedback the authors have addressed my concern.", "I increase my rating from 6 to 7,"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_993_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_98_4", "review_text": "The paper \"A Block Coordinate Ascent Algorithm for Mean-Variance Optimization\" proposes a new algorithm for reinforcement learning with a mean-variance objective that has a hard constraint on the reward variance and analyses the convergence of the algorithm in both infinite and finite horizon cases. The derivations for the new algorithm use a transformation based on a Fenchel dual (to transform a quadratic term into a linear term plus terms with an added additional variable) enabling gradient descent to be applied on the transformed Lagrangian dual of the original objective. The contribution w.r.t. the proofs and the new algorithm appear solid.  The paper is in general well written. There are some typos that should be fixed. The main problem in the paper is the reporting of the experimental results. The representation used for the policy is not discussed, the variance limit is not defined, and it is unclear whether the reported results are statistically significant.  The main claims about related work are as follows: \"1) Most of the analyses of ODE-based methods are asymptotic, with no sample complexity analysis.\" Most are asymptotic? The paper needs to discuss those cases where the analysis is not asymptotic. This is discussed later in the paper? Should be already mentioned here. \"2) It is well-known that multi-time-scale approaches are sensitive to the choice of the stepsize schedules, which is a non-trivial burden in real-world problems.\" \"3) The ODE approach does not allow extra penalty functions. Adding penalty functions can often strengthen the robustness of the algorithm, encourages sparsity and incorporates prior knowledge into the problem [Hastie et al., 2001].\"  Claims 1) - 3) seem correct and the proposed algorithm could offer some improvement over these previous approaches.  Algorithm 1: Each episode starts from the initial state s_1 until ending in the recurrent state s^*. It could help the reader to give an explanation why this is done so? Is this absolutely necessary for the analysis of the algorithm?  EXPERIMENTS: In the experiments, it is unclear what kind of representation the policy follows. It cannot be tabular since some of the problems have continuous states. It is also unclear whether the form of the policy influences the performance of the algorithms.  \\xi, the limit on the expected variance of the rewards (Equation 1), should be defined for each problem.  The statistical significance of the results is now described only in textual form. For example, \"The results indicate that MVP yields a higher mean return with less variance compared to the competing algorithms.\"  Firstly, according to my understanding the objective is not to minimize variance but to limit it, at least according to Equation 1. As such the variance of the comparison methods does not matter if it remains under the limit (which is not defined). Of course the variance is of separate interest for understanding how far each algorithm is from the limit. I recommend reporting whether the variance limit is exceeded and by how much. Furthermore, I recommend performing statistical significance testing on both the mean and variance.  LANGUAGE: In some places there is some unclarity that should be fixed. For example, in \"yet almost all the reported analysis of these algorithms are asymptotic [Xu and Yin, 2015].\" almost all? Which reported analysis is not asymptotic?  \"In risk-sensitive mean-variance optimization MDPs, the objective is often to maximize J(\u00ce\u00b8) with a variance constraint, i.e.,\" *often* ? Earlier in the paper there is a discussion on related work but it was not made clear what exactly the objective in those papers is?  Smaller typos: Line 85: \"the third time-scale is to optimizes over\" -> the third time-scale optimizes over Line 48: \"2 Backgrounds\" -> \"2 Background\" ? Line 116: \"and derives novel algorithms\" -> and derive novel algorithms Line 188: \"for which there is no established results\" -> for which there are no established results Line 203: \"Without the loss of generality\" should be usually \"Without loss of generality\" Line 205: \"as as\" -> as Line 206: \"approximate error\" -> approximation error Line 219: \"Now it is ready to provide\" -> Now we provide ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_98_4", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The paper \"A Block Coordinate Ascent Algorithm for Mean-Variance Optimization\" proposes a new alorithm for reinforcement learning with a mean-variance objective that has a hard constraint on the reward variance and analses the convergence of the alorithm in both infinite and finite horizon cases.", "The derivations for the new alorithm use a transformation based on a Fenchel dual(to transform a quadratic term into a linear term plus terms with an added additionalvariable) enabling gradient descent to be applied on the transformed Lagrangian dualof the originalobjective.", "The contribution w r t the proofs and the new alorithm appear solid.", "The paper is in generalwell written.", "There are some typos that should be fixed.", "The main problem in the paper is the reporting of the experimentalresults.", "The representation used for the policy is not discussed, the variance limit is not defined, and it is unclear whether the reported results are statisticaly significant.", "The main claims about related work are as follows: \"1) Most of the analses of ODE-based methods are asymptotic, with no sample complexity analsis.\"", "Most are asymptotic?", "The paper needs to discuss those cases where the analsis is not asymptotic.", "This is discussed later in the paper?", "Should be aleady mentioned here.", "\"2) It is well-known that multi-time-scal approaches are sensitive to the choice of the stepsize schedules, which is a non-trivialburden in realworld problems.\"", "\"3) The ODE approach does not alow extra penaly functions.", "Adding penaly functions can often strengthen the robustness of the alorithm, encourages sparsity and incorporates prior knowledge into the problem [Hastie et al, 2001].\"", "Claims 1) - 3) seem correct and the proposed alorithm could offer some improvement over these previous approaches.", "Algorithm 1: Each episode starts from the initialstate s_1 until ending in the recurrent state s^*.", "It could help the reader to give an explanation why this is done so?", "Is this absolutely necessary for the analsis of the alorithm?", "EXPERIMENTS: In the experiments, it is unclear what kind of representation the policy follows.", "It cannot be tabular since some of the problems have continuous states.", "It is alo unclear whether the form of the policy influences the performance of the alorithms.", "\\xi, the limit on the expected variance of the rewards (eqation 1), should be defined for each problem.", "The statisticalsignificance of the results is now described only in textualform.", "For example, \"The results indicate that MVP yields a higher mean return with less variance compared to the competing alorithms.\"", "Firstly, according to my understanding the objective is not to minimize variance but to limit it, at least according to eqation 1, As such the variance of the comparison methods does not matter if it remains under the limit (which is not defined).", "Of course the variance is of separate interest for understanding how far each alorithm is from the limit.", "I recommend reporting whether the variance limit is exceeded and by how much.", "Furthermore, I recommend performing statisticalsignificance testing on both the mean and variance.", "LANGUAGE: In some places there is some unclarity that should be fixed.", "For example, in \"yet alost al the reported analsis of these alorithms are asymptotic [Xu and Yin, 2015].\"", "alost al?", "Which reported analsis is not asymptotic?", "\"In risk-sensitive mean-variance optimization MDPs, the objective is often to maximize J(\u00ce\u00b8) with a variance constraint, i e ,\" *often* ?", "Earlier in the paper there is a discussion on related work but it was not made clear what exactly the objective in those papers is?", "Smaler typos: Line 85: \"the third time-scal is to optimizes over\" -> the third time-scal optimizes over Line 48: \"2 Backgrounds\" -> \"2 Background\" ?", "Line 116: \"and derives novel alorithms\" -> and derive novel alorithms Line 188: \"for which there is no established results\" -> for which there are no established results Line 203: \"Without the loss of generalty\" should be usualy \"Without loss of generalty\" Line 205: \"as as\" -> as Line 206: \"approximate error\" -> approximation error Line 219: \"Now it is ready to provide\" -> Now we provide"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_98_4", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_977_1", "review_text": "The paper shows a family of data-driven clustering algorithms called (a,b)-loyds++. Parameter a has to do with the initialization phase, while parameter b has to do with the local search/optimization phase.  One of the main technical and interesting results of the paper is the structural result that shows that for a given clustering instance, with high probability over the randomness in Algorithm 1, there are only polynomially many possible sets of output centers in phase 1 of the algorithm as parameter a varies.  This is used for specifying the sample complexity as well as the computational complexity of the proposed algorithm.  The experimental part of the paper is very short and laconic and it is very hard to infer the practical significance of the proposed method.  In general, although many of the ideas in the paper are neat and they are nice combinations of existing ideas in learning theory, I am a bit skeptical about the practicality of the proposed algorithm.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_977_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["The paper shows a family of data-driven clustering alorithms caled (a,b)-loyds++.", "Parameter a has to do with the initialzation phase, while parameter b has to do with the localsearch/optimization phase.", "One of the main technicaland interesting results of the paper is the structuralresult that shows that for a given clustering instance, with high probability over the randomness in Algorithm 1, there are only polynomialy many possible sets of output centers in phase 1 of the alorithm as parameter a varies.", "This is used for specifying the sample complexity as well as the computationalcomplexity of the proposed alorithm.", "The experimentalpart of the paper is very short and laconic and it is very hard to infer the practicalsignificance of the proposed method.", "In general alhough many of the ideas in the paper are neat and they are nice combinations of existing ideas in learning theory, I am a bit skepticalabout the practicalty of the proposed alorithm."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_977_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_969_3", "review_text": "The article proposes a method for adding streamlining constraints in the survey propagation procedure, which improves its performance on random k-SAT problems. In line with classical survey propagation, they use a message passing procedure to compute approximate marginal. However instead of using the marginal to set single variables in the decimation process as previously done in survey propagation, the authors propose to add constraints based upon multiple variables. Iterating this procedure, more highly constrained problems are produced, which can then be solved by a downstream solver. The authors show that this idea improved upon a state-of-the-art survey propagation solver.  The article is well written, presents a novel and effective idea that I expect to see used in future SAT-competitions. While perhaps needed for the target audience of NIPS, I personally find the background section where previous algorithms are presented a bit too long. A substantial part of the paper is dedicated to the background that the reader could have easily been directed to by citations.   I have reviewed this paper at UAI 2017. I voted for acceptance at that time, and I am still leaning towards accepting this paper. One reviewer at UAI 2017 raised highly valid points, which is that incorrect and highly imprecise claims are made in several parts of the paper. I am very glad to see that the authors at least made some effort in revising these overclaiming statements. For example, now the authors only claim that their solvers outperform decimation-only solvers for random k-SAT instances in the abstract, instead of saying outperforming all solvers.  There are still a few places that I am going to bring authors\u00e2\u0080\u0099 attention. In particular, the authors should not make an implication that their method is analogous to streamlining random constraints in model counting, as in [2, 3, 14]. Agreed with reviewer 2 from UAI 2017, I think the contexts are entirely different, and the counting approaches in [2, 3, 14] simply cannot work with very short constraints, such as length-2 constraints used in this paper. I really think the authors should revise their statements in the third paragraph of the introduction.   Once this paper is converted to NIPS style, Figure 2 becomes way too small. Please enlarge the fonts in Figure 2. In addition, below are my detailed comments from UAI 2017.  On the technical side, there are a few directions that are not explored as much as would be ideal. First, the streamlining clauses are added based on the two most polarized variables. As an alternative, we can define a slightly different message passing algorithm which computes the marginal of the disjunction of all pairwise variables. Then we add streamlining constraints based on the pairwise marginal, instead of selecting the two most polarized variables assuming the independence. Will this be a better method?  The algorithmic design choices of section 3.3 could have been motivated more clearly. In particular, it would be interesting to plot how different choices affect the performance. Secondly, the constraints are just added to a single solver which is treated like a black box. To make the case of generality for the method, it would be preferable to use more solvers or have a metric of success that doesn\u00e2\u0080\u0099t depend on the selected black-box solver.   There are also a few presentation details that should be addressed. In section 3.3 the reader is directed to a theorem 1 which does not exist, I assume that it is supposed to be proposition 1. It is assumed that the three rows of figure 3 related to the same run - that could however be made clearer in the caption. In the introduction, only very recent work related to the phase transition of k-SAT is referred to. It would be good to cite several original publications. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_969_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The article proposes a method for adding streamlining constraints in the survey propagation procedure, which improves its performance on random k-SAT problems.", "In line with classicalsurvey propagation, they use a message passing procedure to compute approximate marginal However instead of using the marginalto set single variables in the decimation process as previously done in survey propagation, the authors propose to add constraints based upon multiple variables.", "Iterating this procedure, more highly constrained problems are produced, which can then be solved by a downstream solver.", "The authors show that this idea improved upon a state-of-the-art survey propagation solver.", "The article is well written, presents a novel and effective idea that I expect to see used in future SAT-competitions.", "While perhaps needed for the target audience of NIPS, I personaly find the background secion where previous alorithms are presented a bit too long.", "A substantialpart of the paper is dedicated to the background that the reader could have easily been directed to by citations.", "I have reviewed this paper at UAI 2017, I voted for acceptance at that time, and I am still leaning towards accepting this paper.", "One reviewer at UAI 2017 raised highly vald points, which is that incorrect and highly imprecise claims are made in severalparts of the paper.", "I am very glad to see that the authors at least made some effort in revising these overclaiming statements.", "For example, now the authors only claim that their solvers outperform decimation-only solvers for random k-SAT instances in the abstract, instead of saying outperforming al solvers.", "There are still a few places that I am going to bring authors\u00e2\u0080\u0099 attention.", "In particular, the authors should not make an implication that their method is analgous to streamlining random constraints in model counting, as in [2, 3, 14].", "Agreed with reviewer 2 from UAI 2017, I think the contexts are entirely different, and the counting approaches in [2, 3, 14] simply cannot work with very short constraints, such as length-2 constraints used in this paper.", "I realy think the authors should revise their statements in the third paragraph of the introduction.", "Once this paper is converted to NIPS style, figre 2 becomes way too smal.", "Please enlarge the fonts in figre 2, In addition, below are my detailed comments from UAI 2017, On the technicalside, there are a few directions that are not explored as much as would be ideal First, the streamlining clauses are added based on the two most polarized variables.", "As an alernative, we can define a slightly different message passing alorithm which computes the marginalof the disjunction of al pairwise variables.", "Then we add streamlining constraints based on the pairwise marginal instead of selecting the two most polarized variables assuming the independence.", "Will this be a better method?", "The alorithmic design choices of secion 3 3 could have been motivated more clearly.", "In particular, it would be interesting to plot how different choices affect the performance.", "secndly, the constraints are just added to a single solver which is treated like a black box.", "To make the case of generalty for the method, it would be preferable to use more solvers or have a metric of success that doesn\u00e2\u0080\u0099t depend on the selected black-box solver.", "There are alo a few presentation details that should be addressed.", "In secion 3 3 the reader is directed to a theorem 1 which does not exist, I assume that it is supposed to be proposition 1, It is assumed that the three rows of figre 3 related to the same run - that could however be made clearer in the caption.", "In the introduction, only very recent work related to the phase transition of k-SAT is referred to.", "It would be good to cite severaloriginalpublications."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_969_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_965_3", "review_text": "Summary ------- This paper presents a framework which makes use of manifold learning to add structure into sparse coding models. By adding a manifold structure in the space of the space of the dictionary atoms, it permits to represent each data points with sparser coding signals as the dictionary can be adapted to the specific data point inside the manifold. This idea is combined in section 3 with a temporal regularization for the learned representation which ensure that the sparse code in a video are not changing too fast.   Overall assessment -----------------  Overall, while this paper takes a pedagogical approach to the general concepts of sparse coding and manifold learning, it lacks of proper formalism. The objects in equation (1) to (5) are not defined at all. The spaces in which x, phi, alpha and other variables are defined are not given, making it very hard to follow in the following. Also, the notion of manifold embedding, central in this work is never properly explained. This let the reader guess what are each variable.  Moreover, the evaluation of this technique is weak, as only qualitative results are shown on limited dataset (20x20 video with a 100 frames). Also, the reconstructed video displayed in the one used to learn the model. More extensive evaluation of this technique is needed, on larger video and with more quantitative results.   Questions --------- - Eq(2-3): If I get it correctly, phi_data =x? - Could you clarify the difference between the phi_LM and the P_LM? - Figure1: If I understand correctly, k should be f in the legend to match the text? -l140: I don't see where the sparsity intervene in section2.1. Could you clarify? -Figure3: The obtain representation beta in figure3B is dense. Isn't your goal to derive a \"sparse\" transform?  Typos and nitpicks ------------------ -l40/43: need citations -l110: a m-dimensional manifold in which space? -l111: a generalized eigenvalue decomposition of what? -l227: 'affinity groupe'  Post-rebuttal comments --------------  I have carefully read your rebuttal and the other reviewer comments.  Overall, I agree that the idea is interesting and novel but this paper intention is to bring together manifold learning and sparse coding and I think it lacks pedagogy to do so. It is very vague, as also stated by R1 and as the different spaces are not clearly stated, it is hard to perceive which object is a vector or a function and in which dimension. Personally, I find it really confusing and hard to follow. The rebuttal does not seem to acknowledge this as stated with \"Sparse coding is pretty standard stuff\" and \"the notion of manifold embedding is pretty clear in the manifold learning literature\" and does not clarify the concepts questioned by R1. I am also confused at the fact that the transform is looking for h-sparse function, which are not expected to be sparse according to the rebuttal.  I still recommend rejection, but mainly based on the narrative aspect of the paper. It might be biased by my lack of knowledge in manifold learning but I think the pedagogical part is very important for such a novel approach. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_965_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary ------- This paper presents a framework which makes use of manifold learning to add structure into sparse coding models.", "By adding a manifold structure in the space of the space of the dictionary atoms, it permits to represent each data points with sparser coding signal as the dictionary can be adapted to the specific data point inside the manifold.", "This idea is combined in secion 3 with a temporalregularization for the learned representation which ensure that the sparse code in a video are not changing too fast.", "Overal assessment ----------------- Overal, while this paper takes a pedagogicalapproach to the generalconcepts of sparse coding and manifold learning, it lacks of proper formalsm.", "The objects in eqation (1) to (5) are not defined at al.", "The spaces in which x, phi, alha and other variables are defined are not given, making it very hard to follow in the following.", "Also, the notion of manifold embedding, centralin this work is never properly explained.", "This let the reader guess what are each variable.", "Moreover, the evalation of this technique is weak, as only qualtative results are shown on limited dataset (20x20 video with a 100 frames).", "Also, the reconstructed video displayed in the one used to learn the model.", "More extensive evalation of this technique is needed, on larger video and with more quantitative results.", "Questions --------- - eq2-3): If I get it correctly, phi_data =x?", "- Could you clarify the difference between the phi_LM and the P_LM?", "- figre1: If I understand correctly, k should be f in the legend to match the text?", "-l140: I don't see where the sparsity intervene in secion2.1, Could you clarify?", "-figre3: The obtain representation beta in figre3B is dense.", "Isn't your goalto derive a \"sparse\" transform?", "Typos and nitpicks ------------------ -l40/43: need citations -l110: a m-dimensionalmanifold in which space?", "-l111: a generalzed eigenvale decomposition of what?", "-l227: 'affinity groupe' Post-rebuttalcomments -------------- I have carefully read your rebuttaland the other reviewer comments.", "Overal, I agree that the idea is interesting and novel but this paper intention is to bring together manifold learning and sparse coding and I think it lacks pedagogy to do so.", "It is very vague, as alo stated by R1 and as the different spaces are not clearly stated, it is hard to perceive which object is a vector or a function and in which dimension.", "Personaly, I find it realy confusing and hard to follow.", "The rebuttaldoes not seem to acknowledge this as stated with \"Sparse coding is pretty standard stuff\" and \"the notion of manifold embedding is pretty clear in the manifold learning literature\" and does not clarify the concepts questioned by R1, I am alo confused at the fact that the transform is looking for h-sparse function, which are not expected to be sparse according to the rebuttal I still recommend rejection, but mainly based on the narrative aspect of the paper.", "It might be biased by my lack of knowledge in manifold learning but I think the pedagogicalpart is very important for such a novel approach."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_965_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_959_2", "review_text": "-- Paper Summary   This paper tackles the problem of identifying patterns in spiking population activity of neurons by considering latent structure and trajectories. This is a particularly challenging problem due to potential time misalignment between multiple trials. Additionally, the various time series are generally assumed to be independent while there are also issues with tractability due to linear algebraic operations involving a TxT kernel matrix. This work tackles the latter issue by introducing the sparse variational approximation within the GPFA model, and addresses shared latent structure across trials (or even partitions of trials) by exploiting a nested GP architecture.   -- Originality + Significance  The variational sparse approximation to Gaussian process inference has become the go-to approach for solving tractability issues with GPs without compromising on performance. Although the approximation in itself has been used and applied extensively in other papers, to the best of my knowledge, this paper is the first in applying it to the GPFA model in particular.  In combination with the point process likelihood being considered, the resulting model is sufficiently different from existing approximate models based on sparse VI while also incorporating additional elements (explored in Section 4 of the paper).  A recent paper discussing simultaneous modelling of data and temporal alignment, \u00e2\u0080\u0098Gaussian Process Latent Variable Alignment Learning (Kazlauskaite et al)\u00e2\u0080\u0099, seems to be related in terms of scope. In fact, the generalisation to GPLVMs is listed in the concluding remarks of the paper under review. Although there is a clear distinction between the two papers, particularly with regards to the likelihood considered, any similarity to this work should be duly discussed.  It might be interesting to draw a connection to papers such as \u00e2\u0080\u0098Collaborative Multi-output Gaussian processes (Nguyen & Bonilla)\u00e2\u0080\u0099, where inducing points are shared across multiple latent functions. It is not clear whether the inducing points considered in this paper are unique to each latent function or shared between them, although I believe it\u00e2\u0080\u0099s the former. If not, this could possibly contribute towards further improving scalability.   -- Quality  The model is clearly detailed in Sections 3 and 4. As highlighted earlier, the sparse variational approximation is fairly standard; however, the authors do not limit themselves to the base approximation, but also consider several extensions which make the paper more complete and well-rounded.   Once all aspects of the model are described, I encourage the authors to summarise the overall complexity of the model with regards to how many trials, conditions, time points etc are considered in a given experiment.   -- Writing and Clarity  The paper is very well-written and a pleasure to read - I did not spot any typos while reading it. The figures are well-captioned and easy to interpret. Corresponding discussion of the figures in the text is also appropriate.  Some minor comments: - While the \u00e2\u0080\u0098macaque\u00e2\u0080\u0099 species might be well-known in the biology domain, I would suggest adding a footnote or small parenthesis explaining the term first. It is currently introduced in L57 without much context. - Similarly, it would be good to explain what is \u00e2\u0080\u0098innovations noise\u00e2\u0080\u0099 (L198)  - \u00e2\u0080\u0098Where\u00e2\u0080\u0099 in L121 could be changed to lower case  The content provided in the supplementary material complements the main text with more detailed proofs and figures. I found the balance between the two to be just right.   -- Overall Recommendation  This is a well-written paper with clearly established goals that are both individually and jointly investigated in this paper.  The contributions themselves are fairly modest and application-specific; nonetheless, state-of-the-art results are obtained in the problem setting being investigated, while the majority of the modelling choices are sufficiently general to be of interest to the broader NIPS community.  ------------  -- Post-review  Thank you for replying to my queries, in particular for expanding on the relation of this work to the indicated papers and detailing the overall complexity of the method. I believe that incorporating this discussion into the main paper (along with other minor fixes) will only elevate what is already a very good piece of work!", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_959_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["-- Paper Summary This paper tackles the problem of identifying patterns in spiking population activity of neurons by considering latent structure and trajectories.", "This is a particularly chalenging problem due to potentialtime misalgnment between multiple trial.", "Additionaly, the various time series are generaly assumed to be independent while there are alo issues with tractability due to linear alebraic operations involving a TxT kernel matrix.", "This work tackles the latter issue by introducing the sparse variationalapproximation within the GPFA model, and addresses shared latent structure across trial (or even partitions of trial) by exploiting a nested GP architecture.", "-- Originalty + Significance The variationalsparse approximation to Gaussian process inference has become the go-to approach for solving tractability issues with GPs without compromising on performance.", "Although the approximation in itself has been used and applied extensively in other papers, to the best of my knowledge, this paper is the first in applying it to the GPFA model in particular.", "In combination with the point process likelihood being considered, the resulting model is sufficiently different from existing approximate models based on sparse VI while alo incorporating additionalelements (explored in secion 4 of the paper).", "A recent paper discussing simultaneous modelling of data and temporalalgnment, \u00e2\u0080\u0098Gaussian Process Latent Variable Alignment Learning (Kazlauskaite et al\u00e2\u0080\u0099, seems to be related in terms of scope.", "In fact, the generalsation to GPLVMs is listed in the concluding remarks of the paper under review.", "Although there is a clear distinction between the two papers, particularly with regards to the likelihood considered, any similarity to this work should be duly discussed.", "It might be interesting to draw a connection to papers such as \u00e2\u0080\u0098Collaborative Multi-output Gaussian processes (Nguyen & Bonilla)\u00e2\u0080\u0099, where inducing points are shared across multiple latent functions.", "It is not clear whether the inducing points considered in this paper are unique to each latent function or shared between them, alhough I believe it\u00e2\u0080\u0099s the former.", "If not, this could possibly contribute towards further improving scalbility.", "-- Qualty The model is clearly detailed in secions 3 and 4, As highlighted earlier, the sparse variationalapproximation is fairly standard; however, the authors do not limit themselves to the base approximation, but alo consider severalextensions which make the paper more complete and well-rounded.", "Once al aspects of the model are described, I encourage the authors to summarise the overal complexity of the model with regards to how many trial, conditions, time points etcare considered in a given experiment.", "-- Writing and Clarity The paper is very well-written and a pleasure to read - I did not spot any typos while reading it.", "The figres are well-captioned and easy to interpret.", "Corresponding discussion of the figres in the text is alo appropriate.", "Some minor comments: - While the \u00e2\u0080\u0098macaque\u00e2\u0080\u0099 species might be well-known in the biology domain, I would suggest adding a footnote or smal parenthesis explaining the term first.", "It is currently introduced in L57 without much context.", "- Similarly, it would be good to explain what is \u00e2\u0080\u0098innovations noise\u00e2\u0080\u0099 (L198) - \u00e2\u0080\u0098Where\u00e2\u0080\u0099 in L121 could be changed to lower case The content provided in the supplementary materialcomplements the main text with more detailed proofs and figres.", "I found the balnce between the two to be just right.", "-- Overal Recommendation This is a well-written paper with clearly established goal that are both individualy and jointly investigated in this paper.", "The contributions themselves are fairly modest and application-specific; nonetheless, state-of-the-art results are obtained in the problem setting being investigated, while the majority of the modelling choices are sufficiently generalto be of interest to the broader NIPS community.", "------------ -- Post-review Thank you for replying to my queries, in particular for expanding on the relation of this work to the indicated papers and detailing the overal complexity of the method.", "I believe that incorporating this discussion into the main paper (alng with other minor fixes) will only elevate what is aleady a very good piece of work!"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_959_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_956_3", "review_text": "Given the author's additional information about their plans to open-source the language described in this paper, I've upgrade my review. I'm still concerned that the original paper didn't mention anything about this intent to open-source; but I'm willing to give them the benefit of the doubt because if this is open-sourced, it could be very helpful to the community.  Here are some minor typos I found: Capitalize \u00e2\u0080\u009cequation\u00e2\u0080\u009d, \u00e2\u0080\u009ctable\u00e2\u0080\u009d, \u00e2\u0080\u009csection\u00e2\u0080\u009d as needed throughout the paper. Line 112: \u00e2\u0080\u009cpleasant\u00e2\u0080\u009d to \u00e2\u0080\u009cpleasantly\u00e2\u0080\u009d (and throughout the paper where needed) 219: \u00e2\u0080\u009ctpu\u00e2\u0080\u009d to \u00e2\u0080\u009cTPU\u00e2\u0080\u009d 222: \u00e2\u0080\u009c(3)\u00e2\u0080\u009d to \u00e2\u0080\u009cTable 3\u00e2\u0080\u009d  ORIGINAL REVIEW This paper introduces a convenient notation for compactly describing mappings from a tensor representation of a learning problem\u00e2\u0080\u0099s data and model parameters to an n-dimensional mesh of compute nodes.  The notation is flexible enough to capture both data-parallel and model-parallel mappings, as well as mixtures of the two. The paper uses these mappings to derive first order approximations to the computation and communication times required to perform a single backpropagation update (assuming an optimized communication library like MPI).  The paper then uses these estimates to develop a strategy for simultaneously growing the model size and the number of compute nodes used such that communication does not become a major performance bottleneck.  The paper then uses this strategy to explore the parallel performance of the Transformer sequence transduction model.  The strategy allowed the authors to train a 5B parameter system on 256 nodes and get state-of-the-art performance on the WMT14 En-Fr data set.  When I first read this paper, I thought that the authors meant that they had created a new programming language for easily and efficiently mapping machine learning problems to parallel computer nodes.  I was hoping that this \u00e2\u0080\u009clanguage\u00e2\u0080\u009d would be made available to the reader and that it would include some automatic optimization of the mappings; but as I read more of the paper, I realized that the paper only presented a notation for representing the mapping.  If a new programming  language (or tool) has been created, the authors should make that more clear and maybe give pointers to it.  If it is only a notational convenience, the authors should make that more clear too.  If the contribution of Section 4 is only to introduce a notational convenience, the authors should explain the significance more clearly and/or concretely.  For example, the notation in Algorithm 1 is simply Einstein Summation Notation in another form.  It doesn\u00e2\u0080\u0099t add significantly to the reader\u00e2\u0080\u0099s understanding of the problem.  Furthermore, the observations made in Table 1 are fairly well-known from a parallel computing point of view - most practitioners realize this computation/communication trade off.  And for those NIPS readers who don\u00e2\u0080\u0099t, the paper has no explanation for where these numbers come from.  The paper could be improved if Section 4 was much shorter and the authors spent time explaining how they calculated the terms in Table 1. It seems that the major result of this paper is a better BLEU score from the ability to run a bigger model.  I\u00e2\u0080\u0099m not sure that is significant enough.  The paper would benefit from clarification in several places.  For example, \u00e2\u0080\u009cb\u00e2\u0080\u009d, \u00e2\u0080\u009cd_x\u00e2\u0080\u009d and \u00e2\u0080\u009cd_y\u00e2\u0080\u009d are never explicitly defined.  Equation (3a) is described and then never used again in the paper.  The paper\u00e2\u0080\u0099s \u00e2\u0080\u009c{b-->0}\u00e2\u0080\u009d notation is never explicitly defined.  Presumable \u00e2\u0080\u009c0\u00e2\u0080\u009d means dimension zero of the compute mesh; but it would be better it the authors specifically said it so that the reader doesn\u00e2\u0080\u0099t have to guess.  Likewise, \u00e2\u0080\u009cF\u00e2\u0080\u009d and \u00e2\u0080\u009cD(X,M)\u00e2\u0080\u009d are never defined.  (I know \u00e2\u0080\u009cF\u00e2\u0080\u009d is an arbitrary function, but the paper should say that instead of making the reader guess.) Also, for example, when two model dimensions map to a single mesh dimension, does that mean the mesh dimension is split 50/50?  It could be split based on some communication minimization, or other, algorithm.  The reader has to guess.  The text mentions four layouts but only shows three in Table 1.  In Table 3, why are two of the BLEU scores missing?  Was it that they couldn\u00e2\u0080\u0099t run?  Ran too slow? Wasn\u00e2\u0080\u0099t enough time? That should be explain.  In Section 5, the reader would benefit from some pictures showing, for example, the matrix multiplication, etc., to help them \u00e2\u0080\u009csee\u00e2\u0080\u009d the mapping.  \u00e2\u0080\u009cSOTA\u00e2\u0080\u009d should be replaced with \u00e2\u0080\u009cstate-of-the-art\u00e2\u0080\u009d throughout the paper.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_956_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Given the author's additionalinformation about their plans to open-source the language described in this paper, I've upgrade my review.", "I'm still concerned that the originalpaper didn't mention anything about this intent to open-source; but I'm willing to give them the benefit of the doubt because if this is open-sourced, it could be very helpful to the community.", "Here are some minor typos I found: Capitalze \u00e2\u0080\u009ceqation\u00e2\u0080\u009d, \u00e2\u0080\u009ctable\u00e2\u0080\u009d, \u00e2\u0080\u009csecion\u00e2\u0080\u009d as needed throughout the paper.", "Line 112: \u00e2\u0080\u009cpleasant\u00e2\u0080\u009d to \u00e2\u0080\u009cpleasantly\u00e2\u0080\u009d (and throughout the paper where needed) 219: \u00e2\u0080\u009ctpu\u00e2\u0080\u009d to \u00e2\u0080\u009cTPU\u00e2\u0080\u009d 222: \u00e2\u0080\u009c(3)\u00e2\u0080\u009d to \u00e2\u0080\u009cTable 3\u00e2\u0080\u009d ORIGINAL REVIEW This paper introduces a convenient notation for compactly describing mappings from a tensor representation of a learning problem\u00e2\u0080\u0099s data and model parameters to an n-dimensionalmesh of compute nodes.", "The notation is flexible enough to capture both data-paralel and model-paralel mappings, as well as mixtures of the two.", "The paper uses these mappings to derive first order approximations to the computation and communication times reqired to perform a single backpropagation update (assuming an optimized communication library like MPI).", "The paper then uses these estimates to develop a strategy for simultaneously growing the model size and the number of compute nodes used such that communication does not become a major performance bottleneck.", "The paper then uses this strategy to explore the paralel performance of the Transformer seqence transduction model.", "The strategy alowed the authors to train a 5B parameter system on 256 nodes and get state-of-the-art performance on the WMT14 En-Fr data set.", "When I first read this paper, I thought that the authors meant that they had created a new programming language for easily and efficiently mapping machine learning problems to paralel computer nodes.", "I was hoping that this \u00e2\u0080\u009clanguage\u00e2\u0080\u009d would be made available to the reader and that it would include some automatic optimization of the mappings; but as I read more of the paper, I realzed that the paper only presented a notation for representing the mapping.", "If a new programming language (or tool) has been created, the authors should make that more clear and maybe give pointers to it.", "If it is only a notationalconvenience, the authors should make that more clear too.", "If the contribution of secion 4 is only to introduce a notationalconvenience, the authors should explain the significance more clearly and/or concretely.", "For example, the notation in Algorithm 1 is simply Einstein Summation Notation in another form.", "It doesn\u00e2\u0080\u0099t add significantly to the reader\u00e2\u0080\u0099s understanding of the problem.", "Furthermore, the observations made in Table 1 are fairly well-known from a paralel computing point of view - most practitioners realze this computation/communication trade off.", "And for those NIPS readers who don\u00e2\u0080\u0099t, the paper has no explanation for where these numbers come from.", "The paper could be improved if secion 4 was much shorter and the authors spent time explaining how they calulated the terms in Table 1, It seems that the major result of this paper is a better BLEU score from the ability to run a bigger model.", "I\u00e2\u0080\u0099m not sure that is significant enough.", "The paper would benefit from clarification in severalplaces.", "For example, \u00e2\u0080\u009cb\u00e2\u0080\u009d, \u00e2\u0080\u009cd_x\u00e2\u0080\u009d and \u00e2\u0080\u009cd_y\u00e2\u0080\u009d are never explicitly defined.", "eqation (3a) is described and then never used again in the paper.", "The paper\u00e2\u0080\u0099s \u00e2\u0080\u009c{b-->0}\u00e2\u0080\u009d notation is never explicitly defined.", "Presumable \u00e2\u0080\u009c0\u00e2\u0080\u009d means dimension zero of the compute mesh; but it would be better it the authors specificaly said it so that the reader doesn\u00e2\u0080\u0099t have to guess.", "Likewise, \u00e2\u0080\u009cF\u00e2\u0080\u009d and \u00e2\u0080\u009cD(X,M)\u00e2\u0080\u009d are never defined.", "(I know \u00e2\u0080\u009cF\u00e2\u0080\u009d is an arbitrary function, but the paper should say that instead of making the reader guess.)", "Also, for example, when two model dimensions map to a single mesh dimension, does that mean the mesh dimension is split 50/50?", "It could be split based on some communication minimization, or other, alorithm.", "The reader has to guess.", "The text mentions four layouts but only shows three in Table 1, In Table 3, why are two of the BLEU scores missing?", "Was it that they couldn\u00e2\u0080\u0099t run?", "Ran too slow?", "Wasn\u00e2\u0080\u0099t enough time?", "That should be explain.", "In secion 5, the reader would benefit from some pictures showing, for example, the matrix multiplication, etc, to help them \u00e2\u0080\u009csee\u00e2\u0080\u009d the mapping.", "\u00e2\u0080\u009cSOTA\u00e2\u0080\u009d should be replaced with \u00e2\u0080\u009cstate-of-the-art\u00e2\u0080\u009d throughout the paper."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_956_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_954_3", "review_text": "This is a well written paper that addresses the problem of inserting new objects into an image at plausible locations and scales. The proposed method uses a semantic map to learn so-called \"where\" and \"what\" models. The models are not particularly novel, employing conditional GANs but it is interesting how they work together as well as the introduction of the spatial transformer network.  The main weaknesses that the paper does not address the issue of photometric consistency (unless this is somehow automatically handled by the GANs). For example, how does the model ensure that the correct lighting, shading and shadows are produced? The second weakness is that the model is only tested on the cityscapes dataset, which appears to be relatively simple for this task in that the scenes are relatively constrained and the camera viewpoint is fixed. Nevertheless, the paper does not overstate its contribution claiming to \"take a first step to address the [...] problem.\" ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_954_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["This is a well written paper that addresses the problem of inserting new objects into an image at plausible locations and scals.", "The proposed method uses a semantic map to learn so-caled \"where\" and \"what\" models.", "The models are not particularly novel, employing conditionalGANs but it is interesting how they work together as well as the introduction of the spatialtransformer network.", "The main weaknesses that the paper does not address the issue of photometric consistency (unless this is somehow automaticaly handled by the GANs).", "For example, how does the model ensure that the correct lighting, shading and shadows are produced?", "The secnd weakness is that the model is only tested on the cityscapes dataset, which appears to be relatively simple for this task in that the scenes are relatively constrained and the camera viewpoint is fixed.", "Nevertheless, the paper does not overstate its contribution claiming to \"take a first step to address the [...] problem.\""], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_954_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_954_1", "review_text": "The paper is concentrated in a new task in which we want to model the placement of object given its semantics and context.  The proposed method disentangles the generation process of possible positions and possible shapes, which is certainly a plus.  STN serves as a bottleneck between two modules and made the whole network end-to-end trainable.   At the same time, there are some issues in the current submission:  1. Missing training details The model consists of two generators and four discriminators.  To be honest, I'm doubtful about the training procedure itself, especially no specific details given, such as whether there is mode-dropping or not.  2. Missing qualitative evaluation Even though it's imaginable that for this new task, no direct qualitative metrics could be applied,  this part is a big minus to the convincibility of the proposed method for its audience.  3. Missing ablation study The paper also misses a solid qualitative ablation study.  As is, there might be some visual differences between the presented design and ablated design in Fig. 5.  But the differences are minor and not clear enough to be considered as non-trivial improvement or necessity, especially given a very condense and bulky network architecture.  Overall, this is a paper on the right problem but w/o convincing deliberation of design or qualitative results. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_954_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper is concentrated in a new task in which we want to model the placement of object given its semantics and context.", "The proposed method disentangles the generation process of possible positions and possible shapes, which is certainly a plus.", "STN serves as a bottleneck between two modules and made the whole network end-to-end trainable.", "At the same time, there are some issues in the current submission: 1, Missing training details The model consists of two generators and four discriminators.", "To be honest, I'm doubtful about the training procedure itself, especialy no specific details given, such as whether there is mode-dropping or not.", "2, Missing qualtative evalation Even though it's imaginable that for this new task, no direct qualtative metrics could be applied, this part is a big minus to the convincibility of the proposed method for its audience.", "3, Missing ablation study The paper alo misses a solid qualtative ablation study.", "As is, there might be some visualdifferences between the presented design and ablated design in fig 5, But the differences are minor and not clear enough to be considered as non-trivialimprovement or necessity, especialy given a very condense and bulky network architecture.", "Overal, this is a paper on the right problem but w/o convincing deliberation of design or qualtative results."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_954_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_953_1", "review_text": "This paper proposes a convolutional network architecture where filters are defined as a linear combination of steerable kernel basis functions, such that the network is equivariant to rigid body motions.  The paper's strength lie in the novelty of the proposed method for constructing equivariant filter banks from radial basis functions, as well as a novel equivariant nonlinearity.  Unfortunately, the paper has a number of weaknesses that must be addressed for it to be acceptable for publication. First, the related work section should be expanded, since, although the paper cites many papers in the beginning, the section does not sufficiently explain the state of the field, contributions of prior works, and how the proposed method fits in and contributes upon them. Additionally, I suggest the authors reword their sentence on line 45 regarding the timing of a concurrent work, since it should not be a focus of this section.  Secondly, I feel that section 3, which contains the main contributions of this paper, needs significant editing in order to be more clear, concise, and accessible to readers. I feel that certain more obvious preliminaries have been presented in an overly complicated way, introducing terminology that's inconsistent with previous works, or elaborating on the obvious while hurrying over the more complex material. For example, subsections 3.1 and 3.2 especially could be much shorter and to the point since they present very basic and well known fundamentals, whereas 3.3.1 and 3.4 could be explained with more detail and organization. In addition to this issue, while the authors explain properties of fields, transformations, equivariance, or how SO(3) can be decomposed, they do not do enough to tell the story of why these points are important to their overall problem. I would suggest that the authors try to write these sections so that readers can clearly understand the motivations that lead to each next step in the paper, and in such a way that the material is well grounded and more intuitively linked to their problem application.  The authors also often explain particular choices, such as their novel equivariant nonlinearity, or precomputation details, without sufficiently explaining the alternatives or justifying the underlying reason for their decision. Sure, the proposed nonlinearity satisfies their desired criteria, but the authors should explain why and how they arrived at that nonlinearity among the many possible solutions. And what are it's advantages or disadvantages? Did the authors try alternative nonlinearities, which did not perform well in practice? This would be good to know, and similar questions would hold for other implementation details in the paper.  Third, and most importantly, the experimental section of this paper is severely lacking. The first two experiments presented in 4.1 and 4.2 are not extensive or even analyzed in much detail, one experiment showing 100% accuracy on a toy dataset compared to a baseline which by construction will not perform well, and the other showing a modest improvement from 56% to 58% accuracy over a previous method. The authors themselves downplay the importance of these two experiments (e.g. line 268 - 269). This would be fine if followed by a stronger section, but for their third experiment they present an entrirely new dataset (the proposal and design of a new dataset could be an entire section in of itself with more rigorous presentation of the data properties and statistics) and compare against a single baseline and no other methods. The authors show that their method has heigher test accuracy on the new dataset than the baseline with much fewer parameters, but it's not obvious to me that fewer parameters is actually a disadvantage for this new dataset. It's very possible that the baseline is overly expressive for the amount of data available, and even simpler baselines might be more convincing. Most importantly though, the authors should have experiments that compare with contemporary methods to show the proposed methods strengths and weaknesses, as well as more extensive experiments showing the performance of their method under different implementation details.  Overall, the authors presented an interesting new SE(3) equivariant convolutional network, but they need to first strengthen and focus their experimental section, and second work on the presentation and clarity of their method in section 3. Finally, I encourage the authors to elaborate on how their method relates to other recent works, and clearly emphasize the broader significance of their contributions.  -------------------------------------------------------------------- After reading the rebuttal, I would first like to thank the authors for their efforts to address all of the concerns raised in the initial review.  In particular, the described changes and additions to the experimental section have addressed my primary concerns with the original manuscript. The addition of arbitrary rotations to the Tetris experiment, the ShapeNet/Shrec17 experiment, clarifications of other experimental details, and the promised availability of code and dataset tools greatly strengthen the submission. I also appreciate the additional figure illustrating the effect of the number of parameters on performance. It demonstrates the authors' claims are substantiated by thorough experiments,  and also shows interesting details, i.e. the rough order of magnitude of parameters at which the 3D CNN achieves diminishing returns in performance is around 10^5 vs 10^7, which otherwise would not have been known to the reader.  Aside from the experimental section, I thank the authors for expanding their related works section and for their considerations in making the presentation of their method more accessible, and detailing their design decisions. I still think that the authors should take special care to choose accessible terminology, to not invoke complexity for its own sake, and to give appropriate attention to their various preliminaries. I understand that the authors' terminology is consistent with prior works [4] and [6], however I would still argue that the terminology used, even in those works, is not accessible to a broad audience.  For example, readers familiar with spatial transformer networks, capsules, or problems of 2D and 3D point correspondence more generally, may already have a good intuition for transformations of vector fields, but would find terms like \"fiber\" unfamiliar and unnecessary. Please consider that [4] and [6] are only a sample of the field, and that related works such as Tensor Field Networks [24] use different terminology and cite other related bodies of work, such as PointNet. So, if the authors truly wish to address a broader audience, I would recommend that they consider readers from such perspectives.   Overall, I feel that the authors have addressed many of the concerns raised with the paper's presentation and accessibility. Most importantly, they have strengthened their experimental section significantly, and based on these changes I would now vote for accepting this submission.  Updated Score: 7", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_953_1", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["This paper proposes a convolutionalnetwork architecture where filters are defined as a linear combination of steerable kernel basis functions, such that the network is eqivariant to rigid body motions.", "The paper's strength lie in the novelty of the proposed method for constructing eqivariant filter banks from radialbasis functions, as well as a novel eqivariant nonlinearity.", "Unfortunately, the paper has a number of weaknesses that must be addressed for it to be acceptable for publication.", "First, the related work secion should be expanded, since, alhough the paper cites many papers in the beginning, the secion does not sufficiently explain the state of the field, contributions of prior works, and how the proposed method fits in and contributes upon them.", "Additionaly, I suggest the authors reword their sentence on line 45 regarding the timing of a concurrent work, since it should not be a focus of this secion.", "secndly, I feel that secion 3, which contains the main contributions of this paper, needs significant editing in order to be more clear, concise, and accessible to readers.", "I feel that certain more obvious preliminaries have been presented in an overly complicated way, introducing terminology that's inconsistent with previous works, or elaborating on the obvious while hurrying over the more complex material For example, subsecions 3 1 and 3 2 especialy could be much shorter and to the point since they present very basic and well known fundamental, whereas 3 3 1 and 3 4 could be explained with more detail and organization.", "In addition to this issue, while the authors explain properties of fields, transformations, eqivariance, or how SO(3) can be decomposed, they do not do enough to tell the story of why these points are important to their overal problem.", "I would suggest that the authors try to write these secions so that readers can clearly understand the motivations that lead to each next step in the paper, and in such a way that the materialis well grounded and more intuitively linked to their problem application.", "The authors alo often explain particular choices, such as their novel eqivariant nonlinearity, or precomputation details, without sufficiently explaining the alernatives or justifying the underlying reason for their decision.", "Sure, the proposed nonlinearity satisfies their desired criteria, but the authors should explain why and how they arrived at that nonlinearity among the many possible solutions.", "And what are it's advantages or disadvantages?", "Did the authors try alernative nonlinearities, which did not perform well in practice?", "This would be good to know, and similar questions would hold for other implementation details in the paper.", "Third, and most importantly, the experimentalsecion of this paper is severely lacking.", "The first two experiments presented in 4 1 and 4 2 are not extensive or even analzed in much detail, one experiment showing 100% accuracy on a toy dataset compared to a baseline which by construction will not perform well, and the other showing a modest improvement from 56% to 58% accuracy over a previous method.", "The authors themselves downplay the importance of these two experiments (e g line 268 - 269).", "This would be fine if followed by a stronger secion, but for their third experiment they present an entrirely new dataset (the proposaland design of a new dataset could be an entire secion in of itself with more rigorous presentation of the data properties and statistics) and compare against a single baseline and no other methods.", "The authors show that their method has heigher test accuracy on the new dataset than the baseline with much fewer parameters, but it's not obvious to me that fewer parameters is actualy a disadvantage for this new dataset.", "It's very possible that the baseline is overly expressive for the amount of data available, and even simpler baselines might be more convincing.", "Most importantly though, the authors should have experiments that compare with contemporary methods to show the proposed methods strengths and weaknesses, as well as more extensive experiments showing the performance of their method under different implementation details.", "Overal, the authors presented an interesting new SE(3) eqivariant convolutionalnetwork, but they need to first strengthen and focus their experimentalsecion, and secnd work on the presentation and clarity of their method in secion 3, Finaly, I encourage the authors to elaborate on how their method relates to other recent works, and clearly emphasize the broader significance of their contributions.", "-------------------------------------------------------------------- After reading the rebuttal I would first like to thank the authors for their efforts to address al of the concerns raised in the initialreview.", "In particular, the described changes and additions to the experimentalsecion have addressed my primary concerns with the originalmanuscript.", "The addition of arbitrary rotations to the Tetris experiment, the ShapeNet/Shrec17 experiment, clarifications of other experimentaldetails, and the promised availability of code and dataset tools greatly strengthen the submission.", "I alo appreciate the additionalfigre illustrating the effect of the number of parameters on performance.", "It demonstrates the authors' claims are substantiated by thorough experiments, and alo shows interesting details, i e the rough order of magnitude of parameters at which the 3D CNN achieves diminishing returns in performance is around 10^5 vs 10^7, which otherwise would not have been known to the reader.", "Aside from the experimentalsecion, I thank the authors for expanding their related works secion and for their considerations in making the presentation of their method more accessible, and detailing their design decisions.", "I still think that the authors should take specialcare to choose accessible terminology, to not invoke complexity for its own sake, and to give appropriate attention to their various preliminaries.", "I understand that the authors' terminology is consistent with prior works [4] and [6], however I would still argue that the terminology used, even in those works, is not accessible to a broad audience.", "For example, readers familiar with spatialtransformer networks, capsules, or problems of 2D and 3D point correspondence more generaly, may aleady have a good intuition for transformations of vector fields, but would find terms like \"fiber\" unfamiliar and unnecessary.", "Please consider that [4] and [6] are only a sample of the field, and that related works such as Tensor Field Networks [24] use different terminology and cite other related bodies of work, such as PointNet.", "So, if the authors truly wish to address a broader audience, I would recommend that they consider readers from such perspectives.", "Overal, I feel that the authors have addressed many of the concerns raised with the paper's presentation and accessibility.", "Most importantly, they have strengthened their experimentalsecion significantly, and based on these changes I would now vote for accepting this submission.", "Updated Score: 7"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_953_1", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_94_1", "review_text": "This paper presents an elegant method of zero-shot recognition based on transductive domain-invariant projection learning over both seen and unseen classes. Main theoretical contributions are: (1) the idea of introducing self-reconstruction constraint for unseen classes data as well as seen ones (the third term in eq.1), (2) derivation of an efficient optimization algorithm for this min-min problem, and (3) introducing superclasses to better align two domains. The proposed DIPL method is shown to significantly outperform previous state-of-the-arts on many ZSL tasks.  Strengths: 1. The basic formulation (eq.1) is conceptually simple and reasonable, making the overall method beautiful and general. I think the idea can be useful in many related areas of few-resource learning.  2. The optimization algorithm to handle the transductive constraint (the third term in eq.1) is non-trivial and elegantly derived, resulting in a linear time complexity with respect to the data size which is practical in real situations.  3. Experiments are well-organized and convincing enough to prove the effectiveness of each technical contribution of the method. Particularly, transductive constraint is shown to significantly improve the overall performance. Proposed method is shown to consistently outperforms previous methods on various ZSL tasks.  Weaknesses: 1. It sounds unfair to say \u00e2\u0080\u0098only two free parameters\u00e2\u0080\u0099 (l. 248) considering another parameter beta is set to 0.01 empirically (l. 167). Considering that beta=lambda/(1+gamma), it should be also data dependent.  UPDATES: My score remains still. I think it's a good paper.  Sections 3.3 and 3.4 are bit dense and unfriendly, so maybe it would be a good idea to move some of them to supplementary. Also, the paper would be more perfect if authors the results on ImageNet and SUN are reported in the main content. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_94_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper presents an elegant method of zero-shot recognition based on transductive domain-invariant projection learning over both seen and unseen classes.", "Main theoreticalcontributions are: (1) the idea of introducing self-reconstruction constraint for unseen classes data as well as seen ones (the third term in eq1), (2) derivation of an efficient optimization alorithm for this min-min problem, and (3) introducing superclasses to better algn two domains.", "The proposed DIPL method is shown to significantly outperform previous state-of-the-arts on many ZSL tasks.", "Strengths: 1, The basic formulation (eq1) is conceptualy simple and reasonable, making the overal method beautiful and general I think the idea can be useful in many related areas of few-resource learning.", "2, The optimization alorithm to handle the transductive constraint (the third term in eq1) is non-trivialand elegantly derived, resulting in a linear time complexity with respect to the data size which is practicalin realsituations.", "3, Experiments are well-organized and convincing enough to prove the effectiveness of each technicalcontribution of the method.", "Particularly, transductive constraint is shown to significantly improve the overal performance.", "Proposed method is shown to consistently outperforms previous methods on various ZSL tasks.", "Weaknesses: 1, It sounds unfair to say \u00e2\u0080\u0098only two free parameters\u00e2\u0080\u0099 (l 248) considering another parameter beta is set to 0 01 empiricaly (l 167).", "Considering that beta=lambda/(1+gamma), it should be alo data dependent.", "UPDATES: My score remains still.", "I think it's a good paper.", "secions 3 3 and 3 4 are bit dense and unfriendly, so maybe it would be a good idea to move some of them to supplementary.", "Also, the paper would be more perfect if authors the results on ImageNet and SUN are reported in the main content."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_94_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_932_2", "review_text": "Content:   This submission introduces a new framework for compressing neural networks. The main concept is to define the \"synaptic strength\" of the connection between an input layer and an output feature to the the product of the norms of the kernel of the input layer and the norm of the input layer. A large synaptic strength indicates that a certain input feature plays a substantial role in computing the output feature.  The synaptic strength is incorporated into the training procedure by the means of an additional penalty term that encourages a sparse distribution of synaptic strengths. After training all connections with synaptic strength smaller than some threshold are fixed to zero and the network is finetuned.  The authors apply their method to different networks on CIFAR (including VGG, ReseNet and DenseNet) and ImageNet (ResNet-50) and show good performance (in terms of accuracy and number of remaining parameters and computations). They also look into how the sparsity after training affects accuracy.   Quality:  The idea of synaptic strength appears intriguing. I like especially the idea of pruning whole connections between input channels and output layers instead of individual weights and it's very interesing to see in which layers most pruning is happening (Figure 3 left).  I have some minor issues with the derivations in section 3.2: * eq (1): shouln't the bias be b^{i+1}_k instead of b_{i+1}_c, i.e. the each output feature (k) has a certain bias, not the input channels (c). The same should be the case for the final summand b_c in eq. (3)-(5). * In eq (3)-(5): the convolution and adding of the bias should happen inside the nonlinearity f, not after applying the nonlinearity. Maybe there are just some parantheses missing? * going from eq (3) to eq (4), the factor gamma is moved from inside the nonlinearity outside of it. This works for nonlinearities like relu and prelu (as long as gamma is positive!), but it won't work for other nonlinearities like sigmoids. This condition should be clarified.  The results reported in the paper show that the method manages to decrease the number of parameters while keeping good performance. One other quite recent method that I would like to see compared to in this paper is Louizos et al, \"Learning Sparse Neural Networks through L_0 Regularization\", ICLR 2018 which reports a performance of less than 4% on CIFAR 10 with WideResNets (compared to 5% in this submission with ResNet).  One of the reasons why I would like to see this comparison is that Loizos et al report that besides compressing the network, their method also serves as a regularization method that can improve generalization and I'm wondering whether the same might hold for the proposed method in this submission. Table 1 suggests that might be the case for VGG and ResNet-18 on CIFAR10 but not on ImageNet (Table 2).  Also I'm wondering how strong the dependence on the regularization parameter lambda is. How where the used parameters choosen and how much do the results differ if a different parameter is used?  The bold numbers in Table 3 indicate that the ResNet-50 version of the submission has with 5.9M parameters the smallest number of remaining parameters, however, 3 out of the 4 comparison models in the table have even less parameters.  What exactly is the sparsity in Figure 4 (a) and (b)? The parameter lambda? The threshold tau? Something else? Why did the authors not finetune in the ablation study? If the difference would go away after finetuning, this would change the result of the ablation study, right?   Clarity:  There are some details missing: What was the threshold for pruning connections?  The captions of tables 2 and 4 are not indicating which dataset they are using (ImageNet if I'm not mistaken).  Please have your submission proof-read for English style and grammar issues.   Originality:  The authors make an interesting contribution to the wide field of compressing neural networks. For me the main contribution is to make the connection between a single input feature and a single output feature the target of the compression. I'm not aware that this has been done before -- but my knowledge of this field is like not complete.  The authors compare to some other compression techniques but are missing on some recent state-of-the-art methods that show really good performance (see above for one example)  Significance:  Compressing DNNs is a very important topic for bringing deep learning into everyday applications. The concept of synaptic strength is an very interesting contribution to that field. To help convincing other researchers of this method, I would like to see more comparison with state-of-the art and other potential applications of the method like regularization.  Minor comments: In the caption of Figure 1, \"left\" and \"right\" are switched.   Update after the rebuttal:  The authors addressed most of my questions and concerns. With the promised changes incorporated I think the paper will be a better contribution and therefore I am happy to increase my rating from 6 to 7.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_932_2", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["Content: This submission introduces a new framework for compressing neuralnetworks.", "The main concept is to define the \"synaptic strength\" of the connection between an input layer and an output feature to the the product of the norms of the kernel of the input layer and the norm of the input layer.", "A large synaptic strength indicates that a certain input feature plays a substantialrole in computing the output feature.", "The synaptic strength is incorporated into the training procedure by the means of an additionalpenaly term that encourages a sparse distribution of synaptic strengths.", "After training al connections with synaptic strength smaler than some threshold are fixed to zero and the network is finetuned.", "The authors apply their method to different networks on CIFAR (including VGG, ReseNet and DenseNet) and ImageNet (ResNet-50) and show good performance (in terms of accuracy and number of remaining parameters and computations).", "They alo look into how the sparsity after training affects accuracy.", "Qualty: The idea of synaptic strength appears intriguing.", "I like especialy the idea of pruning whole connections between input channels and output layers instead of individualweights and it's very interesing to see in which layers most pruning is happening (figre 3 left).", "I have some minor issues with the derivations in secion 3 2: * eq(1): shouln't the bias be b^{i+1}_k instead of b_{i+1}_c, i e the each output feature (k) has a certain bias, not the input channels (c).", "The same should be the case for the finalsummand b_c in eq (3)-(5).", "* In eq(3)-(5): the convolution and adding of the bias should happen inside the nonlinearity f, not after applying the nonlinearity.", "Maybe there are just some parantheses missing?", "* going from eq(3) to eq(4), the factor gamma is moved from inside the nonlinearity outside of it.", "This works for nonlinearities like relu and prelu (as long as gamma is positive!", "), but it won't work for other nonlinearities like sigmoids.", "This condition should be clarified.", "The results reported in the paper show that the method manages to decrease the number of parameters while keeping good performance.", "One other quite recent method that I would like to see compared to in this paper is Louizos et al \"Learning Sparse NeuralNetworks through L_0 Regularization\", ICLR 2018 which reports a performance of less than 4% on CIFAR 10 with WideResNets (compared to 5% in this submission with ResNet).", "One of the reasons why I would like to see this comparison is that Loizos et alreport that besides compressing the network, their method alo serves as a regularization method that can improve generalzation and I'm wondering whether the same might hold for the proposed method in this submission.", "Table 1 suggests that might be the case for VGG and ResNet-18 on CIFAR10 but not on ImageNet (Table 2).", "Also I'm wondering how strong the dependence on the regularization parameter lambda is.", "How where the used parameters choosen and how much do the results differ if a different parameter is used?", "The bold numbers in Table 3 indicate that the ResNet-50 version of the submission has with 5 9M parameters the smalest number of remaining parameters, however, 3 out of the 4 comparison models in the table have even less parameters.", "What exactly is the sparsity in figre 4 (a) and (b)?", "The parameter lambda?", "The threshold tau?", "Something else?", "Why did the authors not finetune in the ablation study?", "If the difference would go away after finetuning, this would change the result of the ablation study, right?", "Clarity: There are some details missing: What was the threshold for pruning connections?", "The captions of tables 2 and 4 are not indicating which dataset they are using (ImageNet if I'm not mistaken).", "Please have your submission proof-read for English style and grammar issues.", "Originalty: The authors make an interesting contribution to the wide field of compressing neuralnetworks.", "For me the main contribution is to make the connection between a single input feature and a single output feature the target of the compression.", "I'm not aware that this has been done before -- but my knowledge of this field is like not complete.", "The authors compare to some other compression techniques but are missing on some recent state-of-the-art methods that show realy good performance (see above for one example) Significance: Compressing DNNs is a very important topic for bringing deep learning into everyday applications.", "The concept of synaptic strength is an very interesting contribution to that field.", "To help convincing other researchers of this method, I would like to see more comparison with state-of-the art and other potentialapplications of the method like regularization.", "Minor comments: In the caption of figre 1, \"left\" and \"right\" are switched.", "Update after the rebuttal The authors addressed most of my questions and concerns.", "With the promised changes incorporated I think the paper will be a better contribution and therefore I am happy to increase my rating from 6 to 7"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_932_2", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_92_1", "review_text": "MetaReg in a nutshell: This paper reinterprets and further develops few-shot meta-learning ideas for the  challenging domain generalization paradigm, using standard supervised benchmarks. The main contribution is the learning of a regularizer, as opposed to learning an initial set of parameters well \u00e2\u0080\u009cpositioned\u00e2\u0080\u009d for finetuning. Scores seem to be significantly improved in several cases, but I am not an expert.   Pros: - The paper goes beyond the original inspiration and adapts the approach to serve a substantially different problem. While in meta-learning the degree of similarity between problem instances is substantial, e.g. random subset of classes from ImageNet, dealing well with a multi-modal meta-training set, due to differences between source domains is interesting in itself. - Several practical issues are resolved such that the approach is less expensive and more accurate than baselines. - Several baselines are considered, but I cannot say for sure how strong they are since I am less familiar with the state-of-the-art. - Analysis shows graceful degradation with reduced amounts of data, which is particularly impressive.  Cons: - A substantial bit of the approach could be viewed as derivative if not enough explanation is given for why the miniImageNet task (for example) is not a good paradigm for testing \u00e2\u0080\u009cdomain generalization\u00e2\u0080\u009d as precisely defined in the paper, at the conceptual level. - Furthermore, even if the paradigms are clearly different conceptually, say by definition, it would be good to discuss at length if these conceptual differences are really well embodied by the benchmarks used in the two cases. If the answer is negative, then proposing improved benchmarks in both cases would be useful. - Is learning a regularizer better than MAML because the assumptions of MAML are broken by this different paradigm and the benchmark is sensitive enough to show this? Or simply applying MAML with the same tricks and care would yield similar results? For example MAML is model-agnostic, so it could very well be applied only to task-specific networks. Furthermore, MAML but with meta-optimized per-parameter learning rates (Meta-SGD) could also be argued to be (implicitly) learning to regularize.   Explanation of overall score: Quality: Well balanced paper with substantial experiments and some detailed analysis. Clarity: Haven\u00e2\u0080\u0099t had any difficulties. Originality: Ultimately I find it difficult to judge. Significance: Good scores on supervised benchmarks in a challenging paradigm are fine for research in that sub-field. It is not trivial to relate these results to few-shot meta-learning tasks. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_92_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["MetaReg in a nutshell: This paper reinterprets and further develops few-shot meta-learning ideas for the chalenging domain generalzation paradigm, using standard supervised benchmarks.", "The main contribution is the learning of a regularizer, as opposed to learning an initialset of parameters well \u00e2\u0080\u009cpositioned\u00e2\u0080\u009d for finetuning.", "Scores seem to be significantly improved in severalcases, but I am not an expert.", "Pros: - The paper goes beyond the originalinspiration and adapts the approach to serve a substantialy different problem.", "While in meta-learning the degree of similarity between problem instances is substantial e g random subset of classes from ImageNet, dealng well with a multi-modalmeta-training set, due to differences between source domains is interesting in itself.", "- Severalpracticalissues are resolved such that the approach is less expensive and more accurate than baselines.", "- Severalbaselines are considered, but I cannot say for sure how strong they are since I am less familiar with the state-of-the-art.", "- Analsis shows graceful degradation with reduced amounts of data, which is particularly impressive.", "Cons: - A substantialbit of the approach could be viewed as derivative if not enough explanation is given for why the miniImageNet task (for example) is not a good paradigm for testing \u00e2\u0080\u009cdomain generalzation\u00e2\u0080\u009d as precisely defined in the paper, at the conceptuallevel.", "- Furthermore, even if the paradigms are clearly different conceptualy, say by definition, it would be good to discuss at length if these conceptualdifferences are realy well embodied by the benchmarks used in the two cases.", "If the answer is negative, then proposing improved benchmarks in both cases would be useful.", "- Is learning a regularizer better than MAML because the assumptions of MAML are broken by this different paradigm and the benchmark is sensitive enough to show this?", "Or simply applying MAML with the same tricks and care would yield similar results?", "For example MAML is model-agnostic, so it could very well be applied only to task-specific networks.", "Furthermore, MAML but with meta-optimized per-parameter learning rates (Meta-SGD) could alo be argued to be (implicitly) learning to regularize.", "Explanation of overal score: Qualty: Well balnced paper with substantialexperiments and some detailed analsis.", "Clarity: Haven\u00e2\u0080\u0099t had any difficulties.", "Originalty: Ultimately I find it difficult to judge.", "Significance: Good scores on supervised benchmarks in a chalenging paradigm are fine for research in that sub-field.", "It is not trivialto relate these results to few-shot meta-learning tasks."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_92_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_922_1", "review_text": "The paper proposes an alternative objective function for the Laplacian k-modes problem (for simultaneous clustering and density estimation).  The proposed objective is a bound for the classical objective proposed in the past, which has a certain number of computational advantages. For example, the updates in the iterative algorithm can be done independently for every point and thus the algorithm can be easily parallelized.  I found the proposed bound/objective interesting and its computational advantages significant. The experimental results are convincing; it is particularly interesting that the proposed algorithm is producing solutions that are in fact better for the original laplacian k-modes objective that the algorithm designed for that objective.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_922_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper proposes an alernative objective function for the Laplacian k-modes problem (for simultaneous clustering and density estimation).", "The proposed objective is a bound for the classicalobjective proposed in the past, which has a certain number of computationaladvantages.", "For example, the updates in the iterative alorithm can be done independently for every point and thus the alorithm can be easily paralelized.", "I found the proposed bound/objective interesting and its computationaladvantages significant.", "The experimentalresults are convincing; it is particularly interesting that the proposed alorithm is producing solutions that are in fact better for the originallaplacian k-modes objective that the alorithm designed for that objective."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_922_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_916_3", "review_text": "The paper proposes combining Cross Entropy (CE) minimization with Proximal Policy Optimization (PPO) for optimizing placement decisions of operations in TensorFlow graphs across multiple devices. Results show faster and better optimization results than previous RL-based approach of Mirhoseini et al.  Strengths: - The paper is written very clearly and is easy to follow. - Algorithm seems to be simpler than that proposed by Mirhoseini et al. - The results are significantly better than Mirhoseini et al.  Weaknesses: - The evaluation is incomplete. The previous papers by Mirhoseini et al. unfortunately didn't compare against simple/trivial baseline algorithms like random search (try random placements and keep track of the best), hill climbing, genetic algorithms, etc. to show whether a learning approach outperforms them given the same computational budget and placement evaluation budget. This paper also doesn't address the shortcoming. So it's not at all clear whether placement optimization really requires any sophisticated optimization in the first place.  Comments/Questions: - Please include in the Appendix the type of graphs shown in Figure 2 for all the entries in Table 1. This way it will be clear that the same kind of behavior seen in the three graphs in Figure 2 hold for all the settings.  - Are the results in Table 1 strictly controlled for the same amount of computation and the same number of placement evaluations allowed to Policy Gradient and Post? The text does not say this. If they are not, then the results may not be meaningful.  - For many TensorFlow graphs for which placement optimization is difficult, a key challenge is to stay within the memory limits of the devices. So it may be difficult to find placements, especially early on in the optimization, that satisfy memory constraints. How is this problem handled by the proposed algorithm?  - TensorFlow graph running times can show high variance. What are the error bars for Figure 2 and Table 1?  - Is the algorithm that is labelled as Policy Gradient a re-implementation of the Mirhoseini et al.'s approach? If so, their work relied on grouping the ops and making group-level device placements, and how were the grouping decisions made?", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_916_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The paper proposes combining Cross Entropy (CE) minimization with ProximalPolicy Optimization (PPO) for optimizing placement decisions of operations in TensorFlow graphs across multiple devices.", "Results show faster and better optimization results than previous RL-based approach of Mirhoseini et al Strengths: - The paper is written very clearly and is easy to follow.", "- Algorithm seems to be simpler than that proposed by Mirhoseini et al - The results are significantly better than Mirhoseini et al Weaknesses: - The evalation is incomplete.", "The previous papers by Mirhoseini et al unfortunately didn't compare against simple/trivialbaseline alorithms like random search (try random placements and keep track of the best), hill climbing, genetic alorithms, etc to show whether a learning approach outperforms them given the same computationalbudget and placement evalation budget.", "This paper alo doesn't address the shortcoming.", "So it's not at al clear whether placement optimization realy reqires any sophisticated optimization in the first place.", "Comments/Questions: - Please include in the Appendix the type of graphs shown in figre 2 for al the entries in Table 1, This way it will be clear that the same kind of behavior seen in the three graphs in figre 2 hold for al the settings.", "- Are the results in Table 1 strictly controlled for the same amount of computation and the same number of placement evalations alowed to Policy Gradient and Post?", "The text does not say this.", "If they are not, then the results may not be meaningful.", "- For many TensorFlow graphs for which placement optimization is difficult, a key chalenge is to stay within the memory limits of the devices.", "So it may be difficult to find placements, especialy early on in the optimization, that satisfy memory constraints.", "How is this problem handled by the proposed alorithm?", "- TensorFlow graph running times can show high variance.", "What are the error bars for figre 2 and Table 1?", "- Is the alorithm that is labelled as Policy Gradient a re-implementation of the Mirhoseini et al's approach?", "If so, their work relied on grouping the ops and making group-level device placements, and how were the grouping decisions made?"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_916_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_910_1", "review_text": "This paper considers the problem of streaming stochastic optimization taking into account the arrival patterns of examples in time. Whereas the relevant previous work focuses on learning from a stream (i.e. in one pass over the data, with O(dimension) memory), this work attempts to utilize the time spent between the arrival of examples in order to revisit previously encountered examples.  The problem description is novel and appealing, both in its possible practical relevance and as an interesting new model for consideration in algorithm analysis. However, there are central issues with the comparisons that the paper draws between algorithms, both conceptually and experimentally.  Conceptually, it seems incorrect to say that STRSAGA is a streaming algorithm, and in turn in to repeatedly compare it to one (such as SSVRG), since STRSAGA's memory complexity actually grows linearly with the dataset size (in order to maintain its \"effective sample set\"). In all previous related work, a streaming algorithm essentially means one whose memory usage does not grow with the dataset size. This is exactly what distinguishes streaming algorithms from ERM-based algorithms. The latter maintain an empirical sample of points in memory, whereas the former cannot maintain more than a constant number of them.  Experimentally, the paper's main algorithm (STRSAGA) is missing some comparisons to natural baselines. Both DYNASAGA and SSVRG are not basic (nor widely used) algorithms. Meanwhile, a comparison to the simplest and most basic streaming algorithm, plain SGD, is missing.  Relating to baselines, the paper includes the introductory remark (line 74):  > We also show that STRSAGA significantly outperforms SSVRG [FGKS15], the state-of-the-art streaming data algorithm  The original SSVRG paper [FGKS15] offers no experiments, and I don't know of any published since. It's a theoretical result, being used here as an experimental baseline, as a means of demonstrating an empirical advantage. Because it isn't actually a commonly accepted state of the art in the practical sense, outperforming SSVRG in practice does not imply an improvement relative to the state of scientific knowledge. Again, the more obvious comparison here would be to plain one-pass SGD.  ----  Edited after author response:  The authors addressed the concern about experimental comparisons to SGD in their response. I suggest including this in the paper.  On the point of \"streaming\", here is a valid run of the algorithm:  Fix an integer k. Suppose there is a dataset of size 2k, and STRSAGA is run for steps 1, ..., k, where at each step it receives two subsequent data points from the dataset. After step k, STRSAGA has half of the original dataset stored in its effective sample set. Now suppose STRSAGA continues to run for T additional steps, receiving zero new points at each step. Then, during these T additional steps, STRSAGA processes that half of the original dataset that it had stored.  So STRSAGA's description includes, as a special case, an algorithm for minimizing empirical risk on half of a dataset, and this indicates that the paper needs work in its formal setup, not only in terminology. Maybe the right direction is to require a limit on memory, as reviewer 2 suggests as well.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_910_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper considers the problem of streaming stochastic optimization taking into account the arrivalpatterns of examples in time.", "Whereas the relevant previous work focuses on learning from a stream (i e in one pass over the data, with O(dimension) memory), this work attempts to utilize the time spent between the arrivalof examples in order to revisit previously encountered examples.", "The problem description is novel and appealng, both in its possible practicalrelevance and as an interesting new model for consideration in alorithm analsis.", "However, there are centralissues with the comparisons that the paper draws between alorithms, both conceptualy and experimentaly.", "Conceptualy, it seems incorrect to say that STRSAGA is a streaming alorithm, and in turn in to repeatedly compare it to one (such as SSVRG), since STRSAGA's memory complexity actualy grows linearly with the dataset size (in order to maintain its \"effective sample set\").", "In al previous related work, a streaming alorithm essentialy means one whose memory usage does not grow with the dataset size.", "This is exactly what distinguishes streaming alorithms from ERM-based alorithms.", "The latter maintain an empiricalsample of points in memory, whereas the former cannot maintain more than a constant number of them.", "Experimentaly, the paper's main alorithm (STRSAGA) is missing some comparisons to naturalbaselines.", "Both DYNASAGA and SSVRG are not basic (nor widely used) alorithms.", "Meanwhile, a comparison to the simplest and most basic streaming alorithm, plain SGD, is missing.", "Relating to baselines, the paper includes the introductory remark (line 74): > We alo show that STRSAGA significantly outperforms SSVRG [FGKS15], the state-of-the-art streaming data alorithm The originalSSVRG paper [FGKS15] offers no experiments, and I don't know of any published since.", "It's a theoreticalresult, being used here as an experimentalbaseline, as a means of demonstrating an empiricaladvantage.", "Because it isn't actualy a commonly accepted state of the art in the practicalsense, outperforming SSVRG in practice does not imply an improvement relative to the state of scientific knowledge.", "Again, the more obvious comparison here would be to plain one-pass SGD.", "---- Edited after author response: The authors addressed the concern about experimentalcomparisons to SGD in their response.", "I suggest including this in the paper.", "On the point of \"streaming\", here is a vald run of the alorithm: Fix an integer k Suppose there is a dataset of size 2k, and STRSAGA is run for steps 1, ..., k, where at each step it receives two subseqent data points from the dataset.", "After step k, STRSAGA has hal of the originaldataset stored in its effective sample set.", "Now suppose STRSAGA continues to run for T additionalsteps, receiving zero new points at each step.", "Then, during these T additionalsteps, STRSAGA processes that hal of the originaldataset that it had stored.", "So STRSAGA's description includes, as a specialcase, an alorithm for minimizing empiricalrisk on hal of a dataset, and this indicates that the paper needs work in its formalsetup, not only in terminology.", "Maybe the right direction is to reqire a limit on memory, as reviewer 2 suggests as well."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_910_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_909_2", "review_text": "I'm happy with the authors' feedback, and will hence keep my \"accept\" decision.  ==============================================================  [Summary] This paper studies Markov chain gradient descent (MCGD) algorithm(s), an extension of stochastic gradient descent (SGD) in which the random samples are taken following a Markov chain. Built upon existing analysis of MCGD in [1,5,6], the paper generalizes the convergence result in various ways, answering a few open questions. In particular, the paper extends the ergodic result to non-ergodic ones, removes necessity for reversibility of the underlying Markov chain, and is able to deal with non-convex settings. The paper also provides a novel analysis based on keeping track of varying levels of mixing time corresponding to progressively better mixing, which may also shed light on future work. The numerical part of this paper is only for illustrative purposes (as the algorithm is not new), but the comparison between MCGD and SGD-T is informative and provides a good start and motivation for a more thorough study of the theoretical aspects of the algorithm.  [Quality, originality and significance] The paper deals with a few challenging open problems in the analysis of MCGD. Previously, all analysis are done for convex objectives and reversible Markov chains. But non-reversible Markov chains can have much better mixing/convergence behavior both in theory and practice [14], and non-convex settings are of great practical importance in e.g. deep learning. The paper elegantly deals with these issues by introducing a new varying mixing time level analysis, without adding artificial assumptions.   [Clarity] The paper is generally very well-written. The authors make notable efforts in motivating the necessity and challenges of the analysis for non-reversible and non-convex settings. In particular, the explanation of the assumptions between lines 117-128 is rather clear and frank. The example between lines 22-28 is also very good and showcase the advantage of MCGD over SGD in such a scenario. Nevertheless, a few things (mostly typos and wording) can still be slightly improved. Firstly, it might be slightly better to also mention the general MCMC in the example between lines 22-28. It may also help the readers to understand if a more explicit explanation of how the examples between lines 29-33 is related to the stochastic programming setting (1) is given. There are a few slight typos and wording issues, the removing of which may improve readability: 1. line 7: wider of -> wider range of;  2. line 19: expansive -> expensive;  3. line 25: If -> Even if; 4. line 29: natural -> naturally; 5. line 91: SG4 -> SGD4; 6. line 123: slower -> lower; 7. line 125: non-differential -> non-differentiable; 8. line 230: for the -> due to. Another suggestion is that the authors can explicitly state which results correspond to ergodic ones and which correspond to non-ergodic ones by e.g. directly stating that \u00e2\u0080\u009cThen we have the non-ergodic convergence\u00e2\u0080\u009d instead of just \u00e2\u0080\u009cThen we have\u00e2\u0080\u009d in line 193. This may help some readers who are not familiar with the definition of ergodicity in the optimization scenario to understand the results  [Some suggestions for improvement] Here I list a few things that I think can be further improved: 1. The example between lines 61-68 does not seem to guarantee a uniform stationary distribution for the Markov chain over the graph, and hence may not be completely consistent with (4). The authors may want to pay some attention to this potential issue. 2. It may help a lot if the authors can provide a non-reversible Markov chain for the numerical experiments (or just prove and state, if the example on page 3 is), and provide non-ergodic convergence curves. This will make the motivating example on page 3 even more inspiring, which will then illustrate the good performance of MCGD beyond ergodic convergence, reversible Markov chains, and convexity, which naturally ask for the new analysis proposed later in this paper. 3. The authors may want to either mention at the end of Section 1 or the beginning of Section 2 that the optimization problem in study for the finite state cases is always in the form of (4).   4. Give at least one sentence of explanation for the significance of obtaining non-ergodic convergence results, either in theory or in practice. Also explain the major hurdle of restricting to reversible Markov chains and convex objectives in the previous works. In particular, the authors may want to highlight the main idea of how varying mixing levels help solve the non-convexity and non-reversibility issue, and how it leads to non-ergodic results. 5. It looks a bit weird to add the reversibility assumption back in Section 5 when continuous state space is involved. The authors may want to make more explanations for this.  In general, this paper is well-written with insights and sufficient motivation, and it addresses a few challenging and open problems. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_909_2", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["I'm happy with the authors' feedback, and will hence keep my \"accept\" decision.", "============================================================== [Summary] This paper studies Markov chain gradient descent (MCGD) alorithm(s), an extension of stochastic gradient descent (SGD) in which the random samples are taken following a Markov chain.", "Built upon existing analsis of MCGD in [1,5,6], the paper generalzes the convergence result in various ways, answering a few open questions.", "In particular, the paper extends the ergodic result to non-ergodic ones, removes necessity for reversibility of the underlying Markov chain, and is able to dealwith non-convex settings.", "The paper alo provides a novel analsis based on keeping track of varying levels of mixing time corresponding to progressively better mixing, which may alo shed light on future work.", "The numericalpart of this paper is only for illustrative purposes (as the alorithm is not new), but the comparison between MCGD and SGD-T is informative and provides a good start and motivation for a more thorough study of the theoreticalaspects of the alorithm.", "[Qualty, originalty and significance] The paper deal with a few chalenging open problems in the analsis of MCGD.", "Previously, al analsis are done for convex objectives and reversible Markov chains.", "But non-reversible Markov chains can have much better mixing/convergence behavior both in theory and practice [14], and non-convex settings are of great practicalimportance in e g deep learning.", "The paper elegantly deal with these issues by introducing a new varying mixing time level analsis, without adding artificialassumptions.", "[Clarity] The paper is generaly very well-written.", "The authors make notable efforts in motivating the necessity and chalenges of the analsis for non-reversible and non-convex settings.", "In particular, the explanation of the assumptions between lines 117-128 is rather clear and frank.", "The example between lines 22-28 is alo very good and showcase the advantage of MCGD over SGD in such a scenario.", "Nevertheless, a few things (mostly typos and wording) can still be slightly improved.", "Firstly, it might be slightly better to alo mention the generalMCMC in the example between lines 22-28, It may alo help the readers to understand if a more explicit explanation of how the examples between lines 29-33 is related to the stochastic programming setting (1) is given.", "There are a few slight typos and wording issues, the removing of which may improve readability: 1, line 7: wider of -> wider range of; 2, line 19: expansive -> expensive; 3, line 25: If -> Even if; 4, line 29: natural-> naturaly; 5, line 91: SG4 -> SGD4; 6, line 123: slower -> lower; 7, line 125: non-differential-> non-differentiable; 8, line 230: for the -> due to.", "Another suggestion is that the authors can explicitly state which results correspond to ergodic ones and which correspond to non-ergodic ones by e g directly stating that \u00e2\u0080\u009cThen we have the non-ergodic convergence\u00e2\u0080\u009d instead of just \u00e2\u0080\u009cThen we have\u00e2\u0080\u009d in line 193, This may help some readers who are not familiar with the definition of ergodicity in the optimization scenario to understand the results [Some suggestions for improvement] Here I list a few things that I think can be further improved: 1, The example between lines 61-68 does not seem to guarantee a uniform stationary distribution for the Markov chain over the graph, and hence may not be completely consistent with (4).", "The authors may want to pay some attention to this potentialissue.", "2, It may help a lot if the authors can provide a non-reversible Markov chain for the numericalexperiments (or just prove and state, if the example on page 3 is), and provide non-ergodic convergence curves.", "This will make the motivating example on page 3 even more inspiring, which will then illustrate the good performance of MCGD beyond ergodic convergence, reversible Markov chains, and convexity, which naturaly ask for the new analsis proposed later in this paper.", "3, The authors may want to either mention at the end of secion 1 or the beginning of secion 2 that the optimization problem in study for the finite state cases is alays in the form of (4).", "4, Give at least one sentence of explanation for the significance of obtaining non-ergodic convergence results, either in theory or in practice.", "Also explain the major hurdle of restricting to reversible Markov chains and convex objectives in the previous works.", "In particular, the authors may want to highlight the main idea of how varying mixing levels help solve the non-convexity and non-reversibility issue, and how it leads to non-ergodic results.", "5, It looks a bit weird to add the reversibility assumption back in secion 5 when continuous state space is involved.", "The authors may want to make more explanations for this.", "In general this paper is well-written with insights and sufficient motivation, and it addresses a few chalenging and open problems."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_909_2", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_906_3", "review_text": "The authors propose a framework for modeling dynamic network cascade diffusion and contrast the approach in particular to InfoPath but also several more recent static network estimation procedures. The model is probabilistic and extends the work of Williams (ref 7) to cascade diffusion by learning the latent network structure solely based on the nodes observed contamination times within a cascade. The framework uses the partial observational framework discussed in ref 27 and inference of determinantal point processes as discussed in ref 28 in order to establish a distribution of plausible edges given the observed cascades. The MDMN model of ref 7 is then used as a latent representation of this unobserved network representation. The framework is extended to the modeling of dynamic networks considering a time interval w and updating the model at time t+1 using the model at time t as a starting point.   Quality: The manuscript is well written, the experimentation solid, and the approach well motivated improving upon current state-of-the-art of network quantification based on observed cascades.  Clarity: The manuscript is generally well written and well rooted in the existing literature. There are a few typos that should be corrected, i.e. \u00e2\u0080\u009cis the |Rk x Rk| is the restriction\u00e2\u0080\u00a6\u00e2\u0080\u009d -> \u00e2\u0080\u009cis the |Rk x Rk| restriction\u00e2\u0080\u00a6\u00e2\u0080\u009d \u00e2\u0080\u009cand and\u00e2\u0080\u009d -> \u00e2\u0080\u009cand\u00e2\u0080\u009d I would further recommend that the section \u00e2\u0080\u009cRelated Work\u00e2\u0080\u009d be integrated into the existing introduction as there are quite some overlaps between the introduction and related work section. In particular, remarks such as \u00e2\u0080\u009cOur work is different in nature to the existing methods in that we aim at providing a generative probabilistic  model for the underlying dynamic network from diffusion data.\u00e2\u0080\u009d and \u00e2\u0080\u009cHowever, these models assume that networks are fully observed. In contrast, our work here considers the network is unobserved but what we observe are node infection times of a stochastic cascading process spreading over the network.\u00e2\u0080\u009d These points are already remarked in the introduction also discussing some of the current state of the art. It could on related work also be worth mentioning probabilistic generative dynamic models assuming fully observed networks, see for instance as part of the related work Ishiguro, Katsuhiko, et al. \"Dynamic infinite relational model for time-varying relational data analysis.\" Advances in Neural Information Processing Systems. 2010.  Originality: The novelty of the paper is combining the use of latent network modeling based on the mixture of   Dirichlet network distributions (MDND) modeling framework ref 7 to operate not directly on an observed network but a latent network defined though cascades using results from ref. 27 and 28 in order to define a distribution over latent edges. In ref 7 the MDND was established as a competitive link-prediction framework and it is thus reasonable to use this as a starting point of latent variable modeling of the network structure. However, other competitive probabilistic link prediction modeling approaches choices could also have been relevant choices, such as:  Palla, Konstantina, David Knowles, and Zoubin Ghahramani. \"An infinite latent attribute model for network data.\" arXiv preprint arXiv:1206.6416 (2012). And within the framework of Fox and Carron the extension to modeling block structure Herlau, Tue, Mikkel N. Schmidt, and Morten M\u00c3\u00b8rup. \"Completely random measures for modelling block-structured sparse networks.\" Advances in Neural Information Processing Systems. 2016. It would improve the paper to discuss how the present framework extends to arbitrary generative models replacing the MDND with other choices of latent representations which would expand the scope of the present framework. That being said there are many merits of the MDND and this is a sound and strong starting point. Combining generative network models for modeling cascades is an interesting and useful novel contribution.  Significance: The proposed framework is a fine extension of the MDND framework to the modeling of network structure based on observed cascades and form a new and powerful tool for analyzing network dynamics. In particular, the experimental results emphasizes the utility of the proposed framework outperforming existing approaches while providing a nice probabilistic generative modeling framework for the extraction of dynamic network structure.  It is unclear to me why the network needs to be discretized in time segments w as the cascades are in continuous time. Furthermore, the dynamic modeling stemming from updating the model from previous timesteps seem a bit heuristic and to hinge on how much the sampling procedure changes the model across the time steps which in turn also reflect the ability of the sampler to properly mix and for how long the inference procedure is run (i.e., how many samples are drawn at each time step). It would improve the manuscript to clarify these aspects. It would also be good to include a discussion of the stability of the inferred parameters and thus reliability of the inference procedure. Furthermore, it would be good to clarify how the predictions are made, i.e. InfoPath rely on point estimates but the current procedure I assume is based on averaging samples. This should be clarified, and if averaging samples it would be good to also demonstrate what the performance of a corresponding point estimate (by highest likelihood sample) would provide to assess the merits of simply providing Bayesian averaging as compared to a more advanced MDND model.  I have read the authors rebuttal and find that they satisfactorily discuss the raised concerns. I argue for accepting this paper. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_906_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The authors propose a framework for modeling dynamic network cascade diffusion and contrast the approach in particular to InfoPath but alo severalmore recent static network estimation procedures.", "The model is probabilistic and extends the work of Williams (ref 7) to cascade diffusion by learning the latent network structure solely based on the nodes observed contamination times within a cascade.", "The framework uses the partialobservationalframework discussed in ref 27 and inference of determinantalpoint processes as discussed in ref 28 in order to establish a distribution of plausible edges given the observed cascades.", "The MDMN model of ref 7 is then used as a latent representation of this unobserved network representation.", "The framework is extended to the modeling of dynamic networks considering a time intervalw and updating the model at time t+1 using the model at time t as a starting point.", "Qualty: The manuscript is well written, the experimentation solid, and the approach well motivated improving upon current state-of-the-art of network quantification based on observed cascades.", "Clarity: The manuscript is generaly well written and well rooted in the existing literature.", "There are a few typos that should be corrected, i e \u00e2\u0080\u009cis the |Rk x Rk| is the restriction\u00e2\u0080\u00a6\u00e2\u0080\u009d -> \u00e2\u0080\u009cis the |Rk x Rk| restriction\u00e2\u0080\u00a6\u00e2\u0080\u009d \u00e2\u0080\u009cand and\u00e2\u0080\u009d -> \u00e2\u0080\u009cand\u00e2\u0080\u009d I would further recommend that the secion \u00e2\u0080\u009cRelated Work\u00e2\u0080\u009d be integrated into the existing introduction as there are quite some overlaps between the introduction and related work secion.", "In particular, remarks such as \u00e2\u0080\u009cOur work is different in nature to the existing methods in that we aim at providing a generative probabilistic model for the underlying dynamic network from diffusion data.\u00e2\u0080\u009d and \u00e2\u0080\u009cHowever, these models assume that networks are fully observed.", "In contrast, our work here considers the network is unobserved but what we observe are node infection times of a stochastic cascading process spreading over the network.\u00e2\u0080\u009d These points are aleady remarked in the introduction alo discussing some of the current state of the art.", "It could on related work alo be worth mentioning probabilistic generative dynamic models assuming fully observed networks, see for instance as part of the related work Ishiguro, Katsuhiko, et al \"Dynamic infinite relationalmodel for time-varying relationaldata analsis.\"", "Advances in NeuralInformation Processing Systems.", "2010, Originalty: The novelty of the paper is combining the use of latent network modeling based on the mixture of Dirichlet network distributions (MDND) modeling framework ref 7 to operate not directly on an observed network but a latent network defined though cascades using results from ref.", "27 and 28 in order to define a distribution over latent edges.", "In ref 7 the MDND was established as a competitive link-prediction framework and it is thus reasonable to use this as a starting point of latent variable modeling of the network structure.", "However, other competitive probabilistic link prediction modeling approaches choices could alo have been relevant choices, such as: Pala, Konstantina, David Knowles, and Zoubin Ghahramani.", "\"An infinite latent attribute model for network data.\"", "arXiv preprint arXiv:1206.6416 (2012).", "And within the framework of Fox and Carron the extension to modeling block structure Herlau, Tue, Mikkel N Schmidt, and Morten M\u00c3\u00b8rup.", "\"Completely random measures for modelling block-structured sparse networks.\"", "Advances in NeuralInformation Processing Systems.", "2016, It would improve the paper to discuss how the present framework extends to arbitrary generative models replacing the MDND with other choices of latent representations which would expand the scope of the present framework.", "That being said there are many merits of the MDND and this is a sound and strong starting point.", "Combining generative network models for modeling cascades is an interesting and useful novel contribution.", "Significance: The proposed framework is a fine extension of the MDND framework to the modeling of network structure based on observed cascades and form a new and powerful tool for analzing network dynamics.", "In particular, the experimentalresults emphasizes the utility of the proposed framework outperforming existing approaches while providing a nice probabilistic generative modeling framework for the extraction of dynamic network structure.", "It is unclear to me why the network needs to be discretized in time segments w as the cascades are in continuous time.", "Furthermore, the dynamic modeling stemming from updating the model from previous timesteps seem a bit heuristic and to hinge on how much the sampling procedure changes the model across the time steps which in turn alo reflect the ability of the sampler to properly mix and for how long the inference procedure is run (i e , how many samples are drawn at each time step).", "It would improve the manuscript to clarify these aspects.", "It would alo be good to include a discussion of the stability of the inferred parameters and thus reliability of the inference procedure.", "Furthermore, it would be good to clarify how the predictions are made, i e InfoPath rely on point estimates but the current procedure I assume is based on averaging samples.", "This should be clarified, and if averaging samples it would be good to alo demonstrate what the performance of a corresponding point estimate (by highest likelihood sample) would provide to assess the merits of simply providing Bayesian averaging as compared to a more advanced MDND model.", "I have read the authors rebuttaland find that they satisfactorily discuss the raised concerns.", "I argue for accepting this paper."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_906_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_906_2", "review_text": "The authors consider the problem of constructing generative models from partial observations. More specifically, they propose a generative model for networks where the observations consist of times when cascades spread over the network. In this setting, the observations lack information regarding the resulted edges. The goal is to infer the latent structure of the network over which the cascades propagated.   They propose a hierarchical non-parametric edge-exchangeable network model along with a inference framework, DYFERENCE.   I really enjoyed reading this work. The authors deal with a very interesting problem with possible real world applications. The proposed work is novel enough to my understanding. They do an excellent job presenting their idea in a coherent and scientifically deep fashion. The inference seems the most challenging part of the model but the proposed framework covers the difficult aspects of it.   More: The content appear to be correct regarding technical details. The submission is very clear and well organised. The experimental results are thorough and sufficiently prove the performance of the model.   Line 119: not sure how the integer valued weights are sampled here. Also, z_ij and d_uv in eq(3), why different term here?  All in all, I am eager to suggest acceptance. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_906_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["The authors consider the problem of constructing generative models from partialobservations.", "More specificaly, they propose a generative model for networks where the observations consist of times when cascades spread over the network.", "In this setting, the observations lack information regarding the resulted edges.", "The goalis to infer the latent structure of the network over which the cascades propagated.", "They propose a hierarchicalnon-parametric edge-exchangeable network model alng with a inference framework, DYFERENCE.", "I realy enjoyed reading this work.", "The authors dealwith a very interesting problem with possible realworld applications.", "The proposed work is novel enough to my understanding.", "They do an excellent job presenting their idea in a coherent and scientificaly deep fashion.", "The inference seems the most chalenging part of the model but the proposed framework covers the difficult aspects of it.", "More: The content appear to be correct regarding technicaldetails.", "The submission is very clear and well organised.", "The experimentalresults are thorough and sufficiently prove the performance of the model.", "Line 119: not sure how the integer valed weights are sampled here.", "Also, z_ij and d_uv in eq3), why different term here?", "All in al, I am eager to suggest acceptance."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_906_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_905_2", "review_text": "After rebutal; I do not wish to change my evaluation. Regarding convergence, I think that this should be clarified in the paper, to at least ensure that this is not producting divergent sequences under resaonable assumptions. As for the variance, the author control the variance of a certain variable \\hat{g} given g but they should control the variance of \\hat{g} without conditioning to invoke general convergence results. This is very minor but should be mentioned.      The authors consider the problem of empirical risk minimization using a distributed stochastic gradient descent algorithm. In this setting, communication cost constitutes a significant bottleneck. The authors generalize recently proposed scheme which aims at obtaining random sparse unbiased estimates of a vector while ensuring minimal variance. The authors describe an active set algorithm which allows to perform this operation given decomposition in an orthonormal basis. Extensive experiments based on low rank approximation of the gradient matrix suggest that the proposed approach allows to speedup convergence by reducing the communication cost.   Main comments I have very limited knowledge about distributed optimization, so I might miss some important points or shortcomings in the paper.  Overall the paper is well written and seems to reference correctly the corresponding litterature. The proposed algorithm is quite natural. I did not have a careful look at all proof details but I could not see anything which looked abnormal. I am not really able to criticize numerical experiments beyond the fact that they are convincing to me.  The overall mathematical exposition is quite elementary, some elements could be cut out, for example all the Lemmas related to algorithm 1 may not be necessary in the main text, this is actually a simple active set method. Another example is the notion of equivalence of norms and Theorem 10, this can be found in a first year analysis course and does not bring much to the paper. Lemma 8 is also well known.   The question of the convergence of this process is not touched. How does the sparsification affect convergence?  Why not comparing to ternGrad?    Minor comments  I am not quite sure about the relevance of the concept of \"atomic decomposition\". From definition 1, this is just decomposition in an orthonormal basis, which is a less fancy name but more standard as a mathematical concept.  In Theorem 5, what does $j = argmax$ mean in the second statement? Similarly what is \"i\" in the first statement. Logical quantifiers should be used here.  Figure 1, I would rather say top 2 values standing out  The constraint \"can be represented with k bits\" is not really meaningful. Any character string can be compressed to a single bit using the appropriate dictionary. May be the authors have in mind a specific representation or model.  \"In what follows, you may think of g as the stochastic gradient\" is not at the usual level of formality in scientific papers.  Line 203: we s and suppose  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_905_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["After rebutal I do not wish to change my evalation.", "Regarding convergence, I think that this should be clarified in the paper, to at least ensure that this is not producting divergent seqences under resaonable assumptions.", "As for the variance, the author control the variance of a certain variable \\hat{g} given g but they should control the variance of \\hat{g} without conditioning to invoke generalconvergence results.", "This is very minor but should be mentioned.", "The authors consider the problem of empiricalrisk minimization using a distributed stochastic gradient descent alorithm.", "In this setting, communication cost constitutes a significant bottleneck.", "The authors generalze recently proposed scheme which aims at obtaining random sparse unbiased estimates of a vector while ensuring minimalvariance.", "The authors describe an active set alorithm which alows to perform this operation given decomposition in an orthonormalbasis.", "Extensive experiments based on low rank approximation of the gradient matrix suggest that the proposed approach alows to speedup convergence by reducing the communication cost.", "Main comments I have very limited knowledge about distributed optimization, so I might miss some important points or shortcomings in the paper.", "Overal the paper is well written and seems to reference correctly the corresponding litterature.", "The proposed alorithm is quite natural I did not have a careful look at al proof details but I could not see anything which looked abnormal I am not realy able to criticize numericalexperiments beyond the fact that they are convincing to me.", "The overal mathematicalexposition is quite elementary, some elements could be cut out, for example al the Lemmas related to alorithm 1 may not be necessary in the main text, this is actualy a simple active set method.", "Another example is the notion of eqivalnce of norms and Theorem 10, this can be found in a first year analsis course and does not bring much to the paper.", "Lemma 8 is alo well known.", "The question of the convergence of this process is not touched.", "How does the sparsification affect convergence?", "Why not comparing to ternGrad?", "Minor comments I am not quite sure about the relevance of the concept of \"atomic decomposition\".", "From definition 1, this is just decomposition in an orthonormalbasis, which is a less fancy name but more standard as a mathematicalconcept.", "In Theorem 5, what does $j = argmax$ mean in the secnd statement?", "Similarly what is \"i\" in the first statement.", "Logicalquantifiers should be used here.", "figre 1, I would rather say top 2 vales standing out The constraint \"can be represented with k bits\" is not realy meaningful.", "Any character string can be compressed to a single bit using the appropriate dictionary.", "May be the authors have in mind a specific representation or model.", "\"In what follows, you may think of g as the stochastic gradient\" is not at the usuallevel of formalty in scientific papers.", "Line 203: we s and suppose"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_905_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_904_1", "review_text": "Many combinatorial optimization problems are only solvable exactly for small problem sizes, so various heuristics are used to find approximate solutions for larger problem sizes. Recently, there have been a number of attempts to use neural networks to learn these heuristics.  This work is focused on the vehicle routing problem, a generalization of the well-known traveling salesman problem and task of significant real world interest.  The solution explored in the paper is to use standard RL techniques (REINFORCE and A3C) with a slightly modified pointer net architecture. The modification is that the encoder is feedforward convolutional network rather than an RNN, meaning the network is invariant to the ordering of the input sequence.  The empirical results are quite impressive, they find that this approach is able to find solutions superior to that of well-known heuristics and a baseline library of heuristics in 100\\% of cases for the larger problem size (200 nodes).  This work is appropriately written and cites relevant prior work. The primary weakness of this work is that it may be of more limited significance. The prior work of Bello demonstrated that RL with pointer networks were capable of outperform OR Tools on the TSP problem. This work is a generalisation of that work (with a minor architectural changes).  There are two questions I have that would merit discussion in the paper.  - Bello et al. use active search (further RL training on a specific problem instance) in order to iteratively search for a better solution. Was this approach tried here / why was it not used here?  - How generalizable are the solutions learned for problems outside the training distribution. For example VRP100 on tasks of size 99 or 101? This seems like an important question for practical applications.  Minor issues: - Although possible rewards mentioned are the negative total vehicle distance or average service time, the reward function actually used is, as far as I could find, never explicitly stated.  - The policy is denoted as both $\\pi$ (standard RL notation) and, to emphasize the sequential structure $P(Y|X_0)$. This change seems distracting.  -- The author's response demonstrated some level of generalisation in problem size and explained why they are not using active search (although it would be nice to see this as a baseline). Given the generalisation results I've increased my rating.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_904_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Many combinatorialoptimization problems are only solvable exactly for smal problem sizes, so various heuristics are used to find approximate solutions for larger problem sizes.", "Recently, there have been a number of attempts to use neuralnetworks to learn these heuristics.", "This work is focused on the vehicle routing problem, a generalzation of the well-known traveling salsman problem and task of significant realworld interest.", "The solution explored in the paper is to use standard RL techniques (REINFORCE and A3C) with a slightly modified pointer net architecture.", "The modification is that the encoder is feedforward convolutionalnetwork rather than an RNN, meaning the network is invariant to the ordering of the input seqence.", "The empiricalresults are quite impressive, they find that this approach is able to find solutions superior to that of well-known heuristics and a baseline library of heuristics in 100\\% of cases for the larger problem size (200 nodes).", "This work is appropriately written and cites relevant prior work.", "The primary weakness of this work is that it may be of more limited significance.", "The prior work of Bello demonstrated that RL with pointer networks were capable of outperform OR Tools on the TSP problem.", "This work is a generalsation of that work (with a minor architecturalchanges).", "There are two questions I have that would merit discussion in the paper.", "- Bello et al use active search (further RL training on a specific problem instance) in order to iteratively search for a better solution.", "Was this approach tried here / why was it not used here?", "- How generalzable are the solutions learned for problems outside the training distribution.", "For example VRP100 on tasks of size 99 or 101?", "This seems like an important question for practicalapplications.", "Minor issues: - Although possible rewards mentioned are the negative totalvehicle distance or average service time, the reward function actualy used is, as far as I could find, never explicitly stated.", "- The policy is denoted as both $\\pi$ (standard RL notation) and, to emphasize the seqentialstructure $P(Y|X_0)$.", "This change seems distracting.", "-- The author's response demonstrated some level of generalsation in problem size and explained why they are not using active search (alhough it would be nice to see this as a baseline).", "Given the generalsation results I've increased my rating."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_904_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_900_2", "review_text": "This paper proposed convergence analysis for ADAM under certain parameter settings and proved the convergence to a stationary point for nonconvex problems. Moreover, the authors proposed an adaptive SGD (i.e., YOGI) and evaluated it on the different learning models.  Generally, the studied problem is interesting and the proposed algorithm demonstrated good performance on its testing problems. However, some important issues are not clearly stated in the current manuscript: 1. This paper has stated that YOGI controls the increase in effective learning rate, but it is not clear how it impacts the learning rate? 2. The proof of the convergence in ADAM only considered the case that $\\beta_1=0$. Thus it is also not very clear how about the convergence proof with the condition $\\beta_1\\in(0,1)$? 3. There are some types and improper presentations in Appendix. For example, in the first line of page 12, the update rule $v_t,i$ of YOGI does not match with the update rule in Algorithm 2. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_900_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["This paper proposed convergence analsis for ADAM under certain parameter settings and proved the convergence to a stationary point for nonconvex problems.", "Moreover, the authors proposed an adaptive SGD (i e , YOGI) and evalated it on the different learning models.", "Generaly, the studied problem is interesting and the proposed alorithm demonstrated good performance on its testing problems.", "However, some important issues are not clearly stated in the current manuscript: 1, This paper has stated that YOGI controls the increase in effective learning rate, but it is not clear how it impacts the learning rate?", "2, The proof of the convergence in ADAM only considered the case that $\\beta_1=0$.", "Thus it is alo not very clear how about the convergence proof with the condition $\\beta_1\\in(0,1)$?", "3, There are some types and improper presentations in Appendix.", "For example, in the first line of page 12, the update rule $v_t,i$ of YOGI does not match with the update rule in Algorithm 2,"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_900_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_881_2", "review_text": "This works explores a novel matching procedure between activations in neural networks, that can be used to determine whether two identical networks initialized from a different seed converge to the same intermediate representations. With a carful laid theory, a suitable and provably efficient algorithms and empirical experiments, the authors give non-trivial insights into the representations learned by networks. The authors establish in an eloquent and concise way the necessary concepts for their exact and approximately matching activations metric. I enjoyed both the convincing motivation given and the carful treatment all the way to a practical algorithm that can be easily used. I was, however, a bit disappointed from the empirical experiments. I feel that this work could benefit from a wider range of networks tested and variety of activations. By doing a more comprehensive comparison we might be able to learn how different architectures behave and get more practical insights which a currently a bit lacking to my taste.  Strengths - A novel approach with thorough survey on past attempts - Good theoretical and justifiable argument, with efficient algorithms - Interesting results regarding convolutional vs fully-connected layers  Weakness - Empirical results could benefit from a wider range of architectures and tasks (currently only VGG on cifar10). Some could argue that they are currently not convincing.  Edit: Following rebuttal, I've decided to update my review and recommend acceptance. I recommend that additional empirical results be referred to in main text.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_881_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This works explores a novel matching procedure between activations in neuralnetworks, that can be used to determine whether two identicalnetworks initialzed from a different seed converge to the same intermediate representations.", "With a carful laid theory, a suitable and provably efficient alorithms and empiricalexperiments, the authors give non-trivialinsights into the representations learned by networks.", "The authors establish in an eloquent and concise way the necessary concepts for their exact and approximately matching activations metric.", "I enjoyed both the convincing motivation given and the carful treatment al the way to a practicalalorithm that can be easily used.", "I was, however, a bit disappointed from the empiricalexperiments.", "I feel that this work could benefit from a wider range of networks tested and variety of activations.", "By doing a more comprehensive comparison we might be able to learn how different architectures behave and get more practicalinsights which a currently a bit lacking to my taste.", "Strengths - A novel approach with thorough survey on past attempts - Good theoreticaland justifiable argument, with efficient alorithms - Interesting results regarding convolutionalvs fully-connected layers Weakness - Empiricalresults could benefit from a wider range of architectures and tasks (currently only VGG on cifar10).", "Some could argue that they are currently not convincing.", "Edit: Following rebuttal I've decided to update my review and recommend acceptance.", "I recommend that additionalempiricalresults be referred to in main text."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_881_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_871_1", "review_text": " The authors study the problem of structure learning for Bayesian networks. The conventional methods for this task include the constraint-based methods or the score-based methods which involve optimizing a discrete score function over the set of DAGs with a combinatorial constraint. Unlike the existing approaches, the authors propose formulating the problem as a continuous optimization problem over real matrices, which performs a global search, and can be solved using standard numerical algorithms. The main idea in this work is using a smooth function for expressing an equality constraint to force acyclicity on the estimated structure. The paper is very well written and enjoyable to read. I have the following comments:  - Least-Squares loss is used in this work as the score function. It seems that the main reason for this choice is its desirability from the optimization point of view. I was wondering if there are any structure related guarantee when using this score function. For example, will the global optimum be in the Markov equivalence class of the ground truth DAG? Will we be able to detect the v-structures?, etc.  - Two restricting assumptions in this work are linearity and the assumption of full observability. Both of these assumptions are perfectly reasonable for this stage of the research, but I was wondering if the authors have examined their approach on models which are violating these assumptions? Specifically, in the case of non-linear SEM, how would be the output related to the ground truth DAG? Or more importantly, how essential is additive noise for the performance of Least-Squares loss?  - Augmented Lagrangian method is used for solving the equality-constrained program. My concern is that in this method, the penalty term may force some sparsity restrictions on the learned structure. This may prevent the proposed approach from working well for all desired levels of sparsity.  - The main technical tool in this work is the use of function h(.) for characterizing acyclicity. This characterization seems to be new in the literature, but it would be a more clarifying if the authors mention that the connection between the trace of the powers of the adjacency matrix and cycles in the corresponding graph was known in the literature (for example, Frank Harary, Bennet Manvel \"On the number of cycles in a graph,\" 1971).  My concern about the function h(.) is regarding property (b) of function: \"The values of h quantify the \u00e2\u0080\u009cDAG-ness\u00e2\u0080\u009d of the graph\". I am not sure how true this claim is: First of all, the value of h depends on the edge weights in the graph. Therefore, two graphs with exactly same structure but different weights will get different values for h(W). This gets more problematic as we can design a graph with more cycles, but smaller weights and end up getting a lower value for h compared to another graph with fewer cycles but larger weights.  - Another concern of mine regarding function h(.) is that it over counts the cycles: If there is just one loop (cycle of length 1) in the graph, its effect will appear in all powers of the adjacency matrix. Also, if there is a cycle of length 3 in the graph, it will cause a non-zero value for all of its three corresponding vertices on the diagonal of W^3. In line 422 in the supplementary materials, it is mentioned that tr(B+B^2+...) counts the number of cycles in B. Based on the aforementioned examples, can we say that this sentence is not necessarily true? A clarification in this regard would be appreciated.  - I suspect that for small values of coefficients, specifically, if all were less than 1, for example, w_{ij}~unif([0.1 0.5]) the error of the proposed method will increase. This is due to the fact that h(w) will be small and the algorithm may make more errors. It would be appreciated if the authors also examine their proposed method on such values.  - The simulations and experiments are sufficient and seem fair.   -----After author feedback:   I thank the authors for their responses. Based on the responses, I increase my score to 8. However, I still have concerns regarding the used score function, the properties of function h(.), and the performance on real data. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_871_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": [" The authors study the problem of structure learning for Bayesian networks.", "The conventionalmethods for this task include the constraint-based methods or the score-based methods which involve optimizing a discrete score function over the set of DAGs with a combinatorialconstraint.", "Unlike the existing approaches, the authors propose formulating the problem as a continuous optimization problem over realmatrices, which performs a globalsearch, and can be solved using standard numericalalorithms.", "The main idea in this work is using a smooth function for expressing an eqalty constraint to force acyclicity on the estimated structure.", "The paper is very well written and enjoyable to read.", "I have the following comments: - Least-Squares loss is used in this work as the score function.", "It seems that the main reason for this choice is its desirability from the optimization point of view.", "I was wondering if there are any structure related guarantee when using this score function.", "For example, will the globaloptimum be in the Markov eqivalnce class of the ground truth DAG?", "Will we be able to detect the v-structures?, etc - Two restricting assumptions in this work are linearity and the assumption of full observability.", "Both of these assumptions are perfectly reasonable for this stage of the research, but I was wondering if the authors have examined their approach on models which are violating these assumptions?", "Specificaly, in the case of non-linear SEM, how would be the output related to the ground truth DAG?", "Or more importantly, how essentialis additive noise for the performance of Least-Squares loss?", "- Augmented Lagrangian method is used for solving the eqalty-constrained program.", "My concern is that in this method, the penaly term may force some sparsity restrictions on the learned structure.", "This may prevent the proposed approach from working well for al desired levels of sparsity.", "- The main technicaltool in this work is the use of function h(.)", "for characterizing acyclicity.", "This characterization seems to be new in the literature, but it would be a more clarifying if the authors mention that the connection between the trace of the powers of the adjacency matrix and cycles in the corresponding graph was known in the literature (for example, Frank Harary, Bennet Manvel \"On the number of cycles in a graph,\" 1971).", "My concern about the function h(.)", "is regarding property (b) of function: \"The vales of h quantify the \u00e2\u0080\u009cDAG-ness\u00e2\u0080\u009d of the graph\".", "I am not sure how true this claim is: First of al, the vale of h depends on the edge weights in the graph.", "Therefore, two graphs with exactly same structure but different weights will get different vales for h(W).", "This gets more problematic as we can design a graph with more cycles, but smaler weights and end up getting a lower vale for h compared to another graph with fewer cycles but larger weights.", "- Another concern of mine regarding function h(.)", "is that it over counts the cycles: If there is just one loop (cycle of length 1) in the graph, its effect will appear in al powers of the adjacency matrix.", "Also, if there is a cycle of length 3 in the graph, it will cause a non-zero vale for al of its three corresponding vertices on the diagonalof W^3, In line 422 in the supplementary material, it is mentioned that tr(B+B^2+...) counts the number of cycles in B Based on the aforementioned examples, can we say that this sentence is not necessarily true?", "A clarification in this regard would be appreciated.", "- I suspect that for smal vales of coefficients, specificaly, if al were less than 1, for example, w_{ij}~unif([0 1 0 5]) the error of the proposed method will increase.", "This is due to the fact that h(w) will be smal and the alorithm may make more errors.", "It would be appreciated if the authors alo examine their proposed method on such vales.", "- The simulations and experiments are sufficient and seem fair.", "-----After author feedback: I thank the authors for their responses.", "Based on the responses, I increase my score to 8, However, I still have concerns regarding the used score function, the properties of function h(.", "), and the performance on realdata."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_871_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_867_3", "review_text": "Thanks for the rebuttal from the authors. I have read the rebuttal. I have adjusted my rating accordingly. =============== This paper addresses the challenge of causal inference under both interference and unmeasured confounding. A classical solution to interference is chain graph; a framework for unmeasured confounding is latent variable DAG. Hence, this work tries to bring together the two to develop latent variable chain graphs. It develops the identification conditions, provides estimation algorithm, and performs experiments.   The paper is nicely written and well motivated. The network example in the introduction is illuminating. The technical content of the paper is also self-contained, especially for reading unfamiliar with segregated projection. One place that could be elaborated is in ADMG. the condition for a double arrow to exist is rather abstract (and a bit hard to parse). Maybe more explanation on Fig. 1 could help.  However, the empirical studies is not convincing yet. The study contains one simulation of different network sizes. The estimates do not seem close to the ground truth values. the confidence intervals also do not contain the truth values. While the paper makes conceptual contribution, it is not yet clear how well the proposed method solve the problem.  Lastly, a few question of interest remains open here:  1. Does unmeasured confounding interact with network interference?   2. Does dependent data exhibit other complications than unmeasured confounding and interference?  3. Chain graphs are known to be computational expensive. Does unmeasured confounding worsen the situation? How expensive is the computation in the simulation studies?  4. This work requires community membership does not directly influence sharing, except as mediated by social network activity of the user. How restrictive is this condition? (Without this assumption, does it imply some form of interaction between unmeasured confounding and interference?)  5. How does dependent data move beyond interference? Does  the dependence exacerbate the unmeasured confounding issue? How?", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_867_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["Thanks for the rebuttalfrom the authors.", "I have read the rebuttal I have adjusted my rating accordingly.", "=============== This paper addresses the chalenge of causalinference under both interference and unmeasured confounding.", "A classicalsolution to interference is chain graph; a framework for unmeasured confounding is latent variable DAG.", "Hence, this work tries to bring together the two to develop latent variable chain graphs.", "It develops the identification conditions, provides estimation alorithm, and performs experiments.", "The paper is nicely written and well motivated.", "The network example in the introduction is illuminating.", "The technicalcontent of the paper is alo self-contained, especialy for reading unfamiliar with segregated projection.", "One place that could be elaborated is in ADMG.", "the condition for a double arrow to exist is rather abstract (and a bit hard to parse).", "Maybe more explanation on fig 1 could help.", "However, the empiricalstudies is not convincing yet.", "The study contains one simulation of different network sizes.", "The estimates do not seem close to the ground truth vales.", "the confidence interval alo do not contain the truth vales.", "While the paper makes conceptualcontribution, it is not yet clear how well the proposed method solve the problem.", "Lastly, a few question of interest remains open here: 1, Does unmeasured confounding interact with network interference?", "2, Does dependent data exhibit other complications than unmeasured confounding and interference?", "3, Chain graphs are known to be computationalexpensive.", "Does unmeasured confounding worsen the situation?", "How expensive is the computation in the simulation studies?", "4, This work reqires community membership does not directly influence sharing, except as mediated by socialnetwork activity of the user.", "How restrictive is this condition?", "(Without this assumption, does it imply some form of interaction between unmeasured confounding and interference?)", "5, How does dependent data move beyond interference?", "Does the dependence exacerbate the unmeasured confounding issue?", "How?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_867_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_867_2", "review_text": "The work presented in the paper is clearly of value.  The existing theory for identification and estimation of causal parameters in DAGs for IID data has been central to our understanding of causal inference, and developing analogous results for data under interference would be useful both to apply directly to data in which we know interference occurs and to better understand the potential impacts of violations of the IID assumption.  While the paper should be accepted, the current version could be substantially improved in both organization and in its discussion of several key issues, including generality, assumptions, temporal effects, and prior work.  Organization and Presentation  Some aspects of the organization make the paper challenging for readers.  Some sections do not provide a \u00e2\u0080\u009croadmap\u00e2\u0080\u009d to the basic logic before plunging into the details, others do not present a high-level intuition for why a given theoretical result is being presented,  The entire paper would be substantially improved if the authors provided readers with a high-level roadmap to the overall reasoning of the paper, making clear the basic logic that allows an identification theory to be developed under interference (before plunging into the details of sections 2 and 3).  As I understand it, the outline of that logic is: 1) Represent models as latent variable chain graphs, 2) Divide the model into blocks, 3) Assume no interference between blocks, 4) Express identification theory by using truncated nested factorization of latent projection ADMGs.  This logic differs from the current abstract because it helps readers see how the paper achieves what it does, rather than just what the paper achieves.  The paper provides a great deal of theory with relatively little intuition to help readers understand the underlying concepts.  Such intuition would be relatively easy to provide.  For example, the fixing operation will be novel to most readers, and the paper would be improved by providing an intuition for what fixing corresponds to (if such an intution exists).  The intuition for conditioning, for example, is often presented in terms of partitioning of possible worlds.  If no such intuition exists, then it would be worth explaining up front that it is only a method for producing a nested factorization of an ADMG (or even relegating this to the supplemental material).  The abtract implies that unobserved confounding bias is a necessary (or at least likely) consequence of non-iid data, but the paper doesn\u00e2\u0080\u0099t make clear why this is so.  A quick description would be useful, so that readers would not have to consult outside papers, such as reference 14.  In contrast, Section 1 merely invokes latent confounding as a likely situation that appears in conjunction with interference.  More clarity on this point would help readers.  Generality  It is very difficult to assess the generality of the results presented in the paper.  Specifically, the details of the motivating example provided in Section 2 makes the results appear very narrow, but the more expansive langauge in the introduction and conclusion make the results seem much more general (\u00e2\u0080\u009c\u00e2\u0080\u00a6complete identification theory, and estimation for dependent data.\u00e2\u0080\u009d).  Specifically, the work presented here applies to data consisting of a single object type and stable, symmetric relationships, such as friendship ties.  This is worth emphasizing in the introduction, because interference can occur in cases in which asymmetric relationships also occur (such as social network data, communications data, and citation data) and where multiple types of objects occur.  Assumptions  The method outlined in the paper appears to rely strongly on the presence of blocks (maximal sets of vertices in the model which each pair is connected by an undirected path) that lack interference.  This seems unlikely in many reasonable scenarios.  Interblock non-interference may be a common assumption, but that doesn\u00e2\u0080\u0099t mean that it is realistic.  The authors should either provide evidence that this is a plausible assumption in real applications or provide evidence that moderate violations of this assumption do not greatly affect the results.  Section 2 states that \u00e2\u0080\u009ca crucial assumption in our example is that\u00e2\u0080\u00a6community membership does not directly influence sharing, except as mediated by social network activity of the user.\u00e2\u0080\u009d  This seems a moderately strong assumption, and it would be good to expand somewhat on both the likelihood of being able to gather data that meet such an assumption and the reasons why this assumption is made.  Temporal effects  The motivating example (and other plausible examples) seems extremely difficult to analyze without explicit consideration of the time-series of behavior.  This is not just a simple statement that temporal information aids causal identification.  Instead, the point here is that the system described almost certainly has substantial feedback effects and time-varying exogenous influences, and it may never reach any form of equilibrium.  Thus, it is unclear what a data sample corresponds to here.  The paper would be improved greatly by describing in more detail the underlying assumptions of data collection.  Prior work  The paper ignores a moderately large literature on inferring causal models of non-iid data that has appeared in the graphical models literature over the past decade.  Relevant papers include:  Marc Maier (2013). Reasoning about independence in probabilistic models of relational data. arXiv:1302.4381.  Lee & Honavar (2016). On learning causal models from relational data. AAAI 2016.  Maier et al. (2013). A sound and complete algorithm for learning causal models from relational data.  UAI 2013.  Arbour et al. (2016). Inferring network effects from observational data. KDD 2016.  These papers do not subsume or contradict the current paper, but the current paper would be improved by contrasting the assumptions of these papers with the approach taken here.  Summarize the strengths and weaknesses of the submission, focusing on each of the following four criteria: quality, clarity, originality, and significance.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_867_2", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["The work presented in the paper is clearly of vale.", "The existing theory for identification and estimation of causalparameters in DAGs for IID data has been centralto our understanding of causalinference, and developing analgous results for data under interference would be useful both to apply directly to data in which we know interference occurs and to better understand the potentialimpacts of violations of the IID assumption.", "While the paper should be accepted, the current version could be substantialy improved in both organization and in its discussion of severalkey issues, including generalty, assumptions, temporaleffects, and prior work.", "Organization and Presentation Some aspects of the organization make the paper chalenging for readers.", "Some secions do not provide a \u00e2\u0080\u009croadmap\u00e2\u0080\u009d to the basic logic before plunging into the details, others do not present a high-level intuition for why a given theoreticalresult is being presented, The entire paper would be substantialy improved if the authors provided readers with a high-level roadmap to the overal reasoning of the paper, making clear the basic logic that alows an identification theory to be developed under interference (before plunging into the details of secions 2 and 3).", "As I understand it, the outline of that logic is: 1) Represent models as latent variable chain graphs, 2) Divide the model into blocks, 3) Assume no interference between blocks, 4) Express identification theory by using truncated nested factorization of latent projection ADMGs.", "This logic differs from the current abstract because it helps readers see how the paper achieves what it does, rather than just what the paper achieves.", "The paper provides a great dealof theory with relatively little intuition to help readers understand the underlying concepts.", "Such intuition would be relatively easy to provide.", "For example, the fixing operation will be novel to most readers, and the paper would be improved by providing an intuition for what fixing corresponds to (if such an intution exists).", "The intuition for conditioning, for example, is often presented in terms of partitioning of possible worlds.", "If no such intuition exists, then it would be worth explaining up front that it is only a method for producing a nested factorization of an ADMG (or even relegating this to the supplementalmaterial.", "The abtract implies that unobserved confounding bias is a necessary (or at least likely) conseqence of non-iid data, but the paper doesn\u00e2\u0080\u0099t make clear why this is so.", "A quick description would be useful, so that readers would not have to consult outside papers, such as reference 14, In contrast, secion 1 merely invokes latent confounding as a likely situation that appears in conjunction with interference.", "More clarity on this point would help readers.", "Generalty It is very difficult to assess the generalty of the results presented in the paper.", "Specificaly, the details of the motivating example provided in secion 2 makes the results appear very narrow, but the more expansive langauge in the introduction and conclusion make the results seem much more general(\u00e2\u0080\u009c\u00e2\u0080\u00a6complete identification theory, and estimation for dependent data.\u00e2\u0080\u009d).", "Specificaly, the work presented here applies to data consisting of a single object type and stable, symmetric relationships, such as friendship ties.", "This is worth emphasizing in the introduction, because interference can occur in cases in which asymmetric relationships alo occur (such as socialnetwork data, communications data, and citation data) and where multiple types of objects occur.", "Assumptions The method outlined in the paper appears to rely strongly on the presence of blocks (maximalsets of vertices in the model which each pair is connected by an undirected path) that lack interference.", "This seems unlikely in many reasonable scenarios.", "Interblock non-interference may be a common assumption, but that doesn\u00e2\u0080\u0099t mean that it is realstic.", "The authors should either provide evidence that this is a plausible assumption in realapplications or provide evidence that moderate violations of this assumption do not greatly affect the results.", "secion 2 states that \u00e2\u0080\u009ca crucialassumption in our example is that\u00e2\u0080\u00a6community membership does not directly influence sharing, except as mediated by socialnetwork activity of the user.\u00e2\u0080\u009d This seems a moderately strong assumption, and it would be good to expand somewhat on both the likelihood of being able to gather data that meet such an assumption and the reasons why this assumption is made.", "Temporaleffects The motivating example (and other plausible examples) seems extremely difficult to analze without explicit consideration of the time-series of behavior.", "This is not just a simple statement that temporalinformation aids causalidentification.", "Instead, the point here is that the system described alost certainly has substantialfeedback effects and time-varying exogenous influences, and it may never reach any form of eqilibrium.", "Thus, it is unclear what a data sample corresponds to here.", "The paper would be improved greatly by describing in more detail the underlying assumptions of data collection.", "Prior work The paper ignores a moderately large literature on inferring causalmodels of non-iid data that has appeared in the graphicalmodels literature over the past decade.", "Relevant papers include: Marc Maier (2013).", "Reasoning about independence in probabilistic models of relationaldata.", "arXiv:1302.4381, Lee & Honavar (2016).", "On learning causalmodels from relationaldata.", "AAAI 2016, Maier et al (2013).", "A sound and complete alorithm for learning causalmodels from relationaldata.", "UAI 2013, Arbour et al (2016).", "Inferring network effects from observationaldata.", "KDD 2016, These papers do not subsume or contradict the current paper, but the current paper would be improved by contrasting the assumptions of these papers with the approach taken here.", "Summarize the strengths and weaknesses of the submission, focusing on each of the following four criteria: qualty, clarity, originalty, and significance."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_867_2", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_865_3", "review_text": "This paper proposes to augment standard deep residual networks for image classification with explicit gather-scatter operations, in order to improve propagation of useful contextual information.  It implements a per-channel gather-scatter operation.  The gather phase performs either global average pooling or max pooling (termed \"picking\") per channel, over an extended spatial domain.  The scatter phase upsamples the gathered feature maps back to the original size, and combines them with the input feature maps.  Experiments show integrating gather-scatter operations into residual networks yields a performance boost on the standard ImageNet classification task without any, or with minimal, parameter increase.  The paper justifiably discusses connections with Squeeze-and-Excitation networks [10].  However, it is missing citation, discussion, and comparison to two other highly related recent publications:  (1) Multigrid Neural Architectures     Tsung-Wei Ke, Michael Maire, Stella X. Yu     CVPR 2017  (2) Non-local Neural Networks     Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He     CVPR 2018  The first of these works, [Ke et al, CVPR 2017] extends residual networks with a scale-space information propagation mechanism: at each layer, information flows both up and down a scale-space pyramid.  This is implemented by combining convolution operations with max-pooling, upsampling, and concatenation at every layer in the network.  These ingredients sound quite similar to the proposed gather-scatter scheme and, in fact, could be viewed as a generalization of the proposed gather-scatter approach to one which operates at all spatial scales.  Like the current paper, [Ke et al] specifically mention rapid integration of contextual cues and demonstrate improved accuracy and parameter savings on ImageNet classification using their multigrid residual network.  The second of these related works, [Wang et al, CVPR 2018], suggests inserting a non-local information gathering operation into neural networks, similar in formulation to the gather operation proposed here.  They discuss multiple functional forms and also present results of experiments modifying residual networks to include their proposed operations.  The existence of both of these published prior works decreases the relative novelty of the approach proposed here.  The fact that neither are cited is a serious problem.  Ideally, both would be cited, discussed, and compared against in experiments.  If the particular implementation proposed by this paper has advantages, a thorough experimental comparison to prior work is needed to justify them.  In light of this prior work, I do not believe the idea or current results alone are sufficiently novel or impressive to carry the paper.  ---  The rebuttal addresses my concerns about discussion of related work and addition of experimental comparison to that work. I have raised my overall score. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_865_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper proposes to augment standard deep residualnetworks for image classification with explicit gather-scatter operations, in order to improve propagation of useful contextualinformation.", "It implements a per-channel gather-scatter operation.", "The gather phase performs either globalaverage pooling or max pooling (termed \"picking\") per channel, over an extended spatialdomain.", "The scatter phase upsamples the gathered feature maps back to the originalsize, and combines them with the input feature maps.", "Experiments show integrating gather-scatter operations into residualnetworks yields a performance boost on the standard ImageNet classification task without any, or with minimal parameter increase.", "The paper justifiably discusses connections with Squeeze-and-Excitation networks [10].", "However, it is missing citation, discussion, and comparison to two other highly related recent publications: (1) Multigrid NeuralArchitectures Tsung-Wei Ke, Michael Maire, Stella X Yu CVPR 2017 (2) Non-localNeuralNetworks Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He CVPR 2018 The first of these works, [Ke et al CVPR 2017] extends residualnetworks with a scal-space information propagation mechanism: at each layer, information flows both up and down a scal-space pyramid.", "This is implemented by combining convolution operations with max-pooling, upsampling, and concatenation at every layer in the network.", "These ingredients sound quite similar to the proposed gather-scatter scheme and, in fact, could be viewed as a generalzation of the proposed gather-scatter approach to one which operates at al spatialscals.", "Like the current paper, [Ke et al specificaly mention rapid integration of contextualcues and demonstrate improved accuracy and parameter savings on ImageNet classification using their multigrid residualnetwork.", "The secnd of these related works, [Wang et al CVPR 2018], suggests inserting a non-localinformation gathering operation into neuralnetworks, similar in formulation to the gather operation proposed here.", "They discuss multiple functionalforms and alo present results of experiments modifying residualnetworks to include their proposed operations.", "The existence of both of these published prior works decreases the relative novelty of the approach proposed here.", "The fact that neither are cited is a serious problem.", "Idealy, both would be cited, discussed, and compared against in experiments.", "If the particular implementation proposed by this paper has advantages, a thorough experimentalcomparison to prior work is needed to justify them.", "In light of this prior work, I do not believe the idea or current results alne are sufficiently novel or impressive to carry the paper.", "--- The rebuttaladdresses my concerns about discussion of related work and addition of experimentalcomparison to that work.", "I have raised my overal score."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_865_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_860_2", "review_text": "This paper addresses the topic of unsupervised domain adaptation, i.e. how to adapt a classifier which was trained for one task to another one using unlabeled data of the target task only.  There is a large body of research on this topic. Many algorithms are based on the alignment of the source and target feature distributions.  This paper proposes to extend this idea by constructing multiple feature spaces and aligning them individually, while encouraging agreement between them. This approach is surprisingly successful and outperforms the state-of-the-art on the digit classification tasks MNIST, MINSTM, SVHN, DIGITS, STL and CIFAR.  In Table 1, you provide the results for both classifiers. How do you select the one that you would use in a real application ? One could probably chose either one since their performance are always very close. Can this be guaranteed ?  Since we have two classifiers, one also wonders whether we could get additional improvements by combining them, e.g. by majority vote or averaging the predictions.  You mention that you only use two classifiers in this paper. Obviously, the question arises what would happen when you used more. Do you expect additional improvements ? Or is this computationally intractable ?  How would you align multiple feature spaces - pairwise or with respect to one \"master feature space\".  It would be nice to comment on these topics in the next version of this paper, with our without running experiments.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_860_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper addresses the topic of unsupervised domain adaptation, i e how to adapt a classifier which was trained for one task to another one using unlabeled data of the target task only.", "There is a large body of research on this topic.", "Many alorithms are based on the algnment of the source and target feature distributions.", "This paper proposes to extend this idea by constructing multiple feature spaces and algning them individualy, while encouraging agreement between them.", "This approach is surprisingly successful and outperforms the state-of-the-art on the digit classification tasks MNIST, MINSTM, SVHN, DIGITS, STL and CIFAR.", "In Table 1, you provide the results for both classifiers.", "How do you select the one that you would use in a realapplication ?", "One could probably chose either one since their performance are alays very close.", "Can this be guaranteed ?", "Since we have two classifiers, one alo wonders whether we could get additionalimprovements by combining them, e g by majority vote or averaging the predictions.", "You mention that you only use two classifiers in this paper.", "Obviously, the question arises what would happen when you used more.", "Do you expect additionalimprovements ?", "Or is this computationaly intractable ?", "How would you algn multiple feature spaces - pairwise or with respect to one \"master feature space\".", "It would be nice to comment on these topics in the next version of this paper, with our without running experiments."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_860_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_851_2", "review_text": "The paper introduces a new adaptive coordinate descent algorithm, which selects the coordinates based on a measurement of marginal decrease. The main idea is to measure the marginal decrease of each coordinate with the help of dual residues. The greedy algorithm consists of choosing the coordinate which provides the largest  marginal decrease. However, the greedy version requires the information of all the coordinates which is computationally expensive. To overcome this issue, an adaptive variant which updates the information in an online style has been introduced.   My major concern is about the theoretical analysis of the adaptive algorithm. In Proposition 2, the convergence rate of the algorithm is given under the assumption that the initial function gap f(x_0)-f* is smaller than some quantity Q. However, this assumption is unnatural and inappropriate due to the dependance between Q and f. It is not true that this condition will hold by scaling down the function f, because Q will also scale down. Moreover, Q depends on another highly non trivial quantity c, which depends on the functional property and probably the initial point. Thus, a more careful clarification is needed.   Besides this negative point in the theoretical analysis, I find the experimental section unconvincing. In particular, the parameter choices seems very arbitrary, for example the regularization parameter. Moreover, it is not clear how the algorithm's key parameters are selected like \\epsilon and E. For ridge regression, E is set to be n/2 and for other cases E is d/2. There might be a huge gap between the feature dimension d and the number of samples n. It sounds like taking the best value that works without any theoretical reason.  Overall, the idea of using the marginal decrease as a guidance of coordinate selection is very interesting, but I do not support publication of the paper in the current state due to the weakness in both theoretical and the experimental results.   Some additional remarks: 1) The l1 regularization is not L-bounded unless taking L=infinity  2) Some of the plots do not include any algorithm proposed in the paper, for example in logistic regression on dataset w8a or a9a in Figure 3.   EDIT: I thank authors for addressing may concerns. Even though I still find the theoretical result a bit weak, I believe the paper provides interesting insight and ideas with outstanding empirical performance, as such, I raise my score accordingly.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_851_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper introduces a new adaptive coordinate descent alorithm, which selects the coordinates based on a measurement of marginaldecrease.", "The main idea is to measure the marginaldecrease of each coordinate with the help of dualresidues.", "The greedy alorithm consists of choosing the coordinate which provides the largest marginaldecrease.", "However, the greedy version reqires the information of al the coordinates which is computationaly expensive.", "To overcome this issue, an adaptive variant which updates the information in an online style has been introduced.", "My major concern is about the theoreticalanalsis of the adaptive alorithm.", "In Proposition 2, the convergence rate of the alorithm is given under the assumption that the initialfunction gap f(x_0)-f* is smaler than some quantity Q However, this assumption is unnaturaland inappropriate due to the dependance between Q and f It is not true that this condition will hold by scalng down the function f, because Q will alo scal down.", "Moreover, Q depends on another highly non trivialquantity c, which depends on the functionalproperty and probably the initialpoint.", "Thus, a more careful clarification is needed.", "Besides this negative point in the theoreticalanalsis, I find the experimentalsecion unconvincing.", "In particular, the parameter choices seems very arbitrary, for example the regularization parameter.", "Moreover, it is not clear how the alorithm's key parameters are selected like \\epsilon and E For ridge regression, E is set to be n/2 and for other cases E is d/2, There might be a huge gap between the feature dimension d and the number of samples n It sounds like taking the best vale that works without any theoreticalreason.", "Overal, the idea of using the marginaldecrease as a guidance of coordinate selection is very interesting, but I do not support publication of the paper in the current state due to the weakness in both theoreticaland the experimentalresults.", "Some additionalremarks: 1) The l1 regularization is not L-bounded unless taking L=infinity 2) Some of the plots do not include any alorithm proposed in the paper, for example in logistic regression on dataset w8a or a9a in figre 3, EDIT: I thank authors for addressing may concerns.", "Even though I still find the theoreticalresult a bit weak, I believe the paper provides interesting insight and ideas with outstanding empiricalperformance, as such, I raise my score accordingly."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_851_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_846_1", "review_text": "This paper proposes an algorithm for learning goal-conditioned RL policy, in which a goal is defined as a single image. The authors propose to encode a state (an image) to a vector in latent space using variational autoencoder, and define reward functions inside the latent space. The paper shows that such reward function outperforms baseline such as pixel based reward functions. The authors then proposed latent goal relabeling, which generates new goals and rewards given an exist tuple (s, a, s\u00e2\u0080\u0099). In this way, the off-policy algorithm essentially obtains more training data. Finally, the authors propose goal imagination, which samples goals from latent space during training, essentially allowing training without specifying a particular goal. (interacting with the environment is still requires, because the transition function is unknown).  The experiment results justified the proposed methods, showing that the proposed algorithm is more sample efficient and achieve better performance.  The proposed method is novel and the experiments are thorough, and I'm inclined to accept this paper. Here are some suggestions/comments: 1) A goal in the paper is defined as a single image, which limits the application of the algorithm. Usually goals are more abstract than an image (e.g. in auto driving, probably one goal is to stay in the lane), or sometimes multiple images maps to the same goal. Indeed, defining the goal space the same as observation space is convenient, but has its own limitations. 2) The algorithm first trains a VAE model using some exploration policy, and then fixes the VAE parameters and trains the policy. However, this requires the exploration policy to explore extensively to cover better the state space so as to collect enough data to train the VAE model. This is a time and sample consuming step. Is it possible to incrementally update both VAE and policy parameters? 3) Experiments of reward specification comparison (Figure 4). It would be nice if the authors could add another baseline which is GRiLL plus hand-specified reward function (the reward function Oracle used in Figure 3). It would also be nice if the authors can add another figure which demonstrates the correlation between the proposed reward function and the hand-specified reward function used by Oracle. 4) Line 291: the authors state \u00e2\u0080\u009cVAE is significantly better than HER or not relabeling at all\u00e2\u0080\u009d. However, Figure 5 shows that VAE (the grey line) is doing worse than HER (purple line). The labels in the figure is wrong? 5) Figure 6: it would be better if the authors also run baselines for the variable numbers of objects setting.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_846_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper proposes an alorithm for learning goalconditioned RL policy, in which a goalis defined as a single image.", "The authors propose to encode a state (an image) to a vector in latent space using variationalautoencoder, and define reward functions inside the latent space.", "The paper shows that such reward function outperforms baseline such as pixel based reward functions.", "The authors then proposed latent goalrelabeling, which generates new goal and rewards given an exist tuple (s, a, s\u00e2\u0080\u0099).", "In this way, the off-policy alorithm essentialy obtains more training data.", "Finaly, the authors propose goalimagination, which samples goal from latent space during training, essentialy alowing training without specifying a particular goal (interacting with the environment is still reqires, because the transition function is unknown).", "The experiment results justified the proposed methods, showing that the proposed alorithm is more sample efficient and achieve better performance.", "The proposed method is novel and the experiments are thorough, and I'm inclined to accept this paper.", "Here are some suggestions/comments: 1) A goalin the paper is defined as a single image, which limits the application of the alorithm.", "Usualy goal are more abstract than an image (e g in auto driving, probably one goalis to stay in the lane), or sometimes multiple images maps to the same goal Indeed, defining the goalspace the same as observation space is convenient, but has its own limitations.", "2) The alorithm first trains a VAE model using some exploration policy, and then fixes the VAE parameters and trains the policy.", "However, this reqires the exploration policy to explore extensively to cover better the state space so as to collect enough data to train the VAE model.", "This is a time and sample consuming step.", "Is it possible to incrementaly update both VAE and policy parameters?", "3) Experiments of reward specification comparison (figre 4).", "It would be nice if the authors could add another baseline which is GRiLL plus hand-specified reward function (the reward function Oracle used in figre 3).", "It would alo be nice if the authors can add another figre which demonstrates the correlation between the proposed reward function and the hand-specified reward function used by Oracle.", "4) Line 291: the authors state \u00e2\u0080\u009cVAE is significantly better than HER or not relabeling at al\u00e2\u0080\u009d.", "However, figre 5 shows that VAE (the grey line) is doing worse than HER (purple line).", "The labels in the figre is wrong?", "5) figre 6: it would be better if the authors alo run baselines for the variable numbers of objects setting."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_846_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_83_2", "review_text": "The work gave a nice application of RL to the continual learning problem, particularly focusing on the forward transfer learning case. Namely, as in Progressive Net or DEN, the proposed method follows to expand model architecture for the new task. But, unlike Progressive Net, which expands with fixed size network, and DEN, which has various hyperparameters to tune, the proposed method applies RL framework to learn the model expanding step for each task.   The specific RL technique is not necessarily novel, but quite standard - LSTM controller and actor-critic method for learning. However, I think the idea of applying RL to continual learning is novel enough for a publication. In their experimental results, RCL achieves essentially the same accuracy as PGN and DEN, but with fewer parameters and hyperparameters to tune. The downside is that the training time is much longer than the other method. Also, since their model complexity indeed grows with the number of tasks, it cannot handle too many tasks, which is the common limitation of PGN and DEN. The result on the forgetting behavior is not too surprising since they are freezing the network for the older tasks. Hence, there is not backward transfer happening, if the data from the old task arrives again. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_83_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The work gave a nice application of RL to the continuallearning problem, particularly focusing on the forward transfer learning case.", "Namely, as in Progressive Net or DEN, the proposed method follows to expand model architecture for the new task.", "But, unlike Progressive Net, which expands with fixed size network, and DEN, which has various hyperparameters to tune, the proposed method applies RL framework to learn the model expanding step for each task.", "The specific RL technique is not necessarily novel, but quite standard - LSTM controller and actor-critic method for learning.", "However, I think the idea of applying RL to continuallearning is novel enough for a publication.", "In their experimentalresults, RCL achieves essentialy the same accuracy as PGN and DEN, but with fewer parameters and hyperparameters to tune.", "The downside is that the training time is much longer than the other method.", "Also, since their model complexity indeed grows with the number of tasks, it cannot handle too many tasks, which is the common limitation of PGN and DEN.", "The result on the forgetting behavior is not too surprising since they are freezing the network for the older tasks.", "Hence, there is not backward transfer happening, if the data from the old task arrives again."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_83_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_82_3", "review_text": "This paper conducts an in-depth analysis of the optimal dimension for word embeddings. It starts with proposing a loss, based on a very straightforward motivation, and then decomposes the loss into variance and bias components in a very nice way (which is Theorem 1 in the paper). Then the theorem gets extended to other cases, without changing the main motivation behind it, and reveals its fundamental relation to SNR in information theory and signal processing. Thus it gives a satisfying good theoretical inspection and explanation to [Arora, 2016]. Plus the support of previous research [Levy and Goldberg, 2014] on the connection between skip-gram model and matrix factorization, the whole set of theory becomes applicable to a set of widely used models like skip-gram.   I would say reading through the main part of the paper is enlightening and rather an enjoyable adventure.   The experimental results regarding the robustness of word2vec/glove models w.r.t. dimensions (Section 5.1) are consistent with what many people are experiencing when using these word embeddings. Which the paper has well explained that in its previous sections.   I have to say it is a very good presentation of an in-depth explanation of the well-known word embedding tasks. And the theoretical results do have its practical applications. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_82_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["This paper conducts an in-depth analsis of the optimaldimension for word embeddings.", "It starts with proposing a loss, based on a very straightforward motivation, and then decomposes the loss into variance and bias components in a very nice way (which is Theorem 1 in the paper).", "Then the theorem gets extended to other cases, without changing the main motivation behind it, and reveal its fundamentalrelation to SNR in information theory and signalprocessing.", "Thus it gives a satisfying good theoreticalinspection and explanation to [Arora, 2016].", "Plus the support of previous research [Levy and Goldberg, 2014] on the connection between skip-gram model and matrix factorization, the whole set of theory becomes applicable to a set of widely used models like skip-gram.", "I would say reading through the main part of the paper is enlightening and rather an enjoyable adventure.", "The experimentalresults regarding the robustness of word2vec/glove models w r t dimensions (secion 5 1) are consistent with what many people are experiencing when using these word embeddings.", "Which the paper has well explained that in its previous secions.", "I have to say it is a very good presentation of an in-depth explanation of the well-known word embedding tasks.", "And the theoreticalresults do have its practicalapplications."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_82_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_817_1", "review_text": "The paper establishes problem-specific regret lower bounds for ergodic RL problems with arbitrary structure. The paper focuses on MDPs with finite states and actions, and on learning algorithms that are uniformly good over a class of MDPs. The lower bound is made explicit for unstructured MDPs and Lipschitz MDPs. For unstructured MDPs, the bound extends a previous result in [1] to take into account unknown rewards. For Lipschitz MDPs, the bound depends only on the Lipschitz structure, the sub-optimality gap, and the span of the bias functions, and does not explicitly scale with the size of the state space and action space. The paper then proposes an algorithm, DEL, that matches these lower bounds.   The proposed lower bounds are a generalization of results in [2] from the bandit setting to the RL setting, and the proposed algorithm is an adaptation of the algorithm proposed in [2]. I think the paper is very clearly written in general. The motivation and intuition for the theorems and proofs are all very well explained. The optimization problem which defines the lower bound still seems a little abstract to me. If possible, it might be helpful to further illustrate the lower bounds through more concrete examples other than Lipschitz MDPs.   [1] Apostolos N. Burnetas and Michael N. Katehakis. Optimal adaptive policies for markov decision processes. Mathematics of Operations Research, 22(1):222\u00e2\u0080\u0093255, 1997.  [2] Richard Combes, Stefan Magureanu, and Alexandre Proutiere. Minimal exploration in structured stochastic bandits. In Advances in Neural Information Processing Systems 30, 2017. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_817_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper establishes problem-specific regret lower bounds for ergodic RL problems with arbitrary structure.", "The paper focuses on MDPs with finite states and actions, and on learning alorithms that are uniformly good over a class of MDPs.", "The lower bound is made explicit for unstructured MDPs and Lipschitz MDPs.", "For unstructured MDPs, the bound extends a previous result in [1] to take into account unknown rewards.", "For Lipschitz MDPs, the bound depends only on the Lipschitz structure, the sub-optimalty gap, and the span of the bias functions, and does not explicitly scal with the size of the state space and action space.", "The paper then proposes an alorithm, DEL, that matches these lower bounds.", "The proposed lower bounds are a generalzation of results in [2] from the bandit setting to the RL setting, and the proposed alorithm is an adaptation of the alorithm proposed in [2].", "I think the paper is very clearly written in general The motivation and intuition for the theorems and proofs are al very well explained.", "The optimization problem which defines the lower bound still seems a little abstract to me.", "If possible, it might be helpful to further illustrate the lower bounds through more concrete examples other than Lipschitz MDPs.", "[1] Apostolos N Burnetas and Michael N Katehakis.", "Optimaladaptive policies for markov decision processes.", "Mathematics of Operations Research, 22(1):222\u00e2\u0080\u0093255, 1997, [2] Richard Combes, Stefan Magureanu, and Alexandre Proutiere.", "Minimalexploration in structured stochastic bandits.", "In Advances in NeuralInformation Processing Systems 30, 2017,"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_817_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_812_1", "review_text": "This paper presents a theorem proving algorithm that leverages Monte-Carlo simulations guided by reinforcement learning  from previous proof searches. In particular, to guid the search, the authors use the UCT formula augmented by (1) learning prior probabilities of actions for certain proof states (policy learning), and (2) learning the values corresponding to the same proof states (policy evaluation). The proposed algorithm is using no domain engineering. The authors evaluate their proposal on two datasets: Miz40 and M2k. The evaluation shows the proposed solution outperforms state-of-the are by solving ~40% more problems.  This is a solid paper: it addresses a hard problem, and provide solutions that show significant improvements over the prior work. I have a few questions however, which mainly seek clarifications of the evaluation results: - You mention \"We have also experimented with PUCT as in AlphaZero, however the results are practically the same.\" Can you provide some more color on this? How close were the results? Any tradeoffs? - Does rlCoP with policy and value guidance solve all the problems mlCoP solves on Miz40 dataset? If not, which problems does mlCoP solve and rlCoP doesn't? Same questions for rlCop with policy guidance vs mlCoP for the M2k dataset. - Is there anything special about the solutions shown in Sec 4.6 besides the fact they are more involving? It would be nice to provide some more intuition of why your algorithm perform well in those cases. - When you are training rlCoP on the Miz40 dataset how do you pick the problems in the training set? Randomly? How robust are the results to picking a different training set?  Minor: - \"Published improvements in the theorem proving field are typically between 3 and 10 %.\" Can you please give some references to support your claim. - Please user either Mizar40 or Miz40 for consistency. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_812_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper presents a theorem proving alorithm that leverages Monte-Carlo simulations guided by reinforcement learning from previous proof searches.", "In particular, to guid the search, the authors use the UCT formula augmented by (1) learning prior probabilities of actions for certain proof states (policy learning), and (2) learning the vales corresponding to the same proof states (policy evalation).", "The proposed alorithm is using no domain engineering.", "The authors evalate their proposalon two datasets: Miz40 and M2k.", "The evalation shows the proposed solution outperforms state-of-the are by solving ~40% more problems.", "This is a solid paper: it addresses a hard problem, and provide solutions that show significant improvements over the prior work.", "I have a few questions however, which mainly seek clarifications of the evalation results: - You mention \"We have alo experimented with PUCT as in AlphaZero, however the results are practicaly the same.\"", "Can you provide some more color on this?", "How close were the results?", "Any tradeoffs?", "- Does rlCoP with policy and vale guidance solve al the problems mlCoP solves on Miz40 dataset?", "If not, which problems does mlCoP solve and rlCoP doesn't?", "Same questions for rlCop with policy guidance vs mlCoP for the M2k dataset.", "- Is there anything specialabout the solutions shown in sec4 6 besides the fact they are more involving?", "It would be nice to provide some more intuition of why your alorithm perform well in those cases.", "- When you are training rlCoP on the Miz40 dataset how do you pick the problems in the training set?", "Randomly?", "How robust are the results to picking a different training set?", "Minor: - \"Published improvements in the theorem proving field are typicaly between 3 and 10 %.\"", "Can you please give some references to support your claim.", "- Please user either Mizar40 or Miz40 for consistency."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_812_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_804_4", "review_text": " The article presents Causal InfoGAN, a framework for learning a low-dimensional generative model and structured representations of sequential high-dimensional observations, such as images, from a dynamical system, for use in long-horizon planning. The focus is discrete and deterministic dynamics models that can be used in graph search methods in, for example, classical AI planning  The work follows the InfoGAN approach, adding to the GAN training a loss function that maximizes the mutual information between observation pairs and transitions in the planning model. The GAN is trained to generate sequential observation pairs from the dynamical system maximizing the mutual information between the generated observations. The objective helps the abstract model to capture the relevant changes in the observations, for simplicity this work ignores partial observability. The generative process is induced by a transition in a low-dimensional planning model with noise such that \"small changes to the abstract state correspond to feasible changes to the observation\" -- planning in this model involves \"interpolating between abstract states\".  The transitions in the planning model lead to a low-dimensional representation that is claimed to explain the causal nature of the data.  The experiments reported using Causal InfoGAN include * A toy 2D navigation problem which shows that state abstraction leads to better planning, with clusters that correspond to the possible dynamics of the particle in the task that leads to reasonable generated planning trajectories. The model does not rely on the Euclidean metric which leads to better planning -- the authors point out that E.D can be unsuitable even on low-dimensional continuous domains. * A Rope manipulation data problem which shows that training loss of Causal InfoGAN can generate a latent space that leads to accurate representation of possible changes to the rope and generates high-level plans directly from data without requiring additional human guidance. It is claimed that the objective guarantees feasible transitions and \"causality preserving loss\" leads to a learned latent space in which local perturbations correspond to plausible changes in the image (unlike an infoGAN with a MI loss that does not involve state transitions). Causal InfoGAN appears to generate convincing \"walkthrough sequences\" for manipulating a rope into a given shape, using real image data collected from a robot randomly manipulating the rope.  The paper is generally clear and well written, the quality of the work and the paper seems to be reasonably good, to my knowledge the work seems original and its relation to other work in the field seems to be clearly described, I do not feel able to comment on the significance of the work.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_804_4", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": [" The article presents CausalInfoGAN, a framework for learning a low-dimensionalgenerative model and structured representations of seqentialhigh-dimensionalobservations, such as images, from a dynamicalsystem, for use in long-horizon planning.", "The focus is discrete and deterministic dynamics models that can be used in graph search methods in, for example, classicalAI planning The work follows the InfoGAN approach, adding to the GAN training a loss function that maximizes the mutualinformation between observation pairs and transitions in the planning model.", "The GAN is trained to generate seqentialobservation pairs from the dynamicalsystem maximizing the mutualinformation between the generated observations.", "The objective helps the abstract model to capture the relevant changes in the observations, for simplicity this work ignores partialobservability.", "The generative process is induced by a transition in a low-dimensionalplanning model with noise such that \"smal changes to the abstract state correspond to feasible changes to the observation\" -- planning in this model involves \"interpolating between abstract states\".", "The transitions in the planning model lead to a low-dimensionalrepresentation that is claimed to explain the causalnature of the data.", "The experiments reported using CausalInfoGAN include * A toy 2D navigation problem which shows that state abstraction leads to better planning, with clusters that correspond to the possible dynamics of the particle in the task that leads to reasonable generated planning trajectories.", "The model does not rely on the Euclidean metric which leads to better planning -- the authors point out that E D can be unsuitable even on low-dimensionalcontinuous domains.", "* A Rope manipulation data problem which shows that training loss of CausalInfoGAN can generate a latent space that leads to accurate representation of possible changes to the rope and generates high-level plans directly from data without reqiring additionalhuman guidance.", "It is claimed that the objective guarantees feasible transitions and \"causalty preserving loss\" leads to a learned latent space in which localperturbations correspond to plausible changes in the image (unlike an infoGAN with a MI loss that does not involve state transitions).", "CausalInfoGAN appears to generate convincing \"walthrough seqences\" for manipulating a rope into a given shape, using realimage data collected from a robot randomly manipulating the rope.", "The paper is generaly clear and well written, the qualty of the work and the paper seems to be reasonably good, to my knowledge the work seems originaland its relation to other work in the field seems to be clearly described, I do not feel able to comment on the significance of the work."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_804_4", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_795_1", "review_text": "This paper proposed to compute the distribution over all possible clusterings of a given set of samples. First, a cluster trellis was defined, where 1) each vertex represented one element from the power set of all samples and 2) vertex A was the parent of vertex B if A can be constructed as the union of A and one sample. Second, the partition function w.t.t. all possible clusterings can be computed recursively, resulting in exponential time complexity. Similarly, the clustering associated with the maximal energy can also be computed in a recursively manner. The time complexity was still exponential.  In order to reduce the exponential complexity of the naive implementation of cluster trellis, the sparse trellis was introduced by removing most vertices from the trellis. One example of sparse trellis is that introduced by hierarchical clustering.  Experimental results on a TCGA dataset consisting of 11 samples and 3000 features were presented. The exact pairwise marginals were compared against the approximate marginals.  The idea of computing the exact distribution over all possible clusterings of the sample set seemed to be a novel idea. The introduction of cluster trellis and the recursive algorithms to compute the partition function and the optimal cluster were also novel.  However, I'm not sure about the practicality of the proposed algorithm. First, the full cluster trellis has exponential complexity. For the sparse trellis, the complexity is determined by the number of vertices in the trellis. However, it's not clear how to determine the sparsity of the sparse trellis.   Second, since this work emphasized the importance of computing the exact distribution over all possible clusterings, the introduction of the sparse trellis would inevitably compromise this objective because the remaining clusterings had to be determined by some heuristic methods, such as hierarchical clustering.   Third, the experimental evaluation seemed limited because only one dataset was used and there were only 11 samples. More extensive evaluations on the synthetic and benchmark datasets, such as those datasets from the UCI repository, are needed.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_795_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper proposed to compute the distribution over al possible clusterings of a given set of samples.", "First, a cluster trellis was defined, where 1) each vertex represented one element from the power set of al samples and 2) vertex A was the parent of vertex B if A can be constructed as the union of A and one sample.", "secnd, the partition function w t t al possible clusterings can be computed recursively, resulting in exponentialtime complexity.", "Similarly, the clustering associated with the maximalenergy can alo be computed in a recursively manner.", "The time complexity was still exponential In order to reduce the exponentialcomplexity of the naive implementation of cluster trellis, the sparse trellis was introduced by removing most vertices from the trellis.", "One example of sparse trellis is that introduced by hierarchicalclustering.", "Experimentalresults on a TCGA dataset consisting of 11 samples and 3000 features were presented.", "The exact pairwise marginal were compared against the approximate marginal.", "The idea of computing the exact distribution over al possible clusterings of the sample set seemed to be a novel idea.", "The introduction of cluster trellis and the recursive alorithms to compute the partition function and the optimalcluster were alo novel.", "However, I'm not sure about the practicalty of the proposed alorithm.", "First, the full cluster trellis has exponentialcomplexity.", "For the sparse trellis, the complexity is determined by the number of vertices in the trellis.", "However, it's not clear how to determine the sparsity of the sparse trellis.", "secnd, since this work emphasized the importance of computing the exact distribution over al possible clusterings, the introduction of the sparse trellis would inevitably compromise this objective because the remaining clusterings had to be determined by some heuristic methods, such as hierarchicalclustering.", "Third, the experimentalevalation seemed limited because only one dataset was used and there were only 11 samples.", "More extensive evalations on the synthetic and benchmark datasets, such as those datasets from the UCI repository, are needed."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_795_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_790_3", "review_text": "Update: I am getting a better understanding of this paper after a second look, with the help of the rebuttal and the discussions. I think this is a good paper and am changing the evaluation accordingly.  The phenomenon this paper pointed out is rather surprising. In particular in the square loss case, it says gradient descent acts like a linear regression, in which all bust the last layer barely moves, and the last layer tries to learn the best linear combination of the (almost fixed) hidden representation.   I did some experiments and find that this phenomenon is indeed true -- fixing a time horizon T and letting the dimension of intermediate hidden layers be large, the last layer changes more significantly than all other layers. This is really interesting and maybe the authors can bring this fact in a stronger tone.  About the relationship with Mei et al., I agree with the rebuttal -- the views are largely complementary. While both focuses on wide neural networks, Mei et al. identifies the exact dynamics for one-hidden-layer nets with a fixed size, while this work assumes the size goes to infinity but is able to characterize arbitrary deep nets. ---------------------- This paper proposes a Neural Tangent Kernel, a model of the gradient descent dynamics of neural networks in the function space. In the case of linear parametrization, this is a kernel gradient descent with a constant kernel (the tangent kernel). In the non-linear case, this result cease to hold, but this paper shows that the neural tangent kernel converges, in the infinite width limit, to a fixed kernel over any finite time horizon. Consequently, the training dynamics of a very wide neural net can be similar to that of a least-squares when it uses the square loss.  I feel like this is a solid piece of theoretical work but am not quite sure about its connection to (and significant among) concurrent results. In particular, does the limiting invariant kernel say something similar to \"no spurious local minima\" or \"no bad critical point / essential convexity\" in the infinite-n limit? One possibility is to compare with Mei et al. (2018), which builds on the observation that one-hidden-layer net is a linear function of the empirical distributions of weights, and thereby the square loss is convex. This empirical distribution is a good \"function space\" for one-hidden-layer nets. As both papers shows some sort of \"linear regression\"-like scenario in the infinite-width limit, I wonder if any interesting interpretations / connections can pop up from here.  I also find it hard to pin down some technical details about kernels, especially Section 3.0 about functional derivatives and kernel gradients (perhaps not easy anyway due to the space constraint). But it would still be great if this part can be made more approachable to non-kernel-experts.   Reference: Mei, Song, Andrea Montanari, and Phan-Minh Nguyen. \"A Mean Field View of the Landscape of Two-Layers Neural Networks.\" arXiv preprint arXiv:1804.06561 (2018). ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_790_3", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Update: I am getting a better understanding of this paper after a secnd look, with the help of the rebuttaland the discussions.", "I think this is a good paper and am changing the evalation accordingly.", "The phenomenon this paper pointed out is rather surprising.", "In particular in the square loss case, it says gradient descent acts like a linear regression, in which al bust the last layer barely moves, and the last layer tries to learn the best linear combination of the (alost fixed) hidden representation.", "I did some experiments and find that this phenomenon is indeed true -- fixing a time horizon T and letting the dimension of intermediate hidden layers be large, the last layer changes more significantly than al other layers.", "This is realy interesting and maybe the authors can bring this fact in a stronger tone.", "About the relationship with Mei et al, I agree with the rebuttal-- the views are largely complementary.", "While both focuses on wide neuralnetworks, Mei et al identifies the exact dynamics for one-hidden-layer nets with a fixed size, while this work assumes the size goes to infinity but is able to characterize arbitrary deep nets.", "---------------------- This paper proposes a NeuralTangent Kernel, a model of the gradient descent dynamics of neuralnetworks in the function space.", "In the case of linear parametrization, this is a kernel gradient descent with a constant kernel (the tangent kernel).", "In the non-linear case, this result cease to hold, but this paper shows that the neuraltangent kernel converges, in the infinite width limit, to a fixed kernel over any finite time horizon.", "Conseqently, the training dynamics of a very wide neuralnet can be similar to that of a least-squares when it uses the square loss.", "I feel like this is a solid piece of theoreticalwork but am not quite sure about its connection to (and significant among) concurrent results.", "In particular, does the limiting invariant kernel say something similar to \"no spurious localminima\" or \"no bad criticalpoint / essentialconvexity\" in the infinite-n limit?", "One possibility is to compare with Mei et al (2018), which builds on the observation that one-hidden-layer net is a linear function of the empiricaldistributions of weights, and thereby the square loss is convex.", "This empiricaldistribution is a good \"function space\" for one-hidden-layer nets.", "As both papers shows some sort of \"linear regression\"-like scenario in the infinite-width limit, I wonder if any interesting interpretations / connections can pop up from here.", "I alo find it hard to pin down some technicaldetails about kernels, especialy secion 3 0 about functionalderivatives and kernel gradients (perhaps not easy anyway due to the space constraint).", "But it would still be great if this part can be made more approachable to non-kernel-experts.", "Reference: Mei, Song, Andrea Montanari, and Phan-Minh Nguyen.", "\"A Mean Field View of the Landscape of Two-Layers NeuralNetworks.\"", "arXiv preprint arXiv:1804.06561 (2018)."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_790_3", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_783_3", "review_text": "Summary:  This paper studies lower bounds for optimization problems based on a notion of \"computation graph,\" which is to say, how long one has to have computations depend on one another. The authors prove lower bounds on optimization that scale as 1 / \\sqrt{D}, where D is this computation depth (or 1 / D^2 if the function is smooth), with variants depending on the type of oracle access the methods have. These results are more or less new, though I think it would be nice if the authors gave a bit more credit to researchers who developed many of the technical techniques in the results.  Criticisms and prior work:  Many of the difficult technical lemmas in the supplement are due to Woodwarth and Srebro [WS16] (https://arxiv.org/abs/1605.08003), which were corrected by Carmon et al. [CDHS17] (https://arxiv.org/abs/1710.11606). In particular, Lemma 1 in this paper is Lemma 9 of [CDHS17], and Lemma 2 is basically Lemma 4 of [CDHS17]. Lemma 3 is Lemma 11 of [CDHS17]. The inequalities involving Surface Area [lines 429--434] are on page 20 of [WS16]. This type of more or less technical copying is unseemly, and does not give appropriate credit to the work of [WS16] and [CDHS17]. I would rather not reject the paper for this, because I think there is some good content in the remainder of the paper, but it is inappropriate to reprove results, without citation, that due to others. The lower bound constructions are similar to those of Nesterov in his 2004 book as well, but probably worth keeping explicitly.  Additional comments: Line 109: These are not really the tightest possible lower bounds in that sense. The function f == 0 has lower bound 0 for any function. As such this sentence seems daft. Line 208: This is not particularly surprising. An algorithm that waits and collects mini-batches will have reduced variance gradient estimates, which are well-known to yield better convergence [e.g. the work of Dekel, Gilad-Bachrach, Shamir, Xiao]. Line 299: The word crisp is the wrong word here. Sharp or tight. Line 327: This line makes no sense to me, because I did not see real discussion of variance bounds in the paper.  POST FEEDBACK REVIEW  I believe the authors when they say they'll give appropriate citations to the prior literature. Happy to have the paper in, assuming that they will do this.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_783_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary: This paper studies lower bounds for optimization problems based on a notion of \"computation graph,\" which is to say, how long one has to have computations depend on one another.", "The authors prove lower bounds on optimization that scal as 1 / \\sqrt{D}, where D is this computation depth (or 1 / D^2 if the function is smooth), with variants depending on the type of oracle access the methods have.", "These results are more or less new, though I think it would be nice if the authors gave a bit more credit to researchers who developed many of the technicaltechniques in the results.", "Criticisms and prior work: Many of the difficult technicallemmas in the supplement are due to Woodwarth and Srebro [WS16] (https://arxiv.org/abs/1605.08003), which were corrected by Carmon et al [CDHS17] (https://arxiv.org/abs/1710.11606).", "In particular, Lemma 1 in this paper is Lemma 9 of [CDHS17], and Lemma 2 is basicaly Lemma 4 of [CDHS17].", "Lemma 3 is Lemma 11 of [CDHS17].", "The ineqalties involving Surface Area [lines 429--434] are on page 20 of [WS16].", "This type of more or less technicalcopying is unseemly, and does not give appropriate credit to the work of [WS16] and [CDHS17].", "I would rather not reject the paper for this, because I think there is some good content in the remainder of the paper, but it is inappropriate to reprove results, without citation, that due to others.", "The lower bound constructions are similar to those of Nesterov in his 2004 book as well, but probably worth keeping explicitly.", "Additionalcomments: Line 109: These are not realy the tightest possible lower bounds in that sense.", "The function f == 0 has lower bound 0 for any function.", "As such this sentence seems daft.", "Line 208: This is not particularly surprising.", "An alorithm that waits and collects mini-batches will have reduced variance gradient estimates, which are well-known to yield better convergence [e g the work of Dekel, Gilad-Bachrach, Shamir, Xiao].", "Line 299: The word crisp is the wrong word here.", "Sharp or tight.", "Line 327: This line makes no sense to me, because I did not see realdiscussion of variance bounds in the paper.", "POST FEEDBACK REVIEW I believe the authors when they say they'll give appropriate citations to the prior literature.", "Happy to have the paper in, assuming that they will do this."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_783_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_777_3", "review_text": "%% Summary %%  This paper develops new PAC-Bayes bounds with data-dependent priors. Distribution-dependent PAC-Bayesian bounds (especially ones with distribution-dependent priors) are by now well-known. However, as far as I am aware, the authors' bound is the first non-trivial PAC-Bayesian bound where the prior is allowed to depend on the data. The key idea to accomplish this is the observation that a differentially private prior can be related to a prior that does not depend on the data, thereby allowing (as the authors do in their first main result) the development of a PAC-Bayesian bound that uses a data-dependent-yet-differentially-private prior based on the standard one that uses a data-independent prior. The proof of the new bound depends on the connection between max information and differential privacy (versions of the latter imply bounds on versions of the former). A second key result of the authors, more relevant from the computational perspective, is that if a differentially private prior is close in 2-Wasserstein distance to some other (not necessarily differentially private) prior, then a PAC-Bayesian bound can again be developed using this latter data-dependent-but-not-differentially-private prior, where we pick up some additional error according to the 2-Wasserstein distance. This result allows the authors to leverage a connection between stochastic gradient Langevin dynamics (which is computationally friendly) and Gibbs distributions (which are differentially private but computational nightmares).  In addition to the above bounds, the authors also perform an empirical study. I have to admit that I focused more on the theoretical guarantees, as I believe they already are interesting enough to warrant publication of the paper. Also, the authors did a poor job in writing the Section 6, leaving vital details in the appendix, like figures which they constantly refer to. I feel that this was not in the spirit of abiding by the 8 page limit, as the paper was not self-contained as a result. This also was confusing, as the authors clearly had extra space throughout the paper to include these two figures.   %% Reviewer's Expertise **  I am an expert in PAC-Bayesian inequalities and also well-versed in recent developments related to differential privacy. I am less familiar with stochastic gradient Langevin dynamics but know the basics.    %% Detailed Comments %%  Aside from Section 6, I found this paper to be remarkably well-written and clear. I especially appreciated the key insight in the paragraph immediately after equation (1.1), for why the Lever et al. bound often must be vacuous for large values of $\\tau$.  I believe that Theorem 4.2 is a very interesting (and not so complicated) result which really makes for a significant and original contribution. It should open up future directions in developing new PAC-Bayesian guarantees, and so this result alone I feel makes a compelling argument for accepting this paper. In addition, Theorem 5.3, which allows us to only require a prior that is close in 2-Wasserstein distance to a differentially private one, further broadens the PAC-Bayesian toolbox in a significant and original way. That said, Theorem 5.3 has a major weakness, which is that it forces us to give up on obtaining ``very high probability'' bounds, since (5.3) has a term which grows as $1/\\delta'$ as the failure probability $\\delta'$ decreases. This is a crucial weakness which the authors should mention after Theorem 5.3, including discussion of whether or not this issue is fundamental.  I looked through the proof of the main results Theorems 4.2 and 5.3 and I believe the analysis is sound. I do think the authors made a typo in the definition of $g$ in Theorem 5.3; you should remove the negative sign (indeed the logarithm in (5.4) is not well-defined if the negative sign stays!). I would have liked a more useful/detailed version of what is currently Corollary 5.4. It currently glosses over too many details to really say much. Since you have extra space in the paper, I recommend including a more explicit version of this corollary. You should also include around this point a citation to the Raginsky / Rakhlin / Telgarsky (2017) paper that you refer to in the appendix. I also recommend giving, at least in the appendix, a precise citation of which result from their paper you are using.     Minor comments:  You never explain the notation for the squiggly arrow in the main paper. Please fix this. It is too important / widely used in the main text to be left to the appendix.  On page 4, line 2, you say ``the above result''. I think you are referring to Definition 3.1, which is of course a definition, not a result. So, you should change the text accordingly.  In Theorem 3.2, you have one instance of $n$ which should be replaced by $m$ (see the inline math following the word ``Then'')  In the proof of Lemma D.1, you should mention that the upper bound of total variation by KL divergence is from Pinsker's inequality. ``Standard results'' is a bit vague to inform the uninformed reader.   %% UPDATE AFTER AUTHOR'S RESPONSE %%  I've read the author's rebuttal and their responses are satisfactory. I do hope you will highlight the weakness of the high probability bound involving the 1/\\delta' dependence.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_777_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["%% Summary %% This paper develops new PAC-Bayes bounds with data-dependent priors.", "Distribution-dependent PAC-Bayesian bounds (especialy ones with distribution-dependent priors) are by now well-known.", "However, as far as I am aware, the authors' bound is the first non-trivialPAC-Bayesian bound where the prior is alowed to depend on the data.", "The key idea to accomplish this is the observation that a differentialy private prior can be related to a prior that does not depend on the data, thereby alowing (as the authors do in their first main result) the development of a PAC-Bayesian bound that uses a data-dependent-yet-differentialy-private prior based on the standard one that uses a data-independent prior.", "The proof of the new bound depends on the connection between max information and differentialprivacy (versions of the latter imply bounds on versions of the former).", "A secnd key result of the authors, more relevant from the computationalperspective, is that if a differentialy private prior is close in 2-Wasserstein distance to some other (not necessarily differentialy private) prior, then a PAC-Bayesian bound can again be developed using this latter data-dependent-but-not-differentialy-private prior, where we pick up some additionalerror according to the 2-Wasserstein distance.", "This result alows the authors to leverage a connection between stochastic gradient Langevin dynamics (which is computationaly friendly) and Gibbs distributions (which are differentialy private but computationalnightmares).", "In addition to the above bounds, the authors alo perform an empiricalstudy.", "I have to admit that I focused more on the theoreticalguarantees, as I believe they aleady are interesting enough to warrant publication of the paper.", "Also, the authors did a poor job in writing the secion 6, leaving vitaldetails in the appendix, like figres which they constantly refer to.", "I feel that this was not in the spirit of abiding by the 8 page limit, as the paper was not self-contained as a result.", "This alo was confusing, as the authors clearly had extra space throughout the paper to include these two figres.", "%% Reviewer's Expertise ** I am an expert in PAC-Bayesian ineqalties and alo well-versed in recent developments related to differentialprivacy.", "I am less familiar with stochastic gradient Langevin dynamics but know the basics.", "%% Detailed Comments %% Aside from secion 6, I found this paper to be remarkably well-written and clear.", "I especialy appreciated the key insight in the paragraph immediately after eqation (1 1), for why the Lever et al bound often must be vacuous for large vales of $\\tau$.", "I believe that Theorem 4 2 is a very interesting (and not so complicated) result which realy makes for a significant and originalcontribution.", "It should open up future directions in developing new PAC-Bayesian guarantees, and so this result alne I feel makes a compelling argument for accepting this paper.", "In addition, Theorem 5 3, which alows us to only reqire a prior that is close in 2-Wasserstein distance to a differentialy private one, further broadens the PAC-Bayesian toolbox in a significant and originalway.", "That said, Theorem 5 3 has a major weakness, which is that it forces us to give up on obtaining ``very high probability'' bounds, since (5 3) has a term which grows as $1/\\delta'$ as the failure probability $\\delta'$ decreases.", "This is a crucialweakness which the authors should mention after Theorem 5 3, including discussion of whether or not this issue is fundamental I looked through the proof of the main results Theorems 4 2 and 5 3 and I believe the analsis is sound.", "I do think the authors made a typo in the definition of $g$ in Theorem 5 3; you should remove the negative sign (indeed the logarithm in (5 4) is not well-defined if the negative sign stays!).", "I would have liked a more useful/detailed version of what is currently Corollary 5 4, It currently glosses over too many details to realy say much.", "Since you have extra space in the paper, I recommend including a more explicit version of this corollary.", "You should alo include around this point a citation to the Raginsky / Rakhlin / Telgarsky (2017) paper that you refer to in the appendix.", "I alo recommend giving, at least in the appendix, a precise citation of which result from their paper you are using.", "Minor comments: You never explain the notation for the squiggly arrow in the main paper.", "Please fix this.", "It is too important / widely used in the main text to be left to the appendix.", "On page 4, line 2, you say ``the above result''.", "I think you are referring to Definition 3 1, which is of course a definition, not a result.", "So, you should change the text accordingly.", "In Theorem 3 2, you have one instance of $n$ which should be replaced by $m$ (see the inline math following the word ``Then'') In the proof of Lemma D 1, you should mention that the upper bound of totalvariation by KL divergence is from Pinsker's ineqalty.", "``Standard results'' is a bit vague to inform the uninformed reader.", "%% UPDATE AFTER AUTHOR'S RESPONSE %% I've read the author's rebuttaland their responses are satisfactory.", "I do hope you will highlight the weakness of the high probability bound involving the 1/\\delta' dependence."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_777_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_760_1", "review_text": "In this paper, a multi-source domain adaptation algorithm is proposed, which is derived from the theory by Mansour et al. 2008 that to learn a weighted combination of source distributions. The authors discussed the proposed algorithm in the stochastic scenario, which is important for being applied into deep neural networks. Experiments on a few benchmarks show that the proposed approach outperforms a few baselines.  Generally, the paper is well written, and the algorithm development is reasonable. However, multiple source domain adaptation is not a new problem, and many approaches have been proposed to tackle with this task based on various principles. Unfortunately, the authors did not present a thorough discussion the connection with existing related works,  [Hoffman et al. 2012, Gong et al 2013b, Xu et al. 2014, Zhang et al. 2015] and reference below. No experimental comparison is provided either. It is interesting to see an instantiation of Mansour\u00e2\u0080\u0099s theory, but the work in its current form is not sufficiently convincing.   [ref-1] Lixin Duan, Dong Xu, Ivor Wai-Hung Tsang. Domain Adaptation from Multiple Sources: A Domain-Dependent Regularization Approach. In IEEE Transactions on Neural Networks and Learning Systems (T-NNLS), 2012. [ref-2] Aditya Khosla, Tinghui Zhou, Tomasz Malisiewicz, Alexei A. Efros, Antonio Torralba. Undoing the Damage of Dataset Bias. In ECCV 2012.  [ref-3] Saeid Motiian, Marco Piccirilli, Donald A. Adjeroh, Gianfranco Doretto. Unified Deep Supervised Domain Adaptation and Generalization. In ICCV 2017.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_760_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["In this paper, a multi-source domain adaptation alorithm is proposed, which is derived from the theory by Mansour et al 2008 that to learn a weighted combination of source distributions.", "The authors discussed the proposed alorithm in the stochastic scenario, which is important for being applied into deep neuralnetworks.", "Experiments on a few benchmarks show that the proposed approach outperforms a few baselines.", "Generaly, the paper is well written, and the alorithm development is reasonable.", "However, multiple source domain adaptation is not a new problem, and many approaches have been proposed to tackle with this task based on various principles.", "Unfortunately, the authors did not present a thorough discussion the connection with existing related works, [Hoffman et al 2012, Gong et al2013b, Xu et al 2014, Zhang et al 2015] and reference below.", "No experimentalcomparison is provided either.", "It is interesting to see an instantiation of Mansour\u00e2\u0080\u0099s theory, but the work in its current form is not sufficiently convincing.", "[ref-1] Lixin Duan, Dong Xu, Ivor Wai-Hung Tsang.", "Domain Adaptation from Multiple Sources: A Domain-Dependent Regularization Approach.", "In IEEE Transactions on NeuralNetworks and Learning Systems (T-NNLS), 2012, [ref-2] Aditya Khosla, Tinghui Zhou, Tomasz Malsiewicz, Alexei A Efros, Antonio Torrala.", "Undoing the Damage of Dataset Bias.", "In ECCV 2012, [ref-3] Saeid Motiian, Marco Piccirilli, Donal A Adjeroh, Gianfranco Doretto.", "Unified Deep Supervised Domain Adaptation and Generalzation.", "In ICCV 2017,"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_760_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_747_1", "review_text": "The paper tackles a multi-agent credit assignment problem, an egregious problem within multi-agent systems by extending existing methods on difference rewards for settings in which the population of the system is large. Though the results are relevant and lead to an improvement for large population systems, the contribution is nonetheless limited to a modification of existing techniques for a specific setting which seemingly requires the number of agents to be large and for the agents to observe a count of the agents within their neighbourhood. The results of the paper enable improved credit assignment in the presence of noise from other agents' actions, an improved baseline leading to reduced variance and, in turn, better estimates of the collective policy gradient (under homogeneity assumptions). The analysis of the paper applies to a specific setting in which the reward function has a term that is common to all agents and therefore is not decomposable. The extent to which this property is to be found in multi-agent systems, however, is not discussed. The setting is also partially observable multi-agent system - an instance of which is motivated by the authors. This, as the authors claim, implies that the agents need not observe the full state but need only make local observations for which the problem is formulated using a decentralised POMDP framework. The claims of the paper are supported by some theoretical results though some important details on which the theory rely seem to be omitted. Additionally, the analysis of the paper is accompanied by some experiments that showcase the benefits of the approach. A weakness of the general method is that the approach seems to alleviate computational complexity during execution of a learned policy but during the learning phase, however, the method seems not to alleviate the problem of explosive complexity in the number of agents which may cause tractability issues for large populations. Furthermore, the method seems reliant on the population size being large for the approximations to hold though the paper does not include a discussion on when the population size is reasonably large for the method to be valid. Finally, though the contribution is useful for the given setting, it is not clear how often the central assumption of non-decomposability occurs in multi-agent systems. (edited) There are also some other important questions that if addressed would improve the paper: In particular, though the setting of the paper is said to be a partially observable - it seems that 'distant' agents do not have an immediate effect on the agents\u00e2\u0080\u0099 rewards since the rewards depend on variables that are defined locally  (though they may interact with the agent at some later time). In this sense each agent's observations fully capture all relevant state information - it doesn't seem as though extra information concerning the agent's immediate reward or state transition can be inferred by including global information.  Secondly, the authors introduce the notion of agent types as a way of introducing heterogeneity into the formalism. The notion of agent types, however, seems inconsistent since it is assumed that the agents have the same policy which would differ for different agent types if type is any meaningful parameter (i.e. determines the agents' rewards/state transition probabilities). Additionally, heterogeneity from agent types also seems not to fit with the idea of a global critic.  Lastly, the advantage function (15) as used in the cited paper is used in a team game setting when agents have the same reward function. There are a number of details on which the theory is built that are omitted - in particular:  1. The authors do not state conditions under which sufficient statistic is actually sufficient (is this derived from application of the law of large numbers?) - this also seems to impose conditions of homogeneity on the agents - without a clear statement of the conditions under which this holds, some other statements are hard to evaluate e.g. line 163: \"which makes learning scalable even with very large number of agents\" and \"Crucially, the above computation is independent of agent population M\"- it seems that these statements in fact only hold in cases when M is large. This also arises in lines 195-196 where M must be large for the approximation to be valid as well as in the proof B1.  2. The authors state that \"Previous work shows that count tables are the sufficient statistic for planning\" - this seems to be fairly fundamental, it would be of great benefit to the reader to have a citation and a reference to the result for this remark. The paper would also benefit from a discussion on the solution admitted by the method. Specifically, though the setting is non-cooperative since each agent maximises their individual rewards the examples discussed nonetheless suggest the authors seek to target cooperative or team games. Though cooperative and team-based games can be tackled in a decentralised way,  the stable points in non-cooperative game setting (i.e. Markov game) are described by Nash equilibria (Markov-perfect Nash equilibria) which are in general inefficient from a social welfare perspective. The authors ought to include a discussion on how they expect the payoffs from the learned policies which seem to be generated by Nash equilibrium strategies to perform in relation to the system goal in general and, possibly how they might overcome challenges of inefficiency from non-cooperative challenges.    3. What is the meaning of d - can the authors give an example?  4. Additionally, the authors state that \"We assume that Qw is differentiable in all input parameters\". This doesn't seem to be a reasonable assumption given that one of the inputs n^{sa} is a discrete integer count.    The reason for my score is the following. The paper is clearly written leading to a coherent exposition and its objectives are clearly stated. The contribution seems however only incremental given the existing (and cited) methods on difference rewards and in the absence of clear statements when the method is most applicable. The crucial element, however, is about the correctness of the method. I have two major concerns: i) about the differentiability of Q_w* and ii) about small population sizes. There's also a (minor) issue about the claim that the method can work with heterogeneous populations, where the method, which seems to depend on one single policy being learned, may break down. i) The assumption of differentiability of Q_w*, which appears to be (likely) invalidated in the current setting as one of its inputs is a discrete integer variable. This seems to me to be a concern as differentiation here is ill-defined. The authors have not addressed this issue in their rebuttal.   ii) The derivations of the Q function estimates rely on large populations (e.g. eqs. (5), (9)), and use previous results (e.g. citations [4] and [6] on the appendix) but those papers (beside having many notational inconsistencies) also rely on large populations.  Overall, the paper is well written and easy to follow, but I  have major concerns with the correctness of the method. Also, reading the previous papers that this paper heavily relies on, the contribution looks very incremental. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_747_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["The paper tackles a multi-agent credit assignment problem, an egregious problem within multi-agent systems by extending existing methods on difference rewards for settings in which the population of the system is large.", "Though the results are relevant and lead to an improvement for large population systems, the contribution is nonetheless limited to a modification of existing techniques for a specific setting which seemingly reqires the number of agents to be large and for the agents to observe a count of the agents within their neighbourhood.", "The results of the paper enable improved credit assignment in the presence of noise from other agents' actions, an improved baseline leading to reduced variance and, in turn, better estimates of the collective policy gradient (under homogeneity assumptions).", "The analsis of the paper applies to a specific setting in which the reward function has a term that is common to al agents and therefore is not decomposable.", "The extent to which this property is to be found in multi-agent systems, however, is not discussed.", "The setting is alo partialy observable multi-agent system - an instance of which is motivated by the authors.", "This, as the authors claim, implies that the agents need not observe the full state but need only make localobservations for which the problem is formulated using a decentralsed POMDP framework.", "The claims of the paper are supported by some theoreticalresults though some important details on which the theory rely seem to be omitted.", "Additionaly, the analsis of the paper is accompanied by some experiments that showcase the benefits of the approach.", "A weakness of the generalmethod is that the approach seems to aleviate computationalcomplexity during execution of a learned policy but during the learning phase, however, the method seems not to aleviate the problem of explosive complexity in the number of agents which may cause tractability issues for large populations.", "Furthermore, the method seems reliant on the population size being large for the approximations to hold though the paper does not include a discussion on when the population size is reasonably large for the method to be vald.", "Finaly, though the contribution is useful for the given setting, it is not clear how often the centralassumption of non-decomposability occurs in multi-agent systems.", "(edited) There are alo some other important questions that if addressed would improve the paper: In particular, though the setting of the paper is said to be a partialy observable - it seems that 'distant' agents do not have an immediate effect on the agents\u00e2\u0080\u0099 rewards since the rewards depend on variables that are defined localy (though they may interact with the agent at some later time).", "In this sense each agent's observations fully capture al relevant state information - it doesn't seem as though extra information concerning the agent's immediate reward or state transition can be inferred by including globalinformation.", "secndly, the authors introduce the notion of agent types as a way of introducing heterogeneity into the formalsm.", "The notion of agent types, however, seems inconsistent since it is assumed that the agents have the same policy which would differ for different agent types if type is any meaningful parameter (i e determines the agents' rewards/state transition probabilities).", "Additionaly, heterogeneity from agent types alo seems not to fit with the idea of a globalcritic.", "Lastly, the advantage function (15) as used in the cited paper is used in a team game setting when agents have the same reward function.", "There are a number of details on which the theory is built that are omitted - in particular: 1, The authors do not state conditions under which sufficient statistic is actualy sufficient (is this derived from application of the law of large numbers?)", "- this alo seems to impose conditions of homogeneity on the agents - without a clear statement of the conditions under which this holds, some other statements are hard to evalate e g line 163: \"which makes learning scalble even with very large number of agents\" and \"Crucialy, the above computation is independent of agent population M\"- it seems that these statements in fact only hold in cases when M is large.", "This alo arises in lines 195-196 where M must be large for the approximation to be vald as well as in the proof B1, 2, The authors state that \"Previous work shows that count tables are the sufficient statistic for planning\" - this seems to be fairly fundamental it would be of great benefit to the reader to have a citation and a reference to the result for this remark.", "The paper would alo benefit from a discussion on the solution admitted by the method.", "Specificaly, though the setting is non-cooperative since each agent maximises their individualrewards the examples discussed nonetheless suggest the authors seek to target cooperative or team games.", "Though cooperative and team-based games can be tackled in a decentralsed way, the stable points in non-cooperative game setting (i e Markov game) are described by Nash eqilibria (Markov-perfect Nash eqilibria) which are in generalinefficient from a socialwelfare perspective.", "The authors ought to include a discussion on how they expect the payoffs from the learned policies which seem to be generated by Nash eqilibrium strategies to perform in relation to the system goalin generaland, possibly how they might overcome chalenges of inefficiency from non-cooperative chalenges.", "3, What is the meaning of d - can the authors give an example?", "4, Additionaly, the authors state that \"We assume that Qw is differentiable in al input parameters\".", "This doesn't seem to be a reasonable assumption given that one of the inputs n^{sa} is a discrete integer count.", "The reason for my score is the following.", "The paper is clearly written leading to a coherent exposition and its objectives are clearly stated.", "The contribution seems however only incrementalgiven the existing (and cited) methods on difference rewards and in the absence of clear statements when the method is most applicable.", "The crucialelement, however, is about the correctness of the method.", "I have two major concerns: i) about the differentiability of Q_w* and ii) about smal population sizes.", "There's alo a (minor) issue about the claim that the method can work with heterogeneous populations, where the method, which seems to depend on one single policy being learned, may break down.", "i) The assumption of differentiability of Q_w*, which appears to be (likely) invaldated in the current setting as one of its inputs is a discrete integer variable.", "This seems to me to be a concern as differentiation here is ill-defined.", "The authors have not addressed this issue in their rebuttal ii) The derivations of the Q function estimates rely on large populations (e g eq.", "(5), (9)), and use previous results (e g citations [4] and [6] on the appendix) but those papers (beside having many notationalinconsistencies) alo rely on large populations.", "Overal, the paper is well written and easy to follow, but I have major concerns with the correctness of the method.", "Also, reading the previous papers that this paper heavily relies on, the contribution looks very incremental"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_747_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_743_3", "review_text": "UPDATED REVIEW: the authors responded to most comments. Although they provided details in the response, It's not clear to me if they will include discussions of (1) piecewise activation functions and in neuroscience e.g. two-compartment models in the related work (2) generalization (+learning curves) in the manuscript; I think both these things would improve the work. I still find it strange that no generalization results were presented in the original submission.  I agree with the other reviewers that the title sounds strange (typically you're advised not to use subjective descriptions like \"great\" or \"amazing\" in scientific work). I have updated my rating to 6.  ========================  PAPER SUMMARY:The authors propose a network architecture to model synaptic plasticity in dendritic arbours, which ends up looking to me like alternating layers of maxout and regular units, with some randomly-dropped connections. The proposed architecture is tested on MNIST, CIFAR, and a range of UCI classification tasks, and found to outperform alternatives. Insight about why this is the case is provided in the form of an analysis of expressivity, measured as number of linear regions in loss space.  STRENGTHS:   - quality: The paper is generally well-written and the structure and experiments are largely well-suited to evaluate the proposed architecture. The introduction and related work do a good job contextualizing the work. The experiments about expressivity are interesting and relevant.   - clarity: What is proposed and what is done are both clear. Details of datasets, experiments, and explanations of related work are generally very good.   - originality: To my knowledge, the proposed architecture is novel. Being somewhat familiar with the biology, I find piecewise linear/max operations a reasonable approximation intuitively.   WEAKNESSES:   - quality: It seems to me that the chosen \"algorithm\" for choosing dendrite synapses is very much like dropout with a fixed mask. Introducing this sparsity is a form of regularization, and a more fair comparison would be to do a similar regularization for the feed-forward nets (e.g. dropout, instead of bn/ln; for small networks like this as far as I know bn/ln are more helpful for optimization than regularization). It also seems to me that the proposed structure is very much like alternating layers of maxout and regular units, with this random-fixed dropout; I think this would be worth comparing to.  I think there are some references missing, in the area of similar/relevant neuroscience models and in the area of learned piecewise activation functions.  It would be reassuring to mention the computation time required and whether this differs from standard ff nets. Also, most notably, there are no accuracy results presented, no val/test results, and no mention is made of generalization performance for the MNIST/CIFAR experiments.    - clarity:  Some of the sentences are oddly constructed, long, or contain minor spelling and grammar errors .The manuscript should be further proofread for these issues. For readers not familiar with the biological language, it would be helpful to have a diagram of a neuron/dendritic arbour; in the appendix if necessary. It was not 100% clear to me from the explanations whether or not the networks compared have the same numbers of parameters; this seems like an important point to confirm.   - significance: I find it hard to assess the significance without generalizaion/accuracy results for the MNIST/CIFAR experiments.   REPRODUCABILITY: For the most part the experiments and hyperparameters are well-explained (some specific comments below), and I would hope the authors would make their code available.  SPECIFIC COMMENTS:   - in the abstract, I think it should say something like \"...attain greater expressivity, as measured by the change in linear regions in output space after [citation]. \" instead of just \"attain greater expressivity\"   - it would be nice to see learning curves for all experiments, at least in an appendix.    - in Figure 1, it would be very helpful to show a FNN and D-Net with the same number of parameters in each (unless I misunderstood, the FNN has 20 and the DNN has 16).   - There are some \"For the rest part\" -> for the rest of (or rephrase)   - missing references: instead of having a section just about Maxout networks, I think the related work should have a section called something like \"learned piecewise-linear activation functions\" which includes maxout and other works in this category, e.g. Noisy Activation Functions (Gulcehre 2016). Also, it's not really my field but I believe there is some work on two-compartment models in neuroscience and modeling these as deep nets which would be quite relevant for this work.   - It always bothers me somewhat when people refer to the brain as 'sparse' and use this as a justification for sparse neural networks. Yes, overall/considering all neurons the brain as one network it would be sparse, but building a 1000 unit network to do classification is much more analogous to a functional subunit of the brain (e.g. a subsection of the visual pathway), and connections in these networks are frequently quite dense. The authors are not the first to make this argument and I am certainly not blaming them for its origin, but I take this opportunity to point it out as (I believe) flawed. :)   - the definition of \"neuron transition\" is not clear to me - the sentence before Definition 2 suggests that it is a change in _classification_ (output space), which leads to a switch in the linear region of a piecewise linear function, but the Definition and the subsequent sentence seem to imply it is only the latter part (a change from one linear region of the activation function to another; nothing to do with the output space). If the latter, it is not clear to me how/whether or not these \"transitions\" say anything useful about learning. If it is the former (more similar to Raghu et al), I find the definition given unclear.    - I like the expressiveness experiments, but It would be nice to see some actual numbers instead of just descriptions.   - unless I missed it somehow, the \"SNN\" is never defined. and it is very unclear to me whether it refers to a self-organizing neural network cited in [12]. or a \"sparse\" neural network, and in any case what exactly this architecture is.   - also possible I missed it despite looking, but I could not find what non-linearity is used on D-Nets for the non-dendrite units   OVERALL ASSESSMENT: My biggest issue with the paper is the lack of mention/results about generalization on MNIST/CIFAR, and the ambiguity about fair comparison. If these issues are resolved I would be very willing to change my rating.  CONFIDENCE IN MY SCORE: This is the first time I've given a confidence of 5. With due credit to the authors, I believe I've understood most things about the paper, and I am familiar with the relevant work. Of course I'm not infallible and it's possible I've missed or misunderstood something, especially relating to the things I noted finding unclear.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_743_3", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["UPDATED REVIEW: the authors responded to most comments.", "Although they provided details in the response, It's not clear to me if they will include discussions of (1) piecewise activation functions and in neuroscience e g two-compartment models in the related work (2) generalzation (+learning curves) in the manuscript; I think both these things would improve the work.", "I still find it strange that no generalzation results were presented in the originalsubmission.", "I agree with the other reviewers that the title sounds strange (typicaly you're advised not to use subjective descriptions like \"great\" or \"amazing\" in scientific work).", "I have updated my rating to 6, ======================== PAPER SUMMARY:The authors propose a network architecture to model synaptic plasticity in dendritic arbours, which ends up looking to me like alernating layers of maxout and regular units, with some randomly-dropped connections.", "The proposed architecture is tested on MNIST, CIFAR, and a range of UCI classification tasks, and found to outperform alernatives.", "Insight about why this is the case is provided in the form of an analsis of expressivity, measured as number of linear regions in loss space.", "STRENGTHS: - qualty: The paper is generaly well-written and the structure and experiments are largely well-suited to evalate the proposed architecture.", "The introduction and related work do a good job contextualzing the work.", "The experiments about expressivity are interesting and relevant.", "- clarity: What is proposed and what is done are both clear.", "Details of datasets, experiments, and explanations of related work are generaly very good.", "- originalty: To my knowledge, the proposed architecture is novel.", "Being somewhat familiar with the biology, I find piecewise linear/max operations a reasonable approximation intuitively.", "WEAKNESSES: - qualty: It seems to me that the chosen \"alorithm\" for choosing dendrite synapses is very much like dropout with a fixed mask.", "Introducing this sparsity is a form of regularization, and a more fair comparison would be to do a similar regularization for the feed-forward nets (e g dropout, instead of bn/ln; for smal networks like this as far as I know bn/ln are more helpful for optimization than regularization).", "It alo seems to me that the proposed structure is very much like alernating layers of maxout and regular units, with this random-fixed dropout; I think this would be worth comparing to.", "I think there are some references missing, in the area of similar/relevant neuroscience models and in the area of learned piecewise activation functions.", "It would be reassuring to mention the computation time reqired and whether this differs from standard ff nets.", "Also, most notably, there are no accuracy results presented, no valtest results, and no mention is made of generalzation performance for the MNIST/CIFAR experiments.", "- clarity: Some of the sentences are oddly constructed, long, or contain minor spelling and grammar errors .The manuscript should be further proofread for these issues.", "For readers not familiar with the biologicallanguage, it would be helpful to have a diagram of a neuron/dendritic arbour; in the appendix if necessary.", "It was not 100% clear to me from the explanations whether or not the networks compared have the same numbers of parameters; this seems like an important point to confirm.", "- significance: I find it hard to assess the significance without generalzaion/accuracy results for the MNIST/CIFAR experiments.", "REPRODUCABILITY: For the most part the experiments and hyperparameters are well-explained (some specific comments below), and I would hope the authors would make their code available.", "SPECIFIC COMMENTS: - in the abstract, I think it should say something like \"...attain greater expressivity, as measured by the change in linear regions in output space after [citation]. \"", "instead of just \"attain greater expressivity\" - it would be nice to see learning curves for al experiments, at least in an appendix.", "- in figre 1, it would be very helpful to show a FNN and D-Net with the same number of parameters in each (unless I misunderstood, the FNN has 20 and the DNN has 16).", "- There are some \"For the rest part\" -> for the rest of (or rephrase) - missing references: instead of having a secion just about Maxout networks, I think the related work should have a secion caled something like \"learned piecewise-linear activation functions\" which includes maxout and other works in this category, e g Noisy Activation Functions (Gulcehre 2016).", "Also, it's not realy my field but I believe there is some work on two-compartment models in neuroscience and modeling these as deep nets which would be quite relevant for this work.", "- It alays bothers me somewhat when people refer to the brain as 'sparse' and use this as a justification for sparse neuralnetworks.", "Yes, overal/considering al neurons the brain as one network it would be sparse, but building a 1000 unit network to do classification is much more analgous to a functionalsubunit of the brain (e g a subsecion of the visualpathway), and connections in these networks are freqently quite dense.", "The authors are not the first to make this argument and I am certainly not blaming them for its origin, but I take this opportunity to point it out as (I believe) flawed.", ":) - the definition of \"neuron transition\" is not clear to me - the sentence before Definition 2 suggests that it is a change in _classification_ (output space), which leads to a switch in the linear region of a piecewise linear function, but the Definition and the subseqent sentence seem to imply it is only the latter part (a change from one linear region of the activation function to another; nothing to do with the output space).", "If the latter, it is not clear to me how/whether or not these \"transitions\" say anything useful about learning.", "If it is the former (more similar to Raghu et al, I find the definition given unclear.", "- I like the expressiveness experiments, but It would be nice to see some actualnumbers instead of just descriptions.", "- unless I missed it somehow, the \"SNN\" is never defined.", "and it is very unclear to me whether it refers to a self-organizing neuralnetwork cited in [12].", "or a \"sparse\" neuralnetwork, and in any case what exactly this architecture is.", "- alo possible I missed it despite looking, but I could not find what non-linearity is used on D-Nets for the non-dendrite units OVERALL ASSESSMENT: My biggest issue with the paper is the lack of mention/results about generalzation on MNIST/CIFAR, and the ambiguity about fair comparison.", "If these issues are resolved I would be very willing to change my rating.", "CONFIDENCE IN MY SCORE: This is the first time I've given a confidence of 5, With due credit to the authors, I believe I've understood most things about the paper, and I am familiar with the relevant work.", "Of course I'm not infalible and it's possible I've missed or misunderstood something, especialy relating to the things I noted finding unclear."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_743_3", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_743_2", "review_text": "[I include in square brackets, below in my point-by-point criticisms, my responses to the author's feedback on the review. Overall, my opinion has not changed: this is a strong submission.]  The authors build a new neural network architecture (D-nets) in which inputs impinge on different dendritic branches, each of which takes a weighted some over those inputs. The unit output is the max over the activations of its dendritic branches. This is a variant on the maxout networks, which have a similar architecture. The key difference appears to be that the D-net dendritic branches get sparse non-overlapping sets of inputs, whereas in maxout, each branch gets all of the inputs.  The authors use a similar proof strategy to Ref. 6, to show that D-nets can be universal function approximators, and evaluate both the expressivity of their networks (using transition number as the measure), and the performance of their networks on a wide range of ML tasks. Performance is compared with maxout, and with traditional neural nets, and the D-nets are found to have the highest expressivity and best performance of the architectures considered.  Overall, I was impressed by this submission. The comparisons to previous network structures are very thorough, the performance appears to be quite good, the D-net idea is straightforward but (as far as I can tell) somewhat novel, and the paper is relatively well-written.  I have a few comments / suggestions, listed below.  1. The proof in Section 3.2 is nice, but a little restrictive. It would be nice to have a more general proof, applying to conditions other than d_1=1. If such a proof is possible, I would highly recommend including it. Also, if there are conditions on d such that the networks are not universal function approximators, those conditions should be identified and stated.  [I am glad to hear that the proof can be generalized beyond d_1=1. I am somewhat concerned about the need for non-random connectivity that the first layer: is the requirement very restrictive? It would be worth clarifying that requirement (when it is likely to be satisfied or not), so that readers know clearly when they should, or should not, expect the DNNs to be universal function approximators.]  2. In the discussion of Sparse neural networks, there are a few recent neuroscience papers that are relevant, and that the authors should consider reading and/or citing (listed below). These might inform the optimal \"d\" values of the D-networks, and the methods from these papers could be relevant for understanding the optimal \"d\" values in the D-nets.  a) Litwin-Kumar, A., Harris, K.D., Axel, R., Sompolinsky, H. and Abbott, L.F., 2017. Optimal degrees of synaptic connectivity. Neuron, 93(5), pp.1153-1164.  b) Cayco-Gajic, N.A., Clopath, C. and Silver, R.A., 2017. Sparse synaptic connectivity is required for decorrelation and pattern separation in feedforward networks. Nature Communications, 8(1), p.1116.  [I am glad that you found these useful.]  3. It took me awhile to figure out that the acronyms  \"BN\" and \"LN\" in the figures and captions were batch norm and layer norm. I would suggest spelling those out in the legend to Fig. 4.  [Thanks for adding these; I think they will help with clarity.]  4. Why give the Avg. rank diff. instead of just Avg. rank? As far as I can tell, these diff values are just avg. rank - 4.5, and reporting them makes the actual rank values less transparent.  [It sounds like you will change these to avg. rank, which I support. I understand that there is precedent for the other way of reporting the results (avg. rank diff.), but sometimes previous work was flawed, and it's best not to repeat those flaws...]", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_743_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["[I include in square brackets, below in my point-by-point criticisms, my responses to the author's feedback on the review.", "Overal, my opinion has not changed: this is a strong submission.]", "The authors build a new neuralnetwork architecture (D-nets) in which inputs impinge on different dendritic branches, each of which takes a weighted some over those inputs.", "The unit output is the max over the activations of its dendritic branches.", "This is a variant on the maxout networks, which have a similar architecture.", "The key difference appears to be that the D-net dendritic branches get sparse non-overlapping sets of inputs, whereas in maxout, each branch gets al of the inputs.", "The authors use a similar proof strategy to Ref.", "6, to show that D-nets can be universalfunction approximators, and evalate both the expressivity of their networks (using transition number as the measure), and the performance of their networks on a wide range of ML tasks.", "Performance is compared with maxout, and with traditionalneuralnets, and the D-nets are found to have the highest expressivity and best performance of the architectures considered.", "Overal, I was impressed by this submission.", "The comparisons to previous network structures are very thorough, the performance appears to be quite good, the D-net idea is straightforward but (as far as I can tell) somewhat novel, and the paper is relatively well-written.", "I have a few comments / suggestions, listed below.", "1, The proof in secion 3 2 is nice, but a little restrictive.", "It would be nice to have a more generalproof, applying to conditions other than d_1=1, If such a proof is possible, I would highly recommend including it.", "Also, if there are conditions on d such that the networks are not universalfunction approximators, those conditions should be identified and stated.", "[I am glad to hear that the proof can be generalzed beyond d_1=1, I am somewhat concerned about the need for non-random connectivity that the first layer: is the reqirement very restrictive?", "It would be worth clarifying that reqirement (when it is likely to be satisfied or not), so that readers know clearly when they should, or should not, expect the DNNs to be universalfunction approximators.]", "2, In the discussion of Sparse neuralnetworks, there are a few recent neuroscience papers that are relevant, and that the authors should consider reading and/or citing (listed below).", "These might inform the optimal\"d\" vales of the D-networks, and the methods from these papers could be relevant for understanding the optimal\"d\" vales in the D-nets.", "a) Litwin-Kumar, A , Harris, K D , Axel, R , Sompolinsky, H and Abbott, L F , 2017, Optimaldegrees of synaptic connectivity.", "Neuron, 93(5), pp.1153-1164, b) Cayco-Gajic, N A , Clopath, C and Silver, R A , 2017, Sparse synaptic connectivity is reqired for decorrelation and pattern separation in feedforward networks.", "Nature Communications, 8(1), p 1116, [I am glad that you found these useful.]", "3, It took me awhile to figre out that the acronyms \"BN\" and \"LN\" in the figres and captions were batch norm and layer norm.", "I would suggest spelling those out in the legend to fig 4, [Thanks for adding these; I think they will help with clarity.]", "4, Why give the Avg.", "rank diff.", "instead of just Avg.", "rank?", "As far as I can tell, these diff vales are just avg.", "rank - 4 5, and reporting them makes the actualrank vales less transparent.", "[It sounds like you will change these to avg.", "rank, which I support.", "I understand that there is precedent for the other way of reporting the results (avg.", "rank diff.", "), but sometimes previous work was flawed, and it's best not to repeat those flaws...]"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_743_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_73_2", "review_text": "Summary The authors trained spiking neural networks to perform sequential MNIST, TIMIT, learning to learn families of non-linear transformations, and meta-reinforcement learning of water mazes. To accomplish this, they trained a population of LIF neurons using BPTT with smooth pseudo-derivatives around the spikes and the deep rewiring algorithm for tuning network connectivity. Some of the LIF neurons had an adapting property whereby their excitability was reduced after firing.  Positives The idea of doing sequence classification, L2L, and meta-rl problems in spiking networks is very appealing, because of the applications in modeling of biological neural activity and neuromorphic computing. The tasks are compelling and the results seem strong. Even though the critical learning algorithm, BPTT, doesn't have a biological interpretation, the fact that the authors are able to solve these tasks with RSNNs at all appears to be a technical feat and a useful demonstration.   Areas for Improvement However, the paper doesn't provide a historical summary of the state of the art for RSNNs applied to these sorts of problems, so as someone without a working knowledge of that literature, I'm not able to evaluate how large of an advance the paper makes beyond prior work.  Further, the paper doesn't clearly explain the motivation behind the architecture and learning algorithm design. What's the role of the adaptive LIF units? Do they help with long-term dependencies somehow? Why does the architecture have \"Long short term memory\" in its name? Is it to do with the adaptive units, rewiring algorithm, something else? What are the essential differences between this architecture and, say, a homogenous population of LIF neurons, which make it better suited to tasks with long-term dependencies? Does deep rewiring matter -- what happens without it? In order to understand the implications of this work, these issues need to be made clear.  Summary I think the quality of the work behind this paper is probably strong, but the lack of clarity makes it difficult to understand the implications of the work and to assess its originality and significance. I think an improved draft on this work could be quite a strong paper, but I'll have to recommend rejection for now.  Edit after author feedback and reviewer discussion: In their rebuttal the authors explained the novelty of the work and justified some design/naming choices I asked about in my review. However, the rebuttal didn't indicate exactly how they would fix the clarity problems that led me to need to ask about those two points. Overall this seems to me like valuable work written in a somewhat unsatisfactory manner. I increased my rating to 6 to reflect the apparent quality of the underlying work, and hope the authors improve the clarity for the camera ready. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_73_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary The authors trained spiking neuralnetworks to perform seqentialMNIST, TIMIT, learning to learn families of non-linear transformations, and meta-reinforcement learning of water mazes.", "To accomplish this, they trained a population of LIF neurons using BPTT with smooth pseudo-derivatives around the spikes and the deep rewiring alorithm for tuning network connectivity.", "Some of the LIF neurons had an adapting property whereby their excitability was reduced after firing.", "Positives The idea of doing seqence classification, L2L, and meta-rl problems in spiking networks is very appealng, because of the applications in modeling of biologicalneuralactivity and neuromorphic computing.", "The tasks are compelling and the results seem strong.", "Even though the criticallearning alorithm, BPTT, doesn't have a biologicalinterpretation, the fact that the authors are able to solve these tasks with RSNNs at al appears to be a technicalfeat and a useful demonstration.", "Areas for Improvement However, the paper doesn't provide a historicalsummary of the state of the art for RSNNs applied to these sorts of problems, so as someone without a working knowledge of that literature, I'm not able to evalate how large of an advance the paper makes beyond prior work.", "Further, the paper doesn't clearly explain the motivation behind the architecture and learning alorithm design.", "What's the role of the adaptive LIF units?", "Do they help with long-term dependencies somehow?", "Why does the architecture have \"Long short term memory\" in its name?", "Is it to do with the adaptive units, rewiring alorithm, something else?", "What are the essentialdifferences between this architecture and, say, a homogenous population of LIF neurons, which make it better suited to tasks with long-term dependencies?", "Does deep rewiring matter -- what happens without it?", "In order to understand the implications of this work, these issues need to be made clear.", "Summary I think the qualty of the work behind this paper is probably strong, but the lack of clarity makes it difficult to understand the implications of the work and to assess its originalty and significance.", "I think an improved draft on this work could be quite a strong paper, but I'll have to recommend rejection for now.", "Edit after author feedback and reviewer discussion: In their rebuttalthe authors explained the novelty of the work and justified some design/naming choices I asked about in my review.", "However, the rebuttaldidn't indicate exactly how they would fix the clarity problems that led me to need to ask about those two points.", "Overal this seems to me like valable work written in a somewhat unsatisfactory manner.", "I increased my rating to 6 to reflect the apparent qualty of the underlying work, and hope the authors improve the clarity for the camera ready."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_73_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_73_1", "review_text": "Summary  Recurrent networks of leaky integrate-and-fire neurons with (spike frequency) adaptation are trained with backpropagation-through-time (adapted to spiking neurons) to perform digit recognition (temporal MNIST), speech recognition (TIMIT), learning to learn simple regression tasks and learning to find a goal location in simple navigation tasks. The performances on temporal MNIST and TIMIT are similar to the one of LSTM-networks. The simple regression and navigation task demonstrate that connection weights exist that allow to solve simple tasks using the short-term memory of spiking neurons with adaptation, without the need of ongoing synaptic plasticity.  Quality  The selection of tasks is interesting, the results are convincing and the supplementary information seems to provide sufficient details to reproduce them.  Clarity  The paper communicates the main messages clearly. But the writing could be improved significantly.   The introduction is not well structured. Why are the contributions in paragraphs 2 and 4 separated by the long paragraph on L2L? What is meant by the two levels of learning and representation (line 43)? Why is the discussion of the PFC and STDP relevant for the rest of the paper (lines 48 to 56)?  I did not understand the sentence that starts on line 123. Fig 1B seems to indicate that the LSNN performs similarly as an LSTM, not significantly better.  line 128: It would be helpful say here already, how the inputs are encoded for the spiking networks such that the reader does not need to go to the supplementary material to understand this aspect.  line 180: I did not understand how the network could learn to cheat.  Originality  The work seems original. But a section on related work is missing. There are also other works that try to solve (temporal) MNIST and TIMIT with networks of spiking neurons (e.g. https://doi.org/10.1016/j.neucom.2013.06.052). How is this work related to other approaches?  Significance  I enjoyed reading this work. It is nice to see networks of adaptive spiking neurons perform well on temporal MNIST and TIMIT and solve the simple regression and navigation tasks without synaptic plasticity (after having learned the domain knowledge). If the approach scales, it may also be interesting for neuromorphic hardware. What we learn about biological neural networks is less clear. Activity or short-term plasticity dependent models of working memory are well known in computational neuroscience (see e.g. http://dx.doi.org/10.1016/j.conb.2013.10.008) and the present work does not seem to make clear testable predictions beyond the observation that these networks are sufficient to solve the studied tasks.    Minor Points: - Why was the same adaptation time constant used for all neurons in the first two tasks, but a distributions of time constants for the second two tasks?  ==== After reading the author's response and the other reviews I am more convinced that this is exciting and novel work. But its presentation and embedding in the literature can clearly be improved. Regarding biological neural networks: I agree with the authors that the work demonstrates the power of adaptation in recurrent networks of spiking neurons. But the hypothesis that adaptation could be used as a form of activity-silent working memory is very straightforward and it is not clear to me, why nature would have favored this over e.g. activity-silent short-term-plasticity based working memory [Mongillo et al. 2008].", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_73_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Summary Recurrent networks of leaky integrate-and-fire neurons with (spike freqency) adaptation are trained with backpropagation-through-time (adapted to spiking neurons) to perform digit recognition (temporalMNIST), speech recognition (TIMIT), learning to learn simple regression tasks and learning to find a goallocation in simple navigation tasks.", "The performances on temporalMNIST and TIMIT are similar to the one of LSTM-networks.", "The simple regression and navigation task demonstrate that connection weights exist that alow to solve simple tasks using the short-term memory of spiking neurons with adaptation, without the need of ongoing synaptic plasticity.", "Qualty The selection of tasks is interesting, the results are convincing and the supplementary information seems to provide sufficient details to reproduce them.", "Clarity The paper communicates the main messages clearly.", "But the writing could be improved significantly.", "The introduction is not well structured.", "Why are the contributions in paragraphs 2 and 4 separated by the long paragraph on L2L?", "What is meant by the two levels of learning and representation (line 43)?", "Why is the discussion of the PFC and STDP relevant for the rest of the paper (lines 48 to 56)?", "I did not understand the sentence that starts on line 123, fig1B seems to indicate that the LSNN performs similarly as an LSTM, not significantly better.", "line 128: It would be helpful say here aleady, how the inputs are encoded for the spiking networks such that the reader does not need to go to the supplementary materialto understand this aspect.", "line 180: I did not understand how the network could learn to cheat.", "Originalty The work seems original But a secion on related work is missing.", "There are alo other works that try to solve (temporal MNIST and TIMIT with networks of spiking neurons (e g https://doi.org/10.1016/j neucom.2013.06.052).", "How is this work related to other approaches?", "Significance I enjoyed reading this work.", "It is nice to see networks of adaptive spiking neurons perform well on temporalMNIST and TIMIT and solve the simple regression and navigation tasks without synaptic plasticity (after having learned the domain knowledge).", "If the approach scals, it may alo be interesting for neuromorphic hardware.", "What we learn about biologicalneuralnetworks is less clear.", "Activity or short-term plasticity dependent models of working memory are well known in computationalneuroscience (see e g http://dx.doi.org/10.1016/j conb.2013.10.008) and the present work does not seem to make clear testable predictions beyond the observation that these networks are sufficient to solve the studied tasks.", "Minor Points: - Why was the same adaptation time constant used for al neurons in the first two tasks, but a distributions of time constants for the secnd two tasks?", "==== After reading the author's response and the other reviews I am more convinced that this is exciting and novel work.", "But its presentation and embedding in the literature can clearly be improved.", "Regarding biologicalneuralnetworks: I agree with the authors that the work demonstrates the power of adaptation in recurrent networks of spiking neurons.", "But the hypothesis that adaptation could be used as a form of activity-silent working memory is very straightforward and it is not clear to me, why nature would have favored this over e g activity-silent short-term-plasticity based working memory [Mongillo et al 2008]."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_73_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_739_1", "review_text": "The paper presents a learning scheme for deep policies which is based on sequentially combining existing methods of learning from demonstration and learning from human preferences. The experiments validate the approach with simulated and real human teachers, obtaining interesting results but still remaining some open questions.  It is said \"Expert demonstrations are always kept in the buffer\", so in cases wherein the demonstrations are not good, but the preferences of the teacher can lead to a high performance policy, there would be a problem, because the Demos are pulling the policy to a wrong area in the solution space. How to deal with this problem?   Is it possible to draw from the experiments, in which kind of problems the preferences have a higher impact for the policy improvement. It would be interesting to see comments in a generalized way, about what kind of problems are more problematic for learning with human preferences, and which are prone to be easily trained (e.g. the kind of problems that can get superhuman performance).  Results in Fig 3 (right) show something that can be really problematic in this presented approach. It is shown that the learned reward model is not aiming for the same objectives of the real reward function of the environment. So The RL agent always will try to maximize the reward function, however if it is wrong, obtaining high returns might be senseless (the method is not learning what the human teacher wants to teach, or the human understanding of the task is not complete). In those learning curves, the real return obtained at the end of the process is still an acceptable performance? It would be necessary more   Why in these experiments the learned model r only takes as input the observations? is it for simplifying the model? or because it is known that the real score might be based only in states and not in actions? what would happen when considering the actions along with the observations in these experiments?", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_739_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper presents a learning scheme for deep policies which is based on seqentialy combining existing methods of learning from demonstration and learning from human preferences.", "The experiments valdate the approach with simulated and realhuman teachers, obtaining interesting results but still remaining some open questions.", "It is said \"Expert demonstrations are alays kept in the buffer\", so in cases wherein the demonstrations are not good, but the preferences of the teacher can lead to a high performance policy, there would be a problem, because the Demos are pulling the policy to a wrong area in the solution space.", "How to dealwith this problem?", "Is it possible to draw from the experiments, in which kind of problems the preferences have a higher impact for the policy improvement.", "It would be interesting to see comments in a generalzed way, about what kind of problems are more problematic for learning with human preferences, and which are prone to be easily trained (e g the kind of problems that can get superhuman performance).", "Results in fig3 (right) show something that can be realy problematic in this presented approach.", "It is shown that the learned reward model is not aiming for the same objectives of the realreward function of the environment.", "So The RL agent alays will try to maximize the reward function, however if it is wrong, obtaining high returns might be senseless (the method is not learning what the human teacher wants to teach, or the human understanding of the task is not complete).", "In those learning curves, the realreturn obtained at the end of the process is still an acceptable performance?", "It would be necessary more Why in these experiments the learned model r only takes as input the observations?", "is it for simplifying the model?", "or because it is known that the realscore might be based only in states and not in actions?", "what would happen when considering the actions alng with the observations in these experiments?"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_739_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_738_2", "review_text": "In this paper, the authors have presented the notion of spectral signatures and demonstrate how they can be used to detect backdoor poisoning attacks. Our outlier detection method relies on the idea that learned representations for classifiers amplify signals crucial to classification. To me, the idea makes sense and have some promising results. I have only one concern for this paper. If SVD is employed for the method, what is the computational complexity of the proposed model? Can the method be applied to large-scale real-world applications?", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_738_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["In this paper, the authors have presented the notion of spectralsignatures and demonstrate how they can be used to detect backdoor poisoning attacks.", "Our outlier detection method relies on the idea that learned representations for classifiers amplify signal crucialto classification.", "To me, the idea makes sense and have some promising results.", "I have only one concern for this paper.", "If SVD is employed for the method, what is the computationalcomplexity of the proposed model?", "Can the method be applied to large-scal realworld applications?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_738_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_733_1", "review_text": "Thanks for the author feedback! ---- The paper proposes a modification to how attention is performed in sequence-to-sequence models. Instead of attending at the last layer of the encoder, each layer in the decoder attends to the corresponding layer in the  encoder. This modification allows the models to cover more source words compared to vanilla models. The paper presents a good comparison to previous methods. The visualization provide  useful information on what the model has learned and the ablation studies are also much appreciated. It is very interesting that the layer-wise attention helps them get better performance as they increase the number of layers compared to baseline model.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_733_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["Thanks for the author feedback!", "---- The paper proposes a modification to how attention is performed in seqence-to-seqence models.", "Instead of attending at the last layer of the encoder, each layer in the decoder attends to the corresponding layer in the encoder.", "This modification alows the models to cover more source words compared to vanilla models.", "The paper presents a good comparison to previous methods.", "The visualzation provide useful information on what the model has learned and the ablation studies are alo much appreciated.", "It is very interesting that the layer-wise attention helps them get better performance as they increase the number of layers compared to baseline model."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_733_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_732_2", "review_text": "This paper proposes an adversarial learning approach based on GAN for repairing software vulnerabilities. GAN learns the mapping from one discrete source domain to another target domain, which does not require labeled pairs. The proposed model is shown effectiveness and the experimental performance is close to previous seq2seq approach using labeled pairs of data.  Pros: * Security vulnerabilities in software programs pose serious risks and automatically repairing vulnerabilities is an important task to study.  * It is much easier to obtain unpaired data in many seq2seq applications. The idea of using GAN to learn a mapping between two domains is novel, which is effective to train the model without paired examples.  * The paper is well-organized and easy to follow. The proposed GAN framework and the two regularizations are generally sound.  * The experimental results prove the effectiveness of GAN for vulnerabilities repairing, which obtains comparable performance of state-of-the-art seq2seq models which use labeled pairs of data.   Cons: * The discussion of the differences in the results of AUTO and PREQ regularization could be added in the experiment section.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_732_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper proposes an adversariallearning approach based on GAN for repairing software vulnerabilities.", "GAN learns the mapping from one discrete source domain to another target domain, which does not reqire labeled pairs.", "The proposed model is shown effectiveness and the experimentalperformance is close to previous seqseqapproach using labeled pairs of data.", "Pros: * secrity vulnerabilities in software programs pose serious risks and automaticaly repairing vulnerabilities is an important task to study.", "* It is much easier to obtain unpaired data in many seqseqapplications.", "The idea of using GAN to learn a mapping between two domains is novel, which is effective to train the model without paired examples.", "* The paper is well-organized and easy to follow.", "The proposed GAN framework and the two regularizations are generaly sound.", "* The experimentalresults prove the effectiveness of GAN for vulnerabilities repairing, which obtains comparable performance of state-of-the-art seqseqmodels which use labeled pairs of data.", "Cons: * The discussion of the differences in the results of AUTO and PReqregularization could be added in the experiment secion."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_732_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_730_1", "review_text": "The authors propose a novel method for detecting adversarial attacks on neural network classifiers by modelling the distribution of outputs of hidden fully connected layers rather than the distribution of inputs which is commonly done. The method is called I-defender and it is compared with other methods on an extensive set of benchmarks. The distribution of outputs of the hidden layers is modelled as a mixture of Gaussians which is fit using the EM algorithm.  I'm not at all familiar with the literature on adversarial attacks so I can only write a review assuming the overview of related work in the submission is accurate.  The paper is very clearly written and does a good job of explaining its contributions. The experiments are sensible and show clearly show excellent performance of the suggested approach, often beating the state-of-the-art methods. The idea of modelling the distribution of hidden layers instead of inputs makes a lot of sense to me and if it is indeed novel then it can have a lot of impact.  One general concern I have regarding the approach of detecting adversarial examples by modelling the distribution of real data is that innocent inputs from a different distribution than the training set (such as digits written in different style) could potentially be misclassified as adversarial attacks. This issue is not mentioned at all in the paper. However, since I'm not familiar with the literature I don't know if it's fair to expect the reviewers to address it. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_730_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The authors propose a novel method for detecting adversarialattacks on neuralnetwork classifiers by modelling the distribution of outputs of hidden fully connected layers rather than the distribution of inputs which is commonly done.", "The method is caled I-defender and it is compared with other methods on an extensive set of benchmarks.", "The distribution of outputs of the hidden layers is modelled as a mixture of Gaussians which is fit using the EM alorithm.", "I'm not at al familiar with the literature on adversarialattacks so I can only write a review assuming the overview of related work in the submission is accurate.", "The paper is very clearly written and does a good job of explaining its contributions.", "The experiments are sensible and show clearly show excellent performance of the suggested approach, often beating the state-of-the-art methods.", "The idea of modelling the distribution of hidden layers instead of inputs makes a lot of sense to me and if it is indeed novel then it can have a lot of impact.", "One generalconcern I have regarding the approach of detecting adversarialexamples by modelling the distribution of realdata is that innocent inputs from a different distribution than the training set (such as digits written in different style) could potentialy be misclassified as adversarialattacks.", "This issue is not mentioned at al in the paper.", "However, since I'm not familiar with the literature I don't know if it's fair to expect the reviewers to address it."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_730_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_725_1", "review_text": "Thank you for your thorough response.  I appreciate the additional analysis and I think it will definitely make for a stronger paper.  I also appreciate the run time discussion --- I was confused about the computational costs of the amortization, and the author response cleared that up for me.  I am still a bit confused about why AVF would be less susceptible to local minima (and more likely to use the latent codes) than the baseline comparisons, and it would be great to include some discussion about this improvement.  I have increased my score.   ------------------ The authors present a method for fitting dynamic latent variable models with a variational inference objective.  They use a variational family factorized sequentially to approximate the posterior over the latent variables. They describe the inference procedure using this posterior sequence approximation, which involves solving T optimization problems at each step of the sequence, approximating filtering.  Learning the global parameters requires performing this as an inner loop.  To reduce computation, they use iterative inference models as an amortized inference scheme.  They present experimental comparisons to baseline methods in a variety of domains involving sequence modeling.    *Clarity*:  The presentation is relatively clear --- the introduction clearly states the problem to be solved and approach they take to solve it. Some aspects were confusing, particularly equations 5 and 13 (and further details of iterative inference mode).  *Quality*: The paper appears to be technically correct, and the proposed method is tested in a variety of domains.  The idea of using a sequentially structured inference network is interesting.  I think the results section would be more compelling if alternate inference network schemes were compared (or if a baseline contains an amortization strategy, how does the structure compare?).  *Originality+Impact*:  The approach showed big empirical gains in some real data examples.  I think the potential impact of this method is contingent on some practical aspects, such as run time.    *Questions and Comments*:  - I am a little confused about the term empirical priors, as used in line 82.  Inference models of the form in Eq (4) have difficulty with which particular distribution?  Is the idea that dynamical priors (or even hierarchical priors) induce some structure that is ignored by a generic inference network?  Is the type of structure that the amortized filtering inference approach exploits?  - Iterative inference models are a big part of the proposed method, however they are not well described in this manuscript.  Could some part of section 2.3 explain Eq (5) in greater detail.    - I am a bit confused about the units used in the experiment log-likelihood reporting.  Do the experiments report the probability of test sequences (having marginalized out the latent variables)?    - How does optimization differ between the using the existing filtering methods vs AVF?  Is it a matter of optimization (e.g. would the existing baselines given more time or tuning rise to the performance of AVF?  Is AVF uniformly better?    - For the video modeling --- what is driving this big improvement?  Is the posterior approximation more accurate?  In general, does the use of the AVF framework enable more expressive posterior approximations than the baselines?  Or does it afford more efficient inference?  Or both?    - How much does the amortization afford you?  If the same variational approximation were used within a stochastic variational inference framework (say for a small dataset), we would expect it to outperform an amortized framework in terms of ELBO objective value.  How does including the amortization structure affect the final model fit?    - For learning global parameters, would a filter + smoothing approach be sensible?  Can this approach be used to update global parameters using information from the entire sequence to do learning?  ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_725_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Thank you for your thorough response.", "I appreciate the additionalanalsis and I think it will definitely make for a stronger paper.", "I alo appreciate the run time discussion --- I was confused about the computationalcosts of the amortization, and the author response cleared that up for me.", "I am still a bit confused about why AVF would be less susceptible to localminima (and more likely to use the latent codes) than the baseline comparisons, and it would be great to include some discussion about this improvement.", "I have increased my score.", "------------------ The authors present a method for fitting dynamic latent variable models with a variationalinference objective.", "They use a variationalfamily factorized seqentialy to approximate the posterior over the latent variables.", "They describe the inference procedure using this posterior seqence approximation, which involves solving T optimization problems at each step of the seqence, approximating filtering.", "Learning the globalparameters reqires performing this as an inner loop.", "To reduce computation, they use iterative inference models as an amortized inference scheme.", "They present experimentalcomparisons to baseline methods in a variety of domains involving seqence modeling.", "*Clarity*: The presentation is relatively clear --- the introduction clearly states the problem to be solved and approach they take to solve it.", "Some aspects were confusing, particularly eqations 5 and 13 (and further details of iterative inference mode).", "*Qualty*: The paper appears to be technicaly correct, and the proposed method is tested in a variety of domains.", "The idea of using a seqentialy structured inference network is interesting.", "I think the results secion would be more compelling if alernate inference network schemes were compared (or if a baseline contains an amortization strategy, how does the structure compare?).", "*Originalty+Impact*: The approach showed big empiricalgains in some realdata examples.", "I think the potentialimpact of this method is contingent on some practicalaspects, such as run time.", "*Questions and Comments*: - I am a little confused about the term empiricalpriors, as used in line 82, Inference models of the form in eq(4) have difficulty with which particular distribution?", "Is the idea that dynamicalpriors (or even hierarchicalpriors) induce some structure that is ignored by a generic inference network?", "Is the type of structure that the amortized filtering inference approach exploits?", "- Iterative inference models are a big part of the proposed method, however they are not well described in this manuscript.", "Could some part of secion 2 3 explain eq(5) in greater detail.", "- I am a bit confused about the units used in the experiment log-likelihood reporting.", "Do the experiments report the probability of test seqences (having marginalzed out the latent variables)?", "- How does optimization differ between the using the existing filtering methods vs AVF?", "Is it a matter of optimization (e g would the existing baselines given more time or tuning rise to the performance of AVF?", "Is AVF uniformly better?", "- For the video modeling --- what is driving this big improvement?", "Is the posterior approximation more accurate?", "In general does the use of the AVF framework enable more expressive posterior approximations than the baselines?", "Or does it afford more efficient inference?", "Or both?", "- How much does the amortization afford you?", "If the same variationalapproximation were used within a stochastic variationalinference framework (say for a smal dataset), we would expect it to outperform an amortized framework in terms of ELBO objective vale.", "How does including the amortization structure affect the finalmodel fit?", "- For learning globalparameters, would a filter + smoothing approach be sensible?", "Can this approach be used to update globalparameters using information from the entire seqence to do learning?"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_725_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_724_3", "review_text": "The paper studies the problem of sampling from multi-modal distributions using simulated tempering techniques combined with Langevin Monte Carlo. Though the assumption about mixture of strongly log-concave component with the same shape is very artificial, sampling from it with access only to its gradient oracle is still a non-trivial problem. More importantly, since the algorithm itself is not too specific for this model, I think it opens up a promising direction for sampling from more general multi-modal distributions. As far as a know, this is the first attempt towards mixing rate for multi-modal distributions that has polynomial dependence on everything.  The techniques are very interesting: it is known that Langevin diffusion converges fast to stationary at very high temperature, even with multi-modal distributions. This paper makes use of this fact by combining it a meta Markov Chain which moves between partitions at the highest temperature, with fast mixing Langevin algorithm for partitions. To make simulated tempering possible, partition functions are estimated in an iterative way for different temperature levels. The mixing rate estimates for both chains are based on spectral gap estimates.  Besides, one thing I'm not sure is that, even if you're given only gradient oracles for the log density, is it possible to estimate those components so that such heavy mechanism is not needed? For example, if we uniformly sample a lot of starting points and run gradient descent starting from them to find the local minima of -log(p), the modes of each mixture components can be recovered. Then the sampling problem becomes almost trivial for the Gaussian case, and simple tricks seem to work in strongly-log-concave component case. If this simple approach is not excluded, the contribution of this paper might be eclipsed, which explains my score.  The discretization of Langevin diffusion without Metropolis adjustment for mixing rate proof for each component, while the simulated tempering chain is run with that step. Are there particular reason for this?", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_724_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper studies the problem of sampling from multi-modaldistributions using simulated tempering techniques combined with Langevin Monte Carlo.", "Though the assumption about mixture of strongly log-concave component with the same shape is very artificial sampling from it with access only to its gradient oracle is still a non-trivialproblem.", "More importantly, since the alorithm itself is not too specific for this model, I think it opens up a promising direction for sampling from more generalmulti-modaldistributions.", "As far as a know, this is the first attempt towards mixing rate for multi-modaldistributions that has polynomialdependence on everything.", "The techniques are very interesting: it is known that Langevin diffusion converges fast to stationary at very high temperature, even with multi-modaldistributions.", "This paper makes use of this fact by combining it a meta Markov Chain which moves between partitions at the highest temperature, with fast mixing Langevin alorithm for partitions.", "To make simulated tempering possible, partition functions are estimated in an iterative way for different temperature levels.", "The mixing rate estimates for both chains are based on spectralgap estimates.", "Besides, one thing I'm not sure is that, even if you're given only gradient oracles for the log density, is it possible to estimate those components so that such heavy mechanism is not needed?", "For example, if we uniformly sample a lot of starting points and run gradient descent starting from them to find the localminima of -log(p), the modes of each mixture components can be recovered.", "Then the sampling problem becomes alost trivialfor the Gaussian case, and simple tricks seem to work in strongly-log-concave component case.", "If this simple approach is not excluded, the contribution of this paper might be eclipsed, which explains my score.", "The discretization of Langevin diffusion without Metropolis adjustment for mixing rate proof for each component, while the simulated tempering chain is run with that step.", "Are there particular reason for this?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_724_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_714_2", "review_text": "In this work, the authors propose to replace the static non-linear activation functions used in most modern neural networks with context-dependent linear transformations. The authors test their model on a toy dataset and MNIST digit classification as well as on two language modeling tasks, PTB and Wikitext-2. On the latter, they show that their approach out-performs recent comparable architectures.  The paper is mostly clearly written and easy to follow, and the results support the authors' claim (still, running language modeling experiments on datasets at least an order of magnitude larger would significantly strengthen the paper). Further discussion of the added computational cost of the method, which can be as important as the number of parameters both for practical applications and in measuring a model's expressive power, would also be welcome.  A few other random points: - The first part of Section 2 seems to initially motivate the approach as a first order approximation of the regular non-linear activation functions: if that is indeed its purpose, it might help to make it more explicit. - In Figure 3, it looks like the learning rate is cut after 60 epochs on AWD-LSTM and 100 for aLSTM, why is that? - Also, Figure 3 would be more legible with a legend in the graph. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_714_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["In this work, the authors propose to replace the static non-linear activation functions used in most modern neuralnetworks with context-dependent linear transformations.", "The authors test their model on a toy dataset and MNIST digit classification as well as on two language modeling tasks, PTB and Wikitext-2, On the latter, they show that their approach out-performs recent comparable architectures.", "The paper is mostly clearly written and easy to follow, and the results support the authors' claim (still, running language modeling experiments on datasets at least an order of magnitude larger would significantly strengthen the paper).", "Further discussion of the added computationalcost of the method, which can be as important as the number of parameters both for practicalapplications and in measuring a model's expressive power, would alo be welcome.", "A few other random points: - The first part of secion 2 seems to initialy motivate the approach as a first order approximation of the regular non-linear activation functions: if that is indeed its purpose, it might help to make it more explicit.", "- In figre 3, it looks like the learning rate is cut after 60 epochs on AWD-LSTM and 100 for aLSTM, why is that?", "- Also, figre 3 would be more legible with a legend in the graph."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_714_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_713_3", "review_text": "The main result of the paper is giving tight bounds on the number of n-variable boolean functions that can be expressed as degree d-polynomial threshold functions for any fixed d (d growing very mildly with n) also works. To me the rest of the results while interesting seem to be mostly easy applications of the key result to other more fashionable neural network models. However, the tightness of the main result does not translate to tight bounds when other neuroidal models are considered, because of the kind of non-linearities or weight constraints involved.   The main result is highly non-trivial, the proof quite lengthy though elegant, and resolves a 25 year old open problem. Although the proof uses a lot of heavy mathematics, the key contribution seems to be generalizing random matrix theory to a random tensor theory -- the key result being that a large number of stochastically independent random vectors in low-dimension (and hence clearly not linearly indpendent) still yield a high degree of linear independence when tensorized. Although the kind of techniques and results may be unfamiliar to a NIPS audience, I think it would be interesting to the NIPS audience and suggest the paper be accepted.  Below I've included some typos that I found in the 8-page version as well as the longer supplementary (however, the page numbers in the supplementary refer to the arxiv v1 of the paper):  8-page paper: Line 23: contained in |A -> remove the | Line 40: class of Boolean function -> functionS Line 59: Section -> section Line 60: W -> We Eq(7) : Missing [] in the middle term Eq(10) : leq => \\leq I'm not really sure how to interpret the various results Sec 4.2 onwards that read of the form N^2(1 + o(1)) +/- \\Theta(N) terms. Unless we know that o(1) is actually o(1/N), the additional \\Theta(N) terms are essentially meaningless?  Arxiv version: Page 21 (towards end of Proof lemma 4.4): (Cauchy-Schwarz step) -> the equality should be an inequality Page 22 (middle of page just below equation) : extreme combinatorics -> extremal combinatorics? Page 25: I believe there are some typos in Lemma 5.3, e.g. V^\\perp - U^\\perp may not even be a vector space, so I'm not sure what its dimension would be. There appear to be a couple of typos in the proof as well.  Page 27: Third (text) line of Proof of Lemma 5.6 : \\theta^\\perp -> \\theta^\\top Page 28: In Sec 5.4 sometimes E_x and Ex are used to mean the same thing", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_713_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The main result of the paper is giving tight bounds on the number of n-variable boolean functions that can be expressed as degree d-polynomialthreshold functions for any fixed d (d growing very mildly with n) alo works.", "To me the rest of the results while interesting seem to be mostly easy applications of the key result to other more fashionable neuralnetwork models.", "However, the tightness of the main result does not translate to tight bounds when other neuroidalmodels are considered, because of the kind of non-linearities or weight constraints involved.", "The main result is highly non-trivial the proof quite lengthy though elegant, and resolves a 25 year old open problem.", "Although the proof uses a lot of heavy mathematics, the key contribution seems to be generalzing random matrix theory to a random tensor theory -- the key result being that a large number of stochasticaly independent random vectors in low-dimension (and hence clearly not linearly indpendent) still yield a high degree of linear independence when tensorized.", "Although the kind of techniques and results may be unfamiliar to a NIPS audience, I think it would be interesting to the NIPS audience and suggest the paper be accepted.", "Below I've included some typos that I found in the 8-page version as well as the longer supplementary (however, the page numbers in the supplementary refer to the arxiv v1 of the paper): 8-page paper: Line 23: contained in |A -> remove the | Line 40: class of Boolean function -> functionS Line 59: secion -> secion Line 60: W -> We eq7) : Missing [] in the middle term eq10) : leq=> \\leqI'm not realy sure how to interpret the various results sec4 2 onwards that read of the form N^2(1 + o(1)) +/- \\Theta(N) terms.", "Unless we know that o(1) is actualy o(1/N), the additional\\Theta(N) terms are essentialy meaningless?", "Arxiv version: Page 21 (towards end of Proof lemma 4 4): (Cauchy-Schwarz step) -> the eqalty should be an ineqalty Page 22 (middle of page just below eqation) : extreme combinatorics -> extremalcombinatorics?", "Page 25: I believe there are some typos in Lemma 5 3, e g V^\\perp - U^\\perp may not even be a vector space, so I'm not sure what its dimension would be.", "There appear to be a couple of typos in the proof as well.", "Page 27: Third (text) line of Proof of Lemma 5 6 : \\theta^\\perp -> \\theta^\\top Page 28: In sec5 4 sometimes E_x and Ex are used to mean the same thing"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_713_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_702_2", "review_text": "The paper presents a method for video action detection. The proposed method extends the recently proposed 2D capsule networks to 3D. The proposed network consists of a 3D encoder (convolutional layers) followed by two capsule networks; the last of which is fully connected to C capsules (C the number of action classes). For localization, the wrong outputs of the capsules (the ones not belonging to the ground truth class) are masked out and the one remaining (that corresponds to the ground truth class) is first fed to a fully-connected layer and then to a series of transposed convolutions to produce the final pixel-level localization. The method is evaluated on three popular action localization datasets achieving state-of-the-art results.   The paper is well-written and easy to follow. It tackles the difficult problem of action detection, being able to localize actions not only with bounding boxes but also with pixel-wise localizations. The results of Table 1 show that using capsules really outperforms the state of the art for all datasets.   The method is mostly a simple extension of 2D capsules to 3D.  Besides this extension, the main difference from the original work is capsule pooling (Section 3.1). This seems a bit contradictory to the initial capsule works and to the whole idea behind capsules [7,11], where the authors state that pooling throws away information about the precise position of the entity within a region. If there was no memory limitation, do the authors think that the network without the pooling operation could perform better?   For capsule pooling, the authors use the mean of the capsules in the receptive field of each capsule type. Did the authors try to experiment with other types of pooling, such as max-pooling?   It would also be interesting to see where the remainder of the error comes from, eg. if it is due to incorrect localization and/or classification of the actions.   In lines 33-37 of the supplementary material, the authors attribute the low performance of some classes to different backgrounds or to cluttered scenes, which is not the case of other classes, such as cliff diving. It would be beneficial if the authors could comment on that. Moreover, It would be interesting to see what happens when there are multiple people in the scene, eg. ice dancing, with some examples or analysis maybe (given that Table 5 of the supplementary material shows that the proposed method achieves 100% video-mAP for this class).   The authors do not use any motion information. It would be interesting to see how the method would perform with optical flow as input, especially for the failure cases of RGB inputs, eg. cluttered background.   Minor: - line 78: work instead of works.  - line 263: contain instead of contains. - Section 5.3 should also mention that the results are reported in Table 2.  - A small part of the right side of Figure 2 is missing.   [About author feedback] The authors did not really explain the difference between f-map and v-map. Works like [2] and [4] also use multiple frames as input and the difference between their f-map and v-map is expected (temporally consistent detections vs per-frame detections). I am not convinced by the explanation provided by the authors. Regarding the \u00e2\u0080\u009cremainder of the error\u00e2\u0080\u009d: localization can mean temporal or spatial; hence, an explanation for this could be useful. Overall, I think that it\u00e2\u0080\u0099s a good submission and I stand by my initial score. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_702_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper presents a method for video action detection.", "The proposed method extends the recently proposed 2D capsule networks to 3D.", "The proposed network consists of a 3D encoder (convolutionallayers) followed by two capsule networks; the last of which is fully connected to C capsules (C the number of action classes).", "For localzation, the wrong outputs of the capsules (the ones not belonging to the ground truth class) are masked out and the one remaining (that corresponds to the ground truth class) is first fed to a fully-connected layer and then to a series of transposed convolutions to produce the finalpixel-level localzation.", "The method is evalated on three popular action localzation datasets achieving state-of-the-art results.", "The paper is well-written and easy to follow.", "It tackles the difficult problem of action detection, being able to localze actions not only with bounding boxes but alo with pixel-wise localzations.", "The results of Table 1 show that using capsules realy outperforms the state of the art for al datasets.", "The method is mostly a simple extension of 2D capsules to 3D.", "Besides this extension, the main difference from the originalwork is capsule pooling (secion 3 1).", "This seems a bit contradictory to the initialcapsule works and to the whole idea behind capsules [7,11], where the authors state that pooling throws away information about the precise position of the entity within a region.", "If there was no memory limitation, do the authors think that the network without the pooling operation could perform better?", "For capsule pooling, the authors use the mean of the capsules in the receptive field of each capsule type.", "Did the authors try to experiment with other types of pooling, such as max-pooling?", "It would alo be interesting to see where the remainder of the error comes from, eg.", "if it is due to incorrect localzation and/or classification of the actions.", "In lines 33-37 of the supplementary material the authors attribute the low performance of some classes to different backgrounds or to cluttered scenes, which is not the case of other classes, such as cliff diving.", "It would be beneficialif the authors could comment on that.", "Moreover, It would be interesting to see what happens when there are multiple people in the scene, eg.", "ice dancing, with some examples or analsis maybe (given that Table 5 of the supplementary materialshows that the proposed method achieves 100% video-mAP for this class).", "The authors do not use any motion information.", "It would be interesting to see how the method would perform with opticalflow as input, especialy for the failure cases of RGB inputs, eg.", "cluttered background.", "Minor: - line 78: work instead of works.", "- line 263: contain instead of contains.", "- secion 5 3 should alo mention that the results are reported in Table 2, - A smal part of the right side of figre 2 is missing.", "[About author feedback] The authors did not realy explain the difference between f-map and v-map.", "Works like [2] and [4] alo use multiple frames as input and the difference between their f-map and v-map is expected (temporaly consistent detections vs per-frame detections).", "I am not convinced by the explanation provided by the authors.", "Regarding the \u00e2\u0080\u009cremainder of the error\u00e2\u0080\u009d: localzation can mean temporalor spatial hence, an explanation for this could be useful.", "Overal, I think that it\u00e2\u0080\u0099s a good submission and I stand by my initialscore."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_702_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_701_3", "review_text": "The paper describes Edward2, a probabilistic programming language on top of TensorFlow and supports the TPU, GPU and CPU accelerators. It is the successor of the Edward-1 package.  Edward-2's main USP is that it has a single abstraction (random variable), and offers no separate abstractions to describe learning itself. The learning procedures are left as functions that are user-defined, making Edward-2 low-level (and powerful -- claim).  The paper describes Edward2's tracing mechanism, which allows one to do complex inference procedures, doing interventions on outcomes, etc.  The paper does experiments on No-U-Turn sampler, comparing to other packages in the ecosystem. Additionally it does experiments on VAEs, also comparing to other packages in the ecosystem.  The results showcase that Edward's usage of GPUs (in NUTS) vs Stan and PyMC3 give it considerable speedups (attributing to the use of GPUs). Additionally for VAEs, they show that their use of TPUs give it a 5x speedup over using GPUs, attributing to the TPU being faster.  ------------------------------  The paper is very incomprehensible. I am familiar with TensorFlow and a little bit of probabilistic programs, but I could barely comprehend the paper. I read it 2 and a half times, and I was often short of context. I think the authors seem to have struggled with the page limits and compressed content + removed context. Sections such as 2.2 and 3, 3.1, 3.2 are clearly shortened beyond comprehension for a reader that is not familiar with Edward-1 or whatever context that the authors assume that the reader has. While I have a superficial \"tl;dr\" of such sections, the point that was being made in the section didn't actually come across. I have very little understanding of what makes Edward2 better. All the code samples are not discussed in sufficient detail either, often \"assuming\" that the reader \"gets\" the superiority of what is being presented.  While the project seems to be an impressive effort: \"PPL with CPU, GPU, TPU support and considerable integration with popular framework such as TensorFlow\", the paper should be expanded and probably sent to a venue or journal where one does not have to fight the page limits and can express themselves better. I dont have confidence that as a poster, the authors can do a good job of explaining the framework well. This is my primary reason for rejection of the paper, and I will let the Area Chair make a decision on whether this is a valid reasoning line or not.  Lastly, something that seems to be a dishonest \"wording\" is their sentences around speedups against other packages. Starting from the abstract, and continuing into many places in the paper (8, 44 Table-{1, 2, 3} captions, 235, 243, 9, Table-1 caption, 219, 244) they keep repeating \"Edward2 on TPU vs Pyro on GPU\" or \"Edward2 on GPU vs STAN on CPU\". This is not only disingenous, it's dangerous. If you see Table-2, it is clear that Edward2 on TPU vs Edward2 on GPU is a 5x speed gain. So the main speed gain is actually TPU vs GPU, yet they clearly try to mix up the language so that \"Edward2\" is associated with the speedup rather than \"TPU\". There's more problematic issues with the benchmarking of TPUs vs GPUs. They compare the TPU to a 1080Ti GPU. They are comparing the latest generation TPU hardware to an older generation GPU hardware. This is not acceptable, especially if they want to make their claim that TPUs are faster. If they compare a TPU against Volta GPUs, will their speedup reduce by a significant amount? Definitely, as Volta's fp32 is a 2x number of flops and has more memory bandwidth. This is my added reason for rejecting the paper in it's current form.   Nit: 55, Fig.4, 73 refer Edward2 as \"Edward\", making it confusing.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_701_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper describes Edward2, a probabilistic programming language on top of TensorFlow and supports the TPU, GPU and CPU accelerators.", "It is the successor of the Edward-1 package.", "Edward-2's main USP is that it has a single abstraction (random variable), and offers no separate abstractions to describe learning itself.", "The learning procedures are left as functions that are user-defined, making Edward-2 low-level (and powerful -- claim).", "The paper describes Edward2's tracing mechanism, which alows one to do complex inference procedures, doing interventions on outcomes, etc The paper does experiments on No-U-Turn sampler, comparing to other packages in the ecosystem.", "Additionaly it does experiments on VAEs, alo comparing to other packages in the ecosystem.", "The results showcase that Edward's usage of GPUs (in NUTS) vs Stan and PyMC3 give it considerable speedups (attributing to the use of GPUs).", "Additionaly for VAEs, they show that their use of TPUs give it a 5x speedup over using GPUs, attributing to the TPU being faster.", "------------------------------ The paper is very incomprehensible.", "I am familiar with TensorFlow and a little bit of probabilistic programs, but I could barely comprehend the paper.", "I read it 2 and a hal times, and I was often short of context.", "I think the authors seem to have struggled with the page limits and compressed content + removed context.", "secions such as 2 2 and 3, 3 1, 3 2 are clearly shortened beyond comprehension for a reader that is not familiar with Edward-1 or whatever context that the authors assume that the reader has.", "While I have a superficial\"tl;dr\" of such secions, the point that was being made in the secion didn't actualy come across.", "I have very little understanding of what makes Edward2 better.", "All the code samples are not discussed in sufficient detail either, often \"assuming\" that the reader \"gets\" the superiority of what is being presented.", "While the project seems to be an impressive effort: \"PPL with CPU, GPU, TPU support and considerable integration with popular framework such as TensorFlow\", the paper should be expanded and probably sent to a venue or journalwhere one does not have to figt the page limits and can express themselves better.", "I dont have confidence that as a poster, the authors can do a good job of explaining the framework well.", "This is my primary reason for rejection of the paper, and I will let the Area Chair make a decision on whether this is a vald reasoning line or not.", "Lastly, something that seems to be a dishonest \"wording\" is their sentences around speedups against other packages.", "Starting from the abstract, and continuing into many places in the paper (8, 44 Table-{1, 2, 3} captions, 235, 243, 9, Table-1 caption, 219, 244) they keep repeating \"Edward2 on TPU vs Pyro on GPU\" or \"Edward2 on GPU vs STAN on CPU\".", "This is not only disingenous, it's dangerous.", "If you see Table-2, it is clear that Edward2 on TPU vs Edward2 on GPU is a 5x speed gain.", "So the main speed gain is actualy TPU vs GPU, yet they clearly try to mix up the language so that \"Edward2\" is associated with the speedup rather than \"TPU\".", "There's more problematic issues with the benchmarking of TPUs vs GPUs.", "They compare the TPU to a 1080Ti GPU.", "They are comparing the latest generation TPU hardware to an older generation GPU hardware.", "This is not acceptable, especialy if they want to make their claim that TPUs are faster.", "If they compare a TPU against Volta GPUs, will their speedup reduce by a significant amount?", "Definitely, as Volta's fp32 is a 2x number of flops and has more memory bandwidth.", "This is my added reason for rejecting the paper in it's current form.", "Nit: 55, fig4, 73 refer Edward2 as \"Edward\", making it confusing."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_701_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_697_2", "review_text": "The paper attempts to replace the MLE estimate for a sequence2sequence model with an adversarial criterion. The argument is that auto-regressive neural networks, i.e., recurrent neural networks, do not play nicely with adversarial training. The amount of novelty in the paper is limited as this paper is far from the first to consider a mix of recurrent neural networks and generation. Indeed, about a year ago Yoav Goldberg posted an adversarial review of a related paper: https://medium.com/@yoav.goldberg/an-adversarial-review-of-adversarial-generation-of-natural-language-409ac3378bd7.   I think the evaluation of the paper is quite borked. How can you even consider an evaluation of non-conditioned generation? The paper is hopefully linguistically lost. As far as I can figure, the only reasonable way to evaluate unconditioned generation is through grammaticality, i.e., syntactic correctness. For instance, is the sentence \u00e2\u0080\u009cA yellow banana is lying on the table\u00e2\u0080\u009d better than the sentence \u00e2\u0080\u009ca purple banana is lying on the table\u00e2\u0080\u009d just because the former is more common, and, thus, rightly has higher probability under *any* good model? Of course not! Any attempt at computational creativity has to be able to distinguish likely (probably not creative) from syntactically valid. The paper ignores an entire field of linguistic inquiry. See, for instance, Lau et al. (2018) in Cognitive Science, who investigate the ability of neural language models ot assess grammaticality. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_697_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper attempts to replace the MLE estimate for a seqence2seqence model with an adversarialcriterion.", "The argument is that auto-regressive neuralnetworks, i e , recurrent neuralnetworks, do not play nicely with adversarialtraining.", "The amount of novelty in the paper is limited as this paper is far from the first to consider a mix of recurrent neuralnetworks and generation.", "Indeed, about a year ago Yoav Goldberg posted an adversarialreview of a related paper: https://medium.com/@yoav.goldberg/an-adversarialreview-of-adversarialgeneration-of-naturallanguage-409ac3378bd7, I think the evalation of the paper is quite borked.", "How can you even consider an evalation of non-conditioned generation?", "The paper is hopefully linguisticaly lost.", "As far as I can figre, the only reasonable way to evalate unconditioned generation is through grammaticalty, i e , syntactic correctness.", "For instance, is the sentence \u00e2\u0080\u009cA yellow banana is lying on the table\u00e2\u0080\u009d better than the sentence \u00e2\u0080\u009ca purple banana is lying on the table\u00e2\u0080\u009d just because the former is more common, and, thus, rightly has higher probability under *any* good model?", "Of course not!", "Any attempt at computationalcreativity has to be able to distinguish likely (probably not creative) from syntacticaly vald.", "The paper ignores an entire field of linguistic inquiry.", "See, for instance, Lau et al (2018) in Cognitive Science, who investigate the ability of neurallanguage models ot assess grammaticalty."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_697_2", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_690_3", "review_text": "The paper considers a new generalized formulation of multi-armed bandits (MAB) where additional information each arm may appear arbitrarily even when that arm is not pulled.  The authors call this additional information as information flows.  The paper is very well written.   The authors derive a lower bound on regret and consider cases where the information flow is stationary (iid Bernoulli) and diminishing information flows.  The authors propose a near-optimal policy that adapts to unknown information flow.   The policy attempts to balance exploration and exploitation so that loss due to exploration would equal expected loss due to misidentification of the best arm,  The paper is technically sound; the proofs seem correct and sketched well in the paper. My only regret is that there is no discussion on any practical implications of this model - for what sort of sequential decision making problems is this class models suitable? ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_690_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper considers a new generalzed formulation of multi-armed bandits (MAB) where additionalinformation each arm may appear arbitrarily even when that arm is not pulled.", "The authors cal this additionalinformation as information flows.", "The paper is very well written.", "The authors derive a lower bound on regret and consider cases where the information flow is stationary (iid Bernoulli) and diminishing information flows.", "The authors propose a near-optimalpolicy that adapts to unknown information flow.", "The policy attempts to balnce exploration and exploitation so that loss due to exploration would eqalexpected loss due to misidentification of the best arm, The paper is technicaly sound; the proofs seem correct and sketced well in the paper.", "My only regret is that there is no discussion on any practicalimplications of this model - for what sort of seqentialdecision making problems is this class models suitable?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_690_3", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno1", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_685_1", "review_text": "Updated score from rebuttal. With improved presentation and a clear message, this could be a good paper.   This paper further generalizes the useful notion of mixability for prediction with experts advice, building off a long history of results from the regret minimization community and solving an open problem about characterizing \\Phi mixibility. This is mostly accomplished by defining the \"support loss\", which allows one to upper bound the given loss but possesses nicer properties and the authors to characterize Phi mixability completely, solving an open problem.   A new algorithm (AGAA) is proposed and analyzed. The regret bound is intricate, making comparisons difficult. Some simulations are provided in the appendix, but I feel that this algorithm is under explored.   The technical contributions seem solid, and a long line of work on Phi-mixability is essentially closed by this paper. However, I do have concerns with the presentation and impact. First, the paper is very densely written and would be better suited as a COLT or jmrl paper. Yes, there is a lot of background and definitions to go through, but many of the definitions are unnecessary or unnecessarily technical (e.g. line 87-90). While the technicality of the definitions are necessary for the most general case, the authors should consider presenting a less general case in the main body for venues like NIPS.   The second worry is the interest to the NIPS community. Mixability and aggregating algorithms are not even mainstream in communities like COLT, and I'm afraid this paper will not find the right audience an NIPS and not have the impact it should.    A few more comments:  The typesetting and symbols used are sort of out of control, e.g. the symbol on line 169.  I don't think S was explicitly defined to be the Shannon entropy.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_685_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["Updated score from rebuttal With improved presentation and a clear message, this could be a good paper.", "This paper further generalzes the useful notion of mixability for prediction with experts advice, building off a long history of results from the regret minimization community and solving an open problem about characterizing \\Phi mixibility.", "This is mostly accomplished by defining the \"support loss\", which alows one to upper bound the given loss but possesses nicer properties and the authors to characterize Phi mixability completely, solving an open problem.", "A new alorithm (AGAA) is proposed and analzed.", "The regret bound is intricate, making comparisons difficult.", "Some simulations are provided in the appendix, but I feel that this alorithm is under explored.", "The technicalcontributions seem solid, and a long line of work on Phi-mixability is essentialy closed by this paper.", "However, I do have concerns with the presentation and impact.", "First, the paper is very densely written and would be better suited as a COLT or jmrl paper.", "Yes, there is a lot of background and definitions to go through, but many of the definitions are unnecessary or unnecessarily technical(e g line 87-90).", "While the technicalty of the definitions are necessary for the most generalcase, the authors should consider presenting a less generalcase in the main body for venues like NIPS.", "The secnd worry is the interest to the NIPS community.", "Mixability and aggregating alorithms are not even mainstream in communities like COLT, and I'm afraid this paper will not find the right audience an NIPS and not have the impact it should.", "A few more comments: The typesetting and symbols used are sort of out of control, e g the symbol on line 169, I don't think S was explicitly defined to be the Shannon entropy."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_685_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_684_3", "review_text": "This paper introduces a general template, based on convex relaxation, for post-clustering validation that has theoretical guarantee, without assuming clusterability on the dataset. The authors provides an example of how in the context of k-means clustering, this can be done via SDP formulation. Although there are some parts where I feel the paper can be improved, in general I think this is an interesting theoretical contribution to an area that is important for practical concern (validation for clustering).   Here are some detailed comments for the authors to consider: - Some definitions are confusing: For example, the way the authors define an optimization problem is a bit confusing; in (5) and (6), it took me a while to understand that epsilons are not pre-defined constraints but the optimal values achieved. Also, what exactly is the matrix norm used here to gauge the difference X-X'?  - Is (6) ever tractable? Isn't X* the optimal value unknown to the algorithm? Also, it doesn't seem to appear in the subsequent text (why not removing it?) - How is (12) a special case of (5)? (again, what exactly is the matrix norm used in (5))? - Similarly, in Theorem 3, inner product is used to measure the distance (similarity) between matrices. How is it related to (5)?  - Section 4 is rather unclear. Can the authors spend a few words discussing what exactly are the clustering paradigms (losses) used in the referred papers? - If the method can be indeed extended easily to clustering objectives other than k-means (as claimed in Sec 4), then perhaps the authors should strengthen this statement by showing empirical results. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_684_3", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper introduces a generaltemplate, based on convex relaxation, for post-clustering valdation that has theoreticalguarantee, without assuming clusterability on the dataset.", "The authors provides an example of how in the context of k-means clustering, this can be done via SDP formulation.", "Although there are some parts where I feel the paper can be improved, in generalI think this is an interesting theoreticalcontribution to an area that is important for practicalconcern (valdation for clustering).", "Here are some detailed comments for the authors to consider: - Some definitions are confusing: For example, the way the authors define an optimization problem is a bit confusing; in (5) and (6), it took me a while to understand that epsilons are not pre-defined constraints but the optimalvales achieved.", "Also, what exactly is the matrix norm used here to gauge the difference X-X'?", "- Is (6) ever tractable?", "Isn't X* the optimalvale unknown to the alorithm?", "Also, it doesn't seem to appear in the subseqent text (why not removing it?)", "- How is (12) a specialcase of (5)?", "(again, what exactly is the matrix norm used in (5))?", "- Similarly, in Theorem 3, inner product is used to measure the distance (similarity) between matrices.", "How is it related to (5)?", "- secion 4 is rather unclear.", "Can the authors spend a few words discussing what exactly are the clustering paradigms (losses) used in the referred papers?", "- If the method can be indeed extended easily to clustering objectives other than k-means (as claimed in sec4), then perhaps the authors should strengthen this statement by showing empiricalresults."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_684_3", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_681_3", "review_text": "Summary: This paper suggests a new deep neural classifier that can effectively identify the out-of-distribution samples. Unlike most existing approaches which utilize the posterior distribution (usually, softamx function), the authors utilize the several word embeddings as the model's prediction with shared layers. In order to build a robust classifier, they propose a surrogate loss function which minimizes the cosine similarity between the predicted embedding and the corresponding embedding. Using the proposed inference and detection methods, they evaluate the proposed model on computer vision, and speech command detection tasks and compared it to previous methods.  Strength: The paper is well written and the proposed idea is interesting.   Weakness: However, I'm not very convinced with experimental results and I a bit doubt that this method would work in general and is useful in any sense.  1. The authors propose a new classification network, but I a bit doubt that its classification error is universally as good as the standard softmax network. It is a bit dangerous to build a new model for better detecting out-of-distribution samples, while losing its classification accuracy. Could the authors report the classification accuracy of the proposed classifier on ImageNet data? Some theoretical justifications, if possible, would be great for the issue.  2. The detection procedure (i.e., measuring the norm of the predicted embedding) is not intuitive and I am not convinced why it is expected to work. Could the authors provide more detailed explanations about it?  3. The baselines to compare are not enough, e.g., compare the proposed method with LID [1] which is one of the state-of-the-art detection methods for detecting adversarial samples.  [1] Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Houle, M.E., Schoenebeck, G., Song, D. and Bailey, J., Characterizing adversarial subspaces using local intrinsic dimensionality. In ICLR, 2018  4. Similar to Section 4.3, it is better to report AUROC and detection error when the authors evaluate their methods for detecting adversarial samples.  ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_681_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary: This paper suggests a new deep neuralclassifier that can effectively identify the out-of-distribution samples.", "Unlike most existing approaches which utilize the posterior distribution (usualy, softamx function), the authors utilize the severalword embeddings as the model's prediction with shared layers.", "In order to build a robust classifier, they propose a surrogate loss function which minimizes the cosine similarity between the predicted embedding and the corresponding embedding.", "Using the proposed inference and detection methods, they evalate the proposed model on computer vision, and speech command detection tasks and compared it to previous methods.", "Strength: The paper is well written and the proposed idea is interesting.", "Weakness: However, I'm not very convinced with experimentalresults and I a bit doubt that this method would work in generaland is useful in any sense.", "1, The authors propose a new classification network, but I a bit doubt that its classification error is universaly as good as the standard softmax network.", "It is a bit dangerous to build a new model for better detecting out-of-distribution samples, while losing its classification accuracy.", "Could the authors report the classification accuracy of the proposed classifier on ImageNet data?", "Some theoreticaljustifications, if possible, would be great for the issue.", "2, The detection procedure (i e , measuring the norm of the predicted embedding) is not intuitive and I am not convinced why it is expected to work.", "Could the authors provide more detailed explanations about it?", "3, The baselines to compare are not enough, e g , compare the proposed method with LID [1] which is one of the state-of-the-art detection methods for detecting adversarialsamples.", "[1] Ma, X , Li, B , Wang, Y , Erfani, S M , Wijewickrema, S , Houle, M E , Schoenebeck, G , Song, D and Bailey, J , Characterizing adversarialsubspaces using localintrinsic dimensionalty.", "In ICLR, 2018 4, Similar to secion 4 3, it is better to report AUROC and detection error when the authors evalate their methods for detecting adversarialsamples."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_681_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_67_1", "review_text": "** After rebuttal   Thank you for the author response. I have read the rebuttal and will maintain my score. The submission and rebuttal motivate three orthogonal improvements (metric scaling, task-conditioning, auxiliary task co-training) to Prototypical Networks. The paper would be much better written as three distinct units that evaluate the three components separately and in more depth.  The mathematical analysis section of the paper consists of writing out the gradient of the objective function with the additional temperature parameter. Although this provides intuition **about the limiting cases of \\alpha**, I would hesitate to call this a significantly \"non-trivial\" derivation. I also recommend that the authors provide empirical validation (e.g., plotting the contribution of \\alpha-transformed gradients) for the non-limiting cases of \\alpha in order to validate the intuition that varying \\alpha in non-limiting cases trades off between \"minimizing the overlap of the sample distributions or correcting cluster assignments sample-wise\" (rather than just providing the final test performance as in Figure 3).  I also do not agree that the generalization to a learned temperature parameter is exactly analogous to the development of Prototypical Networks from Matching Networks: While the Prototypical Network is itself a slight modification to the Matching Network, it touches on the important tradeoff between parametric and non-parametric density estimation (e.g., see the section on mixture density estimation in the Prototypical Networks paper). I do not see substantial evidence for an analogous claim that the form of the gradient with the additional learnable temperature parameter \"has implications for future work in few-shot learning (FSL) and metric learning more generally.\" The submission needs more argumentation in order to convince the reader that the derivation would \"drive algorithm design and empirical studies\" more than the provided study that varies \\alpha.  Lastly, while it is nice to see evaluation on more datasets, the episodic training setup of CIFAR-100 is not sufficiently different from the few-shot miniImageNet dataset to be considered a major contribution to the community.  ** Before the rebuttal  This work proposes improvements to the prototypical network approach to few-shot classification introduced in [25]. The improvements are three-fold: (i) the addition of a learned temperature parameter in the computation of the softmax-normalized centroid distance; (ii) a modification to conditional normalization [16, 17] in which the conditioning is done as a function of the task-specific dataset as a whole; and (iii) an auxiliary prediction task implemented as an additional head in the architecture that outputs the logits for a 64-way classification task.  The method gives better performance on the standardized miniImageNet benchmark as well as on a few-shot split of CIFAR100 introduced by the authors.  QUALITY  The theoretical contribution of this paper is to write out the gradient of the objective function from [25] with the addition of the temperature scaling parameter in the softmax computation.  The limiting cases (zero and infinite temperature)  are discussed for intuition even though they do not occur in practice as I assume the temperature parameter is transformed to be positive finite (although this is not stated).  There are some flaws in quality throughout the paper:  Several technical claims / hypotheses made in the paper are not evidenced: \"Neural network initialization and batch norm encourages this regime.\" \"If Df is large, the network may have to work outside of its optimal regime to be able to scale down the feature representation.\" \"We hypothesize that the importance of TEN is not uniformly distributed over the layers in the feature extractor. The lower layers closer to the similarity metric need to be conditioned more than the shallower layers closer to the image because pixel-level features extracted by shallow level layers are not task specific.\"  A conceptual point is made in the conclusion unnecessarily: it does not appear that the fact that \"the scaled cosine similarity...does not belong to the class of Bregman divergences\" is used anywhere in the paper, yet it is mentioned in the conclusion.  CLARITY   The paper is reasonably clear. Some points of are omitted: - Why not report results with temperature scaling and matching networks (instead of prototypical networks)? - What is the architecture of the TEN? What motivated this architecture (specifically, why use the centroids, which enable parameter sharing amongst the feature extractors, but still requires the TEN with additional parameters)? - What is the reason that the TEN \"underperformed\"? Was it overfitting?  The experimental comparison in and the discussion of Table 1 does not identify the differences in architectural complexity between the reported methods (i.e., [1, 14, 15] and the proposed work employ a ResNet architecture while the other methods employ a shallow convolutional network).  ORIGINALITY  The architecture and algorithm are a combination of previously proposed methods (see \"SIGNIFICANCE\" below).  The problem setup is not novel, although the authors apply the few-shot episode generation procedure of [30] to the CIFAR100 dataset.  SIGNIFICANCE  The work is incremental as a combination of previously proposed methods applied to prototypical networks for the task of few-shot classification. In particular: - \"Metric scaling\" is the addition of a learnable temperature parameter to the normalized distance computation in the regime of Matching Networks [30] or Prototypical Networks [25]. - \"Task conditioning\" makes use of a task-dataset-conditioning network to predict the scale and offset parameters of batch normalization layers as in [3, 16, 17].  - Auxiliary tasks are known to be beneficial to few-shot learning [*,**] and learning in general.  Moreover, I disagree with the argument (in the conclusion section) that the task sampling technique should be modified for improved performance on a few-shot task, as we should be hesitant about tuning the dataset (which is a feature of the problem) to an algorithm.  SPECIFIC COMMENTS  pg. 1: \"...one aims to...learn a model that extracts information from a set of labeled examples (sample set)...\" Introduce the terminology \"support set\" alongside \"sample set\". I believe the restriction to the labelled support/unlabelled query setting is not representative of recent works in few-shot learning; e.g., consider [***, ****], which deal with learning with unlabelled data in the support set.  pg. 1: It is strange to introduce few-shot learning with Ravi & Larochelle as the first citation, then to claim that the problem has subsequently been reframed by Ravi & Larochelle as meta-learning -- they are the same paper! This needs to be rewritten to correctly capture the nuanced difference between few-shot and meta-learning.  pg. 1: The claim that certain approaches to few-shot learning and meta-learning are \"influential\" and \"central to the field\" is subjective and   pg. 1: \"a feature extractor (or more generally a learner)\" A feature extractor is more general than a neural network with learned parameters, so this relationship needs to be reversed. Since you consider models with learned parameter, it would be sufficient to rewrite this as \"a feature extractor with learned parameters.\"  line 57: \"parameterized by \\phi, mapping x to z, a representation space of dimension D_z\" z is an element of the representation space, not the representation space itself.  line 59: \"can directly be used to solve the few-shot learning classification problem by association\" This needs a more thorough explanation and a more thorough description of the differences between [30] and [25]. In particular, the training criterion for [25] is discussed in lines 62-63 but [30]'s is not.  line 60: \"proposed to introduce inductive bias\" Framing the computation of the class centroid as an \"inductive bias\" is not useful in this context unless it is identified why it is a useful inductive bias.  line 61: \"a unique feature representation\" The mean of embeddings is not necessarily unique.  line 61: \"for each class k\" It is confusing to use k to index classes when above K have been used to count examples in each class.  line 77-8: \"This is the case of Matching Networks [30], which use a Recurrent Neural Network (RNN) to accumulate information about a given task.\" The vanilla version of MNs does NOT use an RNN; only the \"full-context embedding\" version requires it.  line 108-109: \"We observed that this improvement could be directly attributed to the interference of the different scaling of the metrics with the softmax.\" This needs an experimental result, and so likely does not belong in the \"Model Description\" section.  lines 224: \"We re-implemented prototypical networks...\" Do the experimental results remain the same when employing the authors' original code (https://github.com/jakesnell/prototypical-networks) with the addition of the temperature scaling parameter?  [*] Alonso, H\u00c3\u00a9ctor Mart\u00c3\u00adnez, and Barbara Plank. \"When is multitask learning effective? Semantic sequence prediction under varying data conditions.\" arXiv preprint arXiv:1612.02251 (2016). [**] Rei, Marek. \"Semi-supervised multitask learning for sequence labeling.\" arXiv preprint arXiv:1704.07156 (2017). [***] Finn, Chelsea, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, and Sergey Levine. \"One-shot visual imitation learning via meta-learning.\" In CoRL, 2017. [****] Metz, Luke, Niru Maheswaranathan, Brian Cheung, and Jascha Sohl-Dickstein. \"Learning Unsupervised Learning Rules.\" arXiv preprint arXiv:1804.00222 (2018).", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_67_1", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["** After rebuttal Thank you for the author response.", "I have read the rebuttaland will maintain my score.", "The submission and rebuttalmotivate three orthogonalimprovements (metric scalng, task-conditioning, auxiliary task co-training) to PrototypicalNetworks.", "The paper would be much better written as three distinct units that evalate the three components separately and in more depth.", "The mathematicalanalsis secion of the paper consists of writing out the gradient of the objective function with the additionaltemperature parameter.", "Although this provides intuition **about the limiting cases of \\alha**, I would hesitate to cal this a significantly \"non-trivial derivation.", "I alo recommend that the authors provide empiricalvaldation (e g , plotting the contribution of \\alha-transformed gradients) for the non-limiting cases of \\alha in order to valdate the intuition that varying \\alha in non-limiting cases trades off between \"minimizing the overlap of the sample distributions or correcting cluster assignments sample-wise\" (rather than just providing the finaltest performance as in figre 3).", "I alo do not agree that the generalzation to a learned temperature parameter is exactly analgous to the development of PrototypicalNetworks from Matching Networks: While the PrototypicalNetwork is itself a slight modification to the Matching Network, it touches on the important tradeoff between parametric and non-parametric density estimation (e g , see the secion on mixture density estimation in the PrototypicalNetworks paper).", "I do not see substantialevidence for an analgous claim that the form of the gradient with the additionallearnable temperature parameter \"has implications for future work in few-shot learning (FSL) and metric learning more generaly.\"", "The submission needs more argumentation in order to convince the reader that the derivation would \"drive alorithm design and empiricalstudies\" more than the provided study that varies \\alha.", "Lastly, while it is nice to see evalation on more datasets, the episodic training setup of CIFAR-100 is not sufficiently different from the few-shot miniImageNet dataset to be considered a major contribution to the community.", "** Before the rebuttal This work proposes improvements to the prototypicalnetwork approach to few-shot classification introduced in [25].", "The improvements are three-fold: (i) the addition of a learned temperature parameter in the computation of the softmax-normalzed centroid distance; (ii) a modification to conditionalnormalzation [16, 17] in which the conditioning is done as a function of the task-specific dataset as a whole; and (iii) an auxiliary prediction task implemented as an additionalhead in the architecture that outputs the logits for a 64-way classification task.", "The method gives better performance on the standardized miniImageNet benchmark as well as on a few-shot split of CIFAR100 introduced by the authors.", "QUALITY The theoreticalcontribution of this paper is to write out the gradient of the objective function from [25] with the addition of the temperature scalng parameter in the softmax computation.", "The limiting cases (zero and infinite temperature) are discussed for intuition even though they do not occur in practice as I assume the temperature parameter is transformed to be positive finite (alhough this is not stated).", "There are some flaws in qualty throughout the paper: Severaltechnicalclaims / hypotheses made in the paper are not evidenced: \"Neuralnetwork initialzation and batch norm encourages this regime.\"", "\"If Df is large, the network may have to work outside of its optimalregime to be able to scal down the feature representation.\"", "\"We hypothesize that the importance of TEN is not uniformly distributed over the layers in the feature extractor.", "The lower layers closer to the similarity metric need to be conditioned more than the shalower layers closer to the image because pixel-level features extracted by shalow level layers are not task specific.\"", "A conceptualpoint is made in the conclusion unnecessarily: it does not appear that the fact that \"the scald cosine similarity...does not belong to the class of Bregman divergences\" is used anywhere in the paper, yet it is mentioned in the conclusion.", "CLARITY The paper is reasonably clear.", "Some points of are omitted: - Why not report results with temperature scalng and matching networks (instead of prototypicalnetworks)?", "- What is the architecture of the TEN?", "What motivated this architecture (specificaly, why use the centroids, which enable parameter sharing amongst the feature extractors, but still reqires the TEN with additionalparameters)?", "- What is the reason that the TEN \"underperformed\"?", "Was it overfitting?", "The experimentalcomparison in and the discussion of Table 1 does not identify the differences in architecturalcomplexity between the reported methods (i e , [1, 14, 15] and the proposed work employ a ResNet architecture while the other methods employ a shalow convolutionalnetwork).", "ORIGINALITY The architecture and alorithm are a combination of previously proposed methods (see \"SIGNIFICANCE\" below).", "The problem setup is not novel, alhough the authors apply the few-shot episode generation procedure of [30] to the CIFAR100 dataset.", "SIGNIFICANCE The work is incrementalas a combination of previously proposed methods applied to prototypicalnetworks for the task of few-shot classification.", "In particular: - \"Metric scalng\" is the addition of a learnable temperature parameter to the normalzed distance computation in the regime of Matching Networks [30] or PrototypicalNetworks [25].", "- \"Task conditioning\" makes use of a task-dataset-conditioning network to predict the scal and offset parameters of batch normalzation layers as in [3, 16, 17].", "- Auxiliary tasks are known to be beneficialto few-shot learning [*,**] and learning in general Moreover, I disagree with the argument (in the conclusion secion) that the task sampling technique should be modified for improved performance on a few-shot task, as we should be hesitant about tuning the dataset (which is a feature of the problem) to an alorithm.", "SPECIFIC COMMENTS pg.", "1: \"...one aims to...learn a model that extracts information from a set of labeled examples (sample set)...\" Introduce the terminology \"support set\" alngside \"sample set\".", "I believe the restriction to the labelled support/unlabelled query setting is not representative of recent works in few-shot learning; e g , consider [***, ****], which dealwith learning with unlabelled data in the support set.", "pg.", "1: It is strange to introduce few-shot learning with Ravi & Larochelle as the first citation, then to claim that the problem has subseqently been reframed by Ravi & Larochelle as meta-learning -- they are the same paper!", "This needs to be rewritten to correctly capture the nuanced difference between few-shot and meta-learning.", "pg.", "1: The claim that certain approaches to few-shot learning and meta-learning are \"influential and \"centralto the field\" is subjective and pg.", "1: \"a feature extractor (or more generaly a learner)\" A feature extractor is more generalthan a neuralnetwork with learned parameters, so this relationship needs to be reversed.", "Since you consider models with learned parameter, it would be sufficient to rewrite this as \"a feature extractor with learned parameters.\"", "line 57: \"parameterized by \\phi, mapping x to z, a representation space of dimension D_z\" z is an element of the representation space, not the representation space itself.", "line 59: \"can directly be used to solve the few-shot learning classification problem by association\" This needs a more thorough explanation and a more thorough description of the differences between [30] and [25].", "In particular, the training criterion for [25] is discussed in lines 62-63 but [30]'s is not.", "line 60: \"proposed to introduce inductive bias\" Framing the computation of the class centroid as an \"inductive bias\" is not useful in this context unless it is identified why it is a useful inductive bias.", "line 61: \"a unique feature representation\" The mean of embeddings is not necessarily unique.", "line 61: \"for each class k\" It is confusing to use k to index classes when above K have been used to count examples in each class.", "line 77-8: \"This is the case of Matching Networks [30], which use a Recurrent NeuralNetwork (RNN) to accumulate information about a given task.\"", "The vanilla version of MNs does NOT use an RNN; only the \"full-context embedding\" version reqires it.", "line 108-109: \"We observed that this improvement could be directly attributed to the interference of the different scalng of the metrics with the softmax.\"", "This needs an experimentalresult, and so likely does not belong in the \"Model Description\" secion.", "lines 224: \"We re-implemented prototypicalnetworks...\" Do the experimentalresults remain the same when employing the authors' originalcode (https://github.com/jakesnell/prototypicalnetworks) with the addition of the temperature scalng parameter?", "[*] Alonso, H\u00c3\u00a9ctor Mart\u00c3\u00adnez, and Barbara Plank.", "\"When is multitask learning effective?", "Semantic seqence prediction under varying data conditions.\"", "arXiv preprint arXiv:1612.02251 (2016).", "[**] Rei, Marek.", "\"Semi-supervised multitask learning for seqence labeling.\"", "arXiv preprint arXiv:1704.07156 (2017).", "[***] Finn, Chelsea, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, and Sergey Levine.", "\"One-shot visualimitation learning via meta-learning.\"", "In CoRL, 2017, [****] Metz, Luke, Niru Maheswaranathan, Brian Cheung, and Jascha Sohl-Dickstein.", "\"Learning Unsupervised Learning Rules.\"", "arXiv preprint arXiv:1804.00222 (2018)."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_67_1", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_668_3", "review_text": "This paper develops chaining methods for the mutual-information-based generalization bounds in Russo and Zou'15. For an increasing sequence of partitions of the metric space, the paper can provide upper bounds on the expectation of loss function at algorithmic output point, using the sum of mutual information terms along a chain of hierarchical partition, as in classical chaining upper bounds in empirical process theory.  It is very interesting to see the mutual information bound working in a multi-resolution way under discretization, and being combined with classical chaining techniques. However, this paper is perhaps not strong enough for NIPS:  1. The techniques are standard and simply adapting the classical chaining arguments to this new setting. It follows standard framework in chaining proofs, and applies the Donsker-Varadhan's variational form of KL divergence that has been used in e.g. Xu and Raginsky'17.  2. If the authors are going to convince readers about the usefulness of the discretization method and hierarchical partitioning, they should at least provide some examples where mutual information type bounds are really useful, and see if they get improved. The example provided in this paper, however, is far from satisfactory and actually very artificial. It's basically adding some atom to mess up the original mutual information bound without discretization, and showing that the chaining still works. It provides very little intuition about what we can get by chaining mutual information.  Detailed comments: 1. The authors should have noted existing works on PAC-Bayes chaining results (Audibert and Bousquet, JMLR 2007, Combining PAC-Bayesian and Generic Chaining Bounds). Though the mutual information bounds are different from PAC-Bayes, they are derived from similar techniques. 2. The statement about connection to Zhang et al., (2017) and generalization error of SGD is vacuous and deviates from the theme of this paper. I suggest the authors to remove this part.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_668_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper develops chaining methods for the mutualinformation-based generalzation bounds in Russo and Zou'15, For an increasing seqence of partitions of the metric space, the paper can provide upper bounds on the expectation of loss function at alorithmic output point, using the sum of mutualinformation terms alng a chain of hierarchicalpartition, as in classicalchaining upper bounds in empiricalprocess theory.", "It is very interesting to see the mutualinformation bound working in a multi-resolution way under discretization, and being combined with classicalchaining techniques.", "However, this paper is perhaps not strong enough for NIPS: 1, The techniques are standard and simply adapting the classicalchaining arguments to this new setting.", "It follows standard framework in chaining proofs, and applies the Donsker-Varadhan's variationalform of KL divergence that has been used in e g Xu and Raginsky'17, 2, If the authors are going to convince readers about the usefulness of the discretization method and hierarchicalpartitioning, they should at least provide some examples where mutualinformation type bounds are realy useful, and see if they get improved.", "The example provided in this paper, however, is far from satisfactory and actualy very artificial It's basicaly adding some atom to mess up the originalmutualinformation bound without discretization, and showing that the chaining still works.", "It provides very little intuition about what we can get by chaining mutualinformation.", "Detailed comments: 1, The authors should have noted existing works on PAC-Bayes chaining results (Audibert and Bousquet, JMLR 2007, Combining PAC-Bayesian and Generic Chaining Bounds).", "Though the mutualinformation bounds are different from PAC-Bayes, they are derived from similar techniques.", "2, The statement about connection to Zhang et al, (2017) and generalzation error of SGD is vacuous and deviates from the theme of this paper.", "I suggest the authors to remove this part."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_668_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_65_1", "review_text": "This paper introduces a large set of experiments to compare recently proposed GANs.  It discusses two previously proposed measures -- inception score (IS) and Frechet Inception Distance (FID); and it proposes a new measure in the context of GAN assessment, based on precision, recall and F1.  Precision (P) is measured as the fraction of generated samples with distance below a pre-defined threshold \\delta; while recall (R) is measured as the fraction of inversely generated samples (from test set) with squared Euclidean distance below \\delta (F1 is the usual mean between P and R).  The paper argues that IS only measures precision and FIS measures both, so IS is essentially dropped as a measurement for GANs.  Then the paper argues that it is important to show the mean and variance of FID and P-R-F1 measurements instead of the best values, computed over a set of random initialisations and hyper-parameter search points.  This is an extremely important point that is often overlook by several papers published in the field, so I completely agree with the paper in this aspect.  The paper also shows the performance of each GAN in terms of computational budget (not clear in the paper what this is, but I'm assuming some fixed amount of GPU time, for each tick in the graphs) and conclude that all models can reach similar performance with unlimited computational budget.  The paper also reaches these conclusions: 1) FID cannot detect overfitting to the training data set, and 2) many dimensions have to be taken into account when comparing different GANs, but the paper only explores a subset of them.  I think that it is laudable that a paper tries to address this challenging task, and the results are potentially useful for the community.  I think that the experimental setup is interesting and compelling, but hard to be replicated because that would require a very large amount of computational resources that is not available for the majority of researchers.  The main conclusion of the paper is expected (that there is really no model that is clearly better than others in all conditions and for all datasets), but not very helpful for the practitioner.  There are interesting points, particularly considering the P-R-F1 measure -- for instance, looking at Fig. 5, it seems that NS GAN is a clear winner, but there is no strong comment about that in the paper, so I wonder if there is any flaw in my conclusion.  Also, what is the correlation between F1 and FID measures?   Other issues: - In Figure 1, Why does the text say \"rather high bias\", while the figure caption says \"slight bias\"?  How is it possible to have a bias much bigger than the variance from samples of arguably the same set?   - Please clarify what budget means in Figure 3. - Where is the VAE result in Figure 5? ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_65_1", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper introduces a large set of experiments to compare recently proposed GANs.", "It discusses two previously proposed measures -- inception score (IS) and Frechet Inception Distance (FID); and it proposes a new measure in the context of GAN assessment, based on precision, recal and F1, Precision (P) is measured as the fraction of generated samples with distance below a pre-defined threshold \\delta; while recal (R) is measured as the fraction of inversely generated samples (from test set) with squared Euclidean distance below \\delta (F1 is the usualmean between P and R).", "The paper argues that IS only measures precision and FIS measures both, so IS is essentialy dropped as a measurement for GANs.", "Then the paper argues that it is important to show the mean and variance of FID and P-R-F1 measurements instead of the best vales, computed over a set of random initialsations and hyper-parameter search points.", "This is an extremely important point that is often overlook by severalpapers published in the field, so I completely agree with the paper in this aspect.", "The paper alo shows the performance of each GAN in terms of computationalbudget (not clear in the paper what this is, but I'm assuming some fixed amount of GPU time, for each tick in the graphs) and conclude that al models can reach similar performance with unlimited computationalbudget.", "The paper alo reaches these conclusions: 1) FID cannot detect overfitting to the training data set, and 2) many dimensions have to be taken into account when comparing different GANs, but the paper only explores a subset of them.", "I think that it is laudable that a paper tries to address this chalenging task, and the results are potentialy useful for the community.", "I think that the experimentalsetup is interesting and compelling, but hard to be replicated because that would reqire a very large amount of computationalresources that is not available for the majority of researchers.", "The main conclusion of the paper is expected (that there is realy no model that is clearly better than others in al conditions and for al datasets), but not very helpful for the practitioner.", "There are interesting points, particularly considering the P-R-F1 measure -- for instance, looking at fig 5, it seems that NS GAN is a clear winner, but there is no strong comment about that in the paper, so I wonder if there is any flaw in my conclusion.", "Also, what is the correlation between F1 and FID measures?", "Other issues: - In figre 1, Why does the text say \"rather high bias\", while the figre caption says \"slight bias\"?", "How is it possible to have a bias much bigger than the variance from samples of arguably the same set?", "- Please clarify what budget means in figre 3, - Where is the VAE result in figre 5?"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_65_1", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_648_3", "review_text": "# Update after reading the author response  Thank you for the explanations. I have improved my score. I hope the following points help the authors see why I am still not enthusiastic about acceptance.  1- I still think the comparison to previous work is inadequate. For example, the SAEW algorithm of [12] uses several similar techniques (like BOA plus sequential restarting), and achieves a bound (in a less general setting) that scales with $d_0$ rather than $d_0^2$. (it was only after discussion with other reviewers that I realized your sentence in the Conclusion - \"These rates are deteriorated compared with the optimal one that require restrictive assumption.\" - is perhaps referring to this difference). How do your techniques differ? How do your running times differ? I had suggested a table summarizing the previous work and where your work stands w.r.t. them in terms of assumptions, rates, and complexity, but from the author response, it feels like the authors are mainly looking into only moving the contributions earlier in the intro.  2- I still believe it is hard for the reader to see the general view of your paper. All the relevant points are there, but the context is missing or is lost between seemingly smaller improvements here and there (e.g. relaxing sc to exp-concave or Lojasiewic). It would have been much nicer if the intro started by saying why we need quantile bounds (instead of getting to it only in L138), what others had done (e.g. [18,31,22]), and what specifically was missing in previous work (like the efficient adversarial alg). The reader of course knows that you want to \"obtain lower bounds than any existing online algorithm in sparse setting\", but they first need to see an overview of what existed and what was missing to be able to understand in which direction you will be extending the previous work. A good example of such an introduction is maybe that of [18], among many others. Once this is established, then the contribution section could highlight your most important ideas (more like expanding on the list you have at the end of your introduction section, as opposed to attending to the details of the Lojasiewic's assumption). In this way, it is also easier for the reader to understand (at a high level) your improvements over previous work, because you have already talked about their limitations.   3- I think the 8-page limit should not result in the paper not being self-contained. Relevant results and extra comments could be recalled / put in the appendix, and short explanations could be given to connect things.  I hope that the authors consider these points in the final version if the paper is accepted, or in the subsequent submissions if it is not.  # Summary  The paper seems to provide new projection-free algorithms for online learning over the l1-ball with guarantees that depend on the sparsity of the optimal parameter / competitor. This is what *seems* to be the main contributions of the paper: 1- An algorithm (Alg-1) for the expert-advice setting that enjoys (per Thm 2.1) a quantile bound, which scales with O(1/T) when the losses are exp-concave, improving / extending previous work [18, 31, 22]. 2- A projection-free algorithm (BOA+) for online strongly-convex optimization over the l1 ball, by restarting Alg-1 on grids that include new leaders (in the Follow-The-Leader sense) from the previous rounds. 3- Another algorithm (SABOA) for stochastic strongly-convex optimization over the l1 ball, similar to BOA+ but with a different grid construction. 4- O(1/T) rates for BOA+ and SABOA that depend on the number of non-zero elements of the competitor / optimal parameter.  However, the paper is generally hard to read, in the sense that it is not self-contained (at all), is not coherently written, comparison to previous work is scattered throughout the paper, and and the overall message is hidden by the details. In particular, the high-level view of the paper, the extent of technical novelty, the exact relation to previous work, and if / why the bounds are optimal in each of the problem parameters (i.e., sparsity of the competitor, Lipschitz and exp-concavity constants, etc) is not entirely clear.  As a result of the inaccessibility of the paper, I do not recommend publishing at NIPS.  ## Questions for the authors Please consider answering Q1-Q5 below in the author response. (Please consider answers that shed light on the general view and significance of your work).  # Quality and Significance  From a technical point of view, the contributions seem to be interesting. However, the quality of the presentation suffers, to the point of making the results inaccessible, except to the reader with direct experience working with the underlying algorithms / ideas.  ## Algorithm 1 Alg-1 is the Squint algorithm of [18] with a geometric prior on learning rates. The result seems to improve over [31, Section 4] by requiring only exp-concavity of the losses (in expectation) as opposed to strong convexity. In addition, the KL-div is not simplified to log(K) - as [31] does in their Thm 4.3 for example, so quantile bounds are obtained. It extends [18] (and the relevant prior work that obtain O(1/sqrt(T)) quantile bounds, not cited here) by providing the O(1/T) rate for exp-concave losses. It seems to improve over [22] by being a completely online algorithm and removing a gap term in the bound.  **Q1**: Where similar priors used for Squint before? Compared to [31], are there any other technical novelties I have not mentioned above? What is the challenge of replacing strong convexity with weak exp-concavity (wouldn\u00e2\u0080\u0099t very similar techniques as in [31, Sec 4] directly apply here?)  **Q2**: Why is the weakening of exp-concavity important? Can you provide concrete examples of useful losses where the weak exp-concavity holds, but exp-concavity doesn\u00e2\u0080\u0099t (i.e., what are the \u00e2\u0080\u009cregularity conditions\u00e2\u0080\u009d?)  ## BOA+ and SABOA BOA+ and SABOA extend Alg-1 to the l1 ball (Alg-1 is for a finite set of experts) by restarting it, for exponentially increasing number of time steps, on descritized grids that gradually include improved approximations of the optimal parameter. The algorithms are interesting as they are projection-free, yet obtain the O(1/T) rates of convergence under strongly-convex (or Lojasiewicz) losses.  Again, the lack of coherence and proper comparison with previous work prevents complete appreciation of the results. It seems that the main benefit over previous work are that the algorithms are projection-free, and the Lojasiewicz condition is used, generalizing strong-convexity to a class of non-convex functions. Also, the same bounds apparently apply to general convex functions as well (reducing to O(1/sqrt(T)) in that case).  **Q3**: How do your results (Sec 3) benefit from the exp-concavity condition, as you still need to assume strong-convexity, or it\u00e2\u0080\u0099s non-convex counter-part (Lojasiewicz\u00e2\u0080\u0099 condition)? Would they also benefit from the weakening of exp-concavity in A2?  **Q4**: Regarding [26] and [12], isn\u00e2\u0080\u0099t competing with the minimizer over R^d harder than with the minimizer of B_1, as the former always has a lower loss than the latter, and thus the bounds will be stronger?  **Q5**: How do the computational complexity of BOA+ / SABOA compare with previous work? Are [13] and [32] the only relevant work here? How do the bounds compare? Is the dependence on each of the problem parameters (|| Theta ||_0, G, alpha, beta, mu, etc) optimal? What / where are the relevant lower bounds?  # Clarity  I found the paper hard to read, even for someone with experience in online learning, the expert advice framework, bandits, etc. The reader needs deep familiarity with specific previous work (Squint, BOA, etc). While the relevant sections are there (contributions, previous work, etc.), one has to read the paper multiple times, as well as the related work, to find out what the actual contributions are, why they are important, how they compare with previous work, etc. A few examples are provided below:  1- I recommend consulting a professional editing service to improve general readability. There are several sentences that are not informative, or are confusing. It is not clear what some pronouns refer to. For example: \u00e2\u0080\u009cThese results generalize previous work [..]. **They** are obtained under [..] Lojasiewicz condition.\u00e2\u0080\u009d Which results? All of them? But this seemed to relate to convex / exp-concave functions. One has to read until the end to find out which results is given under what condition.  2- The introduction should discuss what is the goal of the paper, what are the high-level results, and why they matter and were not obtained before. Instead, it gets to details such as using Dirac masses to get the regret, and goes to \u00e2\u0080\u009cPrevious work\u00e2\u0080\u009d. What do you want to do? Why?  3- The previous work section seems incomplete, uninformative, and vague. What is \u00e2\u0080\u009ca subroutine centered around the current estimate\u00e2\u0080\u009d? Why should we know this? We still don\u00e2\u0080\u0099t know what the paper is trying to do\u00e2\u0080\u00a6 Shouldn\u00e2\u0080\u0099t Lines 41,42 actually just go to the \u00e2\u0080\u009ccontributions\u00e2\u0080\u009d section?  4- Similar vague sentences and paragraphs appear throughout the paper. The paper is not self-contained (e.g., \u00e2\u0080\u009cextended to a unique approximately sparse Theta* [ ..] see [1;3]\u00e2\u0080\u009d). Hand-wavy explanations and phrases are used where appropriate mathematical expressions should appear (e.g., \u00e2\u0080\u009cset of hard-truncated and dilated soft-thresholded versions of [..] as in (43)\u00e2\u0080\u009d). On the other hand, explanation is absent where it would be useful. For example, why should one consider SABOA instead of BOA+ in the stochastic setting? Why can we use previous iterates instead of the leaders here?  # Originality  The comparison with related work is unclear. The reader needs to go to the related work and find the results and compare them with the current results (even, e.g., the respective Theorem numbers are not given).  I recommend providing a table comparing previous work (e.g., as in [22]), showing whether each result concerned regret or cumulative risk [as in 22], strongly-convex, exp-concave, or weak exp-concave losses, was it an h.p. or expectation bound, etc.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_648_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["# Update after reading the author response Thank you for the explanations.", "I have improved my score.", "I hope the following points help the authors see why I am still not enthusiastic about acceptance.", "1- I still think the comparison to previous work is inadeqate.", "For example, the SAEW alorithm of [12] uses severalsimilar techniques (like BOA plus seqentialrestarting), and achieves a bound (in a less generalsetting) that scals with $d_0$ rather than $d_0^2$.", "(it was only after discussion with other reviewers that I realzed your sentence in the Conclusion - \"These rates are deteriorated compared with the optimalone that reqire restrictive assumption.\"", "- is perhaps referring to this difference).", "How do your techniques differ?", "How do your running times differ?", "I had suggested a table summarizing the previous work and where your work stands w r t them in terms of assumptions, rates, and complexity, but from the author response, it feels like the authors are mainly looking into only moving the contributions earlier in the intro.", "2- I still believe it is hard for the reader to see the generalview of your paper.", "All the relevant points are there, but the context is missing or is lost between seemingly smaler improvements here and there (e g relaxing sc to exp-concave or Lojasiewic).", "It would have been much nicer if the intro started by saying why we need quantile bounds (instead of getting to it only in L138), what others had done (e g [18,31,22]), and what specificaly was missing in previous work (like the efficient adversarialal).", "The reader of course knows that you want to \"obtain lower bounds than any existing online alorithm in sparse setting\", but they first need to see an overview of what existed and what was missing to be able to understand in which direction you will be extending the previous work.", "A good example of such an introduction is maybe that of [18], among many others.", "Once this is established, then the contribution secion could highlight your most important ideas (more like expanding on the list you have at the end of your introduction secion, as opposed to attending to the details of the Lojasiewic's assumption).", "In this way, it is alo easier for the reader to understand (at a high level) your improvements over previous work, because you have aleady taled about their limitations.", "3- I think the 8-page limit should not result in the paper not being self-contained.", "Relevant results and extra comments could be recaled / put in the appendix, and short explanations could be given to connect things.", "I hope that the authors consider these points in the finalversion if the paper is accepted, or in the subseqent submissions if it is not.", "# Summary The paper seems to provide new projection-free alorithms for online learning over the l1-bal with guarantees that depend on the sparsity of the optimalparameter / competitor.", "This is what *seems* to be the main contributions of the paper: 1- An alorithm (Alg-1) for the expert-advice setting that enjoys (per Thm 2 1) a quantile bound, which scals with O(1/T) when the losses are exp-concave, improving / extending previous work [18, 31, 22].", "2- A projection-free alorithm (BOA+) for online strongly-convex optimization over the l1 bal, by restarting Alg-1 on grids that include new leaders (in the Follow-The-Leader sense) from the previous rounds.", "3- Another alorithm (SABOA) for stochastic strongly-convex optimization over the l1 bal, similar to BOA+ but with a different grid construction.", "4- O(1/T) rates for BOA+ and SABOA that depend on the number of non-zero elements of the competitor / optimalparameter.", "However, the paper is generaly hard to read, in the sense that it is not self-contained (at al), is not coherently written, comparison to previous work is scattered throughout the paper, and and the overal message is hidden by the details.", "In particular, the high-level view of the paper, the extent of technicalnovelty, the exact relation to previous work, and if / why the bounds are optimalin each of the problem parameters (i e , sparsity of the competitor, Lipschitz and exp-concavity constants, etc is not entirely clear.", "As a result of the inaccessibility of the paper, I do not recommend publishing at NIPS.", "## Questions for the authors Please consider answering Q1-Q5 below in the author response.", "(Please consider answers that shed light on the generalview and significance of your work).", "# Qualty and Significance From a technicalpoint of view, the contributions seem to be interesting.", "However, the qualty of the presentation suffers, to the point of making the results inaccessible, except to the reader with direct experience working with the underlying alorithms / ideas.", "## Algorithm 1 Alg-1 is the Squint alorithm of [18] with a geometric prior on learning rates.", "The result seems to improve over [31, secion 4] by reqiring only exp-concavity of the losses (in expectation) as opposed to strong convexity.", "In addition, the KL-div is not simplified to log(K) - as [31] does in their Thm 4 3 for example, so quantile bounds are obtained.", "It extends [18] (and the relevant prior work that obtain O(1/sqrt(T)) quantile bounds, not cited here) by providing the O(1/T) rate for exp-concave losses.", "It seems to improve over [22] by being a completely online alorithm and removing a gap term in the bound.", "**Q1**: Where similar priors used for Squint before?", "Compared to [31], are there any other technicalnovelties I have not mentioned above?", "What is the chalenge of replacing strong convexity with weak exp-concavity (wouldn\u00e2\u0080\u0099t very similar techniques as in [31, sec4] directly apply here?)", "**Q2**: Why is the weakening of exp-concavity important?", "Can you provide concrete examples of useful losses where the weak exp-concavity holds, but exp-concavity doesn\u00e2\u0080\u0099t (i e , what are the \u00e2\u0080\u009cregularity conditions\u00e2\u0080\u009d?)", "## BOA+ and SABOA BOA+ and SABOA extend Alg-1 to the l1 bal (Alg-1 is for a finite set of experts) by restarting it, for exponentialy increasing number of time steps, on descritized grids that gradualy include improved approximations of the optimalparameter.", "The alorithms are interesting as they are projection-free, yet obtain the O(1/T) rates of convergence under strongly-convex (or Lojasiewicz) losses.", "Again, the lack of coherence and proper comparison with previous work prevents complete appreciation of the results.", "It seems that the main benefit over previous work are that the alorithms are projection-free, and the Lojasiewicz condition is used, generalzing strong-convexity to a class of non-convex functions.", "Also, the same bounds apparently apply to generalconvex functions as well (reducing to O(1/sqrt(T)) in that case).", "**Q3**: How do your results (sec3) benefit from the exp-concavity condition, as you still need to assume strong-convexity, or it\u00e2\u0080\u0099s non-convex counter-part (Lojasiewicz\u00e2\u0080\u0099 condition)?", "Would they alo benefit from the weakening of exp-concavity in A2?", "**Q4**: Regarding [26] and [12], isn\u00e2\u0080\u0099t competing with the minimizer over R^d harder than with the minimizer of B_1, as the former alays has a lower loss than the latter, and thus the bounds will be stronger?", "**Q5**: How do the computationalcomplexity of BOA+ / SABOA compare with previous work?", "Are [13] and [32] the only relevant work here?", "How do the bounds compare?", "Is the dependence on each of the problem parameters (|| Theta ||_0, G, alha, beta, mu, etc optimal What / where are the relevant lower bounds?", "# Clarity I found the paper hard to read, even for someone with experience in online learning, the expert advice framework, bandits, etc The reader needs deep familiarity with specific previous work (Squint, BOA, etc.", "While the relevant secions are there (contributions, previous work, etc), one has to read the paper multiple times, as well as the related work, to find out what the actualcontributions are, why they are important, how they compare with previous work, etc A few examples are provided below: 1- I recommend consulting a professionalediting service to improve generalreadability.", "There are severalsentences that are not informative, or are confusing.", "It is not clear what some pronouns refer to.", "For example: \u00e2\u0080\u009cThese results generalze previous work [..].", "**They** are obtained under [..] Lojasiewicz condition.\u00e2\u0080\u009d Which results?", "All of them?", "But this seemed to relate to convex / exp-concave functions.", "One has to read until the end to find out which results is given under what condition.", "2- The introduction should discuss what is the goalof the paper, what are the high-level results, and why they matter and were not obtained before.", "Instead, it gets to details such as using Dirac masses to get the regret, and goes to \u00e2\u0080\u009cPrevious work\u00e2\u0080\u009d.", "What do you want to do?", "Why?", "3- The previous work secion seems incomplete, uninformative, and vague.", "What is \u00e2\u0080\u009ca subroutine centered around the current estimate\u00e2\u0080\u009d?", "Why should we know this?", "We still don\u00e2\u0080\u0099t know what the paper is trying to do\u00e2\u0080\u00a6 Shouldn\u00e2\u0080\u0099t Lines 41,42 actualy just go to the \u00e2\u0080\u009ccontributions\u00e2\u0080\u009d secion?", "4- Similar vague sentences and paragraphs appear throughout the paper.", "The paper is not self-contained (e g , \u00e2\u0080\u009cextended to a unique approximately sparse Theta* [ ..] see [1;3]\u00e2\u0080\u009d).", "Hand-wavy explanations and phrases are used where appropriate mathematicalexpressions should appear (e g , \u00e2\u0080\u009cset of hard-truncated and dilated soft-thresholded versions of [..] as in (43)\u00e2\u0080\u009d).", "On the other hand, explanation is absent where it would be useful.", "For example, why should one consider SABOA instead of BOA+ in the stochastic setting?", "Why can we use previous iterates instead of the leaders here?", "# Originalty The comparison with related work is unclear.", "The reader needs to go to the related work and find the results and compare them with the current results (even, e g , the respective Theorem numbers are not given).", "I recommend providing a table comparing previous work (e g , as in [22]), showing whether each result concerned regret or cumulative risk [as in 22], strongly-convex, exp-concave, or weak exp-concave losses, was it an h p or expectation bound, etc"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_648_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno1", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_648_1", "review_text": "This paper considers online learning with a family of losses defined on the L1 ball with some parametrized curvature. The algorithm automatically adapts to this curvature information. In the case of strongly-convex losses, a variant of the algorithm can adapt to the sparsity (L0 norm, _not_ the L1 norm) of the competitor.  The algorithm itself is a somewhat technical modification of an experts algorithm that mainains a set of experts corresponding both to (point, learning rate) pairs, where the points come from some specified subset of the L1 ball.  Quality: This paper seems to have nice results. I liked that the algorithm can adapt to the curvature without knowing the curvature parameters, and I was also impressed by the second algorithm's ability to adapt to the L_0 norm of the competitor. I really liked the inductive technique used in the proof of Theorem 3.3. The results of Theorem 3.2 are a little hard to interpret, due to the unusual distance term. It seems clear there is a runtime/regret bound tradeoff at work here, but is there some example for a regret bound that is better than 1/sqrt{T}? It seems that (at the cost of exponenial runtime, as in Theorem 3.1), this should be achieveable. Is there anything better one can do?   Clarity: I found this paper a bit difficult to follow at times. In particular, the intuition for the proofs is not presented well, which I found very distressing since the statements seem relatively powerful and the corresponding proofs seem very technical.  In the sketch of proof for theorem 3.2, on line 221, it seems to be implied that regrets is linear in the comparison point, which confused me since the loss functions have curvature. I believe this was actually a statement about linearized regret, but this was not clear without some poking in the appendix.   In the proof of theorem 3.3, the value \"a\" is initially defined to have a term \\log(3d), but later (line 594), this seems to become \\log(2d).   In line 89, it is stated that under the Lojasiewicz condition the algorithm obtains low regret for comparitors with l1 norm bounded by c<1. However, the corresponding theorem (which I believe is Theorem 3.4) I believe replaces c with 1-\\gamma. It seems best to use the same notation.  Equation (7) in the appendix is stated to be a restatement of Theorem 3.2 of Wittenberger(2017), but it is not obvious to me that it is the same as it seems to be missing a log(E_\\pi_0[1/\\eta]/E_{\\pi[1/\\eta]}). No doubt I'm missing something here, but the proofs are technical enough that I'd appreciate even small gaps being filled.   The use of NP to describe an algorithm in line 175 was also a bit confusing to me. The algorithm proposed is exponential time. But to be precise, algorithms are not in NP - problems are. And this problem seems not to be since it is solved in polynomial time in the next theorem. Maybe there is some other meaning of NP, but in general the meaning is clear if you just say exponential time.  Also, there are some shenanigans with the typesetting. The paper is over the length limit, and it appears to have smaller text and bigger margins than it should.  Finally, there are few minor grammatical errors 84: \"it exists\" -> \"there exists\" 159: \"it is worth to point out\" -> \"it is useful to point out\" 175: sentence starting with \"In Section 3.1...\" seems to switch between plural and singular tenses several times.   Originality:  I believe these results are original.  Significance:  The adaptivity of the algorithm to the curvature and L0 sparsity is interesting. I think the analysis of the algorithm of section 3.3 had some interesting techniques. Overall I think there is reasonable hope the techniques may be used to design future algorithms.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_648_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper considers online learning with a family of losses defined on the L1 bal with some parametrized curvature.", "The alorithm automaticaly adapts to this curvature information.", "In the case of strongly-convex losses, a variant of the alorithm can adapt to the sparsity (L0 norm, _not_ the L1 norm) of the competitor.", "The alorithm itself is a somewhat technicalmodification of an experts alorithm that mainains a set of experts corresponding both to (point, learning rate) pairs, where the points come from some specified subset of the L1 bal.", "Qualty: This paper seems to have nice results.", "I liked that the alorithm can adapt to the curvature without knowing the curvature parameters, and I was alo impressed by the secnd alorithm's ability to adapt to the L_0 norm of the competitor.", "I realy liked the inductive technique used in the proof of Theorem 3 3, The results of Theorem 3 2 are a little hard to interpret, due to the unusualdistance term.", "It seems clear there is a runtime/regret bound tradeoff at work here, but is there some example for a regret bound that is better than 1/sqrt{T}?", "It seems that (at the cost of exponenialruntime, as in Theorem 3 1), this should be achieveable.", "Is there anything better one can do?", "Clarity: I found this paper a bit difficult to follow at times.", "In particular, the intuition for the proofs is not presented well, which I found very distressing since the statements seem relatively powerful and the corresponding proofs seem very technical In the sketc of proof for theorem 3 2, on line 221, it seems to be implied that regrets is linear in the comparison point, which confused me since the loss functions have curvature.", "I believe this was actualy a statement about linearized regret, but this was not clear without some poking in the appendix.", "In the proof of theorem 3 3, the vale \"a\" is initialy defined to have a term \\log(3d), but later (line 594), this seems to become \\log(2d).", "In line 89, it is stated that under the Lojasiewicz condition the alorithm obtains low regret for comparitors with l1 norm bounded by c<1, However, the corresponding theorem (which I believe is Theorem 3 4) I believe replaces c with 1-\\gamma.", "It seems best to use the same notation.", "eqation (7) in the appendix is stated to be a restatement of Theorem 3 2 of Wittenberger(2017), but it is not obvious to me that it is the same as it seems to be missing a log(E_\\pi_0[1/\\eta]/E_{\\pi[1/\\eta]}).", "No doubt I'm missing something here, but the proofs are technicalenough that I'd appreciate even smal gaps being filled.", "The use of NP to describe an alorithm in line 175 was alo a bit confusing to me.", "The alorithm proposed is exponentialtime.", "But to be precise, alorithms are not in NP - problems are.", "And this problem seems not to be since it is solved in polynomialtime in the next theorem.", "Maybe there is some other meaning of NP, but in generalthe meaning is clear if you just say exponentialtime.", "Also, there are some shenanigans with the typesetting.", "The paper is over the length limit, and it appears to have smaler text and bigger margins than it should.", "Finaly, there are few minor grammaticalerrors 84: \"it exists\" -> \"there exists\" 159: \"it is worth to point out\" -> \"it is useful to point out\" 175: sentence starting with \"In secion 3 1 ..\" seems to switch between pluraland singular tenses severaltimes.", "Originalty: I believe these results are original Significance: The adaptivity of the alorithm to the curvature and L0 sparsity is interesting.", "I think the analsis of the alorithm of secion 3 3 had some interesting techniques.", "Overal I think there is reasonable hope the techniques may be used to design future alorithms."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_648_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_641_4", "review_text": "This paper shows that under technical conditions, as the size of the \"minipool\" approaches infinity, uncertainty sampling is moving in the descent directions of the expected 0-1 loss in expectation. Therefore, uncertainty sampling may be interpreted as performing SGD with respect to the expected 0-1 loss. Based on this interpretation, the authors tried explaining why uncertainty sampling sometimes yields a smaller risk than the standard random sampling approach and why different initialization gives different outputs, as these are common behaviors of the SGD.   The authors' perspective is quite fresh and inspiring, but there are some weakness.   First, the main result, Corollary 10, is not very strong. It is asymptotic, and requires the iterates to lie in a \"good\" set of regular parameters; the condition on the iterates was not checked. Corollary 10 only requires a lower bound on the regularization parameter; however, if the parameter is set too large such that the regularization term is dominating, then the output will be statistically meaningless.   Second, there is an obvious gap between the interpretation and what has been proved. Even if Corollary 10 holds under more general and acceptable conditions, it only says that uncertainty sampling iterates along the descent directions of the expected 0-1 loss. I don't think that one may claim that uncertainty sampling is SGD merely based on Corollary 10. Furthermore, existing results for SGD require some regularity conditions on the objective function, and the learning rate should be chosen properly with respect to the conditions; as the conditions were not checked for the expected 0-1 loss and the \"learning rate\" in uncertainty sampling was not specified, it seems not very rigorous to explain empirical observations based on existing results of SGD.   The paper is overall well-structured. I appreciate the authors' trying providing some intuitive explanations of the proofs, though there are some over-simplifications in my view. The writing looks very hasty; there are many typos and minor grammar mistakes.   I would say that this work is a good starting point for an interesting research direction, but currently not very sufficient for publication.   Other comments:  1. ln. 52: Not all convex programs can be efficiently solved. See, e.g. \"Gradient methods for minimizing composite functions\" by Yu. Nesterov.  2. ln. 55: I don't see why the regularized empirical risk minimizer will converge to the risk minimizer without any condition on, for example, the regularization parameter. 3. ln. 180--182: Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss; this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate.    4. ln. 182--184: Non-convexity may not be an issue for the SGD to converge, if the function Z has some good properties.  5. The proofs in the supplementary material are too terse. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_641_4", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper shows that under technicalconditions, as the size of the \"minipool\" approaches infinity, uncertainty sampling is moving in the descent directions of the expected 0-1 loss in expectation.", "Therefore, uncertainty sampling may be interpreted as performing SGD with respect to the expected 0-1 loss.", "Based on this interpretation, the authors tried explaining why uncertainty sampling sometimes yields a smaler risk than the standard random sampling approach and why different initialzation gives different outputs, as these are common behaviors of the SGD.", "The authors' perspective is quite fresh and inspiring, but there are some weakness.", "First, the main result, Corollary 10, is not very strong.", "It is asymptotic, and reqires the iterates to lie in a \"good\" set of regular parameters; the condition on the iterates was not checked.", "Corollary 10 only reqires a lower bound on the regularization parameter; however, if the parameter is set too large such that the regularization term is dominating, then the output will be statisticaly meaningless.", "secnd, there is an obvious gap between the interpretation and what has been proved.", "Even if Corollary 10 holds under more generaland acceptable conditions, it only says that uncertainty sampling iterates alng the descent directions of the expected 0-1 loss.", "I don't think that one may claim that uncertainty sampling is SGD merely based on Corollary 10, Furthermore, existing results for SGD reqire some regularity conditions on the objective function, and the learning rate should be chosen properly with respect to the conditions; as the conditions were not checked for the expected 0-1 loss and the \"learning rate\" in uncertainty sampling was not specified, it seems not very rigorous to explain empiricalobservations based on existing results of SGD.", "The paper is overal well-structured.", "I appreciate the authors' trying providing some intuitive explanations of the proofs, though there are some over-simplifications in my view.", "The writing looks very hasty; there are many typos and minor grammar mistakes.", "I would say that this work is a good starting point for an interesting research direction, but currently not very sufficient for publication.", "Other comments: 1, ln.", "52: Not al convex programs can be efficiently solved.", "See, e g \"Gradient methods for minimizing composite functions\" by Yu.", "Nesterov.", "2, ln.", "55: I don't see why the regularized empiricalrisk minimizer will converge to the risk minimizer without any condition on, for example, the regularization parameter.", "3, ln.", "180--182: Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss; this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate.", "4, ln.", "182--184: Non-convexity may not be an issue for the SGD to converge, if the function Z has some good properties.", "5, The proofs in the supplementary materialare too terse."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_641_4", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno1", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_640_3", "review_text": "This paper proposed an online learning algorithm for static and dynamic sum-product networks (SPNs), a type of probabilistic model with tractable inference. The authors essentially combine local structure search in SPNs with a hard variant of expectation-maximization [1]. The algorithm maintains empirical covariance estimates of product nodes and leverages statistical dependence tests to decide when to replace a product (factorized distribution) with either a new leaf or a mixture (sum node). The algorithm further includes a pruning mechanism in order to trim over-grown structures. The proposed method is called online Structure Learning with Running Average Update (oSLRAU).  Strengths: + the hard EM scheme, already used by Poon and Domingos [1], is an effective and efficient method for parameter learning in SPNs. While Poon and Domingos applied it to select a sub-structure in a pre-determined layout, its use for flexible structure learning is good idea.  + the structure updates by monitoring empirical means and covariances at product nodes is also a natural and elegant choice.  + together with network pruning, the proposed structure learning scheme is natural and has the potential to become a state-of-the-art method.  Weaknesses: - while the approach has certain potential strengths, see above, the paper does not elaborate on them in a satisfying way. This approach could break new ground in learning SPNs, but the paper is presented in a \"yet-another-SPN-learning-algorithm\" fashion. - the paper is overloaded: online learning of both parameters and structure in (static) SPNs is already an important topic far from being closed. The paper, however, additionally discusses dynamic SPNs in a somewhat superficial way. In that way, the paper is not focused on a particular problem. - the experimental evaluation is also rather unfocused. It is not clear to me why the particular tasks and comparison methods where chosen.  Quality: The approach in this paper is reasonably justified. In particular, it leverages the hard EM variant due to Poon & Domingos [1], which was successful in selecting a sub-structure in a large potential structure layout tailored to images. In this paper, this method is used in a completely dynamic way, which I find promising. The structural updates (replacing product nodes with multi-variate Gaussians or new sum nodes; pruning) are also natural and remind at structural search in SPNs [2,3]. However, these advantages are not elaborated in a satisfying manner. I would really like to see a serious attempt to establish a new state-of-the-art method for learning SPNs; no theoretical justification/motivation for oSLRAU is given (besides a Theorem in the supplementary, guaranteeing that the likelihood of the last single sample is guaranteed to be increased -- does this really matter?), nor is it empirically demonstrated that it improves state-of-the-art. In particular, an eager comparison with LearnSPN is left out. Additionally I don't see the benefit to also discuss oSLRAU for dynamic SPNs, in particular, as these are discussed in a quite superficial and incomprehensible way.   Clarity: The paper is reasonably clear, but could be improved at some parts. In particular, the paper does not give a focused impression (what is the goal of the paper), many choices are not motivated (e.g. why compare e.g. with NVP but not with LearnSPN), many relevant parts are deferred to the supplementary.  Originality: The paper is quite original, but it does not discuss prior art in a fully adequate and careful way.  Two examples: 1) \"SPNs were first introduced in [Poon and Domgos, 2011] as new type of deep representation.\" While it is certainly true that Poon and Domingos introduced new insights and ideas to SPNs, it is crucial to acknowledge the work of Darwiche, e.g. [4]. 2) \"SPNs are equivalent to Bayesian networks and Markov networks [Zhao et al., 2015], ...\" First it is not at all explained in what sense SPNs are supposed to be equivalent to Bayesian networks and Markov networks, and second, this is not what Zhao et al. have discussed. SPNs are certainly not equivalent to Markov network (in whatever sense), and also not to Bayesian networks. Zhao et al. have shown the SPNs can be cast into special Bayesian networks incorporating a layer of latent variables. Furthermore, it is clear that Bayesian networks over discrete variables using CPTs can also be easily mapped to SPNs, but, clearly, somewhat more exotic Bayesian networks are not easily mapped to SPNs.   Significance: The ideas in this paper have the potential to establish new state-of-the-art and are therefore of potential significance. However, as mentioned above, due to the rather unfocused presentation, motivation, and empirical evaluation, the paper does not unfold this potential.  [1] Poon, H. and Domingos, P., \"Sum-Product Networks: A new deep architecture\", UAI, 2011. [2] Dennis, A. and Ventura, D., \"Greedy Structure Search for Sum-Product Networks\", IJCAI, 2015. [3] Peharz, R. and Gens, R. and Domingos, P. \"Learning selective sum-product networks\", LTPM, 2014. [4] Darwiche, A., \"A differential approach to inference in Bayesian networks\", ACM, 2003.    ***EDIT***  The authors (and reviewer #1) have discussed NP-hardness of hard EM.   Please note that hard EM is *not* NP-hard in SPNs.   In fact, it is well tractable. To see this, assume that X are the observed variables and Z are the latent variables associated with the sum nodes. Hard-EM is like soft-EM, but where the expectation over the complete log-likelihood w.r.t. the posterior P(Z | X) is replaced with the MAP solution of P(Z | X), i.e.  argmax_theta E_{P(Z | X ; theta_old)} [log P(X,Z)]       (soft EM) becomes argmax_theta log P( X, argmax_Z(P(X, Z ; theta_old)) )   (hard EM)  where theta are all parameters (sum-weights, params of input distributions). The critical bit is computing  Z* = argmax_Z(P(X, Z ; theta_old)), i.e. the most likely joint state of the latent variables (which determines an induced tree, see Zhao et al. [1]) given a sample for X. This inference query is well tractable. In fact, already Poon and Domingos [2] gave the correct algorithm for this (without proof): simply replace sum nodes with max nodes in the upwards pass and perform max-backtracking. That this algorithm is indeed correct was proved by Peharz et al. [3], Theorem 2: While reviewer #1 is right that MAP inference is in general NP-hard, inferring Z* is a notable exception, since the augmented SPN (the SPN which makes the latent variables explicit [3]) is *selective*. Note that the augmented SPN does not need to be constructed explicitly. It is clear that given Z* for each sample, updating the parameters is easy, in fact closed form.  Also note that the same (exact) inference of Z* as required for hard EM was used by Vergari et al. [4], with the goal to infer a data representation.  The authors also discussed a variant of hard EM used by Poon and Domingos [2], where sums are used in the upwards pass. It is rather clear that this is a kind of nested hard EM: perform MAP inference of the top sum layer, with the latent variables below marginalized, fix (condition on) this assignment for the top layer, and continue with MAP inference in the next layer, and so forth.  It would be desirable that the authors incorporate this well-established theory in their paper, since hard EM is the central working horse of their method.   A further point of importance is the connection between Bayesian networks, Markov networks and SPNs.   Reviewer #1 stated: \"\"\" \"SPNs are equivalent to Bayesian and Markov networks\" - this might be misleading, since to represent the same domain, one may need an exponentially large SPN in order to represent the same as a BN or MRF. So we should be careful with the \"equivalence\" usage. \"\"\"  I stated: \"\"\" 2) \"SPNs are equivalent to Bayesian networks and Markov networks [Zhao et al., 2015], ...\" First it is not at all explained in what sense SPNs are supposed to be equivalent to Bayesian networks and Markov networks, and second, this is not what Zhao et al. have discussed. SPNs are certainly not equivalent to Markov network (in whatever sense), and also not to Bayesian networks. Zhao et al. have shown the SPNs can be cast into special Bayesian networks incorporating a layer of latent variables. Furthermore, it is clear that Bayesian networks over discrete variables using CPTs can also be easily mapped to SPNs, but, clearly, somewhat more exotic Bayesian networks are not easily mapped to SPNs.  \"\"\"  The authors were evidently not alerted by the fact that two reviewers were independently puzzled by their claim. According to common understanding, Markov networks and Bayesian networks are *not* equivalent, see any common text book on graphical models [5]. So they cannot both be equivalent to SPNs.  The notion of equivalence used by the authors, by which two models are equivalent whenever they can be convert into each other -- possibly under an exponential blowup -- is not meaningful. Sure, a fully connected BN can represent any distribution, so can a fully connected Markov network. This does *not* make these models equivalent.  The authors stated that they are not aware of more exotic variants of BNs which cannot obviously be converted into an SPN. Take for example a BN over continuous variables, whose conditional distributions are Gamma distributions, parametrized via neural networks taking the parents' values as inputs (note that BNs are not restricted to discrete variables, so this perfectly defines a BN). It is not clear to me how to convert this BN into an SPN. Moreover, how would the authors convert a restricted Boltzmann machine (which is a MN) into an SPN? This will be hard, given the intractability of the RBM's partition function.  Claiming equivalence between SPNs, BNs and MNs in the very introduction of the paper is a deepity, at best.    The authors kindly invited me to re-read their paper, and re-iterated their contributions. However, the \"what\" was not the problem for me in the first place, but rather the \"why\". As said in my review, the use of hard EM for online structure learning is very promising and already challenging on its own. As illustrated above, there is also a lot of theory on this topic which should be addressed and build on. To additionally apply the framework to dynamic SPNs makes the paper rather convoluted and unfocused. Perhaps this is just personal opinion, but the authors did not explain their motivation in a satisfying manner.   Due to the the shortcomings discussed above, I stick with my initial score.     [1] Zhao et al., On the relationship between SPNs and BNs, 2015. [2] Poon and DOmingos, SPNs: a new deep architeccture, 2011. [3] Peharz et al., On the latent variable interpretation in SPNs, 2017. [4] Vergari et al., Sum-Product autoencoding, 2018. [5] Koller and Friedman, Probabilistic Graphical Models, 2009.  ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_640_3", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["This paper proposed an online learning alorithm for static and dynamic sum-product networks (SPNs), a type of probabilistic model with tractable inference.", "The authors essentialy combine localstructure search in SPNs with a hard variant of expectation-maximization [1].", "The alorithm maintains empiricalcovariance estimates of product nodes and leverages statisticaldependence tests to decide when to replace a product (factorized distribution) with either a new leaf or a mixture (sum node).", "The alorithm further includes a pruning mechanism in order to trim over-grown structures.", "The proposed method is caled online Structure Learning with Running Average Update (oSLRAU).", "Strengths: + the hard EM scheme, aleady used by Poon and Domingos [1], is an effective and efficient method for parameter learning in SPNs.", "While Poon and Domingos applied it to select a sub-structure in a pre-determined layout, its use for flexible structure learning is good idea.", "+ the structure updates by monitoring empiricalmeans and covariances at product nodes is alo a naturaland elegant choice.", "+ together with network pruning, the proposed structure learning scheme is naturaland has the potentialto become a state-of-the-art method.", "Weaknesses: - while the approach has certain potentialstrengths, see above, the paper does not elaborate on them in a satisfying way.", "This approach could break new ground in learning SPNs, but the paper is presented in a \"yet-another-SPN-learning-alorithm\" fashion.", "- the paper is overloaded: online learning of both parameters and structure in (static) SPNs is aleady an important topic far from being closed.", "The paper, however, additionaly discusses dynamic SPNs in a somewhat superficialway.", "In that way, the paper is not focused on a particular problem.", "- the experimentalevalation is alo rather unfocused.", "It is not clear to me why the particular tasks and comparison methods where chosen.", "Qualty: The approach in this paper is reasonably justified.", "In particular, it leverages the hard EM variant due to Poon & Domingos [1], which was successful in selecting a sub-structure in a large potentialstructure layout tailored to images.", "In this paper, this method is used in a completely dynamic way, which I find promising.", "The structuralupdates (replacing product nodes with multi-variate Gaussians or new sum nodes; pruning) are alo naturaland remind at structuralsearch in SPNs [2,3].", "However, these advantages are not elaborated in a satisfying manner.", "I would realy like to see a serious attempt to establish a new state-of-the-art method for learning SPNs; no theoreticaljustification/motivation for oSLRAU is given (besides a Theorem in the supplementary, guaranteeing that the likelihood of the last single sample is guaranteed to be increased -- does this realy matter?", "), nor is it empiricaly demonstrated that it improves state-of-the-art.", "In particular, an eager comparison with LearnSPN is left out.", "Additionaly I don't see the benefit to alo discuss oSLRAU for dynamic SPNs, in particular, as these are discussed in a quite superficialand incomprehensible way.", "Clarity: The paper is reasonably clear, but could be improved at some parts.", "In particular, the paper does not give a focused impression (what is the goalof the paper), many choices are not motivated (e g why compare e g with NVP but not with LearnSPN), many relevant parts are deferred to the supplementary.", "Originalty: The paper is quite original but it does not discuss prior art in a fully adeqate and careful way.", "Two examples: 1) \"SPNs were first introduced in [Poon and Domgos, 2011] as new type of deep representation.\"", "While it is certainly true that Poon and Domingos introduced new insights and ideas to SPNs, it is crucialto acknowledge the work of Darwiche, e g [4].", "2) \"SPNs are eqivalnt to Bayesian networks and Markov networks [Zhao et al, 2015], ...\" First it is not at al explained in what sense SPNs are supposed to be eqivalnt to Bayesian networks and Markov networks, and secnd, this is not what Zhao et al have discussed.", "SPNs are certainly not eqivalnt to Markov network (in whatever sense), and alo not to Bayesian networks.", "Zhao et al have shown the SPNs can be cast into specialBayesian networks incorporating a layer of latent variables.", "Furthermore, it is clear that Bayesian networks over discrete variables using CPTs can alo be easily mapped to SPNs, but, clearly, somewhat more exotic Bayesian networks are not easily mapped to SPNs.", "Significance: The ideas in this paper have the potentialto establish new state-of-the-art and are therefore of potentialsignificance.", "However, as mentioned above, due to the rather unfocused presentation, motivation, and empiricalevalation, the paper does not unfold this potential [1] Poon, H and Domingos, P , \"Sum-Product Networks: A new deep architecture\", UAI, 2011, [2] Dennis, A and Ventura, D , \"Greedy Structure Search for Sum-Product Networks\", IJCAI, 2015, [3] Peharz, R and Gens, R and Domingos, P \"Learning selective sum-product networks\", LTPM, 2014, [4] Darwiche, A , \"A differentialapproach to inference in Bayesian networks\", ACM, 2003, ***EDIT*** The authors (and reviewer #1) have discussed NP-hardness of hard EM.", "Please note that hard EM is *not* NP-hard in SPNs.", "In fact, it is well tractable.", "To see this, assume that X are the observed variables and Z are the latent variables associated with the sum nodes.", "Hard-EM is like soft-EM, but where the expectation over the complete log-likelihood w r t the posterior P(Z | X) is replaced with the MAP solution of P(Z | X), i e argmax_theta E_{P(Z | X ; theta_old)} [log P(X,Z)] (soft EM) becomes argmax_theta log P( X, argmax_Z(P(X, Z ; theta_old)) ) (hard EM) where theta are al parameters (sum-weights, params of input distributions).", "The criticalbit is computing Z* = argmax_Z(P(X, Z ; theta_old)), i e the most likely joint state of the latent variables (which determines an induced tree, see Zhao et al [1]) given a sample for X This inference query is well tractable.", "In fact, aleady Poon and Domingos [2] gave the correct alorithm for this (without proof): simply replace sum nodes with max nodes in the upwards pass and perform max-backtracking.", "That this alorithm is indeed correct was proved by Peharz et al [3], Theorem 2: While reviewer #1 is right that MAP inference is in generalNP-hard, inferring Z* is a notable exception, since the augmented SPN (the SPN which makes the latent variables explicit [3]) is *selective*.", "Note that the augmented SPN does not need to be constructed explicitly.", "It is clear that given Z* for each sample, updating the parameters is easy, in fact closed form.", "Also note that the same (exact) inference of Z* as reqired for hard EM was used by Vergari et al [4], with the goalto infer a data representation.", "The authors alo discussed a variant of hard EM used by Poon and Domingos [2], where sums are used in the upwards pass.", "It is rather clear that this is a kind of nested hard EM: perform MAP inference of the top sum layer, with the latent variables below marginalzed, fix (condition on) this assignment for the top layer, and continue with MAP inference in the next layer, and so forth.", "It would be desirable that the authors incorporate this well-established theory in their paper, since hard EM is the centralworking horse of their method.", "A further point of importance is the connection between Bayesian networks, Markov networks and SPNs.", "Reviewer #1 stated: \"\"\" \"SPNs are eqivalnt to Bayesian and Markov networks\" - this might be misleading, since to represent the same domain, one may need an exponentialy large SPN in order to represent the same as a BN or MRF.", "So we should be careful with the \"eqivalnce\" usage. \"\"\"", "I stated: \"\"\" 2) \"SPNs are eqivalnt to Bayesian networks and Markov networks [Zhao et al, 2015], ...\" First it is not at al explained in what sense SPNs are supposed to be eqivalnt to Bayesian networks and Markov networks, and secnd, this is not what Zhao et al have discussed.", "SPNs are certainly not eqivalnt to Markov network (in whatever sense), and alo not to Bayesian networks.", "Zhao et al have shown the SPNs can be cast into specialBayesian networks incorporating a layer of latent variables.", "Furthermore, it is clear that Bayesian networks over discrete variables using CPTs can alo be easily mapped to SPNs, but, clearly, somewhat more exotic Bayesian networks are not easily mapped to SPNs. \"\"\"", "The authors were evidently not alrted by the fact that two reviewers were independently puzzled by their claim.", "According to common understanding, Markov networks and Bayesian networks are *not* eqivalnt, see any common text book on graphicalmodels [5].", "So they cannot both be eqivalnt to SPNs.", "The notion of eqivalnce used by the authors, by which two models are eqivalnt whenever they can be convert into each other -- possibly under an exponentialblowup -- is not meaningful.", "Sure, a fully connected BN can represent any distribution, so can a fully connected Markov network.", "This does *not* make these models eqivalnt.", "The authors stated that they are not aware of more exotic variants of BNs which cannot obviously be converted into an SPN.", "Take for example a BN over continuous variables, whose conditionaldistributions are Gamma distributions, parametrized via neuralnetworks taking the parents' vales as inputs (note that BNs are not restricted to discrete variables, so this perfectly defines a BN).", "It is not clear to me how to convert this BN into an SPN.", "Moreover, how would the authors convert a restricted Boltzmann machine (which is a MN) into an SPN?", "This will be hard, given the intractability of the RBM's partition function.", "Claiming eqivalnce between SPNs, BNs and MNs in the very introduction of the paper is a deepity, at best.", "The authors kindly invited me to re-read their paper, and re-iterated their contributions.", "However, the \"what\" was not the problem for me in the first place, but rather the \"why\".", "As said in my review, the use of hard EM for online structure learning is very promising and aleady chalenging on its own.", "As illustrated above, there is alo a lot of theory on this topic which should be addressed and build on.", "To additionaly apply the framework to dynamic SPNs makes the paper rather convoluted and unfocused.", "Perhaps this is just personalopinion, but the authors did not explain their motivation in a satisfying manner.", "Due to the the shortcomings discussed above, I stick with my initialscore.", "[1] Zhao et al, On the relationship between SPNs and BNs, 2015, [2] Poon and DOmingos, SPNs: a new deep architeccture, 2011, [3] Peharz et al, On the latent variable interpretation in SPNs, 2017, [4] Vergari et al, Sum-Product autoencoding, 2018, [5] Koller and Friedman, Probabilistic GraphicalModels, 2009,"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_640_3", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno1", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_242_2", "review_text": "The paper was too technical for a conference review (with 34 pages of supplement!), that too within a short period of time. I glanced over the high level contributions and if the proofs are correct, would definitely fit into the theoretical niche areas of NIPS. I would defer to the opinion of other reviewers who might have been able to provide more time to the paper for a thorough review.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_242_2", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}, "score": 1.0, "tokenized_review_text": ["The paper was too technicalfor a conference review (with 34 pages of supplement!", "), that too within a short period of time.", "I glanced over the high level contributions and if the proofs are correct, would definitely fit into the theoreticalniche areas of NIPS.", "I would defer to the opinion of other reviewers who might have been able to provide more time to the paper for a thorough review."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_242_2", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_630_1", "review_text": "This paper adds diminishing / accelerating return constraints to lattice models. The authors showed with the additional knowledge of features, their approach can reduce the testing error on some datasets. I think the idea of the paper, that to utilize human knowledge when the data is scarce, is very interesting. Utilizing diminishing / accelerating return constraints is novel according to my knowledge. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_630_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno3", "evidence": 1, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 1.0, "tokenized_review_text": ["This paper adds diminishing / accelerating return constraints to lattice models.", "The authors showed with the additionalknowledge of features, their approach can reduce the testing error on some datasets.", "I think the idea of the paper, that to utilize human knowledge when the data is scarce, is very interesting.", "Utilizing diminishing / accelerating return constraints is novel according to my knowledge."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_630_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno3", "evidence": 1, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_61_3", "review_text": "The paper proposes an alternative architecture to mainstream captioning models which usually follow a sequential structure. The model has two stages: 1) generating explicit semantic representations given images using noun phrases. 2) composing the noun phrases using a recursive architecture to generate the final caption.   - Idea/approach wise I think this is an interesting direction to go for generating captions, especially with the issues currently associated with captioning models (e.g. lack of diversity).  - The paper is very well written. It is easy to follow the ideas and get to the details of the approach, the illustrations (figures) are motivating and clear.  - While the current approach only outperforms the state of the art with one metric (SPICE), the experimental results are strong -- with good analysis to show where further improvements can be made (e.g. providing ground truth noun phrases), and where the strengths of the model is (generalization to other datasets).  Things to improve: - It would be great to show the training and testing time of the model. For example, how long does it take to train the connecting module? Comparing all pairs of left and right might take a long time.  - While SPICE is shown to have correlated more with human judgement, it would still be good to conduct some human evaluation experiments to strengthen the paper. - It would be nice to show some failure cases of the model, and see whether it is n-gram grammatical structure that fails in the most cases. - Are the modules trained jointly? If not, would joint training help?", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_61_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper proposes an alernative architecture to mainstream captioning models which usualy follow a seqentialstructure.", "The model has two stages: 1) generating explicit semantic representations given images using noun phrases.", "2) composing the noun phrases using a recursive architecture to generate the finalcaption.", "- Idea/approach wise I think this is an interesting direction to go for generating captions, especialy with the issues currently associated with captioning models (e g lack of diversity).", "- The paper is very well written.", "It is easy to follow the ideas and get to the details of the approach, the illustrations (figres) are motivating and clear.", "- While the current approach only outperforms the state of the art with one metric (SPICE), the experimentalresults are strong -- with good analsis to show where further improvements can be made (e g providing ground truth noun phrases), and where the strengths of the model is (generalzation to other datasets).", "Things to improve: - It would be great to show the training and testing time of the model.", "For example, how long does it take to train the connecting module?", "Comparing al pairs of left and right might take a long time.", "- While SPICE is shown to have correlated more with human judgement, it would still be good to conduct some human evalation experiments to strengthen the paper.", "- It would be nice to show some failure cases of the model, and see whether it is n-gram grammaticalstructure that fails in the most cases.", "- Are the modules trained jointly?", "If not, would joint training help?"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_61_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_259_2", "review_text": "This paper presents a method for unsupervised learning of shape and pose with differentiable point clouds. During training, it uses multiple views of the same object as input, and estimate the camera poses and the 3d point cloud by minimizing the reprojection loss between the multiple input images. The key novelty is the differentiable point cloud rendering (reprojection) operation (Fig.2), which is similar to operations in CVPR 2018 SplatNet.   Overall, the differentiable point cloud rendering is interesting, which potential applications to many other vision tasks. The experimental results are promising.   A few questions.  1. If camera pose is unknown, even with multiple images, there is inherently ambiguity for 3D reconstruction. For example, from two views, we can obtain perspective reconstruction at best. When more information is present, for example, camera is calibration, we can then obtain affine reconstruction and metric reconstruction. Given this, I want to know how the paper handles such reconstruction ambiguity from a single input image?   2. What is the benefit of using a point cloud as the 3D representation, compared to 3D meshes, for example? There is a recent CVPR 2018 paper on nenural mesh rendering? Will that be used for the same task? If so, what is the pro and con?   3. The reprojection loss heavily depends on the background. What the algorithm will do, if the input images are real images with cluttered background?   ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_259_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 3.0, "tokenized_review_text": ["This paper presents a method for unsupervised learning of shape and pose with differentiable point clouds.", "During training, it uses multiple views of the same object as input, and estimate the camera poses and the 3d point cloud by minimizing the reprojection loss between the multiple input images.", "The key novelty is the differentiable point cloud rendering (reprojection) operation (fig2), which is similar to operations in CVPR 2018 SplatNet.", "Overal, the differentiable point cloud rendering is interesting, which potentialapplications to many other vision tasks.", "The experimentalresults are promising.", "A few questions.", "1, If camera pose is unknown, even with multiple images, there is inherently ambiguity for 3D reconstruction.", "For example, from two views, we can obtain perspective reconstruction at best.", "When more information is present, for example, camera is calbration, we can then obtain affine reconstruction and metric reconstruction.", "Given this, I want to know how the paper handles such reconstruction ambiguity from a single input image?", "2, What is the benefit of using a point cloud as the 3D representation, compared to 3D meshes, for example?", "There is a recent CVPR 2018 paper on nenuralmesh rendering?", "Will that be used for the same task?", "If so, what is the pro and con?", "3, The reprojection loss heavily depends on the background.", "What the alorithm will do, if the input images are realimages with cluttered background?"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_259_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_278_2", "review_text": "This paper considers a classic problem in Bayesian optimization, where we seek to maximize a one-dimensional function evaluated without noise with a Brownian motion prior.  Using a novel algorithm and analysis that builds on Munos 2011 but goes substantially beyond it, it shows that an epsilon-optimal point can be found using log^2(1/epsilon) samples.  This provides over the previous best-known rate for this problem.  The results are quite nice from the point of view of the theoretical foundations of Bayesian optimization.  Indeed, optimizing with a Brownian motion prior has been studied since the 1970s by Calvin and Zilinskas especially, and this result improves on all of those results.  Thus, I feel the work is of high quality.  The work is also original --- although the paper builds on work by Munos and Calvin, there is a lot that is new.  The paper is also quite clear.  The only problem is with the paper's significance for the NIPS community, which often wants to see meaningful empirical results and practical applicability.  Unfortunately one-dimensional problems are much less common in practice than multi-dimensional ones, and Wiener process priors often don't fit the functions we optimize very well.  I feel that this work *is* significant from a theory perspective, given the dearth of results on convergence rates for Bayesian optimization, and is a stepping stone to understanding rates for more practical settings.  Beyond this, I only have some minor advice on clarity:  Lipschitz discussion: When I read the initial parts of the paper, I found the discussion of Lipschitz continuity confusing, since the path of a Brownian motion is not differentiable, and I believe is not Lipschitz continuous in the classical sense.  Here we are looking at finite meshes of decreasing size, and so after reading into the body of the paper I understood what was meant, but perhaps there is a way to write the initial discussion in a way that does not confuse readers familiar with the infinite roughness of Brownian motion's paths.   Throughout, I find the word \"Brownian\" without \"motion\" or \"bridge\" strange.  I recommend talking about a \"Brownian motion\" rather than a \"Brownian\".  If you like, you could abbreviate this at BM.  Typos: line 117 typo: \"The full proofs the auxiliary lemmas\" line 139 typo: \"achieving such PAC guarantee is low.\" line 150 and 151: it would be more clear to write the necessary condition for splitting as max(W(a),W(b)) >= M - eta*(b-a).", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_278_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper considers a classic problem in Bayesian optimization, where we seek to maximize a one-dimensionalfunction evalated without noise with a Brownian motion prior.", "Using a novel alorithm and analsis that builds on Munos 2011 but goes substantialy beyond it, it shows that an epsilon-optimalpoint can be found using log^2(1/epsilon) samples.", "This provides over the previous best-known rate for this problem.", "The results are quite nice from the point of view of the theoreticalfoundations of Bayesian optimization.", "Indeed, optimizing with a Brownian motion prior has been studied since the 1970s by Calin and Zilinskas especialy, and this result improves on al of those results.", "Thus, I feel the work is of high qualty.", "The work is alo original--- alhough the paper builds on work by Munos and Calin, there is a lot that is new.", "The paper is alo quite clear.", "The only problem is with the paper's significance for the NIPS community, which often wants to see meaningful empiricalresults and practicalapplicability.", "Unfortunately one-dimensionalproblems are much less common in practice than multi-dimensionalones, and Wiener process priors often don't fit the functions we optimize very well.", "I feel that this work *is* significant from a theory perspective, given the dearth of results on convergence rates for Bayesian optimization, and is a stepping stone to understanding rates for more practicalsettings.", "Beyond this, I only have some minor advice on clarity: Lipschitz discussion: When I read the initialparts of the paper, I found the discussion of Lipschitz continuity confusing, since the path of a Brownian motion is not differentiable, and I believe is not Lipschitz continuous in the classicalsense.", "Here we are looking at finite meshes of decreasing size, and so after reading into the body of the paper I understood what was meant, but perhaps there is a way to write the initialdiscussion in a way that does not confuse readers familiar with the infinite roughness of Brownian motion's paths.", "Throughout, I find the word \"Brownian\" without \"motion\" or \"bridge\" strange.", "I recommend taling about a \"Brownian motion\" rather than a \"Brownian\".", "If you like, you could abbreviate this at BM.", "Typos: line 117 typo: \"The full proofs the auxiliary lemmas\" line 139 typo: \"achieving such PAC guarantee is low.\"", "line 150 and 151: it would be more clear to write the necessary condition for splitting as max(W(a),W(b)) >= M - eta*(b-a)."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_278_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_296_1", "review_text": "Summary:  This paper considers the problem of tree-based search by leveraging a given (learned or hand-designed) policy to solve goal-based search problems. The paper proposes two different search algorithms with varying strengths and weakness, and provides guarantees on the number of nodes to be expanded before reaching a goal state. First, LevineTS based on Levine Search performs best-first search enumeration: penalizes with depth of a node and performs state cuts using the policy. Second, LubyTS is based on existing work on scheduling for randomized algorithms. It takes advantage of large number of candidate solutions (goal states) in the form of known maximum depth at which these solutions are present. It samples trajectories of this length using the policy until solution is found. Experiments are performed on Sokoban domain using a neural network policy learned using a reinforcement learning algorithm and comparison is performed with a domain-independent planner with good results.  Pros:  - Very well-written paper. - The proposed tree search algorithms and guarantees on expected search time (in terms of expanded nodes) to reach goal state. - Technically solid work.  Cons:  - The practical significance of this problem and tree search algorithms is not clear. - Lack of experimental results on more practical real-world applications of this problem setting and algorithms.   Detailed Comments:  1. Section 2 introduces too much notation that I don't think is necessary to explain the problem setting and algorithms. These are very simple search concepts.  2. I would have at least liked to see some potential real-world use-cases of the problem setting considering this paper is submitted to a NIPS conference.  3. Experimental results validate the algorithms and guarantees, but it would have been nice to see more empirical analysis on real-world use cases.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_296_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["Summary: This paper considers the problem of tree-based search by leveraging a given (learned or hand-designed) policy to solve goalbased search problems.", "The paper proposes two different search alorithms with varying strengths and weakness, and provides guarantees on the number of nodes to be expanded before reaching a goalstate.", "First, LevineTS based on Levine Search performs best-first search enumeration: penalzes with depth of a node and performs state cuts using the policy.", "secnd, LubyTS is based on existing work on scheduling for randomized alorithms.", "It takes advantage of large number of candidate solutions (goalstates) in the form of known maximum depth at which these solutions are present.", "It samples trajectories of this length using the policy until solution is found.", "Experiments are performed on Sokoban domain using a neuralnetwork policy learned using a reinforcement learning alorithm and comparison is performed with a domain-independent planner with good results.", "Pros: - Very well-written paper.", "- The proposed tree search alorithms and guarantees on expected search time (in terms of expanded nodes) to reach goalstate.", "- Technicaly solid work.", "Cons: - The practicalsignificance of this problem and tree search alorithms is not clear.", "- Lack of experimentalresults on more practicalrealworld applications of this problem setting and alorithms.", "Detailed Comments: 1, secion 2 introduces too much notation that I don't think is necessary to explain the problem setting and alorithms.", "These are very simple search concepts.", "2, I would have at least liked to see some potentialrealworld use-cases of the problem setting considering this paper is submitted to a NIPS conference.", "3, Experimentalresults valdate the alorithms and guarantees, but it would have been nice to see more empiricalanalsis on realworld use cases."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_296_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_298_1", "review_text": "The committee machine is a simple and natural model for a 2-layer neural network. (Here is the formal definition: it is a function R^n -> {+1,-1}, computed by taking K different linear combinations of the n inputs according to the weight matrix W (this is the hidden layer), then taking the sign of each hidden value, and then taking the majority vote of all these signs. The results of the paper also apply to many related models: you are allowed an arbitrary function mapping the K hidden values to the final binary output.)  This paper studies the problem of learning the weights W under a natural random model. We are given m random examples (X,Y) where the input X (in R^n) is iid Gaussian and Y (in {+1,-1}) is the associated output of the network. The unknown weights W are iid from a known prior. The authors study the asymptotic regime where the dimension n goes to infinity with the ratio alpha = m/n held constant (recall m is the number of samples) and the number of hidden layers K held constant.  Since the above is a fully-specified random model, it is amenable to study via tools from statistical physics. Prior work has rigorously analyzed the simpler case of \"generalized linear models\" which includes single-layer neural networks (K=1). Prior work has also analyzed the two-layer case using non-rigorous heuristics from statistical physics (which are well-established and widely believed to be reliable). The first contribution of the present work is to rigorously analyze the two-layer case (showing that the heuristics are indeed correct). Specifically, they give an exact formula for the limiting value (as n goes to infinity) of the information-theoretically optimal generalization error as a function of the sample complexity (alpha = m/n). The proof uses the \"adaptive interpolation method\", a recent method that has been successful for related problems.  The second contribution of the present work is to give a polynomial-time algorithm for learning the weights W based on AMP (approximate message passing). They also give an exact formula for the generalization error (as n goes to infinity) that it achieves. AMP is a well-established framework and is widely conjectured to be optimal among all polynomial-time algorithms for this type of problem. By comparing the formulas for AMP's performance and the information-theoretically optimal performance, the authors identify regimes that appear to have inherent statistical-to-computational gaps. The authors give a thorough investigation of these gaps and of the various \"phase transitions\" occurring in the problem.  I think this is a strong paper that builds on a lot of deep and powerful machinery from statistical physics in order to give important and fundamental advances towards a rigorous understanding of neural networks. The paper is well-written. I would be interested if the authors could comment on whether there is any hope of extending the results to more than two layers.  EDIT: I have read the other reviews and the author feedback. My opinion of the paper remains the same -- I vote to accept it.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_298_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 3.0, "tokenized_review_text": ["The committee machine is a simple and naturalmodel for a 2-layer neuralnetwork.", "(Here is the formaldefinition: it is a function R^n -> {+1,-1}, computed by taking K different linear combinations of the n inputs according to the weight matrix W (this is the hidden layer), then taking the sign of each hidden vale, and then taking the majority vote of al these signs.", "The results of the paper alo apply to many related models: you are alowed an arbitrary function mapping the K hidden vales to the finalbinary output.)", "This paper studies the problem of learning the weights W under a naturalrandom model.", "We are given m random examples (X,Y) where the input X (in R^n) is iid Gaussian and Y (in {+1,-1}) is the associated output of the network.", "The unknown weights W are iid from a known prior.", "The authors study the asymptotic regime where the dimension n goes to infinity with the ratio alha = m/n held constant (recal m is the number of samples) and the number of hidden layers K held constant.", "Since the above is a fully-specified random model, it is amenable to study via tools from statisticalphysics.", "Prior work has rigorously analzed the simpler case of \"generalzed linear models\" which includes single-layer neuralnetworks (K=1).", "Prior work has alo analzed the two-layer case using non-rigorous heuristics from statisticalphysics (which are well-established and widely believed to be reliable).", "The first contribution of the present work is to rigorously analze the two-layer case (showing that the heuristics are indeed correct).", "Specificaly, they give an exact formula for the limiting vale (as n goes to infinity) of the information-theoreticaly optimalgeneralzation error as a function of the sample complexity (alha = m/n).", "The proof uses the \"adaptive interpolation method\", a recent method that has been successful for related problems.", "The secnd contribution of the present work is to give a polynomialtime alorithm for learning the weights W based on AMP (approximate message passing).", "They alo give an exact formula for the generalzation error (as n goes to infinity) that it achieves.", "AMP is a well-established framework and is widely conjectured to be optimalamong al polynomialtime alorithms for this type of problem.", "By comparing the formulas for AMP's performance and the information-theoreticaly optimalperformance, the authors identify regimes that appear to have inherent statisticalto-computationalgaps.", "The authors give a thorough investigation of these gaps and of the various \"phase transitions\" occurring in the problem.", "I think this is a strong paper that builds on a lot of deep and powerful machinery from statisticalphysics in order to give important and fundamentaladvances towards a rigorous understanding of neuralnetworks.", "The paper is well-written.", "I would be interested if the authors could comment on whether there is any hope of extending the results to more than two layers.", "EDIT: I have read the other reviews and the author feedback.", "My opinion of the paper remains the same -- I vote to accept it."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_298_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_317_3", "review_text": "The paper provides an interesting analysis of gradient descent for deep linear networks as well as ReLU networks with only one hidden layer. Both cases use squared loss. The paper is well-written and well-organized and builds on tools from discrete-time dynamical systems. The paper has several interesting (and to the best of my knowledge original) components: 1. Providing upper bounds on step size for reaching each solution of a linear network. 2. For learning positive definite matrices by linear networks, identity initialization of weights allows the largest step size. 3. Analysis of the solution obtained by linear networks initialized by identity weights when the target matrix has negative eigenvalues. 4. Relationship between step size and model's output for a single hidden layer network with ReLU activations.  Question: Q1. Figure 2 shows with the smaller learning rate, the estimated function converges to a solution, and with the larger one it oscillates. I am wondering if the convergence/oscillation claim here is made based on mathematically analysis the resulted dynamical system or is judged based on numerically computed notion residual? If the latter, couldn't it be the case that the oscillation are not really perfect and are slowly converging to the target function? Since your point here is not speed of convergence, but rather realization of a perfect convergence or oscillation, numerical assessment may be misleading if that is what you are doing.  Q2. The paper has a general result for deep linear networks to learn an arbitrary nonzero matrix (Theorem 1 and Corollary 1). Specifically, in Corollary 1 authors provide an upper bound on the learning rate based on the largest singular value of the matrix. Later in the paper, when they add further assumption that the matrix is positive definite and weight matrices are initialized by identity, the step size bound becomes tighter. I am wondering if the authors have any intuition about what a worst case matrix and initialization would be for the general linear network case, to get a better understanding of the quality of the general-case bound.  Minor comment: In Example 1, the specification of the set S as S={0,d^2,-d^2,...} is ambiguous. Adding one more pair before \"...\" would help.  POST REBUTTAL: I had some minor questions which the authors replied. My rating for the paper is 8.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_317_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, "score": 4.0, "tokenized_review_text": ["The paper provides an interesting analsis of gradient descent for deep linear networks as well as ReLU networks with only one hidden layer.", "Both cases use squared loss.", "The paper is well-written and well-organized and builds on tools from discrete-time dynamicalsystems.", "The paper has severalinteresting (and to the best of my knowledge original components: 1, Providing upper bounds on step size for reaching each solution of a linear network.", "2, For learning positive definite matrices by linear networks, identity initialzation of weights alows the largest step size.", "3, Analsis of the solution obtained by linear networks initialzed by identity weights when the target matrix has negative eigenvales.", "4, Relationship between step size and model's output for a single hidden layer network with ReLU activations.", "Question: Q1, figre 2 shows with the smaler learning rate, the estimated function converges to a solution, and with the larger one it oscillates.", "I am wondering if the convergence/oscillation claim here is made based on mathematicaly analsis the resulted dynamicalsystem or is judged based on numericaly computed notion residual If the latter, couldn't it be the case that the oscillation are not realy perfect and are slowly converging to the target function?", "Since your point here is not speed of convergence, but rather realzation of a perfect convergence or oscillation, numericalassessment may be misleading if that is what you are doing.", "Q2, The paper has a generalresult for deep linear networks to learn an arbitrary nonzero matrix (Theorem 1 and Corollary 1).", "Specificaly, in Corollary 1 authors provide an upper bound on the learning rate based on the largest singular vale of the matrix.", "Later in the paper, when they add further assumption that the matrix is positive definite and weight matrices are initialzed by identity, the step size bound becomes tighter.", "I am wondering if the authors have any intuition about what a worst case matrix and initialzation would be for the generallinear network case, to get a better understanding of the qualty of the generalcase bound.", "Minor comment: In Example 1, the specification of the set S as S={0,d^2,-d^2,...} is ambiguous.", "Adding one more pair before \"...\" would help.", "POST REBUTTAL: I had some minor questions which the authors replied.", "My rating for the paper is 8"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_317_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_321_2", "review_text": "Summary: This work aggregates noisy/inconsistent pairwise preferences into a rating for each item, as well as actively selecting the pairs to query. The technique used for aggregation is the Bradley-Terry model with computational saving techniques. The pairs are queried with Expected Information Gain (from the Bradley-Terry model) and either choosing the most informative pairs or choosing a batch of pairs corresponding to a MST built on the graph with edges based on the most informative pairs.  Questions: Something that I didn\u00e2\u0080\u0099t quite understand is that this work claimed to run the preferences in batches, however, it doesn\u00e2\u0080\u0099t appear that they are run in batches for the first standard trial number. Can the authors please clarify this?  The runtime for small problems (n=10-20) show that the algorithm runs relatively slowly and quadratically. How does this scale to the large real-world datasets? Why weren\u00e2\u0080\u0099t runtime experiments run for the real-world datasets?  Quality: The techniques in this work seem to be relatively principled and fit into the related work well. The experiments show that this is an effective technique compared to the related work, at least for two datasets, IQA and VQA. Generally, in the experiments, the technique achieves the same results with half the number of comparisons.  Clarity: This paper lays out concepts in an orderly way and is clear to read. One minor note is that the \u00e2\u0080\u009cNotation\u00e2\u0080\u009d section includes more than just notation, but modeling assumptions, so it is more than just notation. Also, I think the indentation of Algorithm 1 is off, the \u00e2\u0080\u009cend for\u00e2\u0080\u009d should come earlier.  Originality: This work seems like a different take on a well-established problem. I\u00e2\u0080\u0099m not familiar enough with the preference aggregation literature to determine how similar this is to other work.  Significance: I have some concerns with the runtime and efficiency of the method proposed in this work, however, it seems principled and has good empirical accuracies.   After rebuttal: Thank you for the runtime experiments. I now see that the runtime is small compared to the annotation time.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_321_2", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary: This work aggregates noisy/inconsistent pairwise preferences into a rating for each item, as well as actively selecting the pairs to query.", "The technique used for aggregation is the Bradley-Terry model with computationalsaving techniques.", "The pairs are queried with Expected Information Gain (from the Bradley-Terry model) and either choosing the most informative pairs or choosing a batch of pairs corresponding to a MST built on the graph with edges based on the most informative pairs.", "Questions: Something that I didn\u00e2\u0080\u0099t quite understand is that this work claimed to run the preferences in batches, however, it doesn\u00e2\u0080\u0099t appear that they are run in batches for the first standard trialnumber.", "Can the authors please clarify this?", "The runtime for smal problems (n=10-20) show that the alorithm runs relatively slowly and quadraticaly.", "How does this scal to the large realworld datasets?", "Why weren\u00e2\u0080\u0099t runtime experiments run for the realworld datasets?", "Qualty: The techniques in this work seem to be relatively principled and fit into the related work well.", "The experiments show that this is an effective technique compared to the related work, at least for two datasets, IQA and VQA.", "Generaly, in the experiments, the technique achieves the same results with hal the number of comparisons.", "Clarity: This paper lays out concepts in an orderly way and is clear to read.", "One minor note is that the \u00e2\u0080\u009cNotation\u00e2\u0080\u009d secion includes more than just notation, but modeling assumptions, so it is more than just notation.", "Also, I think the indentation of Algorithm 1 is off, the \u00e2\u0080\u009cend for\u00e2\u0080\u009d should come earlier.", "Originalty: This work seems like a different take on a well-established problem.", "I\u00e2\u0080\u0099m not familiar enough with the preference aggregation literature to determine how similar this is to other work.", "Significance: I have some concerns with the runtime and efficiency of the method proposed in this work, however, it seems principled and has good empiricalaccuracies.", "After rebuttal Thank you for the runtime experiments.", "I now see that the runtime is smal compared to the annotation time."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_321_2", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_32_2", "review_text": "This paper addresses the problem of minimizing the effect of negative (e.g., false, harmful) information cascades in online social networks, i.e. misinformation containment. In particular, they consider the case of an arbitrary number of cascades, whereas most prior work in NIPS, KDD, INFOCOM, etc. have focused on the cases of one or two cascades. The authors provide a formal model for multi-cascade influence diffusion and cascade priority (Section 3), design an algorithm for minimizing the number of affected nodes (Section 5), provide theoretical bounds in terms of runtime and optimality (Section 4), and demonstrate the superiority of their algorithm against baselines on real-world datasets.  Overall, I think this is a very good submission. The authors provide clear motivation for the multi-cascade misinformation problem, rigorous theory around the proposed algorithm, and a reasonably comprehensive set of experiments on three real-world datasets. The paper is both original and significant because at least to my knowledge, the multi-cascade problem in online social networks has not been mathematically modeled before. Further, the paper is well written, with all ideas and even theorems explained with clarity. For these reasons, I recommend accepting the paper.  At the same time, I also found two areas for improvement. First, I would encourage the authors to consider a more comprehensive set of propagation probabilities in the experimentation. As it stands, it seems that these are set deterministically based on the observed social network, e.g., the number of activities observed from u to v and the out degree of particular nodes. This is not likely to capture nuances in how people influence one another, though, including the susceptibility of individuals, the influential power of individuals, and the fraction of interactions that are actually attempting to spread information. There is of course no way to account for all of these factors, but one idea would be to add random Gaussian noise on each of the link weights, and average the results over multiple trials, to see how robust the algorithms are to fluctuations. Another possibility would be to weight each of the probabilities by a measure of importance of the root node, like their social centrality.  Second, I feel that the authors refer to the supplemental material too often. To rectify this, I would suggest moving Section 4 and a few of the less important theorems entirely to the supplemental material, and instead including more of the proofs from Sections 3 and 5 in the manuscript itself. This way the paper would be more self-contained, and the reader does not have to flip back and forth between the paper and the supplement as much.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_32_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper addresses the problem of minimizing the effect of negative (e g , fale, harmful) information cascades in online socialnetworks, i e misinformation containment.", "In particular, they consider the case of an arbitrary number of cascades, whereas most prior work in NIPS, KDD, INFOCOM, etc have focused on the cases of one or two cascades.", "The authors provide a formalmodel for multi-cascade influence diffusion and cascade priority (secion 3), design an alorithm for minimizing the number of affected nodes (secion 5), provide theoreticalbounds in terms of runtime and optimalty (secion 4), and demonstrate the superiority of their alorithm against baselines on realworld datasets.", "Overal, I think this is a very good submission.", "The authors provide clear motivation for the multi-cascade misinformation problem, rigorous theory around the proposed alorithm, and a reasonably comprehensive set of experiments on three realworld datasets.", "The paper is both originaland significant because at least to my knowledge, the multi-cascade problem in online socialnetworks has not been mathematicaly modeled before.", "Further, the paper is well written, with al ideas and even theorems explained with clarity.", "For these reasons, I recommend accepting the paper.", "At the same time, I alo found two areas for improvement.", "First, I would encourage the authors to consider a more comprehensive set of propagation probabilities in the experimentation.", "As it stands, it seems that these are set deterministicaly based on the observed socialnetwork, e g , the number of activities observed from u to v and the out degree of particular nodes.", "This is not likely to capture nuances in how people influence one another, though, including the susceptibility of individual, the influentialpower of individual, and the fraction of interactions that are actualy attempting to spread information.", "There is of course no way to account for al of these factors, but one idea would be to add random Gaussian noise on each of the link weights, and average the results over multiple trial, to see how robust the alorithms are to fluctuations.", "Another possibility would be to weight each of the probabilities by a measure of importance of the root node, like their socialcentralty.", "secnd, I feel that the authors refer to the supplementalmaterialtoo often.", "To rectify this, I would suggest moving secion 4 and a few of the less important theorems entirely to the supplementalmaterial and instead including more of the proofs from secions 3 and 5 in the manuscript itself.", "This way the paper would be more self-contained, and the reader does not have to flip back and forth between the paper and the supplement as much."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_32_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_332_2", "review_text": "Update after rebuttal:  As mentioned in my review, the authors should clarify that using the multiplicative weight scheme was suggested by Blum et al. and its overhead was discussed (without proof) to be the same as one shown in Theorem 3 of this paper---overhead log^2(k). For a reference, see the last paragraph of section 3 in http://papers.nips.cc/paper/6833-collaborative-pac-learning.pdf. The technical insight of this paper is, in addition to using multiplicative weight update, to change the \"Accuracy Test\" to the \"Weak Test\" to further reduce the samples complexity down to the overhead of log(k). The authors in their rebuttal have ignored this fact. So it's best if the camera-ready version reflects this fact accurately.  Before rebuttal:  This paper continues the study of collaboration in the context of machine learning and obtains improved same complexity bounds.   Background: The collaborative PAC model, introduced by Blum et al (NIPS\u00e2\u0080\u009917), considers a setting where k players with different distributions D_i's that are all consistent with some unknown function f^* want to (\\epsilon, \\delta)-learn a classifier for their own distribution. The question Blum et al. asks is what is the total \u00e2\u0080\u009coverhead\u00e2\u0080\u009d over the sample complexity of accomplishing one task, if the players can collaborate. As an example when players do not collaborate, the k tasks have to be performed individually leading to an overhead of O(k). Blum et al. shows that in the personalized setting, where different players can use different classifiers, the overhead is O(log(k)) with k = O(d) . They also considered a centralized setting where all players should use the same functions. In this case, they showed that overhead is O(log(k)^2) when k = O(d). They also showed a matching lower bound of Omega(log(k)) overhead for the case of k=d.  Summary: This paper obtains an improved overhead for the centralized setting. Their main result, appearing in section 3, is that one can get an overhead of O(log(k)) in the centralized setting. More precisely, the sample complexity they obtain is: O(\\epsilon^-1 (d+k)(ln(k) + ln(1/delta)). There second contribution is to extend the lower bound of Blum et al. to the more general case of k = d^O(1). Lastly, they do a set of experiments comparing their algorithm to a naive algorithm and the Blum et al. algorithm on a number of datasets and show that their algorithms have better empirical performance.  Overall, I think this is a nice paper. The problem and the setting it studies is very natural. I think the subject matter can be of interest to the broader community and can be related to other areas including, federated and distributed learning, multi-task learning, and transfer learning. I appreciate that the authors have complemented their theoretical results with the experimental findings.   There are a few weaker points in the paper that I explain below.  1. The Basic algorithm: The authors spend quite a bit of space on the basic algorithm that has a log^2(k) overhead in the Centralized setting. My first concern about this is that Blum et al. discussed this algorithm briefly in their paper (see last paragraph section 3 of the Blum et al.) and the fact that it has log^2(k) overhead without going into the details. The reason is that the proof of this algorithm is too similar to the original approach of Blum et al. So, I don\u00e2\u0080\u0099t think the authors should focus so much of their efforts and presentation the paper on this basic algorithm. Secondly, their proof approach appears to be incremental over Blum et al approach. In my opinion the authors should simply state these results without proof (defer the proof to the appendix) and also mention that it was discussed by Blum et al.  2. I think the novel and interesting part of this paper is indeed the algorithm in Section 3. Unfortunately, very little information is given about this proof. I would suggest that the authors expand this part and include the proofs.  3. I'm not sure if the sample complexity in Theorem 4 is accurate. Let k =1, then this is showing a sample complexity of d/\\epsilon ln(1/\\delta) for one task. But, the best upper bound we know in the PAC setting is 1/\\epsilon (d ln(1/\\epsilon) + \\ln(1/\\delta)) with an additional  ln(1/\\epsilon). I ask the authors to explain in the rebuttal what the correct sample complexity is in this case.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_332_2", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Update after rebuttal As mentioned in my review, the authors should clarify that using the multiplicative weight scheme was suggested by Blum et al and its overhead was discussed (without proof) to be the same as one shown in Theorem 3 of this paper---overhead log^2(k).", "For a reference, see the last paragraph of secion 3 in http://papers.nips.cc/paper/6833-collaborative-pac-learning.pdf.", "The technicalinsight of this paper is, in addition to using multiplicative weight update, to change the \"Accuracy Test\" to the \"Weak Test\" to further reduce the samples complexity down to the overhead of log(k).", "The authors in their rebuttalhave ignored this fact.", "So it's best if the camera-ready version reflects this fact accurately.", "Before rebuttal This paper continues the study of collaboration in the context of machine learning and obtains improved same complexity bounds.", "Background: The collaborative PAC model, introduced by Blum et al(NIPS\u00e2\u0080\u009917), considers a setting where k players with different distributions D_i's that are al consistent with some unknown function f^* want to (\\epsilon, \\delta)-learn a classifier for their own distribution.", "The question Blum et al asks is what is the total\u00e2\u0080\u009coverhead\u00e2\u0080\u009d over the sample complexity of accomplishing one task, if the players can collaborate.", "As an example when players do not collaborate, the k tasks have to be performed individualy leading to an overhead of O(k).", "Blum et al shows that in the personalzed setting, where different players can use different classifiers, the overhead is O(log(k)) with k = O(d) .", "They alo considered a centralzed setting where al players should use the same functions.", "In this case, they showed that overhead is O(log(k)^2) when k = O(d).", "They alo showed a matching lower bound of Omega(log(k)) overhead for the case of k=d Summary: This paper obtains an improved overhead for the centralzed setting.", "Their main result, appearing in secion 3, is that one can get an overhead of O(log(k)) in the centralzed setting.", "More precisely, the sample complexity they obtain is: O(\\epsilon^-1 (d+k)(ln(k) + ln(1/delta)).", "There secnd contribution is to extend the lower bound of Blum et al to the more generalcase of k = d^O(1).", "Lastly, they do a set of experiments comparing their alorithm to a naive alorithm and the Blum et al alorithm on a number of datasets and show that their alorithms have better empiricalperformance.", "Overal, I think this is a nice paper.", "The problem and the setting it studies is very natural I think the subject matter can be of interest to the broader community and can be related to other areas including, federated and distributed learning, multi-task learning, and transfer learning.", "I appreciate that the authors have complemented their theoreticalresults with the experimentalfindings.", "There are a few weaker points in the paper that I explain below.", "1, The Basic alorithm: The authors spend quite a bit of space on the basic alorithm that has a log^2(k) overhead in the Centralzed setting.", "My first concern about this is that Blum et al discussed this alorithm briefly in their paper (see last paragraph secion 3 of the Blum et al) and the fact that it has log^2(k) overhead without going into the details.", "The reason is that the proof of this alorithm is too similar to the originalapproach of Blum et al So, I don\u00e2\u0080\u0099t think the authors should focus so much of their efforts and presentation the paper on this basic alorithm.", "secndly, their proof approach appears to be incrementalover Blum et alapproach.", "In my opinion the authors should simply state these results without proof (defer the proof to the appendix) and alo mention that it was discussed by Blum et al 2, I think the novel and interesting part of this paper is indeed the alorithm in secion 3, Unfortunately, very little information is given about this proof.", "I would suggest that the authors expand this part and include the proofs.", "3, I'm not sure if the sample complexity in Theorem 4 is accurate.", "Let k =1, then this is showing a sample complexity of d/\\epsilon ln(1/\\delta) for one task.", "But, the best upper bound we know in the PAC setting is 1/\\epsilon (d ln(1/\\epsilon) + \\ln(1/\\delta)) with an additional ln(1/\\epsilon).", "I ask the authors to explain in the rebuttalwhat the correct sample complexity is in this case."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_332_2", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_332_3", "review_text": "Overview: This paper studies the problem of (realizable-case) Collaborative PAC learning. In more detail, let H be an hypothesis class, and let h*\\in H be the target concept. Assume we are given an access to k unknown distributions D1,\u00e2\u0080\u00a6,Dk, and that our goal is to output an hypothesis h such that w.h.p the loss of h w.r.t *each* of the D_i\u00e2\u0080\u0099s is at most epsilon.  The main results in this paper are: 1. An upper bound of O((d+k)(log k + log(1/delta))  / epsilon), were d is the VC dimension of H, and epsilon and delta are the accuracy and confidence parameters. 2. A lower bound of Omega(dlog(k) + klog(d)) for fixed epsilon,delta (epsilon=delta=0.005).  The main technical tool is the Multiplicative Weights method, which is applied similarly like in Adaboost (the authors should discuss the connection with Adaboost and boosting in more detail).  The high-level idea is simple: at each round a mixture of the D_i\u00e2\u0080\u0099s is being weakly learned, and the weights of the mixture are updated in a multiplicative fashion according to the loss of the weak learner. Similar arguments like in the analysis of Adaboost yield an upper bound that is weaker by a factor of log(k) from 1 above (such a bound was obtained by Blum et al. in a previous work). Most of the technical effort is dedicated to shaving this factor.   I think this is a nice result, with a non-trivial variant of Adaboost. The presentation and the english can and should be significantly improved.  A comment to the authors: How do the results and techniques in your paper compare to those in \u00e2\u0080\u009cImproved Algorithms for Collaborative PAC Learniing\u00e2\u0080\u009d (link: https://arxiv.org/abs/1805.08356), and also in \u00e2\u0080\u009cOn Communication Complexity of Classification Problems\u00e2\u0080\u009d (link: https://arxiv.org/abs/1711.05893), where variants of Adaboost are also heavily exploited to ensure that different parties agree on the same hypothesis which is consistent (or has low error) w.r.t a distributed sample.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_332_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 3.0, "tokenized_review_text": ["Overview: This paper studies the problem of (realzable-case) Collaborative PAC learning.", "In more detail, let H be an hypothesis class, and let h*\\in H be the target concept.", "Assume we are given an access to k unknown distributions D1,\u00e2\u0080\u00a6,Dk, and that our goalis to output an hypothesis h such that w h p the loss of h w r t *each* of the D_i\u00e2\u0080\u0099s is at most epsilon.", "The main results in this paper are: 1, An upper bound of O((d+k)(log k + log(1/delta)) / epsilon), were d is the VC dimension of H, and epsilon and delta are the accuracy and confidence parameters.", "2, A lower bound of Omega(dlog(k) + klog(d)) for fixed epsilon,delta (epsilon=delta=0 005).", "The main technicaltool is the Multiplicative Weights method, which is applied similarly like in Adaboost (the authors should discuss the connection with Adaboost and boosting in more detail).", "The high-level idea is simple: at each round a mixture of the D_i\u00e2\u0080\u0099s is being weakly learned, and the weights of the mixture are updated in a multiplicative fashion according to the loss of the weak learner.", "Similar arguments like in the analsis of Adaboost yield an upper bound that is weaker by a factor of log(k) from 1 above (such a bound was obtained by Blum et al in a previous work).", "Most of the technicaleffort is dedicated to shaving this factor.", "I think this is a nice result, with a non-trivialvariant of Adaboost.", "The presentation and the english can and should be significantly improved.", "A comment to the authors: How do the results and techniques in your paper compare to those in \u00e2\u0080\u009cImproved Algorithms for Collaborative PAC Learniing\u00e2\u0080\u009d (link: https://arxiv.org/abs/1805.08356), and alo in \u00e2\u0080\u009cOn Communication Complexity of Classification Problems\u00e2\u0080\u009d (link: https://arxiv.org/abs/1711.05893), where variants of Adaboost are alo heavily exploited to ensure that different parties agree on the same hypothesis which is consistent (or has low error) w r t a distributed sample."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_332_3", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_333_1", "review_text": "This paper proposes a novel GAN formulation that allows a GAN to learn discriminative and compact binary codes for image patches. Using (hand designed) binary descriptors has quite some tradition in computer vision. Binary descriptors have several attractive properties, eg. compactness, fast implementation etc.   Using GANs for this purpose is not new (as nicely explained in the paper). The novelty of the method is that it employs two regularization terms that allow weighting of the importance of dimensions with the correlation and to propagate the distances between high and low dim. spaces. This leads to good results and compact codes. So overall this is minor but importnat contribution.   Overall the paper is well written and has a clear contribution. My main concerns are that the paper does not explain how to set the hyperparameters. In addition, the experiments are performed on moderately sized databases. An additional large-scale experiment on eg. one of the huge databases for city-scale reconstruction would show how the method scales.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_333_1", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["This paper proposes a novel GAN formulation that alows a GAN to learn discriminative and compact binary codes for image patches.", "Using (hand designed) binary descriptors has quite some tradition in computer vision.", "Binary descriptors have severalattractive properties, eg.", "compactness, fast implementation etc Using GANs for this purpose is not new (as nicely explained in the paper).", "The novelty of the method is that it employs two regularization terms that alow weighting of the importance of dimensions with the correlation and to propagate the distances between high and low dim.", "spaces.", "This leads to good results and compact codes.", "So overal this is minor but importnat contribution.", "Overal the paper is well written and has a clear contribution.", "My main concerns are that the paper does not explain how to set the hyperparameters.", "In addition, the experiments are performed on moderately sized databases.", "An additionallarge-scal experiment on eg.", "one of the huge databases for city-scal reconstruction would show how the method scals."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_333_1", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_335_3", "review_text": "The authors address the problem of escaping from saddle points in smooth nonconvex optimization problems constrained by a convex set C. A framework is proposed that allows iterates to converge to an (eps, gamma)-SOSP in a finite number of steps. First, an eps-FOSP stationary point is found using an appropriate first-order method (the authors suggest Frank-Wolfe or projected gradient descent). This stationary point may be a saddle point or a local maximizer, so as a second step, a constrained quadratic program is solved to find an (eps, gamma)-SOSP of the original problem. In addition to assuming the constraint set C is convex, the framework also assumes that a constant stepsize is used and that the necessary QPs can be solved in a finite number of arithmetic iterations. The authors provide an upper iteration bound, a lower bound for the decrease in the objective value for each of the first-order methods, and an extension to stochastic problems when the objective function is defined as an expectation of a set of stochastic functions.  This appears to be a solid contribution, giving a sensible framework for tackling optimization problems where saddle points could be encountered by the first-order method, although I am unsure if saddle points will necessarily be escaped from using the framework (see below). The theoretical results appear to be correct, although I was unable to verify all of the proofs due to time constraints. While there are a number of assumptions that are made that enable the theoretical analysis, most (but not all) of these seem sensible in practical settings.   However, I have a couple of concerns/comments/questions: - The framework does not require that the saddle points are delta-strict (line 121), which implies that the (eps, gamma)-SOSP could still be a saddle point. If this were to happen, what would be the best method to get out of this saddle point? Decrease gamma and try again? It does not seem like this framework actually guarantees an escape from saddle points, unless one decreases gamma to be small enough. - The assumption that the stepsize eta is constant is unrealistic since most practitioners decrease the stepsize as iterates get closer to the solution. How difficult is it to adapt the analysis to the case of variable stepsizes? - How much of the analysis can be applied if stochastic gradient descent (SGD) is used to solve the first-order problem? - The following sentence in the abstract is confusing: \"We propose a generic framework that yields convergence to a second-order stationary point of the problem, if the convex set C is simple for a quadratic objective function\". So the objective function needs to be quadratic? Because the text makes it seem like we are minimizing over a general smooth nonconvex function. - It would have been nice if there could have been some computational example of the method in action, but I realize there is a lack of space.  Some editorial comments: - Line 32: \"... later below).\" Either \"later\" or \"below\", not both. - Line 34: semi-colon should be a colon. - Lin 43: \"proposed\". - Line 123: \"... approximate local minimum\". - Line 145: A sentence should preferably not be started with \"i.e.\", rather use \"In other words\" or something along those lines.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_335_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The authors address the problem of escaping from saddle points in smooth nonconvex optimization problems constrained by a convex set C A framework is proposed that alows iterates to converge to an (eps, gamma)-SOSP in a finite number of steps.", "First, an eps-FOSP stationary point is found using an appropriate first-order method (the authors suggest Frank-Wolfe or projected gradient descent).", "This stationary point may be a saddle point or a localmaximizer, so as a secnd step, a constrained quadratic program is solved to find an (eps, gamma)-SOSP of the originalproblem.", "In addition to assuming the constraint set C is convex, the framework alo assumes that a constant stepsize is used and that the necessary QPs can be solved in a finite number of arithmetic iterations.", "The authors provide an upper iteration bound, a lower bound for the decrease in the objective vale for each of the first-order methods, and an extension to stochastic problems when the objective function is defined as an expectation of a set of stochastic functions.", "This appears to be a solid contribution, giving a sensible framework for tackling optimization problems where saddle points could be encountered by the first-order method, alhough I am unsure if saddle points will necessarily be escaped from using the framework (see below).", "The theoreticalresults appear to be correct, alhough I was unable to verify al of the proofs due to time constraints.", "While there are a number of assumptions that are made that enable the theoreticalanalsis, most (but not al) of these seem sensible in practicalsettings.", "However, I have a couple of concerns/comments/questions: - The framework does not reqire that the saddle points are delta-strict (line 121), which implies that the (eps, gamma)-SOSP could still be a saddle point.", "If this were to happen, what would be the best method to get out of this saddle point?", "Decrease gamma and try again?", "It does not seem like this framework actualy guarantees an escape from saddle points, unless one decreases gamma to be smal enough.", "- The assumption that the stepsize eta is constant is unrealstic since most practitioners decrease the stepsize as iterates get closer to the solution.", "How difficult is it to adapt the analsis to the case of variable stepsizes?", "- How much of the analsis can be applied if stochastic gradient descent (SGD) is used to solve the first-order problem?", "- The following sentence in the abstract is confusing: \"We propose a generic framework that yields convergence to a secnd-order stationary point of the problem, if the convex set C is simple for a quadratic objective function\".", "So the objective function needs to be quadratic?", "Because the text makes it seem like we are minimizing over a generalsmooth nonconvex function.", "- It would have been nice if there could have been some computationalexample of the method in action, but I realze there is a lack of space.", "Some editorialcomments: - Line 32: \"... later below).\"", "Either \"later\" or \"below\", not both.", "- Line 34: semi-colon should be a colon.", "- Lin 43: \"proposed\".", "- Line 123: \"... approximate localminimum\".", "- Line 145: A sentence should preferably not be started with \"i e \", rather use \"In other words\" or something alng those lines."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_335_3", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_336_1", "review_text": "This paper studies the reward manipulation attacks on stochastic bandit settings. Here, the main purpose is to guarantee a successful attack. Theorem 1 and Theorem 2 claim that an attack is guaranteed for e-greedy and UCB algorithms respectively.   In my opinion, the paper could provide more background for the readers who are not familiar with the attacks on bandits. What should the attacker do: e.g force the learner into pulling or avoiding target arms, or worsen the learner\u00e2\u0080\u0099s regret ...? Besides, they could discuss what could be done to defend against the attacks?  Secondly, the authors can mention before the Theorem1 that it is a typical high-probability statement and the 'failure probability' parameter _x000e_is usually set close to 0 and the theorems involving high-probability statements are abundant in the literature.  Overall, I like the idea in this paper and I'm sure about the correctness of the theorems. If the authors can clarify some points that I've mentioned, this could be a strong paper. It also opens a new research area in the literature.    ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_336_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["This paper studies the reward manipulation attacks on stochastic bandit settings.", "Here, the main purpose is to guarantee a successful attack.", "Theorem 1 and Theorem 2 claim that an attack is guaranteed for e-greedy and UCB alorithms respectively.", "In my opinion, the paper could provide more background for the readers who are not familiar with the attacks on bandits.", "What should the attacker do: e g force the learner into pulling or avoiding target arms, or worsen the learner\u00e2\u0080\u0099s regret ...?", "Besides, they could discuss what could be done to defend against the attacks?", "secndly, the authors can mention before the Theorem1 that it is a typicalhigh-probability statement and the 'failure probability' parameter _x000e_is usualy set close to 0 and the theorems involving high-probability statements are abundant in the literature.", "Overal, I like the idea in this paper and I'm sure about the correctness of the theorems.", "If the authors can clarify some points that I've mentioned, this could be a strong paper.", "It alo opens a new research area in the literature."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_336_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_339_2", "review_text": "The aim of the paper is to decompose the quantitative measure of discrimination called the equalized odds (EO). The EO measures the extent to which gender, race or other protected characteristics are used in classification. The EO is decomposed into a direct effect, indirect effect and spurious effect. The paper also provides an algorithm for training classifiers with penalization to ensure that these effects are small.  The aim is clear and useful since it is important to minimize the impact of unfairness, with individual measures of the various mechanisms.  The significance of the paper is not clear since it appears to just extend the results of Zhang and Barenboim (2018) by defining causal effects which condition on Y. Clearly there are technical details that are addressed which describe estimation under the graph which conditions on Y. However the level of novelty does not obviously meet the required criteria.  Additionally, the causal explanation formula is not particularly intuitive. The EO is decomposed as EO=DE-IE-SE, with some reversal of the effects. While this seems technically correct, its usefulness is unclear since it is not intuitive. Without some sort of additive decomposition, as with the decomposition of a causal effect into a direct and indirect effect, it may not be helpful in practice.  A difference in effects is useful to decompose but, more generally, it may be a ratio or other contrasts that are of interest. This is a future concern as it may not be as straightforward and solving the difference case would be sufficiently interesting.  The naming of the EO as odds is a bit misleading since it is not a ratio. However I understand that it is already in the literature.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_339_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 2.0, "tokenized_review_text": ["The aim of the paper is to decompose the quantitative measure of discrimination caled the eqalzed odds (EO).", "The EO measures the extent to which gender, race or other protected characteristics are used in classification.", "The EO is decomposed into a direct effect, indirect effect and spurious effect.", "The paper alo provides an alorithm for training classifiers with penalzation to ensure that these effects are smal.", "The aim is clear and useful since it is important to minimize the impact of unfairness, with individualmeasures of the various mechanisms.", "The significance of the paper is not clear since it appears to just extend the results of Zhang and Barenboim (2018) by defining causaleffects which condition on Y Clearly there are technicaldetails that are addressed which describe estimation under the graph which conditions on Y However the level of novelty does not obviously meet the reqired criteria.", "Additionaly, the causalexplanation formula is not particularly intuitive.", "The EO is decomposed as EO=DE-IE-SE, with some reversalof the effects.", "While this seems technicaly correct, its usefulness is unclear since it is not intuitive.", "Without some sort of additive decomposition, as with the decomposition of a causaleffect into a direct and indirect effect, it may not be helpful in practice.", "A difference in effects is useful to decompose but, more generaly, it may be a ratio or other contrasts that are of interest.", "This is a future concern as it may not be as straightforward and solving the difference case would be sufficiently interesting.", "The naming of the EO as odds is a bit misleading since it is not a ratio.", "However I understand that it is aleady in the literature."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_339_2", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_341_1", "review_text": "To conduct image-to-image translation, this paper introduces attention mechanisms to CycleGAN [1]. The divergence between only the relevant parts of both source and target domains is minimized. Compared to recent approaches, the proposed method performs better in conserving the background and gets the lowest FID in quantitative analysis.   Related works Related works follows a clear structure. For image-to-image translation, it introduces supervised and unsupervised methods, followed by mentioning the problem which is the background is affected, and then it refers to some related research on attention learning.  Approach The idea of having continuous attention map for generator is good, and it is also good to read the authors\u00e2\u0080\u0099 explanations of why and how it is valuable. The reason why they use segmented attention map for discriminator is also well presented.  Experiemnts It is interesting to see Figure 3 and Figure 5 have translation results when there is no interested class in source domain, showing this approach applies appropriate attention mechanisms. Some experiment details like the choices of hyperparameters are absent, not being presented in the submission paper or supplementary material. But in the end of the paper, the authors say the code will be released, hopefully this will be the case.  Lack of qualitative analysis about UNIT approach[4].  Other comments The readability of this paper is good. The structure and diagram of the proposed attention method are clearly presented. In conclusion, the authors mention one constraint of the proposed method, which is not being robust to shape changes, but this paper doesn\u00e2\u0080\u0099t involve related examples. It would be better to have the mentioned horse-to-bird results in supplementary material. L210: the last row of Figure 5 doesn\u00e2\u0080\u0099t seem to be an albino tiger, but the last third row is, which the last row of the top part. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_341_1", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["To conduct image-to-image translation, this paper introduces attention mechanisms to CycleGAN [1].", "The divergence between only the relevant parts of both source and target domains is minimized.", "Compared to recent approaches, the proposed method performs better in conserving the background and gets the lowest FID in quantitative analsis.", "Related works Related works follows a clear structure.", "For image-to-image translation, it introduces supervised and unsupervised methods, followed by mentioning the problem which is the background is affected, and then it refers to some related research on attention learning.", "Approach The idea of having continuous attention map for generator is good, and it is alo good to read the authors\u00e2\u0080\u0099 explanations of why and how it is valable.", "The reason why they use segmented attention map for discriminator is alo well presented.", "Experiemnts It is interesting to see figre 3 and figre 5 have translation results when there is no interested class in source domain, showing this approach applies appropriate attention mechanisms.", "Some experiment details like the choices of hyperparameters are absent, not being presented in the submission paper or supplementary material But in the end of the paper, the authors say the code will be released, hopefully this will be the case.", "Lack of qualtative analsis about UNIT approach[4].", "Other comments The readability of this paper is good.", "The structure and diagram of the proposed attention method are clearly presented.", "In conclusion, the authors mention one constraint of the proposed method, which is not being robust to shape changes, but this paper doesn\u00e2\u0080\u0099t involve related examples.", "It would be better to have the mentioned horse-to-bird results in supplementary material L210: the last row of figre 5 doesn\u00e2\u0080\u0099t seem to be an alino tiger, but the last third row is, which the last row of the top part."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_341_1", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_341_2", "review_text": "The authors of this manuscript propose an attention strategy in GAN for image-to-image translation. Their experiments show that the proposed method can well generate better objects without changing the background. Compared with existing GAN method, it is clearly a significant improvement. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_341_2", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno3", "evidence": 1, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 1.0, "tokenized_review_text": ["The authors of this manuscript propose an attention strategy in GAN for image-to-image translation.", "Their experiments show that the proposed method can well generate better objects without changing the background.", "Compared with existing GAN method, it is clearly a significant improvement."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_341_2", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno3", "evidence": 1, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_353_3", "review_text": "This paper shows that Nesterov\u00e2\u0080\u0099s accelerated gradient descent algorithms can be interpreted as computing a saddle point via online optimization algorithms. A convex optimization problem is transformed to be a minmax problem by the Fenchel dual, the solution of which is then approximated via online optimization algorithms.   This paper can be a significant contribution to the optimization community. I would say that this is one of the most natural interpretations of Nesterov\u00e2\u0080\u0099s accelerated gradient methods. The use of weighted regrets and (optimistic) FollowTheLeader (instead of follow the regularized leader) are a little bit artificial but acceptable. The latter is perhaps easier to accept, if the authors point out that \\ell_t is strongly convex due to smoothness of f.   A possible issue is boundedness of the radius D in Section 4. To use Theorem 2 and Corollary 1 to prove the accelerated convergence rate, one has to provide an upper bound of the radius D. It is not immediate to me whether D is actually bounded or not in Section 4. (In Section 4.2, there is a constraint set K, but boundedness of K is not mentioned.)  Other comments:  1. ln 135: It seems that \\ell_t(y) should be equal to -g(x_{t - 1}, y) instead of -g(x_t, y), according to Algorithm 1. Please check.  2. ln 4, Algorithm 2: The x in \\nabal h_t (x) is not defined, though this is not really relevant.  3. Theorem 3: You need to specify \\gamma to use Theorem 2 and Corollary 1. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_353_3", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper shows that Nesterov\u00e2\u0080\u0099s accelerated gradient descent alorithms can be interpreted as computing a saddle point via online optimization alorithms.", "A convex optimization problem is transformed to be a minmax problem by the Fenchel dual the solution of which is then approximated via online optimization alorithms.", "This paper can be a significant contribution to the optimization community.", "I would say that this is one of the most naturalinterpretations of Nesterov\u00e2\u0080\u0099s accelerated gradient methods.", "The use of weighted regrets and (optimistic) FollowTheLeader (instead of follow the regularized leader) are a little bit artificialbut acceptable.", "The latter is perhaps easier to accept, if the authors point out that \\ell_t is strongly convex due to smoothness of f A possible issue is boundedness of the radius D in secion 4, To use Theorem 2 and Corollary 1 to prove the accelerated convergence rate, one has to provide an upper bound of the radius D It is not immediate to me whether D is actualy bounded or not in secion 4, (In secion 4 2, there is a constraint set K, but boundedness of K is not mentioned.)", "Other comments: 1, ln 135: It seems that \\ell_t(y) should be eqalto -g(x_{t - 1}, y) instead of -g(x_t, y), according to Algorithm 1, Please check.", "2, ln 4, Algorithm 2: The x in \\nabalh_t (x) is not defined, though this is not realy relevant.", "3, Theorem 3: You need to specify \\gamma to use Theorem 2 and Corollary 1,"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_353_3", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_363_2", "review_text": "The paper proposes the training of CNNs for classification directly on the DCT coefficients from the JPEG codec.  The removal of the jpeg decoding and the work of CNN directly on DCT which allow for skipping first layers lead to speed advantages, reportedly 1.77x speed up of the modified net over the ResNet-50 baseline.  The paper reads mostly well and the derived CNNs and experimental results support the idea of faster CNNs straight from JPEG DCT coefficients.  The paper suffers, however, on a number of aspects. 1) Related work: I do not see a related work review of publications employing directly the compressed domain for higher level tasks. This work should be placed into the existing literature. 2) Novelty: This paper is not the first to propose working on the compressed domain of an image. Nor the first paper using CNN for classification on the compressed domain. 3) Generality: I am curious if the speed benefits obtained for the CNNs working for classification directly on the DCT coefficients are also achievable for other vision tasks such as (semantic) image segmentation, image translation..  I enumerate here some relevant literature for this paper: Shen et al, Direct feature extraction from compressed images, 1996 Mandal et al, A critical evaluation of image and video indexing techniques in the compressed domain, 1999 Hafed et al, Face Recognition Using the Discrete Cosine Transform, 2001 Feng et al, JPEG compressed image retrieval via statistical features, 2003  and more recent works: Torfasson et al, Towards Image Understanding from Deep Compression without Decoding, 2018 Adler et al, Compressed Learning: A Deep Neural Network Approach, 2016 Fu et al, Using compression to speed up image classification in artificial neural networks, 2016 Aghagolzadeh et al, On hyperspectral classification in the compressed domain, 2015 ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_363_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 3.0, "tokenized_review_text": ["The paper proposes the training of CNNs for classification directly on the DCT coefficients from the JPEG codec.", "The removalof the jpeg decoding and the work of CNN directly on DCT which alow for skipping first layers lead to speed advantages, reportedly 1 77x speed up of the modified net over the ResNet-50 baseline.", "The paper reads mostly well and the derived CNNs and experimentalresults support the idea of faster CNNs straight from JPEG DCT coefficients.", "The paper suffers, however, on a number of aspects.", "1) Related work: I do not see a related work review of publications employing directly the compressed domain for higher level tasks.", "This work should be placed into the existing literature.", "2) Novelty: This paper is not the first to propose working on the compressed domain of an image.", "Nor the first paper using CNN for classification on the compressed domain.", "3) Generalty: I am curious if the speed benefits obtained for the CNNs working for classification directly on the DCT coefficients are alo achievable for other vision tasks such as (semantic) image segmentation, image translation..", "I enumerate here some relevant literature for this paper: Shen et al Direct feature extraction from compressed images, 1996 Mandalet al A criticalevalation of image and video indexing techniques in the compressed domain, 1999 Hafed et al Face Recognition Using the Discrete Cosine Transform, 2001 Feng et al JPEG compressed image retrievalvia statisticalfeatures, 2003 and more recent works: Torfasson et al Towards Image Understanding from Deep Compression without Decoding, 2018 Adler et al Compressed Learning: A Deep NeuralNetwork Approach, 2016 Fu et al Using compression to speed up image classification in artificialneuralnetworks, 2016 Aghagolzadeh et al On hyperspectralclassification in the compressed domain, 2015"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_363_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_366_2", "review_text": "The paper presents a novel graph kernel, adapted to large undirected graphs, able to use nodes attributes. The idea is to use a \"return probability feature\" based on random walks, instead of classical bags of random walks for instance.  The idea is interesting and appears to be efficient. The paper is quite easy to read but some details can be improved (see below). To my knowledge,  the proposed approach is novel, and there are many potential problems that could benefit from this idea.   It is shown that the RPF has several nice properties, such as isomorphic invariance and multi-resolution. It also contains enough information on graph structure such that similar RPF is linked to similar spectral properties.   Details: *l102-103 : a little short I think *133 : times : \\times? *eq(5) and (6) : nice presentation * 3.2.1 : would Nystrom methods be able to help here? * eq (7) : not clear  * experiments : poly kernel not used? why presetting it then? or why not using it? * fig 2 : missing axis legend * biblio [17] : published in ICML 2012 * bibio [31] : missing venue (AAAI) ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_366_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper presents a novel graph kernel, adapted to large undirected graphs, able to use nodes attributes.", "The idea is to use a \"return probability feature\" based on random wals, instead of classicalbags of random wals for instance.", "The idea is interesting and appears to be efficient.", "The paper is quite easy to read but some details can be improved (see below).", "To my knowledge, the proposed approach is novel, and there are many potentialproblems that could benefit from this idea.", "It is shown that the RPF has severalnice properties, such as isomorphic invariance and multi-resolution.", "It alo contains enough information on graph structure such that similar RPF is linked to similar spectralproperties.", "Details: *l102-103 : a little short I think *133 : times : \\times?", "*eq5) and (6) : nice presentation * 3 2 1 : would Nystrom methods be able to help here?", "* eq(7) : not clear * experiments : poly kernel not used?", "why presetting it then?", "or why not using it?", "* fig2 : missing axis legend * biblio [17] : published in ICML 2012 * bibio [31] : missing venue (AAAI)"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_366_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_389_1", "review_text": "Short summary: In this paper, the authors derive uniformly most powerful differentially private simple and one-sided tests for the parameter $\\theta$ of the Binomial distribution with parameters $(n,\\theta)$. In this context, the requirement of differential privacy translates to certain regularity conditions on the test as a function. The authors explicitly establish the necessary form of a test which fulfils these conditions (i.e. the in some sense strongest version of them) and express it as the distribution function of a novel distribution they call Tulap distribution. The UMP-property is then asserted through a Neyman-Pearson-type lemma. Later on, the close connection between the test and the Tulap and Binomial distributions leads to a convenient representation of the associated p-value and therefore the test as such. The paper closes with possible applications to situations without a priori Binomial distributions and simulations comparing the empirical type-I error probability and power when using the new test, the classical non-private UMP test and the test based on Normal approximation.   Comments: Since the differentially private UMP tests for the considered problem were unknown and the authors introduce a new distribution as an essential tool, I consider the paper significant and original. Also, this work appears to be technically sound. A final proof-reading would be advisable nonetheless; for instance, there are several typos in the paragraph on the nearest integer function (lines 98-100) and there is a factor $\\exp(\\epsilon)$ missing in the second equation on page 11. In fact, I would like to mention as my primary concern that I found sections 2 though 4 very difficult to read - fortunately, sections 5 through 7 are well-written and helped clarify my earlier problems. More specifically, Definition 2.1. clearly creates the impression that $X$ is a parameter. Then, in Definition 2.3., $X$ ist the random object and there is a new parameter $\\theta$; however, only a few lines after that, $X$ appears as the index of the test, which is very confusing since it is actually the input variable (i.e. you would typically write $\\phi(X)$). After section 3, there is no motivation yet to introduce the Tulap distribution and on top of that, you are again confused about the role of $X$ since it seems to be a parameter. I understand that each consideration in these sections is an important preparation for what follows, but the current structure is unsettling, at least for me: For instance, would it not be more natural to place Lemma 5.2 at the end of section 3 and let this be the motivation for Definition 4.1? Furthermore, the notion of post-processing (where the interpretation of $X$ as a parameter is warranted) is only needed in section 7, so would it not be more natural to discuss it only in that section? I realise that many people would dismiss all this as being a question of taste and hence it does not affect my opinion that this significant and original paper should be published, but I would still appreciate a more accessible version (through a revised structure or helpful remarks).    Regarding the rebuttal: I have read the other reviews and the authors' response. Even in light of the points raised by the other reviewers, I still vote for accepting the paper since the authors' response is quite convincing; I particulary appreciate how seriously the authors took my review and which adjustments they announced.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_389_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["Short summary: In this paper, the authors derive uniformly most powerful differentialy private simple and one-sided tests for the parameter $\\theta$ of the Binomialdistribution with parameters $(n,\\theta)$.", "In this context, the reqirement of differentialprivacy translates to certain regularity conditions on the test as a function.", "The authors explicitly establish the necessary form of a test which fulfils these conditions (i e the in some sense strongest version of them) and express it as the distribution function of a novel distribution they cal Tulap distribution.", "The UMP-property is then asserted through a Neyman-Pearson-type lemma.", "Later on, the close connection between the test and the Tulap and Binomialdistributions leads to a convenient representation of the associated p-vale and therefore the test as such.", "The paper closes with possible applications to situations without a priori Binomialdistributions and simulations comparing the empiricaltype-I error probability and power when using the new test, the classicalnon-private UMP test and the test based on Normalapproximation.", "Comments: Since the differentialy private UMP tests for the considered problem were unknown and the authors introduce a new distribution as an essentialtool, I consider the paper significant and original Also, this work appears to be technicaly sound.", "A finalproof-reading would be advisable nonetheless; for instance, there are severaltypos in the paragraph on the nearest integer function (lines 98-100) and there is a factor $\\exp(\\epsilon)$ missing in the secnd eqation on page 11, In fact, I would like to mention as my primary concern that I found secions 2 though 4 very difficult to read - fortunately, secions 5 through 7 are well-written and helped clarify my earlier problems.", "More specificaly, Definition 2 1, clearly creates the impression that $X$ is a parameter.", "Then, in Definition 2 3 , $X$ ist the random object and there is a new parameter $\\theta$; however, only a few lines after that, $X$ appears as the index of the test, which is very confusing since it is actualy the input variable (i e you would typicaly write $\\phi(X)$).", "After secion 3, there is no motivation yet to introduce the Tulap distribution and on top of that, you are again confused about the role of $X$ since it seems to be a parameter.", "I understand that each consideration in these secions is an important preparation for what follows, but the current structure is unsettling, at least for me: For instance, would it not be more naturalto place Lemma 5 2 at the end of secion 3 and let this be the motivation for Definition 4 1?", "Furthermore, the notion of post-processing (where the interpretation of $X$ as a parameter is warranted) is only needed in secion 7, so would it not be more naturalto discuss it only in that secion?", "I realse that many people would dismiss al this as being a question of taste and hence it does not affect my opinion that this significant and originalpaper should be published, but I would still appreciate a more accessible version (through a revised structure or helpful remarks).", "Regarding the rebuttal I have read the other reviews and the authors' response.", "Even in light of the points raised by the other reviewers, I still vote for accepting the paper since the authors' response is quite convincing; I particulary appreciate how seriously the authors took my review and which adjustments they announced."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_389_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_392_2", "review_text": "Motivated by the latency in network performance between machines during iterative training, this work proposes a new gradient synchronization algorithm that runs on BCube network. The performance of the algorithm shows significant decrease in the synchronization time with fewer number of switches.   The paper is written well. While the authors mention that common distributed ml algorithm use is PS on a Fat Tree network, their choice of BCube for BML is not well justified.   In terms of the presentation of the paper, too much details on the background and motivation is provided whereas more focus on the details of the algorithm and the evaluation would have added value.   The primary concern of this paper is evaluation. In comparison to its competitor PS algorithm [1], the evaluation seems weak and not well done. While the primary take away in the evaluation is that the BML algorithm performs better than Fat Tree network, it is unclear if the synchronization algorithm is more valuable or the choice of BCube. An study or discussion to understand the contributions of choices to the performance is necessary.   Background and motivation section in the paper does not represent and discuss related work which is also missing from the results section. It is important to have clear description of related work which also discusses comparisons to the presented approach. A couple of missing related literature [2, 3].   [1] Scaling Distributed Machine Learning with the Parameter Server [2] Distributed Training Strategies for the Structured Perceptron [3] http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf  #### After author's reponse #### While, the authors have responded well to my comments, I am unsure how they would include the content in the paper, given the page limits. Based on author's response and reading other reviews, I am inclined to give the paper a positive score. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_392_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Motivated by the latency in network performance between machines during iterative training, this work proposes a new gradient synchronization alorithm that runs on BCube network.", "The performance of the alorithm shows significant decrease in the synchronization time with fewer number of switches.", "The paper is written well.", "While the authors mention that common distributed ml alorithm use is PS on a Fat Tree network, their choice of BCube for BML is not well justified.", "In terms of the presentation of the paper, too much details on the background and motivation is provided whereas more focus on the details of the alorithm and the evalation would have added vale.", "The primary concern of this paper is evalation.", "In comparison to its competitor PS alorithm [1], the evalation seems weak and not well done.", "While the primary take away in the evalation is that the BML alorithm performs better than Fat Tree network, it is unclear if the synchronization alorithm is more valable or the choice of BCube.", "An study or discussion to understand the contributions of choices to the performance is necessary.", "Background and motivation secion in the paper does not represent and discuss related work which is alo missing from the results secion.", "It is important to have clear description of related work which alo discusses comparisons to the presented approach.", "A couple of missing related literature [2, 3].", "[1] Scalng Distributed Machine Learning with the Parameter Server [2] Distributed Training Strategies for the Structured Perceptron [3] http://papers.nips.cc/paper/4687-large-scal-distributed-deep-networks.pdf #### After author's reponse #### While, the authors have responded well to my comments, I am unsure how they would include the content in the paper, given the page limits.", "Based on author's response and reading other reviews, I am inclined to give the paper a positive score."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_392_2", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_377_2", "review_text": "The authors provide a principled statistical account that explains conflicting results in the human perception of faces, and use the AAM technique to translate their approach to a tangible model. They evaluate the account against  data from extant experiments.   Bridging conflicting existing experimental results with concise and elegant statistical account is definitely a worthy endeavor. Building such a model could lead to a substantial contribution. My impression, however, was that the computational level of the model (section 3 and 4.1), the algorithmic (implementation using AAM)  and the interpretation of simulation results in section 4.1.2 are not seamlessly connected. The authors make implicitly strong assumptions to build thee connections,  which hinder the overall scope and potential of the advanced approach.   Such discrepancies between abstract theories and ways to analyze empirical/simulation data are not uncommon in the social sciences (e.g models in economics tend to be very abstract are often translated to linear equations when tested against empirical data) but are quite uncommon in cognitive science and neuroscience, where typically the computational and the algorithmic level of theories are much better integrated.  Minor remarks: 1.The references need to be homogenized. At the moment there are several different styles used.  2. The quality of the graphs could be further improved. Figures 2.b.c They appear to be blurry in my print out. The error bars are quite small. Same for Figure 3.  3. In section 6 the authors propose an experiment and present predictions of two competing accounts. The disfluency account is only mentioned briefly in the introduction before and the details are skipped. I would allocate some supporting material explaining the competing account better, possibly in an appendix. It would have been great to see actual results here, rather than just predictions. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_377_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The authors provide a principled statisticalaccount that explains conflicting results in the human perception of faces, and use the AAM technique to translate their approach to a tangible model.", "They evalate the account against data from extant experiments.", "Bridging conflicting existing experimentalresults with concise and elegant statisticalaccount is definitely a worthy endeavor.", "Building such a model could lead to a substantialcontribution.", "My impression, however, was that the computationallevel of the model (secion 3 and 4 1), the alorithmic (implementation using AAM) and the interpretation of simulation results in secion 4 1 2 are not seamlessly connected.", "The authors make implicitly strong assumptions to build thee connections, which hinder the overal scope and potentialof the advanced approach.", "Such discrepancies between abstract theories and ways to analze empiricalsimulation data are not uncommon in the socialsciences (e g models in economics tend to be very abstract are often translated to linear eqations when tested against empiricaldata) but are quite uncommon in cognitive science and neuroscience, where typicaly the computationaland the alorithmic level of theories are much better integrated.", "Minor remarks: 1 The references need to be homogenized.", "At the moment there are severaldifferent styles used.", "2, The qualty of the graphs could be further improved.", "figres 2 b c They appear to be blurry in my print out.", "The error bars are quite smal.", "Same for figre 3, 3, In secion 6 the authors propose an experiment and present predictions of two competing accounts.", "The disfluency account is only mentioned briefly in the introduction before and the details are skipped.", "I would alocate some supporting materialexplaining the competing account better, possibly in an appendix.", "It would have been great to see actualresults here, rather than just predictions."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_377_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_484_3", "review_text": "Summary: The paper studies multi-step greedy policies and their use in approximate policy iteration. The authors first show a negative result that soft-policy updates using the multi-step greedy policies do not guarantee policy improvement. Then the authors proposed an algorithm that uses cautious soft updates (only update to the kappa greedy policy only when assured to improve, otherwise stay with one-step greedy policy) and show that it converges to the optimal policy. Lastly the authors studied hard updates by extending APIs to multi-step greedy policy setting.   Comments:    1. Theorem 2 presents an interesting and surprising result. Though the authors presented the example in the proof sketch, but I wonder if the authors could provide more intuitions behind this? Based on the theorem, for multi-step greedy policy, it seems that h needs to be bigger than 2. So I suspect that h = 2 will still work (meaning there could exist small alpha)? Obviously h = 1 works, but then why when h = 3, the soft-update suddenly stops working unless alpha is exactly equal to 1?  I would expect that one would require larger alpha when h gets larger.   2. Alg 1 and theorem 4 are nice. While I didn\u00e2\u0080\u0099t check the proof of theorem 4, how fast the algorithm will converge compare to a simple one-step greedy version? Namely what is the exact benefit of introducing the extra q_{\\kappa} here (lemma 3 shows that the contraction is still gamma, and has nothing to do with kappa here)?   3. Regarding the hard updates, how realistic is the assumption on the existence of a kappa-greedy policy oracle? This is different from a greedy oracle that one would typically use in, for instance, CPI, where the oracle can be implemented by classic cost-sensitive classification with cost-to-go evaluated simply by roll-outs. To compute such a kappa-greedy policy here, we essentially need to solve a MDP (i.e. planning), though it is reshaped and the discount factor is decreased. Using a conservative policy iteration for such a greedy oracle is strange. Why not just using CPI to solve the original problem? Can we show that using CPI as the oracle for computing kappa-greedy policy eventually resulting a faster algorithm than CPI itself, if one set kappa optimally?  Similarly, can we show that using CPI as the kappa greedy policy oracle in PSDP resulting a faster algorithm than PSDP?  After rebuttal:   Thanks for detailed comments in the rebuttal. Though understanding the limitation of kappa-greedy oracle and how to set kappa are important for practical applications of the proposed approaches, I do think the paper already contains significant contribution. I've updated my score.  ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_484_3", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["Summary: The paper studies multi-step greedy policies and their use in approximate policy iteration.", "The authors first show a negative result that soft-policy updates using the multi-step greedy policies do not guarantee policy improvement.", "Then the authors proposed an alorithm that uses cautious soft updates (only update to the kappa greedy policy only when assured to improve, otherwise stay with one-step greedy policy) and show that it converges to the optimalpolicy.", "Lastly the authors studied hard updates by extending APIs to multi-step greedy policy setting.", "Comments: 1, Theorem 2 presents an interesting and surprising result.", "Though the authors presented the example in the proof sketc, but I wonder if the authors could provide more intuitions behind this?", "Based on the theorem, for multi-step greedy policy, it seems that h needs to be bigger than 2, So I suspect that h = 2 will still work (meaning there could exist smal alha)?", "Obviously h = 1 works, but then why when h = 3, the soft-update suddenly stops working unless alha is exactly eqalto 1?", "I would expect that one would reqire larger alha when h gets larger.", "2, Alg 1 and theorem 4 are nice.", "While I didn\u00e2\u0080\u0099t check the proof of theorem 4, how fast the alorithm will converge compare to a simple one-step greedy version?", "Namely what is the exact benefit of introducing the extra q_{\\kappa} here (lemma 3 shows that the contraction is still gamma, and has nothing to do with kappa here)?", "3, Regarding the hard updates, how realstic is the assumption on the existence of a kappa-greedy policy oracle?", "This is different from a greedy oracle that one would typicaly use in, for instance, CPI, where the oracle can be implemented by classic cost-sensitive classification with cost-to-go evalated simply by roll-outs.", "To compute such a kappa-greedy policy here, we essentialy need to solve a MDP (i e planning), though it is reshaped and the discount factor is decreased.", "Using a conservative policy iteration for such a greedy oracle is strange.", "Why not just using CPI to solve the originalproblem?", "Can we show that using CPI as the oracle for computing kappa-greedy policy eventualy resulting a faster alorithm than CPI itself, if one set kappa optimaly?", "Similarly, can we show that using CPI as the kappa greedy policy oracle in PSDP resulting a faster alorithm than PSDP?", "After rebuttal Thanks for detailed comments in the rebuttal Though understanding the limitation of kappa-greedy oracle and how to set kappa are important for practicalapplications of the proposed approaches, I do think the paper aleady contains significant contribution.", "I've updated my score."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_484_3", "importance": 0, "reproducibility": 0, "constructiveness": 5, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_484_1", "review_text": "This paper provides the analysis of T-greedy Policy Iteration methods, both in the  online and approximate settings. In this context the paper makes several points. First, it shows that multiple-step greedy policies using soft, step-sized updates is not guaranteed to make improvements. Second, to address the above issue, the authors propose a \"cautious\" improvement operator that works at two time scales: first it solves the optimal policy of small-horizon MDP with shaped reward, and then it uses the computed value to shape the reward for the next iteration. Third, the paper quantifies the tradeoff between short-horizon bootstrap bias and long-rollout variance, which corresponds to the classic \\lambda tradeoff in TD(\\lambda).  This is a dense, theoretical paper. While the authors try to provide intuition behind their results, I still found the paper rather difficult to follow. Ideally, the paper would provide some experimental results to aid the intuition, but it doesn't. This is a missed opportunity in my opinon. There are many questions such expriments could answer. What is the impact of \"cautious\" updates on convergence? Quantitatively quantify the tradeoff between short-horizon bootstrap bias and long-rollout variance, and many more.   Otherwise, the results presented in the paper are significant. In particular, I can see the \"cautious\" updates having a considerable impact in practice, assuming experimental results are going to convincingly illustarte that there are cases of practical interest in which just using soft, step-sized updates fails to converge.  As a final note, I was not able to double-check the proofs so please take this review with a (big) grain of salt.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_484_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["This paper provides the analsis of T-greedy Policy Iteration methods, both in the online and approximate settings.", "In this context the paper makes severalpoints.", "First, it shows that multiple-step greedy policies using soft, step-sized updates is not guaranteed to make improvements.", "secnd, to address the above issue, the authors propose a \"cautious\" improvement operator that works at two time scals: first it solves the optimalpolicy of smal-horizon MDP with shaped reward, and then it uses the computed vale to shape the reward for the next iteration.", "Third, the paper quantifies the tradeoff between short-horizon bootstrap bias and long-rollout variance, which corresponds to the classic \\lambda tradeoff in TD(\\lambda).", "This is a dense, theoreticalpaper.", "While the authors try to provide intuition behind their results, I still found the paper rather difficult to follow.", "Idealy, the paper would provide some experimentalresults to aid the intuition, but it doesn't This is a missed opportunity in my opinon.", "There are many questions such expriments could answer.", "What is the impact of \"cautious\" updates on convergence?", "Quantitatively quantify the tradeoff between short-horizon bootstrap bias and long-rollout variance, and many more.", "Otherwise, the results presented in the paper are significant.", "In particular, I can see the \"cautious\" updates having a considerable impact in practice, assuming experimentalresults are going to convincingly illustarte that there are cases of practicalinterest in which just using soft, step-sized updates fails to converge.", "As a finalnote, I was not able to double-check the proofs so please take this review with a (big) grain of sal."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_484_1", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 2, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_401_3", "review_text": "This paper studies zero-order optimization with noisy observations. The authors study an \"adaptive sampling\" setting, where every query can depend on the results of previous queries. Although adaptive sampling gives the analyst an intuitive advantage over uniform sampling, the existing theoretical result doesn't confirm a more superior convergence rate for it. Through an information theoretic analysis, the paper shows that the classical rate is unimprovable even by active sampling. Further more, it presents a local convergence analysis, showing that if the true function lies in the neighborhood of some desirable reference function, then active sampling does enjoy a better convergence rate than uniform sampling. The gap is presented in both an upper bound and an almost matching lower bound.  Overall, I enjoyed reading the paper. The technical results are solid, interesting and well-presented. The derivation of the lower bound for the active estimator involves some interesting technique. I have two minor questions:  1. The upper bound is presented in a way that with probability at most 1/4, then risk will be bounded by the c*R_n. Why don't the authors prove an upper bound on the expectation of the risk, or prove a high-probability upper bound? A in-expectation upper bound is apparently stronger. If a high-probability bound can be derived from the existing fixed probability bound by repeating the estimation multiple times, it is at least worth mentioning in the paper.  2. It looks like that many constants in the paper depend on the dimension d. For example, the constant C_0 can be exponential in d. Therefore the gap between the upper bound and the lower bound may also have this exponential dependence. If this is true, then it should be explicitly stated in the paper, because in real applications d can be large.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_401_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper studies zero-order optimization with noisy observations.", "The authors study an \"adaptive sampling\" setting, where every query can depend on the results of previous queries.", "Although adaptive sampling gives the analst an intuitive advantage over uniform sampling, the existing theoreticalresult doesn't confirm a more superior convergence rate for it.", "Through an information theoretic analsis, the paper shows that the classicalrate is unimprovable even by active sampling.", "Further more, it presents a localconvergence analsis, showing that if the true function lies in the neighborhood of some desirable reference function, then active sampling does enjoy a better convergence rate than uniform sampling.", "The gap is presented in both an upper bound and an alost matching lower bound.", "Overal, I enjoyed reading the paper.", "The technicalresults are solid, interesting and well-presented.", "The derivation of the lower bound for the active estimator involves some interesting technique.", "I have two minor questions: 1, The upper bound is presented in a way that with probability at most 1/4, then risk will be bounded by the c*R_n.", "Why don't the authors prove an upper bound on the expectation of the risk, or prove a high-probability upper bound?", "A in-expectation upper bound is apparently stronger.", "If a high-probability bound can be derived from the existing fixed probability bound by repeating the estimation multiple times, it is at least worth mentioning in the paper.", "2, It looks like that many constants in the paper depend on the dimension d For example, the constant C_0 can be exponentialin d Therefore the gap between the upper bound and the lower bound may alo have this exponentialdependence.", "If this is true, then it should be explicitly stated in the paper, because in realapplications d can be large."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_401_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_401_2", "review_text": " This paper is a theoretical study of global stochastic optimization of an unknown non-convex function under smoothness conditions in a local minimax setting under active and passive sampling. The paper is presented in the setting where the noise is (sub-)Gaussian. The references and review of prior work is adequate in the context of black box optimization (particularly in conjunction with the appendix), and is of interest to the NIPS theory community with interests in non-convex optimization (as can be seen in the reference list) and active learning as well as the theoretical statistics community. The main original contribution is a precise analysis of the local minimax setting (by introducing the appropriate framework), and showing that the local minimax rates of convergence can be significantly better than the global minimax setting under a Holder-type smoothness and regularity condition (A1,A2) in Section 3.1. The paper does a good job of presenting some intuition for the results particularly in the context of comparison to the analogous problem for (strongly) convex optimization.   The paper is overall well written, with minor typos and formatting issues. The paper could do a better job at pointing to the appropriate appendices in the body of the paper, rather than having to scan the entire appendix (e.g. for Appendix B).  For example, Line 33, the footnote should be moved to avoid confusion. Line 83, continuum armed vs continuous armed. Line 113, the ball should be noted as closed. There is a weird bold n on line 201. Some additional proofreading will likely illuminate these. Shrinkt in Fig.1, etc.  While the proof technique used for showing upper bounds is algorithmic, it remains theoretical (this is not a detriment to the paper; just something to be noted).   Due to time constraints, I have not gone through the entire proofs in detail, but as far as I can tell they appear to be reasonable.    Some technical comments: Local Minimax rate definition (143-164): Expansion on point (1) on how the additional less restrictive assumptions are useful would improve this point. These might be shortened a bit in order (with a bit of expansion in the appendix) in order to provide some more technical proof sketch details in the body of the paper. For the intended audience, I feel that may be more useful.  Example 1,2 (243,244): It seems like condition (A3) is the condition of proposition 2. Remark 1 (212): There is something missing in the last part of the sentence; the violations of the conditions can't be too severe in order for the argument to work. This may be worth expounding for another sentence or two. Theorem 1: It would be useful to give some sketch on the ingredients of the algorithm in the body of the paper at a high level. ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_401_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": [" This paper is a theoreticalstudy of globalstochastic optimization of an unknown non-convex function under smoothness conditions in a localminimax setting under active and passive sampling.", "The paper is presented in the setting where the noise is (sub-)Gaussian.", "The references and review of prior work is adeqate in the context of black box optimization (particularly in conjunction with the appendix), and is of interest to the NIPS theory community with interests in non-convex optimization (as can be seen in the reference list) and active learning as well as the theoreticalstatistics community.", "The main originalcontribution is a precise analsis of the localminimax setting (by introducing the appropriate framework), and showing that the localminimax rates of convergence can be significantly better than the globalminimax setting under a Holder-type smoothness and regularity condition (A1,A2) in secion 3 1, The paper does a good job of presenting some intuition for the results particularly in the context of comparison to the analgous problem for (strongly) convex optimization.", "The paper is overal well written, with minor typos and formatting issues.", "The paper could do a better job at pointing to the appropriate appendices in the body of the paper, rather than having to scan the entire appendix (e g for Appendix B).", "For example, Line 33, the footnote should be moved to avoid confusion.", "Line 83, continuum armed vs continuous armed.", "Line 113, the bal should be noted as closed.", "There is a weird bold n on line 201, Some additionalproofreading will likely illuminate these.", "Shrinkt in fig1, etc While the proof technique used for showing upper bounds is alorithmic, it remains theoretical(this is not a detriment to the paper; just something to be noted).", "Due to time constraints, I have not gone through the entire proofs in detail, but as far as I can tell they appear to be reasonable.", "Some technicalcomments: LocalMinimax rate definition (143-164): Expansion on point (1) on how the additionalless restrictive assumptions are useful would improve this point.", "These might be shortened a bit in order (with a bit of expansion in the appendix) in order to provide some more technicalproof sketc details in the body of the paper.", "For the intended audience, I feel that may be more useful.", "Example 1,2 (243,244): It seems like condition (A3) is the condition of proposition 2, Remark 1 (212): There is something missing in the last part of the sentence; the violations of the conditions can't be too severe in order for the argument to work.", "This may be worth expounding for another sentence or two.", "Theorem 1: It would be useful to give some sketc on the ingredients of the alorithm in the body of the paper at a high level."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_401_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_394_3", "review_text": "This paper studied orthogonality regularizations on training deep CNNs. The authors introduced three novel regularization forms for orthogonality, using double-sided Frobenius norm, Mutual Coherence (MC) and Restricted Isometry Property (RIP) tools, respectfully. Those orthogonality regularizations can plug-and-play with training many CNNs without hassle. They are evaluated on three state-of-the-art models on CIFAR10/100 Strength: - The paper is easy to follow in general. MC and RIP are exploited from compressive sensing literature, and both of their combinations with CNN regularization seem new to me. Particularly, the authors provide an explanation of SRIP\u00e2\u0080\u0099s relationship with the recently proposed spectral norm regularization/spectral normalization [33,34], and shows SRIP to be stricter.  - The proposed techniques are light-weight and easy to plug in. The extra complexities incurred seem to be small (using simplified methods auto-differentiation, power iteration, etc.). They could potentially be easily adopted by many models.  - Experiment advantages are mostly consistent, sometimes notable (2.47%in CIFAR-100). SRIP also outperformed latest competitive methods [15,33]; I like Section 4.5 comparison in particular, which seems to concur that SRIP is stricter.   Weakness: - The experiments are insufficient to validate the claim. Only CIFAR10/100 are used, but many of studied techniques that were effective on CIFAR10/100 and MNIST turned out ineffective on other larger datasets/tasks. I would be happy to raise my score if the authors could provide ImageNet improvement (at least for SO and SRIP).  - As the authors also implied, MC is not enforced in the \u00e2\u0080\u009cright way\u00e2\u0080\u009d (columns not normalized). I would like the authors to report their MC performance with column normalization for completeness.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_394_3", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper studied orthogonalty regularizations on training deep CNNs.", "The authors introduced three novel regularization forms for orthogonalty, using double-sided Frobenius norm, MutualCoherence (MC) and Restricted Isometry Property (RIP) tools, respectfully.", "Those orthogonalty regularizations can plug-and-play with training many CNNs without hassle.", "They are evalated on three state-of-the-art models on CIFAR10/100 Strength: - The paper is easy to follow in general MC and RIP are exploited from compressive sensing literature, and both of their combinations with CNN regularization seem new to me.", "Particularly, the authors provide an explanation of SRIP\u00e2\u0080\u0099s relationship with the recently proposed spectralnorm regularization/spectralnormalzation [33,34], and shows SRIP to be stricter.", "- The proposed techniques are light-weight and easy to plug in.", "The extra complexities incurred seem to be smal (using simplified methods auto-differentiation, power iteration, etc).", "They could potentialy be easily adopted by many models.", "- Experiment advantages are mostly consistent, sometimes notable (2 47%in CIFAR-100).", "SRIP alo outperformed latest competitive methods [15,33]; I like secion 4 5 comparison in particular, which seems to concur that SRIP is stricter.", "Weakness: - The experiments are insufficient to valdate the claim.", "Only CIFAR10/100 are used, but many of studied techniques that were effective on CIFAR10/100 and MNIST turned out ineffective on other larger datasets/tasks.", "I would be happy to raise my score if the authors could provide ImageNet improvement (at least for SO and SRIP).", "- As the authors alo implied, MC is not enforced in the \u00e2\u0080\u009cright way\u00e2\u0080\u009d (columns not normalzed).", "I would like the authors to report their MC performance with column normalzation for completeness."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_394_3", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_394_2", "review_text": "SUMMARY This work investigates various possible soft orthogonality constraints, promoting feature diversity in convolution layers, and yielding some improvement in image classification on CIFAR-10 and CIFAR-100.  STRENGTHS - Tested on popular classification models. - Pretty good overview of prior work. - SRIP is framed in an interesting way in equation 6, for use as a regularizer. - SRIP may be fairly cheap, computationally, when roughly approximated as proposed.  CRITICISMS - Because the proposed constraints enforce filters in convolution layers to be orthogonal to each other, they do not enforce the convolutional operators to be orthogonal; rather, they promote feature diversity in convolution layers. This is indeed proposed in the referenced \"all you need is a good init\" (10) paper as a regularizer. Such a constraint does not target the condition number of layer or address vanishing or exploding signals through a layer. This must be clearly stated and discussed. - Regarding 'scheme change': is it useful to even have a weight decay term for non-convolutional layers? Weight decay in DNNs is in practice enforced as an L2 norm on the weights which is essentially a penalty on the spectral radius (it bounds the largest singular value). Results without scheme change are not shown. The utility of 'scheme change' is stated but not proven. - In section 3.1: if W is m*n, then W'W is n*n, not m*m. Furthermore, it is stated that m \u00e2\u0089\u00a4 n is undercomplete and necessary for the |W'W-I| constraint to work but this is inaccurate. This is actually correct elsewhere in the text but in this section, some symbols appear incorrectly arranged. If m < n, then W may be overcomplete, restricting W'W is problematic, and WW' might work. If m > n, then it may be undercomplete and restricting W'W works. Finally, if m = n, then W may be complete (and restricting W'W works).     -- \"if and only if W is undercomplete (m \u00e2\u0089\u00a4 n)\" -> '(n \u00e2\u0089\u00a4 m)'     -- \"For overcomplete W (m > n), its gram matrix \u00e2\u0088\u0088 m \u00c3\u0097 m cannot be even close to identity, because its rank is at most n\" -> '(n > m)' and 'rank is at most m' - Final performace values tend to be very close together. What is the variance when rerunning experiments? Rerunning an exact reproduction of wide resnet, variance contains the results of multiple papers that claimed SOTA over wide resnets.     -- The authors state that MC outperforms the baseline with a 6.97% error vs 7.04% error on CIFAR 10 and 25.42% for both on CIFAR-100. The performance appears identical for both. - There is no description of the way validation data was split from training data. Was there always a validation set separate from the test set? This should be detailed and made clear. If testing was done on the test set (as in wide resnet), the evaluation is incorrect. - It would be useful to compare against a norm constraint on neighbouring activations (\"Regularizing RNNs by Stabilizing Activations\" - 2015) or a norm constraint on the gradients between neighbouring layers (\"On the difficulty of training recurrent neural networks.\" - 2013).  MINOR COMMENTS - Orthogonality constraints may be more useful for RNNs and GAN discriminators than for ResNets, which already have a stable gradient guarantee, or for encouraging feature diversity in convolution lahyers. - \"which provides a potential link between regularizing orthogonality and spectrum.\" -- it's the same thing - \"we gradually reduce \u00ce\u00bb (initially 0.1) by factors of 1e-3, 1e-4 and 1e-6\" - not 'by factors of', rather 'to'     - learning rate \"decreased by a factor of 0.2\" - 'by a factor of' means divided by, which would in this case mean the lr is increasing     - similarly, 'by a factor of 0.1' - It's surprising that \"DSO always outperforms selective regularization\". - SRIP is interesting. There should be a discussion on the time cost of different regularization approaches. With such a rough approximation as proposed (2 power method iterations), SRIP reduces computational cost from O(n**3) for soft orthogonality to O(n**2); from matrix-matrix multiplication to matrix-vector multiplication. - Perhaps there is a better lambda schedule for soft orthogonality that would make it outperform SRIP. - The MC trick may need a higher weight at first than soft orthogonality and SRIP due to a sparser gradient signal. - If (4) is an approximation, it's not \"equivalent\".  TYPOS     - in Assumption 1: z in [R]^n - \"but unnecessarily appropriate\" - not necessarily - \"phase(direction)\" - space - \"without bothering any assistance components.\" - strange wording - \"could possibly to mutually\" - 'to' -> 'be' - \"structure is most benefit at the initial stage\" - 'beneficial' - eq 5 missing vertical bar  OVERALL OPINION The evaluation of which orthogonality regularizers are possible and useful, and by how much, is a useful one for the community. The SRIP formulation is interesting. However, the scope of the analysis should be expanded and the robustness of comparisons should be improved with statistical analysis. The effect of the proposed regularizations on learned representations and on network dynamics should be clearly identified and discussed. Some errors should be corrected. I would encourage submitting this work to a workshop.  UPDATE Significant work was done in the rebuttal to address the criticisms.  Although the authors did not address the significance of results in Table 1, they (a) confirmed the reliability of results in Table 2 and (b) performed additional experiments on both SVHN and ImageNet that go a long way toward convincing me that SRIP could be a reliably useful regularizer. The authors also included additional experiments with constraints on gradient norm change, further demonstrating superior results with SRIP.  The authors demonstrated a will to correct errors and clarify misleading parts of the text. I would especially encourage that they follow through with clarifying in the beginning that the proposed work enforces orthogonality across filters, encouraging filter diversity, and does not enforce orthogonality \"on linear transformations between hidden layers\" (second paragraph) in the way that some of the references do. The authors clarified some concerns such as whether hyperparameters were tuned on the validation data.  Authors responded qualitatively about time complexity -- this should be in big O notation and would work in their favor to advertise in the text, along with the qualitative note about perceived wall clock time, as the low cost of the method is attractive.  In light of the additional results and the clarification going into the revision, I will raise my rating from a 4 to a 7.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_394_2", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["SUMMARY This work investigates various possible soft orthogonalty constraints, promoting feature diversity in convolution layers, and yielding some improvement in image classification on CIFAR-10 and CIFAR-100, STRENGTHS - Tested on popular classification models.", "- Pretty good overview of prior work.", "- SRIP is framed in an interesting way in eqation 6, for use as a regularizer.", "- SRIP may be fairly cheap, computationaly, when roughly approximated as proposed.", "CRITICISMS - Because the proposed constraints enforce filters in convolution layers to be orthogonalto each other, they do not enforce the convolutionaloperators to be orthogonal rather, they promote feature diversity in convolution layers.", "This is indeed proposed in the referenced \"al you need is a good init\" (10) paper as a regularizer.", "Such a constraint does not target the condition number of layer or address vanishing or exploding signal through a layer.", "This must be clearly stated and discussed.", "- Regarding 'scheme change': is it useful to even have a weight decay term for non-convolutionallayers?", "Weight decay in DNNs is in practice enforced as an L2 norm on the weights which is essentialy a penaly on the spectralradius (it bounds the largest singular vale).", "Results without scheme change are not shown.", "The utility of 'scheme change' is stated but not proven.", "- In secion 3 1: if W is m*n, then W'W is n*n, not m*m Furthermore, it is stated that m \u00e2\u0089\u00a4 n is undercomplete and necessary for the |W'W-I| constraint to work but this is inaccurate.", "This is actualy correct elsewhere in the text but in this secion, some symbols appear incorrectly arranged.", "If m < n, then W may be overcomplete, restricting W'W is problematic, and WW' might work.", "If m > n, then it may be undercomplete and restricting W'W works.", "Finaly, if m = n, then W may be complete (and restricting W'W works).", "-- \"if and only if W is undercomplete (m \u00e2\u0089\u00a4 n)\" -> '(n \u00e2\u0089\u00a4 m)' -- \"For overcomplete W (m > n), its gram matrix \u00e2\u0088\u0088 m \u00c3\u0097 m cannot be even close to identity, because its rank is at most n\" -> '(n > m)' and 'rank is at most m' - Finalperformace vales tend to be very close together.", "What is the variance when rerunning experiments?", "Rerunning an exact reproduction of wide resnet, variance contains the results of multiple papers that claimed SOTA over wide resnets.", "-- The authors state that MC outperforms the baseline with a 6 97% error vs 7 04% error on CIFAR 10 and 25.42% for both on CIFAR-100, The performance appears identicalfor both.", "- There is no description of the way valdation data was split from training data.", "Was there alays a valdation set separate from the test set?", "This should be detailed and made clear.", "If testing was done on the test set (as in wide resnet), the evalation is incorrect.", "- It would be useful to compare against a norm constraint on neighbouring activations (\"Regularizing RNNs by Stabilizing Activations\" - 2015) or a norm constraint on the gradients between neighbouring layers (\"On the difficulty of training recurrent neuralnetworks.\"", "- 2013).", "MINOR COMMENTS - Orthogonalty constraints may be more useful for RNNs and GAN discriminators than for ResNets, which aleady have a stable gradient guarantee, or for encouraging feature diversity in convolution lahyers.", "- \"which provides a potentiallink between regularizing orthogonalty and spectrum.\"", "-- it's the same thing - \"we gradualy reduce \u00ce\u00bb (initialy 0 1) by factors of 1e-3, 1e-4 and 1e-6\" - not 'by factors of', rather 'to' - learning rate \"decreased by a factor of 0 2\" - 'by a factor of' means divided by, which would in this case mean the lr is increasing - similarly, 'by a factor of 0 1' - It's surprising that \"DSO alays outperforms selective regularization\".", "- SRIP is interesting.", "There should be a discussion on the time cost of different regularization approaches.", "With such a rough approximation as proposed (2 power method iterations), SRIP reduces computationalcost from O(n**3) for soft orthogonalty to O(n**2); from matrix-matrix multiplication to matrix-vector multiplication.", "- Perhaps there is a better lambda schedule for soft orthogonalty that would make it outperform SRIP.", "- The MC trick may need a higher weight at first than soft orthogonalty and SRIP due to a sparser gradient signal - If (4) is an approximation, it's not \"eqivalnt\".", "TYPOS - in Assumption 1: z in [R]^n - \"but unnecessarily appropriate\" - not necessarily - \"phase(direction)\" - space - \"without bothering any assistance components.\"", "- strange wording - \"could possibly to mutualy\" - 'to' -> 'be' - \"structure is most benefit at the initialstage\" - 'beneficial - eq5 missing verticalbar OVERALL OPINION The evalation of which orthogonalty regularizers are possible and useful, and by how much, is a useful one for the community.", "The SRIP formulation is interesting.", "However, the scope of the analsis should be expanded and the robustness of comparisons should be improved with statisticalanalsis.", "The effect of the proposed regularizations on learned representations and on network dynamics should be clearly identified and discussed.", "Some errors should be corrected.", "I would encourage submitting this work to a workshop.", "UPDATE Significant work was done in the rebuttalto address the criticisms.", "Although the authors did not address the significance of results in Table 1, they (a) confirmed the reliability of results in Table 2 and (b) performed additionalexperiments on both SVHN and ImageNet that go a long way toward convincing me that SRIP could be a reliably useful regularizer.", "The authors alo included additionalexperiments with constraints on gradient norm change, further demonstrating superior results with SRIP.", "The authors demonstrated a will to correct errors and clarify misleading parts of the text.", "I would especialy encourage that they follow through with clarifying in the beginning that the proposed work enforces orthogonalty across filters, encouraging filter diversity, and does not enforce orthogonalty \"on linear transformations between hidden layers\" (secnd paragraph) in the way that some of the references do.", "The authors clarified some concerns such as whether hyperparameters were tuned on the valdation data.", "Authors responded qualtatively about time complexity -- this should be in big O notation and would work in their favor to advertise in the text, alng with the qualtative note about perceived wal clock time, as the low cost of the method is attractive.", "In light of the additionalresults and the clarification going into the revision, I will raise my rating from a 4 to a 7"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_394_2", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_24_1", "review_text": "The work at hand describes a new distributed implementation (Snap ML) for training generalized linear models for very large datasets. More precisely, the authors extend the popular CoCoA method [15] by providing a hierarchical version that is optimized for distributed computing environments. One of the key ingredients of this new version is the reduction of the overhead caused by the induced inter-node communication (see Section 2.1). In addition to a theoretical analysis of their new approach (Equation (2)), the authors also provide various implementation details including details related to an efficient local GPU solver per compute node (Section 3.1), to buffering techniques to reduce the overhead caused by memory transfers between host and device per compute node (Section 3.2), to an efficient exchange of information between compute nodes (Section 3.3), and to the overall software architecture. The experimental evaluation indicates some benefits of the new hierarchical scheme (Figure 5). It also demonstrates the benefits of the new framework for the Terabyte Click Logs.  The paper is well written and technically sound. I also like the theoretical analysis (Appendix B) of the inter-node communication pattern that is induced by parallelyzing the work per compute node (i.e., by having two loops of parallelism). It think the paper definitely meets the very high NIPS standards. My two main concerns are (1) lack of novelty and (2) the experimental evaluation:  (1) The framework extends the CoCoA framework. While being technically and theoretically sound, I find the practical merits of the approach quite limited. In particular, I am not blown away by the performance gains obtained via the new hierarchical framework. For instance, even given a slow network, I do not find the runtime reduction significant (e.g., 87 seconds instead for t_2=1 compared to 67 seconds for t_2 \\approx 10, see Figure 5). I have the feeling that a similar performance gain could be achieved by compressing a shared vector v prior to sending it over the network.  (2) The approach is clearly of practical importance. However, I was not fully convinced by the experimental evaluation. For instance, in Figure 4, I find the performance comparison between Snap ML, Scikit-Learn, and TensorFlow not entirely fair: Scikit-Learn only makes use of a CPU instead of a V100 GPU. Further, TensorFlow reads the data in batches from disk (as stated by the authors). Thus, Snap ML is faster than Scikit-Learn simply due to the GPU and faster than TensorFlow due to the slow transfer between disk and memory device. Can one improve the performance of TensorFlow by increasing the batch size or by buffering/caching? Also, while I find the results in Figure 7 impressive, I am missing one important baseline: Snap ML with t_2=1, that is, a Spark+GPU version of the previous CoCoA framework (without the additional hierarchical additions). What is the performance of this variant? Do the modifications proposed in the work yield significant better results compared to a rather direct distributed application of the existing framework (i.e., a direct Spark/GPU implementation of the CoCoA implementation)?  Based on the authors' comments, I have decided to increase my score a bit. Overall, it is a decent contribution. I nevertheless think that the experimental evaluation could be improved.  Minor comments: - Figure 5: hierarchical", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_24_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The work at hand describes a new distributed implementation (Snap ML) for training generalzed linear models for very large datasets.", "More precisely, the authors extend the popular CoCoA method [15] by providing a hierarchicalversion that is optimized for distributed computing environments.", "One of the key ingredients of this new version is the reduction of the overhead caused by the induced inter-node communication (see secion 2 1).", "In addition to a theoreticalanalsis of their new approach (eqation (2)), the authors alo provide various implementation details including details related to an efficient localGPU solver per compute node (secion 3 1), to buffering techniques to reduce the overhead caused by memory transfers between host and device per compute node (secion 3 2), to an efficient exchange of information between compute nodes (secion 3 3), and to the overal software architecture.", "The experimentalevalation indicates some benefits of the new hierarchicalscheme (figre 5).", "It alo demonstrates the benefits of the new framework for the Terabyte Click Logs.", "The paper is well written and technicaly sound.", "I alo like the theoreticalanalsis (Appendix B) of the inter-node communication pattern that is induced by paralelyzing the work per compute node (i e , by having two loops of paralelism).", "It think the paper definitely meets the very high NIPS standards.", "My two main concerns are (1) lack of novelty and (2) the experimentalevalation: (1) The framework extends the CoCoA framework.", "While being technicaly and theoreticaly sound, I find the practicalmerits of the approach quite limited.", "In particular, I am not blown away by the performance gains obtained via the new hierarchicalframework.", "For instance, even given a slow network, I do not find the runtime reduction significant (e g , 87 secnds instead for t_2=1 compared to 67 secnds for t_2 \\approx 10, see figre 5).", "I have the feeling that a similar performance gain could be achieved by compressing a shared vector v prior to sending it over the network.", "(2) The approach is clearly of practicalimportance.", "However, I was not fully convinced by the experimentalevalation.", "For instance, in figre 4, I find the performance comparison between Snap ML, Scikit-Learn, and TensorFlow not entirely fair: Scikit-Learn only makes use of a CPU instead of a V100 GPU.", "Further, TensorFlow reads the data in batches from disk (as stated by the authors).", "Thus, Snap ML is faster than Scikit-Learn simply due to the GPU and faster than TensorFlow due to the slow transfer between disk and memory device.", "Can one improve the performance of TensorFlow by increasing the batch size or by buffering/caching?", "Also, while I find the results in figre 7 impressive, I am missing one important baseline: Snap ML with t_2=1, that is, a Spark+GPU version of the previous CoCoA framework (without the additionalhierarchicaladditions).", "What is the performance of this variant?", "Do the modifications proposed in the work yield significant better results compared to a rather direct distributed application of the existing framework (i e , a direct Spark/GPU implementation of the CoCoA implementation)?", "Based on the authors' comments, I have decided to increase my score a bit.", "Overal, it is a decent contribution.", "I nevertheless think that the experimentalevalation could be improved.", "Minor comments: - figre 5: hierarchical"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_24_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_606_3", "review_text": "In this paper, the authors identify ordinary differential equations as the continuous limit of residual networks, and use an adjoint method to derive an augmented ODE which efficiently computes the backward pass. This enables the authors to see ODEs as modeling primitives in deep models, leveraging ODE solvers for efficiently computing both the forward pass and backward pass.   This enables the authors to introduce several models: first, they introduce continuous time normalizing flows as a continuous limit of normalizing flows, and show that they are easier to train (no constraint on the transformation, more efficient computation of the probability flow).  Second, they investigate time-series latent ODEs, time series parametrized by a deterministic ODE and an initial latent state. The authors combine their methods with VAE-style inference networks to train the resulting model.  This is an excellent paper, well written, with exciting methodological work (even if adjoint methods are not new themselves, their application in this context and the leveraging of existing ODE solvers are new ideas in deep learning) and interesting results. I expect the work to have a significant impact.  Minor points: - Hopefully the following is somewhat clear: considering Euler's method with a very small step size as a 'layer' of an ODE solver, a single layer changes its input data relatively little, and consequently many layers will be required for a nonlinear transformation. Therefore, having an ODE as a 'flexible' (high modeling power) layer in a network will require many steps of computation, potentially more than using residual networks where each layer accomplishes more 'work' than infinitesimal layers of an ODE. In other words, are ODE as primitive powerful but ultimately more computationally hungry than a network with a similar modeling power (this does not appear to be the case for CNF, but this seems to rely on the concurrent mixture trick which is not available to 'vanilla' NF, so the mixture-CNF does not obviously seem to be the continuous limit of a vanilla NF). - The explanation of the adjoint method in the appendix is somewhat poorly written. It is not generally (or obviously) true that for any Lagrangian multipliers, the lagrangian loss has same gradient as the actual loss J; and the Lagrangian multipliers function cannot be set arbitrarily (as lines 378-379 seem to imply). The discussion on why J might be known but not j is lacking (lines 384-385), and the intervals used in lines 384+ are not defined before being used. - \\mathcal{J} used in eq 26 of the appendix does not seem to be defined. - In algorithm box 1, it would be desirable to explicitly provide the expected interface of the function ODEsolve, as well as that of its 'Dynamics' argument (an example is given a few lines above, of course, but the box would be easier to read if everything was spelt out clearly) - Perhaps it would be worth explicitly mentioning that variables z_{t_i} in section 6 are deterministic functions of z__{t_0} (hence having the inference network only infer the 'true' latent z_0) - Could the ideas of section 6 be extended to stochastic differential equations? - The model in 6.1 seems to be missing significant amount of details to connect it to the previous section - which was more general than using poisson process likelihood.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_606_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["In this paper, the authors identify ordinary differentialeqations as the continuous limit of residualnetworks, and use an adjoint method to derive an augmented ODE which efficiently computes the backward pass.", "This enables the authors to see ODEs as modeling primitives in deep models, leveraging ODE solvers for efficiently computing both the forward pass and backward pass.", "This enables the authors to introduce severalmodels: first, they introduce continuous time normalzing flows as a continuous limit of normalzing flows, and show that they are easier to train (no constraint on the transformation, more efficient computation of the probability flow).", "secnd, they investigate time-series latent ODEs, time series parametrized by a deterministic ODE and an initiallatent state.", "The authors combine their methods with VAE-style inference networks to train the resulting model.", "This is an excellent paper, well written, with exciting methodologicalwork (even if adjoint methods are not new themselves, their application in this context and the leveraging of existing ODE solvers are new ideas in deep learning) and interesting results.", "I expect the work to have a significant impact.", "Minor points: - Hopefully the following is somewhat clear: considering Euler's method with a very smal step size as a 'layer' of an ODE solver, a single layer changes its input data relatively little, and conseqently many layers will be reqired for a nonlinear transformation.", "Therefore, having an ODE as a 'flexible' (high modeling power) layer in a network will reqire many steps of computation, potentialy more than using residualnetworks where each layer accomplishes more 'work' than infinitesimallayers of an ODE.", "In other words, are ODE as primitive powerful but ultimately more computationaly hungry than a network with a similar modeling power (this does not appear to be the case for CNF, but this seems to rely on the concurrent mixture trick which is not available to 'vanilla' NF, so the mixture-CNF does not obviously seem to be the continuous limit of a vanilla NF).", "- The explanation of the adjoint method in the appendix is somewhat poorly written.", "It is not generaly (or obviously) true that for any Lagrangian multipliers, the lagrangian loss has same gradient as the actualloss J; and the Lagrangian multipliers function cannot be set arbitrarily (as lines 378-379 seem to imply).", "The discussion on why J might be known but not j is lacking (lines 384-385), and the interval used in lines 384+ are not defined before being used.", "- \\mathcalJ} used in eq26 of the appendix does not seem to be defined.", "- In alorithm box 1, it would be desirable to explicitly provide the expected interface of the function ODEsolve, as well as that of its 'Dynamics' argument (an example is given a few lines above, of course, but the box would be easier to read if everything was spelt out clearly) - Perhaps it would be worth explicitly mentioning that variables z_{t_i} in secion 6 are deterministic functions of z__{t_0} (hence having the inference network only infer the 'true' latent z_0) - Could the ideas of secion 6 be extended to stochastic differentialeqations?", "- The model in 6 1 seems to be missing significant amount of details to connect it to the previous secion - which was more generalthan using poisson process likelihood."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_606_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_590_1", "review_text": "This paper demonstrates some of the limits of mechanisms satisfying post hoc generalization, which guarantees accuracy in the adaptive data analysis setting.  They show both an information-theoretic and computational lower bounds for sample complexity, and then show that mechanisms satisfying post hoc generalization do not in the worst case compose non-trivially.  These results tie up some loose ends in adaptive data analysis, e.g. closing the previously-open gap in sample complexity for statistical queries, and gives a more complete picture of what is possible in this area.  On the other hand, I would not call this the most clearly written paper.  In particular, there is very little discussion or overview of the proofs.  I recognize how difficult this is to do given the page limit constraints, but since a fair amount of the proofs are put into the appendix anyway, I consider it very important to communicate the ideas contained within the proofs rather than highlighting the technical details, as is done here.  Nor does this paper highlight the difference between their strategy and what is contained in the previous literature.  The basic strategy, after all, remains the same as in the lower bounds established in previous literature:  Algorithm 2 attempts to uncover the sample given to M, then asks a query that M will overfit on, plus using fingerprinting, etc.  What exactly is the new idea here?  Also, to be blunt, why is the result that post hoc generalization does not compose interesting?  After all, we know that we can achieve O(\\sqrt{k}/\\epsilon^2) sample complexity using differential privacy, and to achieve a better sample complexity, this paper shows that we can't guarantee post hoc generalization at all.  It seems that when it comes to statistical queries, post hoc generalization is a bit besides the point, no?  A few very small things: - Would be helpful to be much more explicit about sample complexity for uniform convergence, that way the reader can compare this to your results. (line 48) - Algorithm 2:  A_1 should start empty: no one has been accused yet. - Algorithm 2:  \\tilde{q}_i^j presumably needs to lose the tilde.  Edit (post author response):  On the new idea in your results:  I appreciate your attempt to stress the idea of an approximate attack rather than an exact attack.  This seems like you're pointing out that a (very similar) attack, even if it doesn't work as well, still works well enough, which may or may not be of sufficient interest/novelty for your readers. On the interesting-ness of composition:  AFAIK, there's no good way to directly show that an algorithm satisfies post hoc generalization without also satisfying DP, information bounds, or the like.  This means it seems rather unlikely that you would actually need composition without already having stronger assumptions on the algorithms that you would like to compose, even if that assumption isn't DP.  Which in turn means I don't know where this result would likely be relevant.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_590_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, "score": 4.0, "tokenized_review_text": ["This paper demonstrates some of the limits of mechanisms satisfying post hoc generalzation, which guarantees accuracy in the adaptive data analsis setting.", "They show both an information-theoretic and computationallower bounds for sample complexity, and then show that mechanisms satisfying post hoc generalzation do not in the worst case compose non-trivialy.", "These results tie up some loose ends in adaptive data analsis, e g closing the previously-open gap in sample complexity for statisticalqueries, and gives a more complete picture of what is possible in this area.", "On the other hand, I would not cal this the most clearly written paper.", "In particular, there is very little discussion or overview of the proofs.", "I recognize how difficult this is to do given the page limit constraints, but since a fair amount of the proofs are put into the appendix anyway, I consider it very important to communicate the ideas contained within the proofs rather than highlighting the technicaldetails, as is done here.", "Nor does this paper highlight the difference between their strategy and what is contained in the previous literature.", "The basic strategy, after al, remains the same as in the lower bounds established in previous literature: Algorithm 2 attempts to uncover the sample given to M, then asks a query that M will overfit on, plus using fingerprinting, etc What exactly is the new idea here?", "Also, to be blunt, why is the result that post hoc generalzation does not compose interesting?", "After al, we know that we can achieve O(\\sqrt{k}/\\epsilon^2) sample complexity using differentialprivacy, and to achieve a better sample complexity, this paper shows that we can't guarantee post hoc generalzation at al.", "It seems that when it comes to statisticalqueries, post hoc generalzation is a bit besides the point, no?", "A few very smal things: - Would be helpful to be much more explicit about sample complexity for uniform convergence, that way the reader can compare this to your results.", "(line 48) - Algorithm 2: A_1 should start empty: no one has been accused yet.", "- Algorithm 2: \\tilde{q}_i^j presumably needs to lose the tilde.", "Edit (post author response): On the new idea in your results: I appreciate your attempt to stress the idea of an approximate attack rather than an exact attack.", "This seems like you're pointing out that a (very similar) attack, even if it doesn't work as well, still works well enough, which may or may not be of sufficient interest/novelty for your readers.", "On the interesting-ness of composition: AFAIK, there's no good way to directly show that an alorithm satisfies post hoc generalzation without alo satisfying DP, information bounds, or the like.", "This means it seems rather unlikely that you would actualy need composition without aleady having stronger assumptions on the alorithms that you would like to compose, even if that assumption isn't DP.", "Which in turn means I don't know where this result would likely be relevant."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_590_1", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_586_3", "review_text": "1. Quality:   The proofs clearly demonstrate that pick-one HSM methods are not ideal for XMLC. However, the primary reasoning for using pick-one HSM is for speed. This paper presents a theoretical argument for using PLT for XMLC which performs better than FastXML with about a 3x speedup at test time. However, the results aren\u00e2\u0080\u0099t very significant over the Parabel model or XML-CNN.  The experimental results section is incomplete. There should be an explanation of the differences between the datasets (e.g. distribution of positive labels), and an explanation of why XT works better on some datasets.  2. Clarity  The formal background was insufficient. Background work wasn\u00e2\u0080\u0099t explained well (especially FastXML, and PLT). F1, Hamming, P@k weren\u00e2\u0080\u0099t explained why they are important for XMLC. P@k is just one measure for XMLC, but many more metrics are important. Minimizing the regret for P@k shouldn\u00e2\u0080\u0099t be the only metric for a good model.   It\u00e2\u0080\u0099s somewhat hard to understand the technical contributions of this work. The contributions aren\u00e2\u0080\u0099t clearly outlined, and it is not very informative.   3. Originality The originality of this work is essentially just from proving PLTs are better than pick-one HSMs. The theorems and proofs are new for XMLC, which is important since pick-one HSMs are frequently used in practice. However, there is a very little technical contribution in terms of the method. It is a small improvement over the FastXML model, albeit the results are better than FastXML. In addition, the method is not explained very well - it is limited to one paragraph.  4. Significance XMLC is a very important task, and the proofs in this paper seem to be significant. However, I\u00e2\u0080\u0099m not sure the experimental results and presentation of the work are significant enough.  ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_586_3", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["1, Qualty: The proofs clearly demonstrate that pick-one HSM methods are not idealfor XMLC.", "However, the primary reasoning for using pick-one HSM is for speed.", "This paper presents a theoreticalargument for using PLT for XMLC which performs better than FastXML with about a 3x speedup at test time.", "However, the results aren\u00e2\u0080\u0099t very significant over the Parabel model or XML-CNN.", "The experimentalresults secion is incomplete.", "There should be an explanation of the differences between the datasets (e g distribution of positive labels), and an explanation of why XT works better on some datasets.", "2, Clarity The formalbackground was insufficient.", "Background work wasn\u00e2\u0080\u0099t explained well (especialy FastXML, and PLT).", "F1, Hamming, P@k weren\u00e2\u0080\u0099t explained why they are important for XMLC.", "P@k is just one measure for XMLC, but many more metrics are important.", "Minimizing the regret for P@k shouldn\u00e2\u0080\u0099t be the only metric for a good model.", "It\u00e2\u0080\u0099s somewhat hard to understand the technicalcontributions of this work.", "The contributions aren\u00e2\u0080\u0099t clearly outlined, and it is not very informative.", "3, Originalty The originalty of this work is essentialy just from proving PLTs are better than pick-one HSMs.", "The theorems and proofs are new for XMLC, which is important since pick-one HSMs are freqently used in practice.", "However, there is a very little technicalcontribution in terms of the method.", "It is a smal improvement over the FastXML model, aleit the results are better than FastXML.", "In addition, the method is not explained very well - it is limited to one paragraph.", "4, Significance XMLC is a very important task, and the proofs in this paper seem to be significant.", "However, I\u00e2\u0080\u0099m not sure the experimentalresults and presentation of the work are significant enough."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_586_3", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_585_1", "review_text": "This paper proposes a multiparty learning algorithm with two different approaches. In the first approach, they combine local models from different owners and then add noise to the global model before revealing it. In the second approach, the global model is trained by each data owner jointly and in each iteration, a sufficient amount of noise is added to the gradient.  The gradient perturbation method proposed in this paper is similar to the method proposed in \u00e2\u0080\u009cA Differentially Private Stochastic Gradient Descent Algorithm for Multiparty Classification\u00e2\u0080\u009d by Rajkumar and Agarwal. First of all, it would be nice to mention the differences between that work. I think it\u00e2\u0080\u0099s also necessary to use that approach as a baseline in the experiments section.   One general problem of this paper is referring to the appendix a lot. This makes the paper harder to follow and understand. Maybe, some of the proofs can be included in the main part of the paper and the more complicated mathematical operations can be given in the appendix. This situation affects the comprehensiveness of the paper.   I also have some doubts about the \u00e2\u0080\u009cG\u00e2\u0080\u009d parameter. Is it possible to set the Lipschitz constant to 1 in this case? If it is how do you prove that? Other than this the number of iterations is important in differentially private settings and affect the performance a lot. How did you choose the \u00e2\u0080\u009cT\u00e2\u0080\u009d?  In most of the cases MPC Grad P outperforms the other algorithms. How do you explain it performs better than the MPC Output P? To sum up, this is an important problem and this paper brings a solution to this problem.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_585_1", "importance": 1, "reproducibility": 1, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper proposes a multiparty learning alorithm with two different approaches.", "In the first approach, they combine localmodels from different owners and then add noise to the globalmodel before revealng it.", "In the secnd approach, the globalmodel is trained by each data owner jointly and in each iteration, a sufficient amount of noise is added to the gradient.", "The gradient perturbation method proposed in this paper is similar to the method proposed in \u00e2\u0080\u009cA Differentialy Private Stochastic Gradient Descent Algorithm for Multiparty Classification\u00e2\u0080\u009d by Rajkumar and Agarwal First of al, it would be nice to mention the differences between that work.", "I think it\u00e2\u0080\u0099s alo necessary to use that approach as a baseline in the experiments secion.", "One generalproblem of this paper is referring to the appendix a lot.", "This makes the paper harder to follow and understand.", "Maybe, some of the proofs can be included in the main part of the paper and the more complicated mathematicaloperations can be given in the appendix.", "This situation affects the comprehensiveness of the paper.", "I alo have some doubts about the \u00e2\u0080\u009cG\u00e2\u0080\u009d parameter.", "Is it possible to set the Lipschitz constant to 1 in this case?", "If it is how do you prove that?", "Other than this the number of iterations is important in differentialy private settings and affect the performance a lot.", "How did you choose the \u00e2\u0080\u009cT\u00e2\u0080\u009d?", "In most of the cases MPC Grad P outperforms the other alorithms.", "How do you explain it performs better than the MPC Output P?", "To sum up, this is an important problem and this paper brings a solution to this problem."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_585_1", "importance": 1, "reproducibility": 1, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_569_2", "review_text": "Universal approximation theoresm have been of interest in Mathematics and, more recently, in Neural Networks. There are different classes of approximators: polynomials, wide neural neworks, deep neural networks, etc. The paper is the first to show that width-limited ResNets are universal approximators. This has been an open problem.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_569_2", "importance": 1, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno3", "evidence": 1, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}, "score": 1.0, "tokenized_review_text": ["Universalapproximation theoresm have been of interest in Mathematics and, more recently, in NeuralNetworks.", "There are different classes of approximators: polynomial, wide neuralneworks, deep neuralnetworks, etc The paper is the first to show that width-limited ResNets are universalapproximators.", "This has been an open problem."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_569_2", "importance": 1, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno3", "evidence": 1, "originality": 1, "metareview": "nota", "presentation": 0, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_564_1", "review_text": "In this work, the authors propose an approach to enforce independence among components of latent representations learned with AEVB. This amounts to adding a penalty term based on the Hilbert-Schmidt Independence Criterion to the ELBO. A set of experiments suggest the approach learns independent components.  The problem is well-motivated, and theoretic justification is given for why the approach could be expected to work. The experiments are also reasonable, but the lack of interpretation of the results on the real datasets makes it difficult to tell whether the results are in some sense \u00e2\u0080\u009cgood.\u00e2\u0080\u009d There is also little theoretical comparison between the proposed approach and similar (cited) work.  === Major comments  As mentioned above, the lack of explanation of the experimental results makes it difficult to interpret them. For example, in Table 1, the *worst* results for the lighting group and direction are in bold. Presumably, that is actually good because it means the latent representations are ignoring the nuisance (lighting) information. However, a more clear explanation would make this point more obvious. Similarly, it is not obvious what the evaluation metrics used on the sc-seq data really show.  The main difference compared to \\beta-TCVAE and VFAE seems to be the choice of mutual information measure. Thus, it would be helpful to more explicitly compare dHSIC and the measures used in the other approaches. Otherwise, it is not clear why we would expect the proposed approach to outperform those.  === Minor comments  At the end of Section 3.1, the authors propound that \u00e2\u0080\u009cthe independence properties\u00e2\u0080\u00a6 will often not be respected by the approximate posterior.\u00e2\u0080\u009d While I agree with this, a reference or two which either prove or demonstrate this empirically would be helpful.  Figure 2 should also show results for an unconstrained VAE as a baseline.  For reference, Table 1 should include unconstrained VAE results. This would make more clear what is \u00e2\u0080\u009clost\u00e2\u0080\u009d (in terms of accuracy) by encouraging independence among the latent features.   === Typos, etc.  \u00e2\u0080\u009cequation 5\u00e2\u0080\u009d -> \u00e2\u0080\u009cEquation 5\u00e2\u0080\u009d  The \u00e2\u0080\u009csuperscript\u00e2\u0080\u009d notation (presumably indicating a single dimension/variable in the respective space) is not defined.  The fonts on Figure 2 should be increased. Also, it is not understandable when printed in black and white. Different marker types could fix that.  \u00e2\u0080\u009chas be shown\u00e2\u0080\u009d -> \u00e2\u0080\u009chas been shown\u00e2\u0080\u009d  MMD is not defined.  \u00e2\u0080\u009cDirichlet kernel\u00e2\u0080\u009d in Proposition 2. This seems more like the definition of the Dirac delta function.  The references are inconsistently formatted. Also, some of the names are misspelled, like \u00e2\u0080\u009cSchlkopf\u00e2\u0080\u009d.  --- After author feedback  The authors have addressed my concerns.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_564_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["In this work, the authors propose an approach to enforce independence among components of latent representations learned with AEVB.", "This amounts to adding a penaly term based on the Hilbert-Schmidt Independence Criterion to the ELBO.", "A set of experiments suggest the approach learns independent components.", "The problem is well-motivated, and theoretic justification is given for why the approach could be expected to work.", "The experiments are alo reasonable, but the lack of interpretation of the results on the realdatasets makes it difficult to tell whether the results are in some sense \u00e2\u0080\u009cgood.\u00e2\u0080\u009d There is alo little theoreticalcomparison between the proposed approach and similar (cited) work.", "=== Major comments As mentioned above, the lack of explanation of the experimentalresults makes it difficult to interpret them.", "For example, in Table 1, the *worst* results for the lighting group and direction are in bold.", "Presumably, that is actualy good because it means the latent representations are ignoring the nuisance (lighting) information.", "However, a more clear explanation would make this point more obvious.", "Similarly, it is not obvious what the evalation metrics used on the sc-seqdata realy show.", "The main difference compared to \\beta-TCVAE and VFAE seems to be the choice of mutualinformation measure.", "Thus, it would be helpful to more explicitly compare dHSIC and the measures used in the other approaches.", "Otherwise, it is not clear why we would expect the proposed approach to outperform those.", "=== Minor comments At the end of secion 3 1, the authors propound that \u00e2\u0080\u009cthe independence properties\u00e2\u0080\u00a6 will often not be respected by the approximate posterior.\u00e2\u0080\u009d While I agree with this, a reference or two which either prove or demonstrate this empiricaly would be helpful.", "figre 2 should alo show results for an unconstrained VAE as a baseline.", "For reference, Table 1 should include unconstrained VAE results.", "This would make more clear what is \u00e2\u0080\u009clost\u00e2\u0080\u009d (in terms of accuracy) by encouraging independence among the latent features.", "=== Typos, etc \u00e2\u0080\u009ceqation 5\u00e2\u0080\u009d -> \u00e2\u0080\u009ceqation 5\u00e2\u0080\u009d The \u00e2\u0080\u009csuperscript\u00e2\u0080\u009d notation (presumably indicating a single dimension/variable in the respective space) is not defined.", "The fonts on figre 2 should be increased.", "Also, it is not understandable when printed in black and white.", "Different marker types could fix that.", "\u00e2\u0080\u009chas be shown\u00e2\u0080\u009d -> \u00e2\u0080\u009chas been shown\u00e2\u0080\u009d MMD is not defined.", "\u00e2\u0080\u009cDirichlet kernel\u00e2\u0080\u009d in Proposition 2, This seems more like the definition of the Dirac delta function.", "The references are inconsistently formatted.", "Also, some of the names are misspelled, like \u00e2\u0080\u009cSchlkopf\u00e2\u0080\u009d.", "--- After author feedback The authors have addressed my concerns."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_564_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_538_2", "review_text": "This paper presents a dynamic Poisson factorisation model for recommendation system, which incorporates meta information of users and items. Specifically, meta information of users and items is incorporated in the gamma scale parameter of the static portions of users and items, respectively; the dynamics are modelled by a Markov chain where the dynamic portions are conditioned on the portions of the previous step. The inference of the model is done by stochastic variational inference. The experiments show that the model has better prediction performance than several previous models on dynamical data.  Quality:  In general, this paper is in good quality.   (1) The motivations for using meta information in recommendation systems are quite intuitive.   (2) The related work and background have been properly covered.  (3) The experiments are relatively strong. The datasets are well selected, the results look promising, and the analysis is comprehensive. To me, this is where the credits come from.  (4) The main issue of the paper is the novelty of the model and the inference. The model structure of using gamma parameters to incorporate meta information has been explored in several previous works and this paper didn't provide a structure with much differences to the previous ones. The same thing happens to the model structure of modelling dynamical data, which is similar to the one in DCPF. The contribution of this paper is combining the two structures into one model with a summation. However, the idea of summation has also been proposed, as in \u00e2\u0080\u009cContent-based recommendations with Poisson factorization\u00e2\u0080\u009d. Using SVI for inference can hardly be counted as the contribution of this paper.   (5) One minor issue is that, to me, the proposed GDMF (the one without meta info) is similar to DCPF, in terms of model structure. But GDMF is reported to have better performance than DCPF. Can the authors clearly point out the differences between GDMF and DCPF, as well as analyse where the performance gain come from?  Clarity:  The paper is easy to follow.   Originality and significance:  As I've discussed, the originality is the main issue. The novelty of the model structure and the inference is limited. But the experiments and results look strong. Therefore, to me, the main significance of the paper is on the empirical results.   --------------------------------------------------------------------------------------------  Thanks for the authors' response, which addresses my concern about the differences between GDMF and DCPF. I hope the this explanation can be added in the revision of the paper.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_538_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper presents a dynamic Poisson factorisation model for recommendation system, which incorporates meta information of users and items.", "Specificaly, meta information of users and items is incorporated in the gamma scal parameter of the static portions of users and items, respectively; the dynamics are modelled by a Markov chain where the dynamic portions are conditioned on the portions of the previous step.", "The inference of the model is done by stochastic variationalinference.", "The experiments show that the model has better prediction performance than severalprevious models on dynamicaldata.", "Qualty: In general this paper is in good qualty.", "(1) The motivations for using meta information in recommendation systems are quite intuitive.", "(2) The related work and background have been properly covered.", "(3) The experiments are relatively strong.", "The datasets are well selected, the results look promising, and the analsis is comprehensive.", "To me, this is where the credits come from.", "(4) The main issue of the paper is the novelty of the model and the inference.", "The model structure of using gamma parameters to incorporate meta information has been explored in severalprevious works and this paper didn't provide a structure with much differences to the previous ones.", "The same thing happens to the model structure of modelling dynamicaldata, which is similar to the one in DCPF.", "The contribution of this paper is combining the two structures into one model with a summation.", "However, the idea of summation has alo been proposed, as in \u00e2\u0080\u009cContent-based recommendations with Poisson factorization\u00e2\u0080\u009d.", "Using SVI for inference can hardly be counted as the contribution of this paper.", "(5) One minor issue is that, to me, the proposed GDMF (the one without meta info) is similar to DCPF, in terms of model structure.", "But GDMF is reported to have better performance than DCPF.", "Can the authors clearly point out the differences between GDMF and DCPF, as well as analse where the performance gain come from?", "Clarity: The paper is easy to follow.", "Originalty and significance: As I've discussed, the originalty is the main issue.", "The novelty of the model structure and the inference is limited.", "But the experiments and results look strong.", "Therefore, to me, the main significance of the paper is on the empiricalresults.", "-------------------------------------------------------------------------------------------- Thanks for the authors' response, which addresses my concern about the differences between GDMF and DCPF.", "I hope the this explanation can be added in the revision of the paper."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_538_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_530_3", "review_text": "When approximating alpha divergence from samples, the estimation variance can be very high due to the unbounded density ratio. In this paper, a new variation of f-divergence is introduced. It guarantees a finite mean of importance weights and its reparametrization gradient can be easily calculated from empirical samples. Experiments on variational inference and reinforcement learning show promising results.   This is a very interesting paper which addresses an important question: in many density ratio-based divergence estimation (such as KL divergence), the fat-tail property of density ratio causes large estimation variance. The alternative definition of the f-divergence shows an interesting way of avoiding such a problem as well as computing the empirical gradient of the divergence minimization problem. The use of emperical CDF of density ratio for suppressing the expectation of f(ratio) is interesting but I still have some concerns:   Proposition 5.1, authors proved the expectation of phi(ratio) is bounded:  1. With respect to what distribution, the expectation is taken? p or q?   2. The proposition only states the bounded mean. Since authors talked about estimation variance of alpha divergence, I thought the second order moment of phi(ratio) might be more interesting than the mean?   3. What is the estimation variance of the gradient in algorithm 1? How does it compare with the alpha divergence?   Otherwise, this paper is well-written and easy to understand. I would like to recommend for acceptance.   -------------------------------------------------------------------------------------------------------------  I have read the feedback from authors. I would upgrade my score by one after the clarification.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_530_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["When approximating alha divergence from samples, the estimation variance can be very high due to the unbounded density ratio.", "In this paper, a new variation of f-divergence is introduced.", "It guarantees a finite mean of importance weights and its reparametrization gradient can be easily calulated from empiricalsamples.", "Experiments on variationalinference and reinforcement learning show promising results.", "This is a very interesting paper which addresses an important question: in many density ratio-based divergence estimation (such as KL divergence), the fat-tail property of density ratio causes large estimation variance.", "The alernative definition of the f-divergence shows an interesting way of avoiding such a problem as well as computing the empiricalgradient of the divergence minimization problem.", "The use of empericalCDF of density ratio for suppressing the expectation of f(ratio) is interesting but I still have some concerns: Proposition 5 1, authors proved the expectation of phi(ratio) is bounded: 1, With respect to what distribution, the expectation is taken?", "p or q?", "2, The proposition only states the bounded mean.", "Since authors taled about estimation variance of alha divergence, I thought the secnd order moment of phi(ratio) might be more interesting than the mean?", "3, What is the estimation variance of the gradient in alorithm 1?", "How does it compare with the alha divergence?", "Otherwise, this paper is well-written and easy to understand.", "I would like to recommend for acceptance.", "------------------------------------------------------------------------------------------------------------- I have read the feedback from authors.", "I would upgrade my score by one after the clarification."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_530_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_527_1", "review_text": " This paper gives an algorithm for learning convex polytopes with a given margin.  A convex polytope is an intersection of some number of halfspaces.  The margin is defined as a notion of distance between the boundary of the polytope and the datapoints (the paper points out there are multiple definitions for this quality).  The main result of this paper is to give a polynomial dependence on t, the number of halfspaces comprising the polytope in the runtime of the algorithm, which gives a super polynomial improvement over past work.  These results are nearly tight, as a polynomial dependence on the margin is not possible if P \\neq NP.  This result is a nice improvement, and hence I am positive about it.  The main downside of this paper is uses a lot of previously known results in a rather straightforward manner to achieve this.  The resulting algorithm is quite simple, as is the analysis.  The lower bound also follows fairly straightforwardly from previous work.  However, my resulting impression remains positive.  The paper is well-written and makes progress on a basic problem, so I vote to accept.  comments:  A key argument seems to be in line 250, where the exponential improvement on the dependence on t appears to come from.  This is minor, but it appears in the title.  I think you are missing an article before the word \u00e2\u0080\u009cmargin\u00e2\u0080\u009d.    The enumeration in line 249 takes time exponential in t.  The greedy algorithm improves this \u00e2\u0080\u0094 so, first, this should be emphasized and not be presented as \u00e2\u0080\u009calternatively\u00e2\u0080\u009d.  Re Lemma 4: it is a standard exercise to write dot products as a function of distances.  It\u00e2\u0080\u0099s not clear this needs to be a lemma.  minor:  l.115 In Lemma 2, why is the second argument of the max 2(v+1)t\\log(3t) and not just 2vt\\log(3t)?  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_527_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": [" This paper gives an alorithm for learning convex polytopes with a given margin.", "A convex polytope is an intersecion of some number of halspaces.", "The margin is defined as a notion of distance between the boundary of the polytope and the datapoints (the paper points out there are multiple definitions for this qualty).", "The main result of this paper is to give a polynomialdependence on t, the number of halspaces comprising the polytope in the runtime of the alorithm, which gives a super polynomialimprovement over past work.", "These results are nearly tight, as a polynomialdependence on the margin is not possible if P \\neqNP.", "This result is a nice improvement, and hence I am positive about it.", "The main downside of this paper is uses a lot of previously known results in a rather straightforward manner to achieve this.", "The resulting alorithm is quite simple, as is the analsis.", "The lower bound alo follows fairly straightforwardly from previous work.", "However, my resulting impression remains positive.", "The paper is well-written and makes progress on a basic problem, so I vote to accept.", "comments: A key argument seems to be in line 250, where the exponentialimprovement on the dependence on t appears to come from.", "This is minor, but it appears in the title.", "I think you are missing an article before the word \u00e2\u0080\u009cmargin\u00e2\u0080\u009d.", "The enumeration in line 249 takes time exponentialin t The greedy alorithm improves this \u00e2\u0080\u0094 so, first, this should be emphasized and not be presented as \u00e2\u0080\u009calernatively\u00e2\u0080\u009d.", "Re Lemma 4: it is a standard exercise to write dot products as a function of distances.", "It\u00e2\u0080\u0099s not clear this needs to be a lemma.", "minor: l 115 In Lemma 2, why is the secnd argument of the max 2(v+1)t\\log(3t) and not just 2vt\\log(3t)?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_527_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_525_1", "review_text": "************************* Summary: ************************* This paper describes MOREL,  an approach for automatically segmenting objects for reinforcement learning. In particular, this work uses SfM-Net [1], which learns to predict optical flow of a single image, to segment the objects in a state, and then uses this object-mask for reinforcement learning. MOREL is evaluated on all 59 Atari games, where it outperforms the baselines in several environments.   ************************* Quality: ************************* This approach appears to be sound. Additionally, it is evaluated within several environments. The paper does not have enough discussion about weaknesses of the approach. Additionally, while there is a clear advantage of using MOREL over the baseline approaches, it would be better to have more than three averaged results.  ************************* Clarity: ************************* This paper is well-written. I did not have any problems understanding the approach or motivation. I did not even find any typos. I do have a couple of comments, though. In the background, the policy is defined w.r.t. histories, but this is not a common way to formulate policies. It is unclear why it is defined in this way in the paper. Additionally, r is never defined.   ************************* Originality: ************************* The main contribution of this work is using SfM-Net to segment images for reinforcement learning. This is similar to feature extraction, and other similar approaches should have been discussed or compared to. In general, the related work lacks discussion of related feature construction and computer vision techniques. Atari is simple and the features could be constructed using very basic computer vision techniques. In fact, Bellemare et al. [2] list a many ways to extract features for Atari, for example by using background subtraction. Additionally, DARLA [3] uses Beta-VAE to learn disentangled features, such as objects, for reinforcement learning, and deep spatial auto-encoders [4] also learn features that encode information about objects.  ************************* Significance: ************************* This work introduces an interesting way to segment objects for reinforcement learning. Vijayanarasimhan et al [1] demonstrate that Sfm-net can work on realistic environments, but it would still be useful to also evaluate MOREL within less trivial environments, particularly because the backgrounds in Atari games are stationary. This would make it clear that it is beneficial to segment objects. For example, do the masks even need to be learned? Can the objects be detected by computing optical flow of the previous and current frames or background subtraction? Can pre-trained features be used?  Additionally, the paper described few changes to SfM-Net. It would have been nice to see results for the unchanged network.  The main changes were a different loss for reconstruction, flow regularization, and a curriculum. These changes are incremental, and so the segmentation results from Figure 3 seem more like result from running SfM-Net on Atari, rather than any contribution from this work. This statement could be argued against by demonstrating that the adjustments to SfM-Net yield different or better results than the unchanged network.  Nevertheless, the approach performs well against the baselines, and I do believe it could be a useful approach since it would likely make it easier to learn about salient objects.   ************************* Comments ************************* The results do not demonstrate that this representation is more interpretable. Detecting objects does not give any insight into the decisions being made by the policy. Using attention might change this. Line 234: I disagree that the segmentation is remarkable since the approach is only evaluated on Atari. Additionally, the model is self-supervised. It is given optical flow and thus predicts optical flow. So the result does not seem too surprising. Why should we assume that moving objects are important?  ************************* Typos ************************* None, well done!  ************************* References: ************************* [1] Vijayanarasimhan, Sudheendra, et al. \"Sfm-net: Learning of structure and motion from video.\"\u00c2\u00a0arXiv preprint arXiv:1704.07804\u00c2\u00a0(2017). [2] Bellemare, Marc G., et al. \"The arcade learning environment: An evaluation platform for general agents.\"\u00c2\u00a0Journal of Artificial Intelligence Research\u00c2\u00a047 (2013): 253-279. [3] Higgins, Irina, et al. \"Darla: Improving zero-shot transfer in reinforcement learning.\" arXiv preprint arXiv:1707.08475 (2017). [4] Finn, Chelsea, et al. \"Deep spatial autoencoders for visuomotor learning.\" arXiv preprint arXiv:1509.06113 (2015).  Update: I have read the review's and author's response. While I appreciate the rigorous studies done in the atari environment, I still believe the paper would be greatly improved if it demonstrated the benefits of the approach in environments with more difficult segmentation. This could still be done in simulation. As such, my score remains the same. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_525_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 5.0, "tokenized_review_text": ["************************* Summary: ************************* This paper describes MOREL, an approach for automaticaly segmenting objects for reinforcement learning.", "In particular, this work uses SfM-Net [1], which learns to predict opticalflow of a single image, to segment the objects in a state, and then uses this object-mask for reinforcement learning.", "MOREL is evalated on al 59 Atari games, where it outperforms the baselines in severalenvironments.", "************************* Qualty: ************************* This approach appears to be sound.", "Additionaly, it is evalated within severalenvironments.", "The paper does not have enough discussion about weaknesses of the approach.", "Additionaly, while there is a clear advantage of using MOREL over the baseline approaches, it would be better to have more than three averaged results.", "************************* Clarity: ************************* This paper is well-written.", "I did not have any problems understanding the approach or motivation.", "I did not even find any typos.", "I do have a couple of comments, though.", "In the background, the policy is defined w r t histories, but this is not a common way to formulate policies.", "It is unclear why it is defined in this way in the paper.", "Additionaly, r is never defined.", "************************* Originalty: ************************* The main contribution of this work is using SfM-Net to segment images for reinforcement learning.", "This is similar to feature extraction, and other similar approaches should have been discussed or compared to.", "In general the related work lacks discussion of related feature construction and computer vision techniques.", "Atari is simple and the features could be constructed using very basic computer vision techniques.", "In fact, Bellemare et al [2] list a many ways to extract features for Atari, for example by using background subtraction.", "Additionaly, DARLA [3] uses Beta-VAE to learn disentangled features, such as objects, for reinforcement learning, and deep spatialauto-encoders [4] alo learn features that encode information about objects.", "************************* Significance: ************************* This work introduces an interesting way to segment objects for reinforcement learning.", "Vijayanarasimhan et al[1] demonstrate that Sfm-net can work on realstic environments, but it would still be useful to alo evalate MOREL within less trivialenvironments, particularly because the backgrounds in Atari games are stationary.", "This would make it clear that it is beneficialto segment objects.", "For example, do the masks even need to be learned?", "Can the objects be detected by computing opticalflow of the previous and current frames or background subtraction?", "Can pre-trained features be used?", "Additionaly, the paper described few changes to SfM-Net.", "It would have been nice to see results for the unchanged network.", "The main changes were a different loss for reconstruction, flow regularization, and a curriculum.", "These changes are incremental and so the segmentation results from figre 3 seem more like result from running SfM-Net on Atari, rather than any contribution from this work.", "This statement could be argued against by demonstrating that the adjustments to SfM-Net yield different or better results than the unchanged network.", "Nevertheless, the approach performs well against the baselines, and I do believe it could be a useful approach since it would likely make it easier to learn about salent objects.", "************************* Comments ************************* The results do not demonstrate that this representation is more interpretable.", "Detecting objects does not give any insight into the decisions being made by the policy.", "Using attention might change this.", "Line 234: I disagree that the segmentation is remarkable since the approach is only evalated on Atari.", "Additionaly, the model is self-supervised.", "It is given opticalflow and thus predicts opticalflow.", "So the result does not seem too surprising.", "Why should we assume that moving objects are important?", "************************* Typos ************************* None, well done!", "************************* References: ************************* [1] Vijayanarasimhan, Sudheendra, et al \"Sfm-net: Learning of structure and motion from video.", "\"\u00c2\u00a0arXiv preprint arXiv:1704.07804\u00c2\u00a0(2017).", "[2] Bellemare, Marc G , et al \"The arcade learning environment: An evalation platform for generalagents.", "\"\u00c2\u00a0Journalof ArtificialIntelligence Research\u00c2\u00a047 (2013): 253-279, [3] Higgins, Irina, et al \"Darla: Improving zero-shot transfer in reinforcement learning.\"", "arXiv preprint arXiv:1707.08475 (2017).", "[4] Finn, Chelsea, et al \"Deep spatialautoencoders for visuomotor learning.\"", "arXiv preprint arXiv:1509.06113 (2015).", "Update: I have read the review's and author's response.", "While I appreciate the rigorous studies done in the atari environment, I still believe the paper would be greatly improved if it demonstrated the benefits of the approach in environments with more difficult segmentation.", "This could still be done in simulation.", "As such, my score remains the same."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_525_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_524_4", "review_text": "This paper presents a method for approximating leverage scores for kernel regression. They propose an algorithm which takes a bottom-up approach and incrementally enlarging the size of the set of columns. Then they argue that combining the leverage score sampling with a preconditioned conjugate gradient method achieves optimal generalization error in time complexity O(n d_eff), where d_eff is the effective dimension of the kernel learning problem, and previously best known running time for this problem  is O(n d^2_eff). The presented algorithm and theoretical results are interesting. However, there are major presentation issues and omissions, especially in the numerical comparisons. Overall, the paper is worthy of publication based on technical contributions. Please see below for detailed comments.  1. The numerical comparisons don't seem to present a fair evaluation of the computational gains. When compared to uniform sampling, the authors only present comparisons within the FALCON algorithm (Figures 4 and 5). Uniform sampling can work better in practice when combined with other methods (e.g. Nystrom, direct solvers, CG and variants ).  2. The authors claim that the time complexity O(lambda^-1 d_eff) is independent in n, and the experiments employ a fixed value of lambda while n grows (Figure 1). However, as noted in Theorem 2, lambda must be set O(d_eff / n ) to achieve optimal generalization error. In this case, the complexity will depend on n.   3. What is 'OPT LS' in Figure 1 ? This doesn't appear in the text.  4. line 42, it's not clear what \"state of the art accuracy\" means since there is no mention of time complexity. Do you mean better accuracy in fixed time complexity?  5. line 44, typo 'our second,'  6. line 71, The notation for the empty subset \\tilde l with double subscript looks odd, is this a typo ?  7. typo in Algorithm 2 description, 'rejection'", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_524_4", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper presents a method for approximating leverage scores for kernel regression.", "They propose an alorithm which takes a bottom-up approach and incrementaly enlarging the size of the set of columns.", "Then they argue that combining the leverage score sampling with a preconditioned conjugate gradient method achieves optimalgeneralzation error in time complexity O(n d_eff), where d_eff is the effective dimension of the kernel learning problem, and previously best known running time for this problem is O(n d^2_eff).", "The presented alorithm and theoreticalresults are interesting.", "However, there are major presentation issues and omissions, especialy in the numericalcomparisons.", "Overal, the paper is worthy of publication based on technicalcontributions.", "Please see below for detailed comments.", "1, The numericalcomparisons don't seem to present a fair evalation of the computationalgains.", "When compared to uniform sampling, the authors only present comparisons within the FALCON alorithm (figres 4 and 5).", "Uniform sampling can work better in practice when combined with other methods (e g Nystrom, direct solvers, CG and variants ).", "2, The authors claim that the time complexity O(lambda^-1 d_eff) is independent in n, and the experiments employ a fixed vale of lambda while n grows (figre 1).", "However, as noted in Theorem 2, lambda must be set O(d_eff / n ) to achieve optimalgeneralzation error.", "In this case, the complexity will depend on n 3, What is 'OPT LS' in figre 1 ?", "This doesn't appear in the text.", "4, line 42, it's not clear what \"state of the art accuracy\" means since there is no mention of time complexity.", "Do you mean better accuracy in fixed time complexity?", "5, line 44, typo 'our secnd,' 6, line 71, The notation for the empty subset \\tilde l with double subscript looks odd, is this a typo ?", "7, typo in Algorithm 2 description, 'rejection'"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_524_4", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_519_2", "review_text": "The goal of this paper is to speed up the greedy MAP inference for determinantal point process (DPP). The proposed algorithm updates the Cholesky facto r incrementally which leads to a lower time complexity compared to the state-of-the-art algorithms. The proposed algorithm is also verified by online A/B testing and is proven to achieve a better relevance and diversity tradeoff.   Overall speaking, the main contribution of this paper is the lower time complexity compared to other greedy algorithms for MAP inference, although most of the techniques are standard.   The application is interesting. In your long sequence recommendation experiment part, you choose the window length to be w=10. Is your experiment sensitive to the choice of window length? In practice, how to choose w? ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_519_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["The goalof this paper is to speed up the greedy MAP inference for determinantalpoint process (DPP).", "The proposed alorithm updates the Cholesky facto r incrementaly which leads to a lower time complexity compared to the state-of-the-art alorithms.", "The proposed alorithm is alo verified by online A/B testing and is proven to achieve a better relevance and diversity tradeoff.", "Overal speaking, the main contribution of this paper is the lower time complexity compared to other greedy alorithms for MAP inference, alhough most of the techniques are standard.", "The application is interesting.", "In your long seqence recommendation experiment part, you choose the window length to be w=10, Is your experiment sensitive to the choice of window length?", "In practice, how to choose w?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_519_2", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_483_2", "review_text": "The authors propose a new way of evaluating generative models using a generalization of precision and recall to generative model. Intuitively, a model has high recall if it captures many modes of the target distribution; a model has high precision if it captures these models well. The authors propose describing the quality of a generative model via a precision-recall curve. The shape of this curve provides information that traditional measures like the Inception score miss (e.g. are we covering many modes well or just one mode).  I think the paper studies a very important topic in generative modeling and provides a way of measuring the quality of generative samples in a way that other models cannot. This allows formally quantifying several crucial issues in generative modeling such as mode collapse, which were only studies qualitatively until now. The paper is also very well written and offers a very thorough discussion of model quality. I suspect this metric will be used in practice.  Comments -------------  - I am still a bit confused as to why the proposed method looks at a tradeoff between precision and recall. In binary classification, there is truly a tradeoff because by varying the threshold outputs a different set of probabilities. But here, the model always produces the same samples; its not like we can explicitly construct the \\mu. Hence, two distinct scalars measuring precision and recall (something like a snapshot along that curve) would make more sense to me. It would be great to have a more thorough discussion of this in the paper.  - All the (elegant) theory assumes that P, Q are over discrete spaces. In practice, the input space is quantized. What is lost during this approximation? How does the number of k-means clusters affect the results? How do we choose k? I don't see a good discussion in the paper.  - Is there a reason why the main results for real generative models are focused on MNIST and Fashion-MNIST? There some plots for Cifar10 and CelebA in the appendix, but there is clearly much more focus on MNIST. This makes the argument seem a bit weaker.  - What is the importance of the feature embedding in which you run k-means? How do I find such features for non-image data? How does the choice of features affect the quality of the results?  - Is it possible to summarize the curve by a single value (like the area under the curve)? Does it give useful insights?", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_483_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The authors propose a new way of evalating generative models using a generalzation of precision and recal to generative model.", "Intuitively, a model has high recal if it captures many modes of the target distribution; a model has high precision if it captures these models well.", "The authors propose describing the qualty of a generative model via a precision-recal curve.", "The shape of this curve provides information that traditionalmeasures like the Inception score miss (e g are we covering many modes well or just one mode).", "I think the paper studies a very important topic in generative modeling and provides a way of measuring the qualty of generative samples in a way that other models cannot.", "This alows formaly quantifying severalcrucialissues in generative modeling such as mode collapse, which were only studies qualtatively until now.", "The paper is alo very well written and offers a very thorough discussion of model qualty.", "I suspect this metric will be used in practice.", "Comments ------------- - I am still a bit confused as to why the proposed method looks at a tradeoff between precision and recal.", "In binary classification, there is truly a tradeoff because by varying the threshold outputs a different set of probabilities.", "But here, the model alays produces the same samples; its not like we can explicitly construct the \\mu.", "Hence, two distinct scalrs measuring precision and recal (something like a snapshot alng that curve) would make more sense to me.", "It would be great to have a more thorough discussion of this in the paper.", "- All the (elegant) theory assumes that P, Q are over discrete spaces.", "In practice, the input space is quantized.", "What is lost during this approximation?", "How does the number of k-means clusters affect the results?", "How do we choose k?", "I don't see a good discussion in the paper.", "- Is there a reason why the main results for realgenerative models are focused on MNIST and Fashion-MNIST?", "There some plots for Cifar10 and CelebA in the appendix, but there is clearly much more focus on MNIST.", "This makes the argument seem a bit weaker.", "- What is the importance of the feature embedding in which you run k-means?", "How do I find such features for non-image data?", "How does the choice of features affect the qualty of the results?", "- Is it possible to summarize the curve by a single vale (like the area under the curve)?", "Does it give useful insights?"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_483_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 3, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_47_1", "review_text": "I enjoyed reading the main paper. I tried going over the supplement but couldn't get through the entire document. My score is low because the supplement is not written very well. In particular, lines 455-458 which is a crucial observation, should be explained more or calculations shown even though it is \"well known\". I do not see any reason why the authors cannot provide a short summary.  My second main concern is regarding the usefulness of the result. The generalization bound shown has the standard dependencies on T but in practice the lipschitz constant l is often huge making the bound trivial.   I also liked reading section 4. I am not sure why hard constraints are also bad. Can the authors explain lines 261-264 in more detail?  Edit: I read the rebuttal from the authors and increased my score. To make the paper more accessible for practitioners, I highly encourage authors to include experiments based on the suggestion provided by R3.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_47_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["I enjoyed reading the main paper.", "I tried going over the supplement but couldn't get through the entire document.", "My score is low because the supplement is not written very well.", "In particular, lines 455-458 which is a crucialobservation, should be explained more or calulations shown even though it is \"well known\".", "I do not see any reason why the authors cannot provide a short summary.", "My secnd main concern is regarding the usefulness of the result.", "The generalzation bound shown has the standard dependencies on T but in practice the lipschitz constant l is often huge making the bound trivial I alo liked reading secion 4, I am not sure why hard constraints are alo bad.", "Can the authors explain lines 261-264 in more detail?", "Edit: I read the rebuttalfrom the authors and increased my score.", "To make the paper more accessible for practitioners, I highly encourage authors to include experiments based on the suggestion provided by R3."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_47_1", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno3", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_421_2", "review_text": "The paper proposed a new adaptive sampling scheme for graph convolutional networks and gained extremely good results on several benchmarks.   The work is an extension of GraphSAGE and FastGCN. Different from GraphSAGE which samples fixed-size neighborhoods for each node, the proposed method sample nodes layer-wise. FastGCN is the most related work, which has the same ideas of layer-wise sampling and variance induction. The improvement of the proposed method on FastGCN mainly lies on the following aspects:  1. The proposed method sample nodes conditioned on the samples of previous layers instead of using layer-independent sampling scheme in FastGCN. 2. For computational efficiency, FastGCN removed the hidden feature part in the optimal sampling distribution in variance reduction, the proposed method used a linear function of node features instead and add the variance in the final objective function. 3. Adding skip connection to preserve second-order proximities.   The paper is well written and technically correct. The ideas of layer-wise sampling and variance reduction are not new, and the improvement on FastGCN is not very significant. But the layer-dependent sampling is interesting, and it does solve the potential drawbacks of FastGCN and leads to a significant performance gain. So the technical contribution is acceptable.  The experimental results are promising. However, the running curve of FastGCN is quite different from the original implementation. I directly run the public FastGCN codes on one dataset (pubmed), the running curve is consistent with the original paper. As there are public codes for FastGCN and GraphSAGE, I think it is better to use their original codes. Especially for FastGCN, as there is a performance gap, I suggest the authors re-check their own implementation or use original FastGCN codes instead. If the paper is accepted, I hope the authors could modify the running curves in Figure2.  It is better to add another recent sampling method in the related work: Chen, Jianfei, Jun Zhu, and Le Song. \"Stochastic Training of Graph Convolutional Networks with Variance Reduction.\" International Conference on Machine Learning. 2018.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_421_2", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["The paper proposed a new adaptive sampling scheme for graph convolutionalnetworks and gained extremely good results on severalbenchmarks.", "The work is an extension of GraphSAGE and FastGCN.", "Different from GraphSAGE which samples fixed-size neighborhoods for each node, the proposed method sample nodes layer-wise.", "FastGCN is the most related work, which has the same ideas of layer-wise sampling and variance induction.", "The improvement of the proposed method on FastGCN mainly lies on the following aspects: 1, The proposed method sample nodes conditioned on the samples of previous layers instead of using layer-independent sampling scheme in FastGCN.", "2, For computationalefficiency, FastGCN removed the hidden feature part in the optimalsampling distribution in variance reduction, the proposed method used a linear function of node features instead and add the variance in the finalobjective function.", "3, Adding skip connection to preserve secnd-order proximities.", "The paper is well written and technicaly correct.", "The ideas of layer-wise sampling and variance reduction are not new, and the improvement on FastGCN is not very significant.", "But the layer-dependent sampling is interesting, and it does solve the potentialdrawbacks of FastGCN and leads to a significant performance gain.", "So the technicalcontribution is acceptable.", "The experimentalresults are promising.", "However, the running curve of FastGCN is quite different from the originalimplementation.", "I directly run the public FastGCN codes on one dataset (pubmed), the running curve is consistent with the originalpaper.", "As there are public codes for FastGCN and GraphSAGE, I think it is better to use their originalcodes.", "Especialy for FastGCN, as there is a performance gap, I suggest the authors re-check their own implementation or use originalFastGCN codes instead.", "If the paper is accepted, I hope the authors could modify the running curves in figre2, It is better to add another recent sampling method in the related work: Chen, Jianfei, Jun Zhu, and Le Song.", "\"Stochastic Training of Graph ConvolutionalNetworks with Variance Reduction.\"", "InternationalConference on Machine Learning.", "2018."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_421_2", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_398_2", "review_text": "I thank the authors for their response.  I felt the authors gave an good response to my questions.  I encourage the authors to more carefully clarify the task since it is a non-standard task if the paper is accepted. ----------- Original review ---------- Summary: Similar to text parsing based on formal grammars, this paper proposes a way to parse images based on formal visual grammars that have a part, subpart structure such as Scene -> Sky, Ground.  The key problem is that splitting the image into *arbitrarily-shaped* pixel regions to associate with the production rules is computationally difficult in general.  This paper proposes to associate formal grammar production rules with submodular Markov random fields (MRF).  The submodular structure of the associated MRF allows for fast inference for a single rule into arbitrarily-shaped subregions and a dynamic-programming-like algorithm for parsing the entire image structure.  The experimental results show that the method is indeed much faster than previous methods.  Pros: 1) Well-written and easy to read even though some of the details are fairly technical. 2) Excellent speed results with competitive or better accuracy. 3) Novel combination of MRFs and formal grammars for images  Cons: 1) The specific task (i.e. input data/parameters and output) seemed a little confusing (note that I am not particularly familiar with the parsing task especially for images).  Is the task a hierarchical version of semantic segmentation?  Are the raw image pixels given to the algorithm or just semantic features like segmentation label?  In one place the energy seems to depend on the raw pixels (Sec. 2.1) but later the energy is denoted to only depend on y (Sec. 4.1); maybe this is just a notation thing but I wanted to check. 2) The experiments are also a little confusing but maybe this is just because the task is not a classic task.  How are the DeepLab unary features used?  Are they used instead of the raw pixel values? 3) What would be an example of a non-tree-structured grammar (see lines 66-68)?  It would be good to more clearly describe the difference from [6,7 ref in paper] that are similar but for tree-structured grammars.  Minor comments: The illustrations were very helpful in making the ideas concrete.  I would suggest presenting the theorem/propositions first and then giving comments on them instead of defining them after giving comments.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_398_2", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["I thank the authors for their response.", "I felt the authors gave an good response to my questions.", "I encourage the authors to more carefully clarify the task since it is a non-standard task if the paper is accepted.", "----------- Originalreview ---------- Summary: Similar to text parsing based on formalgrammars, this paper proposes a way to parse images based on formalvisualgrammars that have a part, subpart structure such as Scene -> Sky, Ground.", "The key problem is that splitting the image into *arbitrarily-shaped* pixel regions to associate with the production rules is computationaly difficult in general This paper proposes to associate formalgrammar production rules with submodular Markov random fields (MRF).", "The submodular structure of the associated MRF alows for fast inference for a single rule into arbitrarily-shaped subregions and a dynamic-programming-like alorithm for parsing the entire image structure.", "The experimentalresults show that the method is indeed much faster than previous methods.", "Pros: 1) Well-written and easy to read even though some of the details are fairly technical 2) Excellent speed results with competitive or better accuracy.", "3) Novel combination of MRFs and formalgrammars for images Cons: 1) The specific task (i e input data/parameters and output) seemed a little confusing (note that I am not particularly familiar with the parsing task especialy for images).", "Is the task a hierarchicalversion of semantic segmentation?", "Are the raw image pixels given to the alorithm or just semantic features like segmentation label?", "In one place the energy seems to depend on the raw pixels (sec 2 1) but later the energy is denoted to only depend on y (sec 4 1); maybe this is just a notation thing but I wanted to check.", "2) The experiments are alo a little confusing but maybe this is just because the task is not a classic task.", "How are the DeepLab unary features used?", "Are they used instead of the raw pixel vales?", "3) What would be an example of a non-tree-structured grammar (see lines 66-68)?", "It would be good to more clearly describe the difference from [6,7 ref in paper] that are similar but for tree-structured grammars.", "Minor comments: The illustrations were very helpful in making the ideas concrete.", "I would suggest presenting the theorem/propositions first and then giving comments on them instead of defining them after giving comments."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_398_2", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_261_1", "review_text": "The main idea is incorporating Nesterov's accelerated gradient descent (AGD) in eigenvalue problem. The approach relies on shift-and-invert preconditioning method that reduces the non-convex objective of Rayleigh quotient to a sequence of convex programs. Shift-and-invert preconditioning improves the convergence dependency of the gradient method to the eigengap of the given matrix. The focus of this paper is using AGD method to approximately solve the convex programs and reaching an accelerated convergence rate for the convex part. Exploiting the accelerated convergence of AGD, they reach an accelerated convergence for the first-order optimization of the eigenvalue problem.  My main concern is regarding the novelty of the paper.  There is an extensive literature on accelerating power iteration method that is totally neglected in this paper. For example, \"accelerated stochastic power iteration\" by CHRISTOPHER DE SA et al. is a recent one. Chebyshev's acceleration in the classic literature of optimization of Rayleigh quotient is also quite related to this paper (see \"convergence rate estimates for iterative methods for a mesh symmetric eigenvalue problem\" by Knyazev). Indeed, gradient descent on eigenvalue problem can directly be accelerated without the \"shift-and-invert\" convex relaxation. The accelerated power iteration does not have the extra logarithmic dependency to the eigengap.     In section 3, the authors are motivating the advantage of their approach in the case of the multiplicity of the largest eigenvalues. However, I think that this case is not considered in the literature due to the degeneracy. As it is mentioned in the introduction, eigenvector problem search for the leading eigenvector. Since the leading eigenvector is not unique in the multiplicity case, this case is skipped in literature. In such a degenerate case, one can still provide a convergence on the eigenvalue (function f(x)) but the leading eigenvector is not well-defined.   The required conditions on initial parameter x_0 are missed in the theorem as well as the algorithm. It is clear that if x_0 is orthogonal to the subspace V, then the algorithm can not retrieve the desired global minimum.    To make the algorithm clearer, I suggest making the terms such that approximate gradient more precise. I think that the number of AGD iterations in step 3 can be determined by their analysis, so it might be better to include this number in the Algorithm as well.   Since the shift parameter sigma is unknown, I think they should include the time complexity of searching for this parameter and analyze the robustness of the method against the choice of sigma.   Regarding experiments, I think that one baseline on real datasets is not enough. Particularly, eigenvector problem is one of the oldest optimization problems with many solvers. For example, accelerated power methods can be a potential baseline for their proposal.   ------------------------------------------------------- I have read the response. Authors had convincing responses and experiements regarding the literature and baselines, hence I decided to increase my score by one. Still, I think that handling the degenerated case lambda_1 = lambda_2 is not a major contribution.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_261_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The main idea is incorporating Nesterov's accelerated gradient descent (AGD) in eigenvale problem.", "The approach relies on shift-and-invert preconditioning method that reduces the non-convex objective of Rayleigh quotient to a seqence of convex programs.", "Shift-and-invert preconditioning improves the convergence dependency of the gradient method to the eigengap of the given matrix.", "The focus of this paper is using AGD method to approximately solve the convex programs and reaching an accelerated convergence rate for the convex part.", "Exploiting the accelerated convergence of AGD, they reach an accelerated convergence for the first-order optimization of the eigenvale problem.", "My main concern is regarding the novelty of the paper.", "There is an extensive literature on accelerating power iteration method that is totaly neglected in this paper.", "For example, \"accelerated stochastic power iteration\" by CHRISTOPHER DE SA et al is a recent one.", "Chebyshev's acceleration in the classic literature of optimization of Rayleigh quotient is alo quite related to this paper (see \"convergence rate estimates for iterative methods for a mesh symmetric eigenvale problem\" by Knyazev).", "Indeed, gradient descent on eigenvale problem can directly be accelerated without the \"shift-and-invert\" convex relaxation.", "The accelerated power iteration does not have the extra logarithmic dependency to the eigengap.", "In secion 3, the authors are motivating the advantage of their approach in the case of the multiplicity of the largest eigenvales.", "However, I think that this case is not considered in the literature due to the degeneracy.", "As it is mentioned in the introduction, eigenvector problem search for the leading eigenvector.", "Since the leading eigenvector is not unique in the multiplicity case, this case is skipped in literature.", "In such a degenerate case, one can still provide a convergence on the eigenvale (function f(x)) but the leading eigenvector is not well-defined.", "The reqired conditions on initialparameter x_0 are missed in the theorem as well as the alorithm.", "It is clear that if x_0 is orthogonalto the subspace V, then the alorithm can not retrieve the desired globalminimum.", "To make the alorithm clearer, I suggest making the terms such that approximate gradient more precise.", "I think that the number of AGD iterations in step 3 can be determined by their analsis, so it might be better to include this number in the Algorithm as well.", "Since the shift parameter sigma is unknown, I think they should include the time complexity of searching for this parameter and analze the robustness of the method against the choice of sigma.", "Regarding experiments, I think that one baseline on realdatasets is not enough.", "Particularly, eigenvector problem is one of the oldest optimization problems with many solvers.", "For example, accelerated power methods can be a potentialbaseline for their proposal ------------------------------------------------------- I have read the response.", "Authors had convincing responses and experiements regarding the literature and baselines, hence I decided to increase my score by one.", "Still, I think that handling the degenerated case lambda_1 = lambda_2 is not a major contribution."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_261_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_496_1", "review_text": "** update ** I increase the score I attribute to this paper since the authors' response to the various problems raised by the reviewers seems to me very satisfactory. However the authors promise several improvements and my score cannot be based solely on promises, so this score only increases by one. Finally, the practical motivations of this little explored field are extremely justified, so I also encourage authors to apply their work to more complex problems, which should lead to interesting results.  ** summary ** This paper sets up an algorithm capable from demonstrations (sequence of states and actions)  and from a set of specifications (set of trajectories), to infer the specifications  governing the actions of the agent and the visited states. These specifications can be seen as non-Markovian reward functions.  Thus, this work is related to inverse reinforcement learning (IRL)  which aims to infer the reward function of an agent  by observing these successive states and actions. By defining the probability of a trajectory knowing a specification  (using the maximum entropy principle) the development leads to a posterior distribution. Two algorithms result from this and allow to test the approach  on the system presented in introduction (motivating the paper).  ** quality ** Although its introduction is interesting, this paper is quite hard to follow,  especially from page 4.  The steps should be better justified or motivated by intuition or pedagogical explanations  of the ongoing development. Also some proofs only appears in the supplementary materials and not in the paper,  making the paper less self-contained. At least sketches of proof should be provided to let the reader study the main arguments.  ** clarity ** As mentioned above, clarity is not the strength of this paper.  This can also be illustrated by the more or less in-depth comments that follow.   page 3:  < Sec > Section  The Markov property is already present in Definition 2.1.  < no \\phi =^{def} 1 - \\phi(\\xi) > no \\phi(\\xi) =^{def} 1 - \\phi(\\xi)  page 4:  In Equation 2, it seems that we multiply a probability of \\xi  (trajectory probability given by the transition functions)  with another probability of \\xi (given by the exponential function).  Some confusion in the notations X and \\xi.  page 6: < the following simple algorithm. > the following simple algorithm (Algorithm 2).  page 8: < queries,\\phi^{hat} > queries, \\phi^{hat}  < assignments.\\footnote{...} > assignments\\footnote{...}.  The conclusion should be a Section.  ** originality ** To the best of my knowledge this paper is the first research  on inferring specifications from demonstrations in the MDP framework. The authors have done a good bibliographical work to position their study  in the relevant literature. I suggest authors read  (Drougard \"Exploiting Imprecise Information Sources in Sequential Decision Making Problems  under Uncertainty.\" 2015) which adapts classical MDP models to Qualitative Possibility Theory. This theory is very close to logic  (and therefore could easily integrate the specifications framework)  while retaining properties similar to Probability Theory  (which allows planning with the same tools).  ** significance ** Although the idea and the algorithms developed are really interesting,  I doubt that the theoretical and applied contributions are worthy of NIPS.  I remain cautious however because the lack of clarity, the absence of sketch of proof  and the short time to review prevents me from checking developments in details.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_496_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["** update ** I increase the score I attribute to this paper since the authors' response to the various problems raised by the reviewers seems to me very satisfactory.", "However the authors promise severalimprovements and my score cannot be based solely on promises, so this score only increases by one.", "Finaly, the practicalmotivations of this little explored field are extremely justified, so I alo encourage authors to apply their work to more complex problems, which should lead to interesting results.", "** summary ** This paper sets up an alorithm capable from demonstrations (seqence of states and actions) and from a set of specifications (set of trajectories), to infer the specifications governing the actions of the agent and the visited states.", "These specifications can be seen as non-Markovian reward functions.", "Thus, this work is related to inverse reinforcement learning (IRL) which aims to infer the reward function of an agent by observing these successive states and actions.", "By defining the probability of a trajectory knowing a specification (using the maximum entropy principle) the development leads to a posterior distribution.", "Two alorithms result from this and alow to test the approach on the system presented in introduction (motivating the paper).", "** qualty ** Although its introduction is interesting, this paper is quite hard to follow, especialy from page 4, The steps should be better justified or motivated by intuition or pedagogicalexplanations of the ongoing development.", "Also some proofs only appears in the supplementary material and not in the paper, making the paper less self-contained.", "At least sketces of proof should be provided to let the reader study the main arguments.", "** clarity ** As mentioned above, clarity is not the strength of this paper.", "This can alo be illustrated by the more or less in-depth comments that follow.", "page 3: < sec> secion The Markov property is aleady present in Definition 2 1, < no \\phi =^{def} 1 - \\phi(\\xi) > no \\phi(\\xi) =^{def} 1 - \\phi(\\xi) page 4: In eqation 2, it seems that we multiply a probability of \\xi (trajectory probability given by the transition functions) with another probability of \\xi (given by the exponentialfunction).", "Some confusion in the notations X and \\xi.", "page 6: < the following simple alorithm.", "> the following simple alorithm (Algorithm 2).", "page 8: < queries,\\phi^{hat} > queries, \\phi^{hat} < assignments.\\footnote{...} > assignments\\footnote{...}.", "The conclusion should be a secion.", "** originalty ** To the best of my knowledge this paper is the first research on inferring specifications from demonstrations in the MDP framework.", "The authors have done a good bibliographicalwork to position their study in the relevant literature.", "I suggest authors read (Drougard \"Exploiting Imprecise Information Sources in SeqentialDecision Making Problems under Uncertainty.\"", "2015) which adapts classicalMDP models to Qualtative Possibility Theory.", "This theory is very close to logic (and therefore could easily integrate the specifications framework) while retaining properties similar to Probability Theory (which alows planning with the same tools).", "** significance ** Although the idea and the alorithms developed are realy interesting, I doubt that the theoreticaland applied contributions are worthy of NIPS.", "I remain cautious however because the lack of clarity, the absence of sketc of proof and the short time to review prevents me from checking developments in details."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_496_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "neurips18", "review_id": "NIPS_2018_449_2", "review_text": "SUMMARY  This paper considers an optimistic variant of Q-learning in an episodic reinforcement learning setting where the transition matrix at each stage is fixed but may be different from the transition matrix of the other stages. Regret bounds are derived that match a lower bound derived in this particular setting up to a factor of sqrt{H}, where H is the episode horizon.   EVALUATION  This is an ok paper that adapts the episodic RL analysis of Azar et al (ICML 2017) to an optimistic Q-learning variant and generalizes it to the case where transition probabilities may be different at different stages. Due to the latter particularity the lower bound that can be achieved is worse than the lower bound in Azar et al (ICML 2017) - which should be pointed out in the main part of the paper and not only in the appendix however. As far as I can tell, apart from the (rather artifical) generalization about the stage-dependent transitions, the analysis is quite similar to Azar et al (ICML 2017). Due to the more general setting this gives regret bounds that are worse by a factor of sqrt{H}.    In my opinion the authors try to oversell their results however. First of all, while the title suggests an analysis of Q-learning, the paper considers a particular variant of Q-learning with exploration bonus and a predefined fixed learning rate, and the analysis is restricted to a rather particular episodic setting. The paper claims to give the first analysis of a model-free RL algorithm, yet does not provide a clear definition what precisely distinguishes a model-free from a model-based algorithm. The vague claim that \"model-free algorithms (...) directly update the value function\" may as well apply to the original paper of Azar et al (ICML 2017), which employs optimistic Q- and value-function, too. Finally, the comparison to other algorithms is rather unfair. In particular, mixing up results for the episodic and the non-episodic case the way it is done in Table 1 is in my view highly misleading. Moreover, it is obvious that if the other algorithms used for comparison would be given the same information as the Q-learning algorithm considered in the paper uses (i.e., that transitions are the same at the same stage) would perform better than claimed in Table 1.   Overall, in my view the paper's main shortcoming is that it does not discuss the differences between the given optimistic Q-learning algorithm and the algorithm of Azar et al (ICML 2017). I think it would be necessary to argue that the latter algorithm cannot be rewritten as a Q-learning variant. Otherwise, the paper at hand would add little to the contribution of Azar et al (ICML 2017).   COMMENTS  - I did not see why when considering the episodic setting as a special case of MDPs (footnote 1 on p.3) the diameter D=H. Depending on how easy it is to reach a particular state, I think the diameter may be much larger than that.  - In the algorithm, p should be given as parameter. The alpha's as given in (3.1) should be specified either in the algorithm or in Thm 1.   - In l.149, there seems to be missing something in the last part of the sentence.  - Thm 3: As said, it should be explicitly mentioned here why this result is not in contradiction to the paper of Azar et al (ICML 2017).  - While I believe that one can derive PAC bounds from the regret bounds, I could not follow the argument between lines 171 and 172. In particular, I could not see why random policy selection would be considered for that.    - I found notation a bit unusual. Typically, t denotes a time step, and delta would be a more common notation for the error probability.   - The paper uses two different *-notations.  - There are a few typos, missing words (mainly articles and 'that'). In general. the paper should be proof-read for English style and grammar issues.  ---  POST-REBUTTAL  I acknowledge the definition of model-free and model-based algorithms given in the author feedback and that the presented algorithm has an improved space complexity over UCBVI. Still, in my opinion this is not such a significant advantage, in particular (as Reviewer #1 mentions) in the tabular setting. Also, it is still not clear to me that a reformulation of UCBVI could not give model-free space complexity, too. Given that the paper considers a (for the addressed practitioners) hardly relevant episodic setting, my overall assessment does not change for the moment. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_449_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["SUMMARY This paper considers an optimistic variant of Q-learning in an episodic reinforcement learning setting where the transition matrix at each stage is fixed but may be different from the transition matrix of the other stages.", "Regret bounds are derived that match a lower bound derived in this particular setting up to a factor of sqrt{H}, where H is the episode horizon.", "EVALUATION This is an ok paper that adapts the episodic RL analsis of Azar et al(ICML 2017) to an optimistic Q-learning variant and generalzes it to the case where transition probabilities may be different at different stages.", "Due to the latter particularity the lower bound that can be achieved is worse than the lower bound in Azar et al(ICML 2017) - which should be pointed out in the main part of the paper and not only in the appendix however.", "As far as I can tell, apart from the (rather artifical generalzation about the stage-dependent transitions, the analsis is quite similar to Azar et al(ICML 2017).", "Due to the more generalsetting this gives regret bounds that are worse by a factor of sqrt{H}.", "In my opinion the authors try to oversell their results however.", "First of al, while the title suggests an analsis of Q-learning, the paper considers a particular variant of Q-learning with exploration bonus and a predefined fixed learning rate, and the analsis is restricted to a rather particular episodic setting.", "The paper claims to give the first analsis of a model-free RL alorithm, yet does not provide a clear definition what precisely distinguishes a model-free from a model-based alorithm.", "The vague claim that \"model-free alorithms (...) directly update the vale function\" may as well apply to the originalpaper of Azar et al(ICML 2017), which employs optimistic Q- and vale-function, too.", "Finaly, the comparison to other alorithms is rather unfair.", "In particular, mixing up results for the episodic and the non-episodic case the way it is done in Table 1 is in my view highly misleading.", "Moreover, it is obvious that if the other alorithms used for comparison would be given the same information as the Q-learning alorithm considered in the paper uses (i e , that transitions are the same at the same stage) would perform better than claimed in Table 1, Overal, in my view the paper's main shortcoming is that it does not discuss the differences between the given optimistic Q-learning alorithm and the alorithm of Azar et al(ICML 2017).", "I think it would be necessary to argue that the latter alorithm cannot be rewritten as a Q-learning variant.", "Otherwise, the paper at hand would add little to the contribution of Azar et al(ICML 2017).", "COMMENTS - I did not see why when considering the episodic setting as a specialcase of MDPs (footnote 1 on p 3) the diameter D=H Depending on how easy it is to reach a particular state, I think the diameter may be much larger than that.", "- In the alorithm, p should be given as parameter.", "The alha's as given in (3 1) should be specified either in the alorithm or in Thm 1, - In l 149, there seems to be missing something in the last part of the sentence.", "- Thm 3: As said, it should be explicitly mentioned here why this result is not in contradiction to the paper of Azar et al(ICML 2017).", "- While I believe that one can derive PAC bounds from the regret bounds, I could not follow the argument between lines 171 and 172, In particular, I could not see why random policy selection would be considered for that.", "- I found notation a bit unusual Typicaly, t denotes a time step, and delta would be a more common notation for the error probability.", "- The paper uses two different *-notations.", "- There are a few typos, missing words (mainly articles and 'that').", "In general the paper should be proof-read for English style and grammar issues.", "--- POST-REBUTTAL I acknowledge the definition of model-free and model-based alorithms given in the author feedback and that the presented alorithm has an improved space complexity over UCBVI.", "Still, in my opinion this is not such a significant advantage, in particular (as Reviewer #1 mentions) in the tabular setting.", "Also, it is still not clear to me that a reformulation of UCBVI could not give model-free space complexity, too.", "Given that the paper considers a (for the addressed practitioners) hardly relevant episodic setting, my overal assessment does not change for the moment."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_449_2", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_532_1", "review_text": "-- Paper Summary   This paper considers an optimisation set-up where the target function may not be known exactly, but rather may be prone to adversarial attacks and/or uncertainty. This interpretation can also be adapted to other problem settings such as reporting optimal subsets/groups of points rather than individual points. The bounds considered in this work are backed up by both theoretic proofs and a thorough set of varied experiments.    -- Originality + Significance  The work presented in this paper appears to be sufficiently novel within the context of GP optimization. The proposal is very well-motivated in the introduction, while the varied experiments are effective in showcasing the potential use-cases of this method. This paper is indeed not the first to consider robust optimisation, but it is sufficiently differentiated (adversarial rather than random uncertainty, noisy function evaluations, single-point sampling rather than batch). Related work is also appropriately cited and discussed.  Given its inherent similarity to optimising under uncertainty (albeit not adversarial), the connection to Bayesian optimisation could perhaps be expanded further; it is currently only briefly mentioned in passing.  With regards to significance, I think that the appeal of this paper is not limited to the optimisation community but could also be of interest to other machine learning researchers and practitioners.   -- Quality  I am satisfied with the extent of both the theoretic analysis and experimental evaluation. While I look forward to reading the opinion of other reviewers who work more closely in the field of multi-armed bandit optimization, I currently have very little concerns about this paper.  The performance of the algorithm with respect to different configurations of \\beta and \\epsilon could be explored further using synthetic examples (even if only in the supplementary material). Although the authors claim that their assignment is typically dependent on the problem being targeted, setting these parameters still feels like an overly ambiguous task. The theoretical choice is claimed to be generally unsuitable and is consequently replaced using a fairly vague heuristic given in L220-222.  It might be down to wording, but it is also slightly unclear as to whether the baselines considered are indeed the closest competitors to the method developed in the paper or simply base approaches which the proposal is all but guaranteed to outperform. Several papers are mentioned in the related work section but are not directly considered in the experimental evaluation. In this regard, I would encourage the authors to justify their choice of competitors more effectively.   -- Writing and Clarity   This is undeniably a very well-written paper \u00e2\u0080\u0093 I could not spot any typos while reading it, and all the concepts are presented in a clear and concise manner. The balance between the content that is included in the main paper and that which is left to the supplementary material is also very suitable \u00e2\u0080\u0093 the supplementary material contains additional experiments as well as proofs corroborating the theorems presented in the main paper.   -- Overall Recommendation  While similar ideas to those explored in this paper may have been tangentially investigated in other forms, I believe this is an excellent paper which ticks all the boxes with regards to content, evaluation and overall presentation. I believe that such a paper could be very well-received by the optimisation community participating at NIPS.  --------------  -- Post rebuttal  Reading the other reviews and the rebuttal has consolidated my views on the quality and significance of this paper. I highly encourage the authors to incorporate the suggestions pointed out in the reviews and subsequently addressed in the rebuttal, in particular the connection to Bayesian optimisation and clarifying why ES and EI share the same issues as GP-UCB. Great work! ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_532_1", "importance": 1, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["-- Paper Summary This paper considers an optimisation set-up where the target function may not be known exactly, but rather may be prone to adversarialattacks and/or uncertainty.", "This interpretation can alo be adapted to other problem settings such as reporting optimalsubsets/groups of points rather than individualpoints.", "The bounds considered in this work are backed up by both theoretic proofs and a thorough set of varied experiments.", "-- Originalty + Significance The work presented in this paper appears to be sufficiently novel within the context of GP optimization.", "The proposalis very well-motivated in the introduction, while the varied experiments are effective in showcasing the potentialuse-cases of this method.", "This paper is indeed not the first to consider robust optimisation, but it is sufficiently differentiated (adversarialrather than random uncertainty, noisy function evalations, single-point sampling rather than batch).", "Related work is alo appropriately cited and discussed.", "Given its inherent similarity to optimising under uncertainty (aleit not adversarial, the connection to Bayesian optimisation could perhaps be expanded further; it is currently only briefly mentioned in passing.", "With regards to significance, I think that the appealof this paper is not limited to the optimisation community but could alo be of interest to other machine learning researchers and practitioners.", "-- Qualty I am satisfied with the extent of both the theoretic analsis and experimentalevalation.", "While I look forward to reading the opinion of other reviewers who work more closely in the field of multi-armed bandit optimization, I currently have very little concerns about this paper.", "The performance of the alorithm with respect to different configrations of \\beta and \\epsilon could be explored further using synthetic examples (even if only in the supplementary material.", "Although the authors claim that their assignment is typicaly dependent on the problem being targeted, setting these parameters still feels like an overly ambiguous task.", "The theoreticalchoice is claimed to be generaly unsuitable and is conseqently replaced using a fairly vague heuristic given in L220-222, It might be down to wording, but it is alo slightly unclear as to whether the baselines considered are indeed the closest competitors to the method developed in the paper or simply base approaches which the proposalis al but guaranteed to outperform.", "Severalpapers are mentioned in the related work secion but are not directly considered in the experimentalevalation.", "In this regard, I would encourage the authors to justify their choice of competitors more effectively.", "-- Writing and Clarity This is undeniably a very well-written paper \u00e2\u0080\u0093 I could not spot any typos while reading it, and al the concepts are presented in a clear and concise manner.", "The balnce between the content that is included in the main paper and that which is left to the supplementary materialis alo very suitable \u00e2\u0080\u0093 the supplementary materialcontains additionalexperiments as well as proofs corroborating the theorems presented in the main paper.", "-- Overal Recommendation While similar ideas to those explored in this paper may have been tangentialy investigated in other forms, I believe this is an excellent paper which ticks al the boxes with regards to content, evalation and overal presentation.", "I believe that such a paper could be very well-received by the optimisation community participating at NIPS.", "-------------- -- Post rebuttal Reading the other reviews and the rebuttalhas consolidated my views on the qualty and significance of this paper.", "I highly encourage the authors to incorporate the suggestions pointed out in the reviews and subseqently addressed in the rebuttal in particular the connection to Bayesian optimisation and clarifying why ES and EI share the same issues as GP-UCB.", "Great work!"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_532_1", "importance": 1, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_55_2", "review_text": "The paper proposes a Contrastive Explanation Method (CEM) with the goal of justifying, or explaining, the decisions made by deep neural networks. A notable characteristic of the proposed method is that for every class of interest it aims at identifying two sets of features that can be used to jutify the decisions related to a given class. The first type, pertinent positives (PN), are features whose occurrence are the minimum necessary to justify the classification prediction.  The second type, pertinent negatives (PN) are features whose absence is necessary to justify the prediction of a given class. Given an input image, explanations are given by extending the output by highlighting these two types of features.    Experiments on the MNIST [38], ABIDE-I [11] and a preocurement fraud dataset [9] show the performance of the proposed method.  ===================  Overall the content of the manuscript is sound, clear and easy to follow.  I find valuable the fact that the evaluation includes experiments datasets on multiples data modalities, i.e. visual data (Sec. 4.1 and 4.3) and text-based data (Sec. 4.2). In addition, this seems to be one of the first works focusing  explictly on the identification of pertinent negatives.  In addition, there seems to be code available in the supplementary material. If the plan is to release code to run the proposed method, this could be good for reproducibility of the presented results.  Having said this, my concerns with the manuscript are the following:   Even when I find novel the fact that the proposed method is explictly designed to identify and indicate PN features, this is not the first work to highlight this type of negative feature. Examples of existing works include Samek et al., 2017 and more recently, Oramas et al. arXiv:1712.06302, which as part of their generated output provided some explanations supporting the absence of specific features. I consider positioning with respect to these works a must in order to effectively highlight the novelty brought by the proposed method.  In Section 3, it is stated that the proposed method aims at identify the features that could serve as PPs and PNs for model explanation.  However, in several of the figures/Tables displaying the explanations of the proposed method just one output of each type of feature (PP or PN) is given. To these outputs already highlight more than one feature of each type? if yes, how can we distinguish between the different features highlighted within a type.  if not, an multiple outputs are posible, what is the criterion to select which features to highlight as part of the output?  In Section 3 it is mentioned the need for an autoencoder (AE). DUring the evaluation, this autoencoder is only employed in 2/3 of the conducted experiments. At this point it is not clear to me when this autoencoder is necessary or not. Is there a principled means to verify whether this autoencoder is necessary?  Experiments are conducted on relatively simple and small datasets. Moreover, the Procurement Fraud dataset used in Section 4.2 does not seem to be public. If this is indeed the case, this would limit future comparisons with respect to this work.  In addition, while the manuscript stresses in the abstract the black box characteristic of deep neural networks (DNNs), the tested architectures are relatively simple and shallow. Therefore the potential of the proposed method is unclear in more complex scenarios. For the case of DNNs for visual data, I would suggest evaluating on one of the standard architectures, e.g. alexnet, VGG, ResNet, etc., for which pre-trained models can be found online. Results on one of this deeper more complex settings will strengthen the potential of the proposed method.  Finally, the presented results are mostly qualitative.  In this regard I would suggest performing a either: a) an occlussion analysis(Zeiler et al., ECCV 2014, Samek et al., 2017) , b) a pointing experiment (Zhang et al., ECCV 2016) or, c) a measurement of explanation accuracy by feature coverage (Oramas et al. arXiv:1712.06302).  Any of these protocols should allow to quantitatively evaluate the relevance of the features highlighted by the proposed as part of the explanation. In addition, I find the set of provided qualitative examples quite reduced. In this regard, I encourage the authors to update the supplementary material in order to show extended qualitative results of the explanations produced by their method.  I would appreciate if my concerns are addressed in the rebuttal.   ========================== Full references ==========================    Jose Oramas, Kaili Wang, Tinne Tuytelaars \"Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks\" (2017), arXiv:1712.06302.  Wojciech Samek, Alexander Binder, Gr\u00c3\u00a9goire Montavon, Sebastian Lapuschkin, and Klaus-Robert M\u00c3\u00bcller: \"Evaluating the Visualization of What a Deep Neural Network has Learned\" IEEE Transactions on Neural Networks and Learning Systems, 28(11):2660-2673, 2017  Matthew D. Zeiler and Rob Fergus.  \"Visualizing and understanding convolutional networks\" ECCV, 2014.  Jianming Zhang, Zhe Lin, Jonathan Brandt, Xiaohui Shen, Stan Sclaroff \"Top-down Neural Attention by Excitation Backprop\" ECCV 2016.    ======================================== Post Rebuttal Update ========================================  I thank the authors for their rebuttal. The provided rebuttal satisfied to some extent most of the points I raised on my review.  I share the R1's view that the proposed idea is interesting. Though, I do not consider the fact of highlighting features that will produce a negative effect that novel. Indeed, most current work in interpretable machine learning (e.g. Selvaraju et al., arXiv:1610.02391,  Chattopadhay et al., WACV'18, Reddy et al., arXiv:1708.06670 ) only highlights features that are present in the instance. However, highlighting other, potentially conflicting, features related to other classes will mostly require generating such visualizations for other non-max classes with high score for the instance being explained.  I share the concerns of R1 on that the evaluation aspect could be improved. Currently, results are reported mostly on a  qualitative fashion. While some deterministic behavior is expected when giving the PPs and PNs as part of the input to the neural network, the identification of these PPs and PNs is not perfect. I still would like to see empirical (quantitative) evidence of to what these elements satisfy that expected behavior.  Moreover, for the case of the MNIST experiment, the rebuttal (responding to R1) states that there is no widely accepted quantitative analysis for measuring explanations on visual datasets. Indeed, there is no unique metric for this yet. However, as I stated on my review, there are several evaluation methods that have been proposed and can help position the proposed method appropriately.   At this point, the rebuttal does not change my initial opinion of the manuscript. I still consider the manuscript a good paper and a good match for NIPS.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_55_2", "importance": 1, "reproducibility": 1, "constructiveness": 4, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 5.0, "tokenized_review_text": ["The paper proposes a Contrastive Explanation Method (CEM) with the goalof justifying, or explaining, the decisions made by deep neuralnetworks.", "A notable characteristic of the proposed method is that for every class of interest it aims at identifying two sets of features that can be used to jutify the decisions related to a given class.", "The first type, pertinent positives (PN), are features whose occurrence are the minimum necessary to justify the classification prediction.", "The secnd type, pertinent negatives (PN) are features whose absence is necessary to justify the prediction of a given class.", "Given an input image, explanations are given by extending the output by highlighting these two types of features.", "Experiments on the MNIST [38], ABIDE-I [11] and a preocurement fraud dataset [9] show the performance of the proposed method.", "=================== Overal the content of the manuscript is sound, clear and easy to follow.", "I find valable the fact that the evalation includes experiments datasets on multiples data modalties, i e visualdata (sec 4 1 and 4 3) and text-based data (sec 4 2).", "In addition, this seems to be one of the first works focusing explictly on the identification of pertinent negatives.", "In addition, there seems to be code available in the supplementary material If the plan is to release code to run the proposed method, this could be good for reproducibility of the presented results.", "Having said this, my concerns with the manuscript are the following: Even when I find novel the fact that the proposed method is explictly designed to identify and indicate PN features, this is not the first work to highlight this type of negative feature.", "Examples of existing works include Samek et al, 2017 and more recently, Oramas et al arXiv:1712.06302, which as part of their generated output provided some explanations supporting the absence of specific features.", "I consider positioning with respect to these works a must in order to effectively highlight the novelty brought by the proposed method.", "In secion 3, it is stated that the proposed method aims at identify the features that could serve as PPs and PNs for model explanation.", "However, in severalof the figres/Tables displaying the explanations of the proposed method just one output of each type of feature (PP or PN) is given.", "To these outputs aleady highlight more than one feature of each type?", "if yes, how can we distinguish between the different features highlighted within a type.", "if not, an multiple outputs are posible, what is the criterion to select which features to highlight as part of the output?", "In secion 3 it is mentioned the need for an autoencoder (AE).", "DUring the evalation, this autoencoder is only employed in 2/3 of the conducted experiments.", "At this point it is not clear to me when this autoencoder is necessary or not.", "Is there a principled means to verify whether this autoencoder is necessary?", "Experiments are conducted on relatively simple and smal datasets.", "Moreover, the Procurement Fraud dataset used in secion 4 2 does not seem to be public.", "If this is indeed the case, this would limit future comparisons with respect to this work.", "In addition, while the manuscript stresses in the abstract the black box characteristic of deep neuralnetworks (DNNs), the tested architectures are relatively simple and shalow.", "Therefore the potentialof the proposed method is unclear in more complex scenarios.", "For the case of DNNs for visualdata, I would suggest evalating on one of the standard architectures, e g alxnet, VGG, ResNet, etc, for which pre-trained models can be found online.", "Results on one of this deeper more complex settings will strengthen the potentialof the proposed method.", "Finaly, the presented results are mostly qualtative.", "In this regard I would suggest performing a either: a) an occlussion analsis(Zeiler et al, ECCV 2014, Samek et al, 2017) , b) a pointing experiment (Zhang et al, ECCV 2016) or, c) a measurement of explanation accuracy by feature coverage (Oramas et al arXiv:1712.06302).", "Any of these protocols should alow to quantitatively evalate the relevance of the features highlighted by the proposed as part of the explanation.", "In addition, I find the set of provided qualtative examples quite reduced.", "In this regard, I encourage the authors to update the supplementary materialin order to show extended qualtative results of the explanations produced by their method.", "I would appreciate if my concerns are addressed in the rebuttal ========================== Full references ========================== Jose Oramas, Kaili Wang, Tinne Tuytelaars \"VisualExplanation by Interpretation: Improving VisualFeedback Capabilities of Deep NeuralNetworks\" (2017), arXiv:1712.06302, Wojciech Samek, Alexander Binder, Gr\u00c3\u00a9goire Montavon, Sebastian Lapuschkin, and Klaus-Robert M\u00c3\u00bcller: \"Evalating the Visualzation of What a Deep NeuralNetwork has Learned\" IEEE Transactions on NeuralNetworks and Learning Systems, 28(11):2660-2673, 2017 Matthew D Zeiler and Rob Fergus.", "\"Visualzing and understanding convolutionalnetworks\" ECCV, 2014, Jianming Zhang, Zhe Lin, Jonathan Brandt, Xiaohui Shen, Stan Sclaroff \"Top-down NeuralAttention by Excitation Backprop\" ECCV 2016, ======================================== Post RebuttalUpdate ======================================== I thank the authors for their rebuttal The provided rebuttalsatisfied to some extent most of the points I raised on my review.", "I share the R1's view that the proposed idea is interesting.", "Though, I do not consider the fact of highlighting features that will produce a negative effect that novel.", "Indeed, most current work in interpretable machine learning (e g Selvaraju et al, arXiv:1610.02391, Chattopadhay et al, WACV'18, Reddy et al, arXiv:1708.06670 ) only highlights features that are present in the instance.", "However, highlighting other, potentialy conflicting, features related to other classes will mostly reqire generating such visualzations for other non-max classes with high score for the instance being explained.", "I share the concerns of R1 on that the evalation aspect could be improved.", "Currently, results are reported mostly on a qualtative fashion.", "While some deterministic behavior is expected when giving the PPs and PNs as part of the input to the neuralnetwork, the identification of these PPs and PNs is not perfect.", "I still would like to see empirical(quantitative) evidence of to what these elements satisfy that expected behavior.", "Moreover, for the case of the MNIST experiment, the rebuttal(responding to R1) states that there is no widely accepted quantitative analsis for measuring explanations on visualdatasets.", "Indeed, there is no unique metric for this yet.", "However, as I stated on my review, there are severalevalation methods that have been proposed and can help position the proposed method appropriately.", "At this point, the rebuttaldoes not change my initialopinion of the manuscript.", "I still consider the manuscript a good paper and a good match for NIPS."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_55_2", "importance": 1, "reproducibility": 1, "constructiveness": 4, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_437_1", "review_text": "Update:  Thanks for your response. I'm glad to hear that you are going to open source the optimizations; I look forward to playing with this. Best of luck with the follow-up work, and I look forward to seeing how the RCRN performs on SNLI in the cross-attention task setting (really hoping to see this in the camera-ready!).  Original Review:  The core idea behind this paper is to use RNNs (LSTMs or GRUs in this work) to compute the gates (input, forget, etc.) for a higher level RNN. They use this idea to show how to improve performance on a large number of tasks (mostly classification) with relatively simple models that have little to no loss in efficiency compared to models that perform similarly. Some of the performances achieved new state-of-the-art results. When implemented well, they can even be faster despite the apparent addition of complexity.   The setup as controller and listener cells seems unnecessarily confusing. It seems clearer to describe this as a collection of three RNNs, two that compute gates for the state produced by the third. If it was presented that way, then it would be clearer that Eq. 15 and 16 are really the meat of the RCRN. The first 14 equations are really just normal (or bidirectional adaptations of normal) RNN equations (7-9 are nice to see for clarity). I understand that it can be helpful to write out all of those equations some times, but I would recommend defining an RNN cell once, and then focus on describing how you use the three different states, rather than duplicating the same equations 2 times in Eq. 1-6 and then again in 10-14. On my first read, I found myself looking for potential difference in all those equations because I assumed they were written out so explicitly for that reason.  In equations 1-3, not sure if it is a typo, but either way: it would be clearer if the W_i, W_f, and W_o used to get i_t^2, f_t^2, and o_t^2 respectively had a numerical superscript like the other matrices. It sounds like it would be a 2, but without the superscript it kind of feels like a typo since all the other matrices have superscripts. U_i^1 is also used for i_t^2, but it seems like that should be U_i^2 instead. Would like a little clarification or a note if these aren\u00e2\u0080\u0099t typos clarifying that some of the weights are indeed shared.  Why not run on SQuAD? That is a pretty standard QA dataset now, so much so that its absence makes me wonder whether that was a failure case for RCRNs. It would be great if you could assuage that concern for future readers. I could almost say the same for MultiNLI over SNLI now as well, but I understand that both of these have external testing systems that can make using them difficult some times.  Why do you only compare with models that do not use semi-supervised learning on external corpora? If you are using CoVe, which is using supervised learning on external corpora and GloVe, then it might seem a bit arbitrary to rule out semi-supervised augmentations in those tables. I think the claims are still effective for RCRN because the BiLSTM and 3l-BiLSTM also use CoVe, POS embeddings, etc.  What exactly does CUDA optimized mean? How hard would these be to make on your own? Or will you be open sourcing these essential optimizations or even better building into something like PyTorch or Tensorflow? If you want maximum impact, definitely help people get that super fast CUDA optimized version. If that existed open source, I would definitely start trying it out.  I\u00e2\u0080\u0099m not convinced about the claim that this is different than \u00e2\u0080\u0098going deeper\u00e2\u0080\u0099. This just seems like a different (apparently smarter/better) way of going deeper than by just stacking RNNs as layers.  I wonder whether you could just use a single RNN cell as the Controller and do a simpler transformation of that state to get the different gate values. Perhaps this could be even faster?  Can we have RCRNs controlling RCRNs?  Character level embeddings are using a BiGRU model; is this better than using pertained character embeddings?  Lots of the true SOTA models for entailment do use sentence cross attention, and you chose not to. Why? How do the RCRN\u00e2\u0080\u0099s purported benefits stand up when attention is in the mix for entailment? Or perhaps the Highway networks are particularly important and you don\u00e2\u0080\u0099t get any benefit from the RCRN without them?   It seems insane at first glance that your 3L-BiLSTM is as good as all those other more complex models even without the RCRN. Is that coming from the GRU character embeddings or the POS embeddings or the CoVe embeddings? Embeddings are just really that important it seems, and as we\u00e2\u0080\u0099ve created better representations, simple BILSTMs and stacked versions are getting better.\u00e2\u0080\u00a8  Overall is a 7, with a confidence of 4.  I'm reserving very confident for reproducibility of systems that have been declared as being open source in the future. This submission includes a lot of detail, but it seems unlikely that everyone who wants to use this work will implement those custom CUDA ops themselves. The RCRN seems simple enough to reproduce, but at the speeds presented, it seems potentially difficult. ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_437_1", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["Update: Thanks for your response.", "I'm glad to hear that you are going to open source the optimizations; I look forward to playing with this.", "Best of luck with the follow-up work, and I look forward to seeing how the RCRN performs on SNLI in the cross-attention task setting (realy hoping to see this in the camera-ready!).", "OriginalReview: The core idea behind this paper is to use RNNs (LSTMs or GRUs in this work) to compute the gates (input, forget, etc) for a higher level RNN.", "They use this idea to show how to improve performance on a large number of tasks (mostly classification) with relatively simple models that have little to no loss in efficiency compared to models that perform similarly.", "Some of the performances achieved new state-of-the-art results.", "When implemented well, they can even be faster despite the apparent addition of complexity.", "The setup as controller and listener cells seems unnecessarily confusing.", "It seems clearer to describe this as a collection of three RNNs, two that compute gates for the state produced by the third.", "If it was presented that way, then it would be clearer that eq 15 and 16 are realy the meat of the RCRN.", "The first 14 eqations are realy just normal(or bidirectionaladaptations of normal RNN eqations (7-9 are nice to see for clarity).", "I understand that it can be helpful to write out al of those eqations some times, but I would recommend defining an RNN cell once, and then focus on describing how you use the three different states, rather than duplicating the same eqations 2 times in eq 1-6 and then again in 10-14, On my first read, I found myself looking for potentialdifference in al those eqations because I assumed they were written out so explicitly for that reason.", "In eqations 1-3, not sure if it is a typo, but either way: it would be clearer if the W_i, W_f, and W_o used to get i_t^2, f_t^2, and o_t^2 respectively had a numericalsuperscript like the other matrices.", "It sounds like it would be a 2, but without the superscript it kind of feels like a typo since al the other matrices have superscripts.", "U_i^1 is alo used for i_t^2, but it seems like that should be U_i^2 instead.", "Would like a little clarification or a note if these aren\u00e2\u0080\u0099t typos clarifying that some of the weights are indeed shared.", "Why not run on SQuAD?", "That is a pretty standard QA dataset now, so much so that its absence makes me wonder whether that was a failure case for RCRNs.", "It would be great if you could assuage that concern for future readers.", "I could alost say the same for MultiNLI over SNLI now as well, but I understand that both of these have externaltesting systems that can make using them difficult some times.", "Why do you only compare with models that do not use semi-supervised learning on externalcorpora?", "If you are using CoVe, which is using supervised learning on externalcorpora and GloVe, then it might seem a bit arbitrary to rule out semi-supervised augmentations in those tables.", "I think the claims are still effective for RCRN because the BiLSTM and 3l-BiLSTM alo use CoVe, POS embeddings, etc What exactly does CUDA optimized mean?", "How hard would these be to make on your own?", "Or will you be open sourcing these essentialoptimizations or even better building into something like PyTorch or Tensorflow?", "If you want maximum impact, definitely help people get that super fast CUDA optimized version.", "If that existed open source, I would definitely start trying it out.", "I\u00e2\u0080\u0099m not convinced about the claim that this is different than \u00e2\u0080\u0098going deeper\u00e2\u0080\u0099.", "This just seems like a different (apparently smarter/better) way of going deeper than by just stacking RNNs as layers.", "I wonder whether you could just use a single RNN cell as the Controller and do a simpler transformation of that state to get the different gate vales.", "Perhaps this could be even faster?", "Can we have RCRNs controlling RCRNs?", "Character level embeddings are using a BiGRU model; is this better than using pertained character embeddings?", "Lots of the true SOTA models for entailment do use sentence cross attention, and you chose not to.", "Why?", "How do the RCRN\u00e2\u0080\u0099s purported benefits stand up when attention is in the mix for entailment?", "Or perhaps the Highway networks are particularly important and you don\u00e2\u0080\u0099t get any benefit from the RCRN without them?", "It seems insane at first glance that your 3L-BiLSTM is as good as al those other more complex models even without the RCRN.", "Is that coming from the GRU character embeddings or the POS embeddings or the CoVe embeddings?", "Embeddings are just realy that important it seems, and as we\u00e2\u0080\u0099ve created better representations, simple BILSTMs and stacked versions are getting better.\u00e2\u0080\u00a8 Overal is a 7, with a confidence of 4, I'm reserving very confident for reproducibility of systems that have been declared as being open source in the future.", "This submission includes a lot of detail, but it seems unlikely that everyone who wants to use this work will implement those custom CUDA ops themselves.", "The RCRN seems simple enough to reproduce, but at the speeds presented, it seems potentialy difficult."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_437_1", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_402_4", "review_text": "[Updates]  After reading the author's response, I think my concerns about the existence of minima has been partly, but not completely addressed. In the begging of the response a proof for the existence of a global minima is provided. However, an important distinction has been ignored. The author wrote that \"By assumption 2, there exists \u00ce\u00b8* such that f(\u00c2\u00b7; \u00ce\u00b8*) achieves zero training error\". However, the existence a parameter for which all the data can be correctly classified (Assumption 2) is not the same as having a parameter for which the loss function is zero. That is precisely how the counterexample I provided works. Of course, the author could avoid this problem by modifying Assumption 2 to \"there exists a parameter for which the loss function is zero\", or by adding one assumption stating that $f$ can be rescaled as they did in the response, which I believe they should.   Another thing I'm very interested in is how difficult is to find a local minima of the modified network. If I understand correctly, after adding the neuron, each stationary point in the previous network becomes a corresponding saddle point (if one just keep the added neuron inactive) in the modified network (except for the global minima). How does such a loss landscape affect the optimization process? Is it computationally efficient to actually find the minima? How well does the minima generalize? It would be more convincing if the authors can provide some numerical experiments.  Overall I believe this is a very good paper, and should be accepted. I've changed my overall score to 7.   [Summary of the paper]  This paper presents a rather surprising theoretical result for the loss surface of binary classification models. It is shown that under mild assumptions, if one adds a specific type of neuron with skip connection to a binary classification model, as well as a quadratic regularization term to the loss function, then every local minima on the loss surface is also a global minima. The result is surprising because virtually no assumptions have been made about the classification model itself, other than that the dataset is realizable by the model (namely, there exists a parameter under which the model can classify all samples in the dataset correctly), hence the result is applicable to many models. The paper also provides some extensions to their main result.  [Quality]  I have concerns about the main result of the paper:  -- In section 3.2, the authors add the output of an exponential neuron to the output of the network, namely, the new architecture $\\tilde{f}$ is defined by  $\\tilde{f}(x, \\theta) = f(x, \\theta) + a \\exp (w^T x + b)$  Note that the added term has an invariance in its parameters, namely, if one perform the following transformation:  $a^\\prime = a / C, b^\\prime = b + \\log C$  then the model will stay exactly the same, i.e., $a^\\prime \\exp (w^T x + b^\\prime) = a \\exp (w^T x + b)$ holds for any input $x$.   Now, consider the loss function $\\tilde{L}_n(\\theta, a/C, w, b + \\log C)$. Because there is also a regularization term for $a$, by the invariance argument above we can see that $\\tilde{L}_n(\\theta, a/C, w, b + \\log C)$ decreases monotonically as $C$ increases (assuming $a \\neq 0$). But as $C$ increases, $b$ is pushed to infinitely faraway. This argument naturally leads to the following concern: Theorem 1 is stated as \"if there is a local minima for $\\tilde{L}_n, then it is a global minima\", but how does one ensure that $\\tilde{L}_n$ actually has a local minima at all?   To further illustrate my point, consider the following very simple example I constructed. Suppose $f(x, \\theta) = 1$, i.e., the model always output 1. Suppose we only have one sample in the dataset, $(x, y) = (0, 1)$. Note that the realizability assumption (Assumption 2) is satisfied. Let the loss function be $l(z) = \\max(0, 2 + z)^3$, so that Assumption 1 is satisfied. Finally let $\\lambda = 2$. Now, we have   $\\tilde{L}_n = \\max(0, 1 - a \\exp(b))^3 + a^2$  One can immediately see that this function has no local minima. To see this, note that when $a = 0$, we have $\\tilde{L}_n = 1$; on the other hand, let $a = t$ for some $t > 0$, and $b = - \\log t$, and we have $L_n -> 0$ as $t -> 0$, but this would also make $b -> +\\infty$. Hence the function has no global minima, and by Theorem 1 it cannot have any local minima.   While this observation does not mean Theorem 1 is wrong (because theorem 1 assumes the existence of a local minima), it does limit the scope of Theorem 1 in the case where local minimas do not exist.   [Clarity]  The paper is well written and well organized. The proof sketch is also easy to follow.   [Originality]  To the best of my knowledge, the results presented in the paper are original.   [Significance]  I really like the results presented in this paper. It is quite surprising that by making very simple modifications of the model, one can eliminate bad local minimas, especially given the fact that little assumptions on the model itself are needed. Despite so, I feel that the significance of the results might be slightly less than it appears:  -- As mentioned in the [Quality] part, there are cases where the loss function of the modified model has no local minima at all. In such cases, the theorems in the paper do not apply. It is not clear to me what conditions are needed to guarantee the existence of local minimas. It would be nice if the authors can address this issue.   -- The theorems in the paper do not actually make any assumptions on the model $f$ except that there exist parameters with which $f$ can correctly classify all samples in the dataset. While this makes the results very general, this unfortunately also implies that the paper is not really about loss surface of neural networks, but rather a general way to modify the loss surface that can be applied to any model so long as the realizability assumption is satisfied. The results seem to have nothing to do with neural networks, and hence it does not really add anything to our understanding of the loss surface of neural networks.  The assumptions made in the paper seem reasonable enough to be satisfied in realistic settings. It would be nice if the authors can present some numerical experiments.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_402_4", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 5.0, "tokenized_review_text": ["[Updates] After reading the author's response, I think my concerns about the existence of minima has been partly, but not completely addressed.", "In the begging of the response a proof for the existence of a globalminima is provided.", "However, an important distinction has been ignored.", "The author wrote that \"By assumption 2, there exists \u00ce\u00b8* such that f(\u00c2\u00b7; \u00ce\u00b8*) achieves zero training error\".", "However, the existence a parameter for which al the data can be correctly classified (Assumption 2) is not the same as having a parameter for which the loss function is zero.", "That is precisely how the counterexample I provided works.", "Of course, the author could avoid this problem by modifying Assumption 2 to \"there exists a parameter for which the loss function is zero\", or by adding one assumption stating that $f$ can be rescald as they did in the response, which I believe they should.", "Another thing I'm very interested in is how difficult is to find a localminima of the modified network.", "If I understand correctly, after adding the neuron, each stationary point in the previous network becomes a corresponding saddle point (if one just keep the added neuron inactive) in the modified network (except for the globalminima).", "How does such a loss landscape affect the optimization process?", "Is it computationaly efficient to actualy find the minima?", "How well does the minima generalze?", "It would be more convincing if the authors can provide some numericalexperiments.", "Overal I believe this is a very good paper, and should be accepted.", "I've changed my overal score to 7, [Summary of the paper] This paper presents a rather surprising theoreticalresult for the loss surface of binary classification models.", "It is shown that under mild assumptions, if one adds a specific type of neuron with skip connection to a binary classification model, as well as a quadratic regularization term to the loss function, then every localminima on the loss surface is alo a globalminima.", "The result is surprising because virtualy no assumptions have been made about the classification model itself, other than that the dataset is realzable by the model (namely, there exists a parameter under which the model can classify al samples in the dataset correctly), hence the result is applicable to many models.", "The paper alo provides some extensions to their main result.", "[Qualty] I have concerns about the main result of the paper: -- In secion 3 2, the authors add the output of an exponentialneuron to the output of the network, namely, the new architecture $\\tilde{f}$ is defined by $\\tilde{f}(x, \\theta) = f(x, \\theta) + a \\exp (w^T x + b)$ Note that the added term has an invariance in its parameters, namely, if one perform the following transformation: $a^\\prime = a / C, b^\\prime = b + \\log C$ then the model will stay exactly the same, i e , $a^\\prime \\exp (w^T x + b^\\prime) = a \\exp (w^T x + b)$ holds for any input $x$.", "Now, consider the loss function $\\tilde{L}_n(\\theta, a/C, w, b + \\log C)$.", "Because there is alo a regularization term for $a$, by the invariance argument above we can see that $\\tilde{L}_n(\\theta, a/C, w, b + \\log C)$ decreases monotonicaly as $C$ increases (assuming $a \\neq0$).", "But as $C$ increases, $b$ is pushed to infinitely faraway.", "This argument naturaly leads to the following concern: Theorem 1 is stated as \"if there is a localminima for $\\tilde{L}_n, then it is a globalminima\", but how does one ensure that $\\tilde{L}_n$ actualy has a localminima at al?", "To further illustrate my point, consider the following very simple example I constructed.", "Suppose $f(x, \\theta) = 1$, i e , the model alays output 1, Suppose we only have one sample in the dataset, $(x, y) = (0, 1)$.", "Note that the realzability assumption (Assumption 2) is satisfied.", "Let the loss function be $l(z) = \\max(0, 2 + z)^3$, so that Assumption 1 is satisfied.", "Finaly let $\\lambda = 2$.", "Now, we have $\\tilde{L}_n = \\max(0, 1 - a \\exp(b))^3 + a^2$ One can immediately see that this function has no localminima.", "To see this, note that when $a = 0$, we have $\\tilde{L}_n = 1$; on the other hand, let $a = t$ for some $t > 0$, and $b = - \\log t$, and we have $L_n -> 0$ as $t -> 0$, but this would alo make $b -> +\\infty$.", "Hence the function has no globalminima, and by Theorem 1 it cannot have any localminima.", "While this observation does not mean Theorem 1 is wrong (because theorem 1 assumes the existence of a localminima), it does limit the scope of Theorem 1 in the case where localminimas do not exist.", "[Clarity] The paper is well written and well organized.", "The proof sketc is alo easy to follow.", "[Originalty] To the best of my knowledge, the results presented in the paper are original [Significance] I realy like the results presented in this paper.", "It is quite surprising that by making very simple modifications of the model, one can eliminate bad localminimas, especialy given the fact that little assumptions on the model itself are needed.", "Despite so, I feel that the significance of the results might be slightly less than it appears: -- As mentioned in the [Qualty] part, there are cases where the loss function of the modified model has no localminima at al.", "In such cases, the theorems in the paper do not apply.", "It is not clear to me what conditions are needed to guarantee the existence of localminimas.", "It would be nice if the authors can address this issue.", "-- The theorems in the paper do not actualy make any assumptions on the model $f$ except that there exist parameters with which $f$ can correctly classify al samples in the dataset.", "While this makes the results very general this unfortunately alo implies that the paper is not realy about loss surface of neuralnetworks, but rather a generalway to modify the loss surface that can be applied to any model so long as the realzability assumption is satisfied.", "The results seem to have nothing to do with neuralnetworks, and hence it does not realy add anything to our understanding of the loss surface of neuralnetworks.", "The assumptions made in the paper seem reasonable enough to be satisfied in realstic settings.", "It would be nice if the authors can present some numericalexperiments."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_402_4", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_349_1", "review_text": "This paper presents an algorithm for computing a near-optimal low-rank approximation for a distance matrix \u00e2\u0080\u0094 i.e. a matrix where the (i,j)th entry equals d(p_i, q_j) for some metric d and sets of points p_1, \u00e2\u0080\u00a6, p_m and q_1,\u00e2\u0080\u00a6 q_n. Distance matrices are common in learning and data analysis tasks and low-rank approximation is a ubiquitous approach to compressing matrices.   In general, the fastest existing low-rank approximation algorithms are randomized and, to compute a k-rank approximation, run in O(nnz(A) + min(n,m)*poly(k/eps)) time for a matrix A with nnz(A) non-zeros. Since the second term is often considered lower order (k is typically << n and eps is moderate), these algorithms run in roughly linear time in the size of the input.   Naturally, this is optimal for general matrices \u00e2\u0080\u0094 if I don\u00e2\u0080\u0099t at least read every entry in the matrix, I could miss a very heavy entry that I would need to see to output a good low-rank approximation. However, we could ask if better runtimes are possible for matrices with more structure, like distance matrices. We might hope for algorithms that run in sublinear time. Recent work shows that, surprisingly, sublinear time low-rank approximation algorithms can be obtained for positive semidefinite matrices, another structured class of matrices. This result relies on the fact that it\u00e2\u0080\u0099s not possible to add an arbitrarily heavy element A_i,j to a PSD matrix without increasing the size of either A_i,i or A_j,j. Accordingly, simply reading the diagonal of A (which only takes n time) avoids the trivial lower bounds that apply to general matrices.   The authors begin with the observation that a similar statement is true for distance matrices. By triangle inequality, if A_i,j is very heavy, A_1,i, A_1,j, or A_1,1 must be too. These entries can all be found by reading the first row of A (or really any single row of A_. As in the case of PSD matrices, this property allows us to avoid lower bounds for general matrices.  The authors leverage this observation to motivate their algorithm, which is based on solving the low-rank approximation using a random subsample of the original matrix. In particular, they sample rows/columns by their norms. It is well known that subsampling in this way makes it possible to obtain a low-rank approximation within additive error eps*||A||_F^2 of optimal. For general matrices, computing norms naively takes nnz(A) time. However, the authors show that for distance matrices, norms can be estimated coarsely in sublinear time. They can subsample the matrix using these coarse estimates, and then recurse to shrink the problem size even smaller. In recursing, the authors alternate between row and column sampling.  Overall, this yields an algorithm that runs in (min(N,m)^1+gamma) * poly(k/eps)^1/gamma time for any chosen gamma, which controls the levels of recursion in the algorithm. The authors present a simpler algorithm with just one level of recursion that runs in min(n,m)^1.34 * poly(k/eps) time. The authors implement this algorithm and it turns out to be quite practical, outperforming nnz(A) time random projection methods pretty significantly.   In addition to their main result, the authors include a number of additional results. Of particular interest is a lower bound, which demonstrates that additive ||A||_F^2 error is necessary \u00e2\u0080\u0094 achieving full relative error for the low-rank approximation problem isn\u00e2\u0080\u0099t possible even for distance matrices without at least reading the whole matrix. This places the complexity of low-rank approximation for distances matrices somewhere between standard matrices, where even additive error is not possible in sublinear time, and PSD matrices, where full relative error is possible in sublinear time.  Overall, I think the paper is well written and the techniques are new and interesting. It\u00e2\u0080\u0099s also nice to see that the main algorithm presented is already practical.   One concern with the paper is that I find the proof of the faster (min(N,m)^1+gamma) * poly(k/eps)^1/gamma difficult to follow. In particular, recursive sampling cannot be performed naively because, after sampling and reweighting rows from a distance matrix, you end up with a matrix that is no longer a distance matrix. To deal with this challenge, the authors suggest partitioning sampled rows into \u00e2\u0080\u009cbuckets\u00e2\u0080\u009d based on how much they were reweighed by. The matrix to be recursed on is a valid distance matrix, at least when restricted to rows in one bucket, which allows column norms to be estimated by estimating the norm in each block of rows separately (estimating column norms is need for the next step of reduction).   This makes perfect sense to me for the two step in(n,m)^1.34 * poly(k/eps) time algorithm (Algorithm 3), but I do not understand how the approach works for the faster Algorithm 2. In particular, I don\u00e2\u0080\u0099t see how the argument carries through multiple levels of recursion without blowing up the number of buckets and, for whatever reason, Algorithm 2 does not include the reweighing step in its pseudocode! I would encourage the authors to add it in explicitly. If this makes the algorithm much more difficult to present, I would encourage the authors to present the simpler, but still interesting Algorithm 3 in the main part of their paper, and to give a full and rigorous development of Algorithm 2 in the appendix.  ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_349_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper presents an alorithm for computing a near-optimallow-rank approximation for a distance matrix \u00e2\u0080\u0094 i e a matrix where the (i,j)th entry eqal d(p_i, q_j) for some metric d and sets of points p_1, \u00e2\u0080\u00a6, p_m and q_1,\u00e2\u0080\u00a6 q_n.", "Distance matrices are common in learning and data analsis tasks and low-rank approximation is a ubiquitous approach to compressing matrices.", "In general the fastest existing low-rank approximation alorithms are randomized and, to compute a k-rank approximation, run in O(nnz(A) + min(n,m)*poly(k/eps)) time for a matrix A with nnz(A) non-zeros.", "Since the secnd term is often considered lower order (k is typicaly << n and eps is moderate), these alorithms run in roughly linear time in the size of the input.", "Naturaly, this is optimalfor generalmatrices \u00e2\u0080\u0094 if I don\u00e2\u0080\u0099t at least read every entry in the matrix, I could miss a very heavy entry that I would need to see to output a good low-rank approximation.", "However, we could ask if better runtimes are possible for matrices with more structure, like distance matrices.", "We might hope for alorithms that run in sublinear time.", "Recent work shows that, surprisingly, sublinear time low-rank approximation alorithms can be obtained for positive semidefinite matrices, another structured class of matrices.", "This result relies on the fact that it\u00e2\u0080\u0099s not possible to add an arbitrarily heavy element A_i,j to a PSD matrix without increasing the size of either A_i,i or A_j,j Accordingly, simply reading the diagonalof A (which only takes n time) avoids the triviallower bounds that apply to generalmatrices.", "The authors begin with the observation that a similar statement is true for distance matrices.", "By triangle ineqalty, if A_i,j is very heavy, A_1,i, A_1,j, or A_1,1 must be too.", "These entries can al be found by reading the first row of A (or realy any single row of A_.", "As in the case of PSD matrices, this property alows us to avoid lower bounds for generalmatrices.", "The authors leverage this observation to motivate their alorithm, which is based on solving the low-rank approximation using a random subsample of the originalmatrix.", "In particular, they sample rows/columns by their norms.", "It is well known that subsampling in this way makes it possible to obtain a low-rank approximation within additive error eps*||A||_F^2 of optimal For generalmatrices, computing norms naively takes nnz(A) time.", "However, the authors show that for distance matrices, norms can be estimated coarsely in sublinear time.", "They can subsample the matrix using these coarse estimates, and then recurse to shrink the problem size even smaler.", "In recursing, the authors alernate between row and column sampling.", "Overal, this yields an alorithm that runs in (min(N,m)^1+gamma) * poly(k/eps)^1/gamma time for any chosen gamma, which controls the levels of recursion in the alorithm.", "The authors present a simpler alorithm with just one level of recursion that runs in min(n,m)^1 34 * poly(k/eps) time.", "The authors implement this alorithm and it turns out to be quite practical outperforming nnz(A) time random projection methods pretty significantly.", "In addition to their main result, the authors include a number of additionalresults.", "Of particular interest is a lower bound, which demonstrates that additive ||A||_F^2 error is necessary \u00e2\u0080\u0094 achieving full relative error for the low-rank approximation problem isn\u00e2\u0080\u0099t possible even for distance matrices without at least reading the whole matrix.", "This places the complexity of low-rank approximation for distances matrices somewhere between standard matrices, where even additive error is not possible in sublinear time, and PSD matrices, where full relative error is possible in sublinear time.", "Overal, I think the paper is well written and the techniques are new and interesting.", "It\u00e2\u0080\u0099s alo nice to see that the main alorithm presented is aleady practical One concern with the paper is that I find the proof of the faster (min(N,m)^1+gamma) * poly(k/eps)^1/gamma difficult to follow.", "In particular, recursive sampling cannot be performed naively because, after sampling and reweighting rows from a distance matrix, you end up with a matrix that is no longer a distance matrix.", "To dealwith this chalenge, the authors suggest partitioning sampled rows into \u00e2\u0080\u009cbuckets\u00e2\u0080\u009d based on how much they were reweighed by.", "The matrix to be recursed on is a vald distance matrix, at least when restricted to rows in one bucket, which alows column norms to be estimated by estimating the norm in each block of rows separately (estimating column norms is need for the next step of reduction).", "This makes perfect sense to me for the two step in(n,m)^1 34 * poly(k/eps) time alorithm (Algorithm 3), but I do not understand how the approach works for the faster Algorithm 2, In particular, I don\u00e2\u0080\u0099t see how the argument carries through multiple levels of recursion without blowing up the number of buckets and, for whatever reason, Algorithm 2 does not include the reweighing step in its pseudocode!", "I would encourage the authors to add it in explicitly.", "If this makes the alorithm much more difficult to present, I would encourage the authors to present the simpler, but still interesting Algorithm 3 in the main part of their paper, and to give a full and rigorous development of Algorithm 2 in the appendix."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_349_1", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_325_1", "review_text": "=== Update after author rebuttal === Thanks to the authors for their rebuttal. I have updated my score. One comment about the fully coupled GLM: since the validation data was taken from a specific portion of the experiment (minutes 45-46), then temporal non-stationarities in the data (e.g. changes in arousal state, adaptation, etc.) will make it harder to generalize. Instead, I would recommend that the authors hold out brief snippets of data throughout the experiment to use for validation and testing.  === Summary === This paper develops a method for scalable inference methods for Poisson generalized linear models (GLMs). These are particularly prevalent in the neuroscience literature. The authors use the polynomial approximate sufficient statistics (PASS-GLM) method to perform approximate Bayesian inference in these models. They apply this method to two neuroscience datasets: modeling primate retinal ganglion cell responses to white noise (here, the authors validate the approximate methods using exact inference) as well as a dataset of spontaneous activity recorded across brain regions in the mouse.  === Review ===  -- Clarity -- The paper is clear and well written. In particular, I appreciated the thorough background section, especially the comparison with the MELE.  -- Originality -- While the applications in neuroscience are new, much of the methods in this paper are directly taken from the PASS-GLM paper. At times, I found it hard to distinguish what (if any) of the method was new, versus deriving the PASS-GLM method for Poisson GLMs specifically.  Note that although the experiments in the PASS-GLM paper focus on logistic regression, that paper makes it clear that the method is appropriate for any model in the GLM family, including Poisson regression.  Therefore, it seems like much of the novelty of this paper is in the applications (specifically, the application to the large neuropixels dataset recorded across multiple mouse brain regions). Unfortunately, this occupies a small fraction of the overall paper.  -- Significance -- In this paper, the authors state (in the introduction) that their contributions are: (a) deriving the expressions for the MLE, MAP, and approximate posterior of a Poisson GLM using the PASS-GLM method, (b) validate the estimators on simulated data and retinal data, (c) introduce two novel extensions of the method, an analytic marginalization when using quadratic approximations and an adaptive procedure for selecting the interval of the polynomial approximation, and (d) apply these methods to study a large dataset recorded across multiple brain regions.  Given that most of the method is derived from the ideas in the PASS-GLM paper, I think (a) and (b) are less significant results.  Moreover, it is hard to judge the significance of the extensions to the method (c). For example, the authors did not report compare their results on using the adaptive intervals in section 4.2 to using fixed intervals, instead simply stating that they \"find that this procedure provides large improvements\" (line 185). Large improvements for which application? Simulated data? Retinal data? Mouse data? If the authors had a figure demonstrating this large improvement on real datasets with the adaptive interval, that would greatly increase the significance of this particular contribution.  Finally, while the application to mouse data (d) is certainly novel, it is equally hard to assess the significance of these findings. Namely, I think the authors should explicitly answer the following question: what scientific question would neuroscientists be able to answer with the approximate inference Poisson GLM that they could not answer otherwise? For example, am I unable to fit the GLM to the dataset using current techniques? Will it just take longer? How much longer? I would appreciate if there was a rough sense of how long it would take to do the exact GLM given N neurons and T time bins, compared to the approximate version.  This presupposed that I even want to fit a massive GLM. The application to the mouse dataset, to me, suggests that this might not be the best idea, as I was quite surprised at how much the GLM overfit to the dataset. The authors report that the model outperforms a homogenous GLM on only 65% of the neurons. Does this mean that the model is strongly overfitting? Shouldn't the hyperparameter search for the regularization parameters have dealt with this? Where was the 1 minute of held out data taken from (randomly throughout the recording, or at the beginning or end?). What if the authors did not fit coupling parameters between all neurons, instead fitting separate GLMs to each area? In that case, are there significant differences in predictive power? What if the full model was uncoupled (only spike history filters)? Also, I would have appreciated more interpretation of the model filters and coupling strengths presented in Fig 4d and 4c. Do these tell us something we did not already know? Do they look significantly different if I took subsets of neurons or data (such that I could do exact inference)?  I can appreciate if the authors' goal was to demonstrate that the approximate GLM works on large datasets, rather than analyze this particular GLM model fit, but it is hard to make sense of the significance of being able to fit a large GLM without more exploration of these details.  === General comments === This paper does a good job of taking a method recently published in the machine learning community (PASS-GLM) and shows how it may be relevant for neuroscience applications.  What I found most difficult about this work is that it is hard to tell which audience this is best suited for. I does not seem like the work is really about novel extensions to PASS-GLM that would be of interest to the machine learning community. Instead, it seems to target those in the neuroscience community who would be interested in building large scale GLMs of their data. However, for a neuroscientist, interested in applications, I think it is difficult to work through the derivations in sections 3 and 4 without a clear understanding of what the approximate GLM buys you, beyond being able to fit a GLM to a large recording (and it is unclear what that buys you in terms of new scientific understanding).  I think the paper could be improved by focusing more on applications to neural datasets, with more rigorous comparisons for the new ideas presented in this paper, as well as clear statements about what the approximate GLM buys you in terms of being able to ask new scientific questions.  The derivation of the approximate Poisson GLM (section 3), while valuable for those interested in applying the method, is harder to slog through when it is unclear what the method buys you (speaking as a neuroscientist). Perhaps focusing on applications and gains over previous methods first, and using that to motivate the derivation, would be more worthwhile for the community.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_325_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["=== Update after author rebuttal=== Thanks to the authors for their rebuttal I have updated my score.", "One comment about the fully coupled GLM: since the valdation data was taken from a specific portion of the experiment (minutes 45-46), then temporalnon-stationarities in the data (e g changes in arousalstate, adaptation, etc) will make it harder to generalze.", "Instead, I would recommend that the authors hold out brief snippets of data throughout the experiment to use for valdation and testing.", "=== Summary === This paper develops a method for scalble inference methods for Poisson generalzed linear models (GLMs).", "These are particularly prevalnt in the neuroscience literature.", "The authors use the polynomialapproximate sufficient statistics (PASS-GLM) method to perform approximate Bayesian inference in these models.", "They apply this method to two neuroscience datasets: modeling primate retinalganglion cell responses to white noise (here, the authors valdate the approximate methods using exact inference) as well as a dataset of spontaneous activity recorded across brain regions in the mouse.", "=== Review === -- Clarity -- The paper is clear and well written.", "In particular, I appreciated the thorough background secion, especialy the comparison with the MELE.", "-- Originalty -- While the applications in neuroscience are new, much of the methods in this paper are directly taken from the PASS-GLM paper.", "At times, I found it hard to distinguish what (if any) of the method was new, versus deriving the PASS-GLM method for Poisson GLMs specificaly.", "Note that alhough the experiments in the PASS-GLM paper focus on logistic regression, that paper makes it clear that the method is appropriate for any model in the GLM family, including Poisson regression.", "Therefore, it seems like much of the novelty of this paper is in the applications (specificaly, the application to the large neuropixels dataset recorded across multiple mouse brain regions).", "Unfortunately, this occupies a smal fraction of the overal paper.", "-- Significance -- In this paper, the authors state (in the introduction) that their contributions are: (a) deriving the expressions for the MLE, MAP, and approximate posterior of a Poisson GLM using the PASS-GLM method, (b) valdate the estimators on simulated data and retinaldata, (c) introduce two novel extensions of the method, an analtic marginalzation when using quadratic approximations and an adaptive procedure for selecting the intervalof the polynomialapproximation, and (d) apply these methods to study a large dataset recorded across multiple brain regions.", "Given that most of the method is derived from the ideas in the PASS-GLM paper, I think (a) and (b) are less significant results.", "Moreover, it is hard to judge the significance of the extensions to the method (c).", "For example, the authors did not report compare their results on using the adaptive interval in secion 4 2 to using fixed interval, instead simply stating that they \"find that this procedure provides large improvements\" (line 185).", "Large improvements for which application?", "Simulated data?", "Retinaldata?", "Mouse data?", "If the authors had a figre demonstrating this large improvement on realdatasets with the adaptive interval that would greatly increase the significance of this particular contribution.", "Finaly, while the application to mouse data (d) is certainly novel, it is eqaly hard to assess the significance of these findings.", "Namely, I think the authors should explicitly answer the following question: what scientific question would neuroscientists be able to answer with the approximate inference Poisson GLM that they could not answer otherwise?", "For example, am I unable to fit the GLM to the dataset using current techniques?", "Will it just take longer?", "How much longer?", "I would appreciate if there was a rough sense of how long it would take to do the exact GLM given N neurons and T time bins, compared to the approximate version.", "This presupposed that I even want to fit a massive GLM.", "The application to the mouse dataset, to me, suggests that this might not be the best idea, as I was quite surprised at how much the GLM overfit to the dataset.", "The authors report that the model outperforms a homogenous GLM on only 65% of the neurons.", "Does this mean that the model is strongly overfitting?", "Shouldn't the hyperparameter search for the regularization parameters have deal with this?", "Where was the 1 minute of held out data taken from (randomly throughout the recording, or at the beginning or end?).", "What if the authors did not fit coupling parameters between al neurons, instead fitting separate GLMs to each area?", "In that case, are there significant differences in predictive power?", "What if the full model was uncoupled (only spike history filters)?", "Also, I would have appreciated more interpretation of the model filters and coupling strengths presented in fig4d and 4c.", "Do these tell us something we did not aleady know?", "Do they look significantly different if I took subsets of neurons or data (such that I could do exact inference)?", "I can appreciate if the authors' goalwas to demonstrate that the approximate GLM works on large datasets, rather than analze this particular GLM model fit, but it is hard to make sense of the significance of being able to fit a large GLM without more exploration of these details.", "=== Generalcomments === This paper does a good job of taking a method recently published in the machine learning community (PASS-GLM) and shows how it may be relevant for neuroscience applications.", "What I found most difficult about this work is that it is hard to tell which audience this is best suited for.", "I does not seem like the work is realy about novel extensions to PASS-GLM that would be of interest to the machine learning community.", "Instead, it seems to target those in the neuroscience community who would be interested in building large scal GLMs of their data.", "However, for a neuroscientist, interested in applications, I think it is difficult to work through the derivations in secions 3 and 4 without a clear understanding of what the approximate GLM buys you, beyond being able to fit a GLM to a large recording (and it is unclear what that buys you in terms of new scientific understanding).", "I think the paper could be improved by focusing more on applications to neuraldatasets, with more rigorous comparisons for the new ideas presented in this paper, as well as clear statements about what the approximate GLM buys you in terms of being able to ask new scientific questions.", "The derivation of the approximate Poisson GLM (secion 3), while valable for those interested in applying the method, is harder to slog through when it is unclear what the method buys you (speaking as a neuroscientist).", "Perhaps focusing on applications and gains over previous methods first, and using that to motivate the derivation, would be more worthwhile for the community."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_325_1", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_308_1", "review_text": "I  have read the replies from reviewers and I decided to increase the score of this paper from 6 to 7.   -----  By minimizing PAC-Bayesian Generalization Bounds\u00e2\u0080\u009d the authors propose to train Gaussian processes (GPs) using a PAC-Bayesian bound for bounded loss functions in the regression case. The paper first recalls the classic PAC-Bayesian theorem (see, e.g. McAllester (1999), Theorem 1 and Seeger (2003), Theorem 3.1) for [0, 1]-valued loss func- tions. They show, by using a union bound, that the generalization bound holds for all parameters \u00ce\u00b8 in a finite parameter space \u00ce\u0098 and they propose to mini- mize this bound to train GP hyper-parameters in case of full GPs and to select hyper-parameters and inducing points for sparse GP models. In order to use the generalization bound the authors restrict their analysis to the 1-0 loss function. Other loss functions are introduced in appendix. They consider a FITC model (Qui\u00c3\u00b1onero-Candela and Rasmussen, 2005) for sparse GP and train by minimizing the generalization bound. They compare the method with standard methods for full GP and sparse GP training on classic data sets and show that their method gives the best generalization guarantees. Quality: The submission is technically sound. The derivations for the training objectives are well explained and an experimental section details the strengths and weaknesses of the method on standard data sets. Clarity: The submission is clearly written and well organized. Below are some points that might need clarification. \u00e2\u0080\u00a2 The sparse GP section 3.2 could be improved by clarifying the treatment of the inducing points z 1 , . . . , z M during the training. It is not completely clear in line 195, 196 how and if the discretization of \u00ce\u0098 influences inducing points selection. \u00e2\u0080\u00a2 The experimental section details the methods compared, however gives no indication on the programming language and software used. Nonetheless he authors note that the software implementing the experiments will be made available after acceptance. \u00e2\u0080\u00a2 line 159 it is not clear to me why a coarser rounding should improve the bound or the optimization. \u00e2\u0080\u00a2 line 200 the FITC model trained with marginal likelihood is known to over-fit, while the kl-PAC-SGP training objective seems to alleviate this behavior it would be interesting to test this on pathological data sets where FITC is known to fail. Originality: The method proposed, to the best of my knowledge, is new for the task of GP regression. However, the use of [0, 1]-valued loss functions renders it a direct extension of GP classification training. Germain et al. (2016) develop a PAC-Bayesian bound for regression with unbounded loss functions which however requires distributional assumptions on the input examples. The authors mention this and note that in order to keep a distribution-free frame- work they use bounded loss functions. The very interesting question raised by this submission is if it is possible to generalize the training method to the unbounded loss functions commonly used when evaluating regression tasks. Significance: The submission introduces a training method for GP regres- sion which, to the best of my knowledge, is a new technique. By shifting the focus on generalization guarantees it provides an interesting point of view in the likelihood dominated landscape of GP training. However, in my opinion, there are several aspects that reduce the significance of this work. \u00e2\u0080\u00a2 the use of [0, 1]-valued loss functions makes this training method much less appealing for practitioners as it leads to less accurate results in MSE than classic methods. \u00e2\u0080\u00a2 Germain et al. (2016) show that if we consider as loss function a bounded negative log-likelihood then minimizing the PAC-Bayesian bound is equiv- alent to maximizing the marginal likelihood. I am wondering if by using an appropriately bounded negative log-likelihood we could obtain better results than [0, 1]-valued loss functions in terms of upper bound and Gibbs risk. \u00e2\u0080\u00a2 The authors show that the discretization of the parameter space \u00ce\u0098 does not affect the method drastically on an example. In the same section, Ap- pendix F, they mention that \u00e2\u0080\u009cas long as a minimal discrimination ability is allowed\u00e2\u0080\u009d (line 502) the training and test risks are not affected. However I am not fully convinced that for ARD kernels with high d a minimal dis- crimination ability is within reach computationally because the number of parameter combinations increases drastically.", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_308_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["I have read the replies from reviewers and I decided to increase the score of this paper from 6 to 7, ----- By minimizing PAC-Bayesian Generalzation Bounds\u00e2\u0080\u009d the authors propose to train Gaussian processes (GPs) using a PAC-Bayesian bound for bounded loss functions in the regression case.", "The paper first recals the classic PAC-Bayesian theorem (see, e g McAllester (1999), Theorem 1 and Seeger (2003), Theorem 3 1) for [0, 1]-valed loss func- tions.", "They show, by using a union bound, that the generalzation bound holds for al parameters \u00ce\u00b8 in a finite parameter space \u00ce\u0098 and they propose to mini- mize this bound to train GP hyper-parameters in case of full GPs and to select hyper-parameters and inducing points for sparse GP models.", "In order to use the generalzation bound the authors restrict their analsis to the 1-0 loss function.", "Other loss functions are introduced in appendix.", "They consider a FITC model (Qui\u00c3\u00b1onero-Candela and Rasmussen, 2005) for sparse GP and train by minimizing the generalzation bound.", "They compare the method with standard methods for full GP and sparse GP training on classic data sets and show that their method gives the best generalzation guarantees.", "Qualty: The submission is technicaly sound.", "The derivations for the training objectives are well explained and an experimentalsecion details the strengths and weaknesses of the method on standard data sets.", "Clarity: The submission is clearly written and well organized.", "Below are some points that might need clarification.", "\u00e2\u0080\u00a2 The sparse GP secion 3 2 could be improved by clarifying the treatment of the inducing points z 1 , .", ".", ".", ", z M during the training.", "It is not completely clear in line 195, 196 how and if the discretization of \u00ce\u0098 influences inducing points selection.", "\u00e2\u0080\u00a2 The experimentalsecion details the methods compared, however gives no indication on the programming language and software used.", "Nonetheless he authors note that the software implementing the experiments will be made available after acceptance.", "\u00e2\u0080\u00a2 line 159 it is not clear to me why a coarser rounding should improve the bound or the optimization.", "\u00e2\u0080\u00a2 line 200 the FITC model trained with marginallikelihood is known to over-fit, while the kl-PAC-SGP training objective seems to aleviate this behavior it would be interesting to test this on pathologicaldata sets where FITC is known to fail.", "Originalty: The method proposed, to the best of my knowledge, is new for the task of GP regression.", "However, the use of [0, 1]-valed loss functions renders it a direct extension of GP classification training.", "Germain et al (2016) develop a PAC-Bayesian bound for regression with unbounded loss functions which however reqires distributionalassumptions on the input examples.", "The authors mention this and note that in order to keep a distribution-free frame- work they use bounded loss functions.", "The very interesting question raised by this submission is if it is possible to generalze the training method to the unbounded loss functions commonly used when evalating regression tasks.", "Significance: The submission introduces a training method for GP regres- sion which, to the best of my knowledge, is a new technique.", "By shifting the focus on generalzation guarantees it provides an interesting point of view in the likelihood dominated landscape of GP training.", "However, in my opinion, there are severalaspects that reduce the significance of this work.", "\u00e2\u0080\u00a2 the use of [0, 1]-valed loss functions makes this training method much less appealng for practitioners as it leads to less accurate results in MSE than classic methods.", "\u00e2\u0080\u00a2 Germain et al (2016) show that if we consider as loss function a bounded negative log-likelihood then minimizing the PAC-Bayesian bound is eqiv- alnt to maximizing the marginallikelihood.", "I am wondering if by using an appropriately bounded negative log-likelihood we could obtain better results than [0, 1]-valed loss functions in terms of upper bound and Gibbs risk.", "\u00e2\u0080\u00a2 The authors show that the discretization of the parameter space \u00ce\u0098 does not affect the method drasticaly on an example.", "In the same secion, Ap- pendix F, they mention that \u00e2\u0080\u009cas long as a minimaldiscrimination ability is alowed\u00e2\u0080\u009d (line 502) the training and test risks are not affected.", "However I am not fully convinced that for ARD kernels with high d a minimaldis- crimination ability is within reach computationaly because the number of parameter combinations increases drasticaly."], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_308_1", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_302_3", "review_text": "The paper proposes a new way to evaluate algorithms given their performance either on tasks or in a match against each other. Many papers evaluate new algorithms and tasks in ad-hoc ways, and it is often unclear which algorithm is better than which, and under what circumstances. The authors bring an educated approach to this issue by borrowing techniques from game theory. They consider a meta-game where one player chooses a team / distribution of algorithm and the other a team / distribution of tasks and propose ranking methods based on this game. There are two somewhat different approaches given in the paper. The first describes a decomposition of the algorithm-vs-task (AvT) or algorithm-vs-algorithm (AvA) matrix that lead to a low-rank approximation of sorts, giving \u00e2\u0080\u0098latent vectors\u00e2\u0080\u0099 for each algorithm that act as a multi-dimensional ranking. These provide a better representation of the algorithms than a one-dimensional ranking such as Elo, at the cost of being less interpretable. In particular they do not force a total order. The second method provides a ranking that tries to maintain a set of properties that seem very reasonable. This method provides each algorithm a score based on its comparison to the min-max strategy in the above mentioned game. The ranking is done according to the score.     Summary: This is somewhat of a non-standard paper as it doesn\u00e2\u0080\u0099t bring any new technique or develop a new mathematical tool. Rather it adapts known techniques in game theory and attempts to bring order to a somewhat chaotic area of algorithm evaluation. I suspect that the decision of accepting / rejecting the paper could be somewhat subjective but my opinion is to accept the paper.  Writing: The paper is a pleasure to read. The authors take time to explain their approach and the intuition for their decisions is presented clearly.   Related literature: The authors should relate their work to the field of dueling bandits. The dueling bandit problem, motivated by IR where algorithms are compared against each other has very similar issue. It is a common case there that the preference between pairs is not transitive meaning alg1 > alg2, alg2 > alg3, alg3 > alg1. Despite that, the bandit problem requires a notion of the best algorithm and of regret, meaning a sub optimality measure for a non-optimal algorithm. The issue is typically solved there by assuming the existence of a Condorcet winner, meaning an algorithm that is likely to beat any other algorithm in a match w.p. larger than 1/2. Given that, the regret associated with a sub-optimal algorithm is determined by how likely it is to lose to this winner. This definition exactly matches the Nash averaging score given here. In fact, there is a paper for dueling bandits titled \u00e2\u0080\u009cInstance-dependent Regret Bounds for Dueling Bandits\u00e2\u0080\u009d that discusses the case where there is no Condorcet winner, and they propose a notion of regret that is strongly related to the Nash averaging score.  Comments: * Equation at 157: Why are the Eigenvalues assumed to be approximately -i,i? Could you add an explanation?  * Line 165: The norm of P is not one - but depends on the number of players. It would be more helpful to discuss something normalized like |P-P\u00e2\u0080\u0099|/|P|. Also, the objective is not to reconstruct P in the Frobenius norm but with logistic loss. Is it possible to present that instead? Finally, why is there a \u00e2\u0080\u0098slight\u00e2\u0080\u0099 improvement? 0.85 to 0.35 seems like a pretty big improvement..  * line 168: Add one line to describe what the algorithms are meant to solve  * Is it true that n_A(i) is the payoff of algorithm i against the maxent NE strategy? This could be mentioned explicitly to demonstrate interpretability   * Theorem 1: The proposed score is the Nash Averaging n_A, but the theorem gives properties of p^*. I understand that the proofs go through p^* but shouldn\u00e2\u0080\u0099t the main statement be written in terms of n_A? Also, the notation \\eps-Nash should be defined before used in a theorem.  * Normalizing scores (in AvT) seem like an important issue that is somewhat avoided - is there any educated way of doing that? Perhaps converting to quantiles so outliers will not be an issue? ", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_302_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The paper proposes a new way to evalate alorithms given their performance either on tasks or in a match against each other.", "Many papers evalate new alorithms and tasks in ad-hoc ways, and it is often unclear which alorithm is better than which, and under what circumstances.", "The authors bring an educated approach to this issue by borrowing techniques from game theory.", "They consider a meta-game where one player chooses a team / distribution of alorithm and the other a team / distribution of tasks and propose ranking methods based on this game.", "There are two somewhat different approaches given in the paper.", "The first describes a decomposition of the alorithm-vs-task (AvT) or alorithm-vs-alorithm (AvA) matrix that lead to a low-rank approximation of sorts, giving \u00e2\u0080\u0098latent vectors\u00e2\u0080\u0099 for each alorithm that act as a multi-dimensionalranking.", "These provide a better representation of the alorithms than a one-dimensionalranking such as Elo, at the cost of being less interpretable.", "In particular they do not force a totalorder.", "The secnd method provides a ranking that tries to maintain a set of properties that seem very reasonable.", "This method provides each alorithm a score based on its comparison to the min-max strategy in the above mentioned game.", "The ranking is done according to the score.", "Summary: This is somewhat of a non-standard paper as it doesn\u00e2\u0080\u0099t bring any new technique or develop a new mathematicaltool.", "Rather it adapts known techniques in game theory and attempts to bring order to a somewhat chaotic area of alorithm evalation.", "I suspect that the decision of accepting / rejecting the paper could be somewhat subjective but my opinion is to accept the paper.", "Writing: The paper is a pleasure to read.", "The authors take time to explain their approach and the intuition for their decisions is presented clearly.", "Related literature: The authors should relate their work to the field of dueling bandits.", "The dueling bandit problem, motivated by IR where alorithms are compared against each other has very similar issue.", "It is a common case there that the preference between pairs is not transitive meaning al1 > al2, al2 > al3, al3 > al1, Despite that, the bandit problem reqires a notion of the best alorithm and of regret, meaning a sub optimalty measure for a non-optimalalorithm.", "The issue is typicaly solved there by assuming the existence of a Condorcet winner, meaning an alorithm that is likely to beat any other alorithm in a match w p larger than 1/2, Given that, the regret associated with a sub-optimalalorithm is determined by how likely it is to lose to this winner.", "This definition exactly matches the Nash averaging score given here.", "In fact, there is a paper for dueling bandits titled \u00e2\u0080\u009cInstance-dependent Regret Bounds for Dueling Bandits\u00e2\u0080\u009d that discusses the case where there is no Condorcet winner, and they propose a notion of regret that is strongly related to the Nash averaging score.", "Comments: * eqation at 157: Why are the Eigenvales assumed to be approximately -i,i?", "Could you add an explanation?", "* Line 165: The norm of P is not one - but depends on the number of players.", "It would be more helpful to discuss something normalzed like |P-P\u00e2\u0080\u0099|/|P|.", "Also, the objective is not to reconstruct P in the Frobenius norm but with logistic loss.", "Is it possible to present that instead?", "Finaly, why is there a \u00e2\u0080\u0098slight\u00e2\u0080\u0099 improvement?", "0 85 to 0 35 seems like a pretty big improvement.. * line 168: Add one line to describe what the alorithms are meant to solve * Is it true that n_A(i) is the payoff of alorithm i against the maxent NE strategy?", "This could be mentioned explicitly to demonstrate interpretability * Theorem 1: The proposed score is the Nash Averaging n_A, but the theorem gives properties of p^*.", "I understand that the proofs go through p^* but shouldn\u00e2\u0080\u0099t the main statement be written in terms of n_A?", "Also, the notation \\eps-Nash should be defined before used in a theorem.", "* Normalzing scores (in AvT) seem like an important issue that is somewhat avoided - is there any educated way of doing that?", "Perhaps converting to quantiles so outliers will not be an issue?"], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_302_3", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_277_3", "review_text": "UPDATE: I have read the authors' response and it was very helpful and addressed my concerns well and I have adjusted my score.  I now see the flaw in the regal reasoning and encourage the authors to add the explicit callout of the backwards inequality in the supplementary material (unless I missed it).  I also agree with the reasons for not comparing to regal empirically.  The point about algorithm mechanics is well thought out, though I still see some benefit to calling it out.  The wording correction you mentioned for line 159 makes sense as well.   Summary:  The paper considers the problem of RL exploration/exploitation in weakly communicating MDPs where many states (S_T) may not actually be reachable.  Such states cause an overestimate of values in algorithms like UCRL, which consider such states in their contribution to the exploration bonus.  The authors propose a new algorithm, TUCRL, that performs an online estimate of the reachability of states, and discards states that are below a threshold based on visits and the number of steps so far.  The algorithm is shown to have improved regret in such MDPs.  Furthermore, a new lower bound is proven showing that no algorithm  in this setting can achieve logarithmic regret without first incurring  exponential regret.  Review:  Overall, the paper makes a strong case for TUCRL.  The proofs are thorough and convincing.  I appreciate having the sketches actually in the paper in addition to the complete results in the supplementary material.  The idea appears to be sound, since UCRL was not making use of the tighter bounds that can be derived on state reachability, and the empirical results verify that the real-world advantages of the improved bound are significant.  The lower bound is also an important result outside of the TUCRL analysis.  My only concerns are in the comparison to Regal, some of the terminology in Section 2, and the description of the algorithm mechanics but I think these can be easily addressed.  The paper\u00e2\u0080\u0099s claim of a flaw in the proof of Regal\u00e2\u0080\u0099s regret was surprising and the logic laid out in the supplementary material appears correct, but the explanation is worded in a confusing way that makes it unclear what exactly the flaw is.  On line 417 of the supplemental material, we see the flawed inequality -C \\Sum{v} <= -C 2^j.  The authors then state: \u00e2\u0080\u009c[that inequality] is not true since -C := -c / sqrt(2^j).  However, that definition of C does not actually invalidate the inequality since C appears on both sides.  The authors later point out that what is needed is a lower bound on v, but they are unable to find one so they declare the proof incorrect.  All the evidence here is pointing to there being a flaw and the authors being right, but we\u00e2\u0080\u0099re missing an actual example where the inequality fails to hold.  The absence of a proof does not mean the statement is necessarily wrong (even though I believe it is).  Can the authors give us an actual MDP or even just plausible numerical instantiations of this inequality that make it untrue?  If so, that would seem to be a much cleaner refute of Regal.  In addition to the unclear terminology above, I was surprised that Regal did not appear in the experiments since it seems to be built for these kinds of environments, even if the theory is flawed.  Would an empirical result actually show TUCRL outperforming Regal?  If all we have is questions about its proof then an empirical result seems needed.  Most of the paper\u00e2\u0080\u0099s terminology is rigorously defined, but I found the definition of S^C and S^T in the beginning of Section 2 surprisingly informal.  The initial definitions make it unclear what cases are allowed under these conditions \u00e2\u0080\u0093 are they hard partitions where only one is visited \u00e2\u0080\u0093 can there be many \u00e2\u0080\u009cisland\u00e2\u0080\u009d MDPs that don\u00e2\u0080\u0099t communicate but an episode can start in any one of them?  In that case, what counts as S^C?  Many of these questions are cleaned up laterin the text, particularly in the multi-chain MDP subsection later in section 2, but they should really be addressed with a formal and rigorous definition of S^C and S^T right at the start.  One of the most interesting parts of the proof was the bounding of the number of times a poorly visited (s,a) is visited.  This is reminiscent of escape probabilities in the PAC literature but in TUCRL, we see a UCB/UCRL like behavior where \u00e2\u0080\u009cjumps\u00e2\u0080\u009d in the exploration occur periodically (though with longer and longer periods).  This is also borne out in the empirical results.  I would have liked to have seen this intuition presented when the algorithm was introduced, maybe as a set of \u00e2\u0080\u009ckey properties\u00e2\u0080\u009d of the algorithm so that users will better understand the behavioral characteristics of the algorithm.  Right now those details are scattered in various sections.  I realize space is tight, but you could add a few lines to the supplemental material covering this.  The main result is a good mathematical derivation but the significance of the empirical results put the theory in a better light.  The lower bound is also a strong contribution and an important component for a theory paper.   Minor notes:   Line 159: poorly visited so far are enabled -> This is unclear.  What does enabled mean?  Shouldn\u00e2\u0080\u0099t poorly visited states be discarded? ", "gold_annotation": {"interpretation": 0, "review_id": "NIPS_2018_277_3", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["UPDATE: I have read the authors' response and it was very helpful and addressed my concerns well and I have adjusted my score.", "I now see the flaw in the regalreasoning and encourage the authors to add the explicit calout of the backwards ineqalty in the supplementary material(unless I missed it).", "I alo agree with the reasons for not comparing to regalempiricaly.", "The point about alorithm mechanics is well thought out, though I still see some benefit to caling it out.", "The wording correction you mentioned for line 159 makes sense as well.", "Summary: The paper considers the problem of RL exploration/exploitation in weakly communicating MDPs where many states (S_T) may not actualy be reachable.", "Such states cause an overestimate of vales in alorithms like UCRL, which consider such states in their contribution to the exploration bonus.", "The authors propose a new alorithm, TUCRL, that performs an online estimate of the reachability of states, and discards states that are below a threshold based on visits and the number of steps so far.", "The alorithm is shown to have improved regret in such MDPs.", "Furthermore, a new lower bound is proven showing that no alorithm in this setting can achieve logarithmic regret without first incurring exponentialregret.", "Review: Overal, the paper makes a strong case for TUCRL.", "The proofs are thorough and convincing.", "I appreciate having the sketces actualy in the paper in addition to the complete results in the supplementary material The idea appears to be sound, since UCRL was not making use of the tighter bounds that can be derived on state reachability, and the empiricalresults verify that the realworld advantages of the improved bound are significant.", "The lower bound is alo an important result outside of the TUCRL analsis.", "My only concerns are in the comparison to Regal some of the terminology in secion 2, and the description of the alorithm mechanics but I think these can be easily addressed.", "The paper\u00e2\u0080\u0099s claim of a flaw in the proof of Regal\u0080\u0099s regret was surprising and the logic laid out in the supplementary materialappears correct, but the explanation is worded in a confusing way that makes it unclear what exactly the flaw is.", "On line 417 of the supplementalmaterial we see the flawed ineqalty -C \\Sum{v} <= -C 2^j The authors then state: \u00e2\u0080\u009c[that ineqalty] is not true since -C := -c / sqrt(2^j).", "However, that definition of C does not actualy invaldate the ineqalty since C appears on both sides.", "The authors later point out that what is needed is a lower bound on v, but they are unable to find one so they declare the proof incorrect.", "All the evidence here is pointing to there being a flaw and the authors being right, but we\u00e2\u0080\u0099re missing an actualexample where the ineqalty fails to hold.", "The absence of a proof does not mean the statement is necessarily wrong (even though I believe it is).", "Can the authors give us an actualMDP or even just plausible numericalinstantiations of this ineqalty that make it untrue?", "If so, that would seem to be a much cleaner refute of Regal In addition to the unclear terminology above, I was surprised that Regaldid not appear in the experiments since it seems to be built for these kinds of environments, even if the theory is flawed.", "Would an empiricalresult actualy show TUCRL outperforming Regal If al we have is questions about its proof then an empiricalresult seems needed.", "Most of the paper\u00e2\u0080\u0099s terminology is rigorously defined, but I found the definition of S^C and S^T in the beginning of secion 2 surprisingly informal The initialdefinitions make it unclear what cases are alowed under these conditions \u00e2\u0080\u0093 are they hard partitions where only one is visited \u00e2\u0080\u0093 can there be many \u00e2\u0080\u009cisland\u00e2\u0080\u009d MDPs that don\u00e2\u0080\u0099t communicate but an episode can start in any one of them?", "In that case, what counts as S^C?", "Many of these questions are cleaned up laterin the text, particularly in the multi-chain MDP subsecion later in secion 2, but they should realy be addressed with a formaland rigorous definition of S^C and S^T right at the start.", "One of the most interesting parts of the proof was the bounding of the number of times a poorly visited (s,a) is visited.", "This is reminiscent of escape probabilities in the PAC literature but in TUCRL, we see a UCB/UCRL like behavior where \u00e2\u0080\u009cjumps\u00e2\u0080\u009d in the exploration occur periodicaly (though with longer and longer periods).", "This is alo borne out in the empiricalresults.", "I would have liked to have seen this intuition presented when the alorithm was introduced, maybe as a set of \u00e2\u0080\u009ckey properties\u00e2\u0080\u009d of the alorithm so that users will better understand the behavioralcharacteristics of the alorithm.", "Right now those details are scattered in various secions.", "I realze space is tight, but you could add a few lines to the supplementalmaterialcovering this.", "The main result is a good mathematicalderivation but the significance of the empiricalresults put the theory in a better light.", "The lower bound is alo a strong contribution and an important component for a theory paper.", "Minor notes: Line 159: poorly visited so far are enabled -> This is unclear.", "What does enabled mean?", "Shouldn\u00e2\u0080\u0099t poorly visited states be discarded?"], "all_annotations": [{"interpretation": 0, "review_id": "NIPS_2018_277_3", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 5, "originality": 1, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_260_1", "review_text": "Strengths 1. Considering dynamic programming problems in continuous time such that the methodologies and tools of dynamical systems and stochastic di_x000b_eren- tial equations is interesting, and the authors do a good job of motivating the generalities of the problem context.  2. The authors initially describe problems/methods in very general terms, which helps preserve understandability of the _x000c_first sections.  Weaknesses  1. The parameterizations considered of the value functions at the end of the day belong to discrete time, due to the need to discretize the SDEs and sample the state-action-reward triples. Given this discrete implementa- tion, and the fact that experimentally the authors run into the conven- tional di_x000e_culties of discrete time algorithms with continuous state-action function approximation, I am a little bewildered as to what the actual bene_x000c_t is of this problem formulation, especially since it requires a re- de_x000c_nition of the value function as one that is compatible with SDEs (eqn. (4) ). That is, the intrinsic theoretical bene_x000c_ts of this perspective are not clear, especially since the main theorem is expressed in terms of RKHS only.  2. In the experiments, the authors mention kernel adaptive _x000c_filters (aka kernel LMS) or Gaussian processes as potential avenues of pursuit for addressing the function estimation in continuous domains. However, these methods are fundamentally limited by their sample complexity bottleneck, i.e., the quadratic complexity in the sample size. There's some experimental ref- erence to forgetting factors, but this issue can be addressed in a rigorous manner that preserves convergence while breaking the bottleneck, see, e.g.,  A. Koppel, G. Warnell, E. Stump, and A. Ribeiro, ``Parsimonious on- line learning with kernels via sparse projections in function space,\" arXiv preprint arXiv:1612.04111, 2016.  Simply applying these methods without consideration for the fact that the sample size conceptually is approaching in_x000c_nity, makes an update of the form (16) inapplicable to RL in general. Evaluating the Bellman operator requires computing an expected value.  3. Moreover, the limited complexity of the numerical evaluation is reflective of this complexity bottleneck, in my opinion. There are far more effective RKHS value function estimation methods than GPTD in terms of value function estimation quality and memory efficiency:  A. Koppel, G. Warnell, E. Stump, P. Stone, and A. Ribeiro. ``Policy Evaluation in Continuous MDPs with E_x000e_cient Kernelized Gradient Tem- poral Di_x000b_fference,\" in IEEE Trans. Automatic Control (submitted), Dec. 2017.\"  It's strange that the authors only compare against a mediocre benchmark rather than the state of the art.  4. The discussion at the beginning of section 3 doesn't make sense or is written in a somewhat self-contradictory manner. The authors should take greater care to explain the di_x000b_erence between value function estimation challenges due to unobservability, and value function estimation problems that come up directly from trying to solve Bellman's evaluation equation. I'm not sure what is meant in this discussion.  5. Also, regarding L87-88: value function estimation is NOT akin supervised learning unless one does Monte Carlo rollouts to do empirical approxima- tions of one of the expectations, due to the double sampling problem, as discussed in  R. S. Sutton, H. R. Maei, and C. Szepesvari, \\A convergent o(n) temporal- di_x000b_erence algorithm for o_x000b_-policy learning with linear function approxi- mation,\" in Advances in neural information processing systems, 2009, pp. 1609?1616.   and analyzed in great detail in :  V. R. Konda and J. N. Tsitsiklis, ``Convergence rate of linear two-timescale stochastic approximation,\" Annals of applied probability, pp. 796- 819, 2004.  6. The Algorithm 1 pseudo-code is strangely broad so as to be hand-waving. There's no speci_x000c_cs of a method that could actually be implemented, or even computed in the abstract. Algorithm 1 could just as well say \"train a deep network\" in the inner loop of an algorithm, which is unacceptable, and not how pseudo-code works. Specifically, one can't simply \"choose\" at random\" an RKHS function estimation algorithm and plug it in and assume it works, since the lion-share of methods for doing so either re- quire in_x000c_nite memory in the limit or employ memory-reduction that cause divergence.  7. L107-114 seems speculative or overly opinionated. This should be stated as a remark, or an aside in a Discussion section, or removed.  8. A general comment: there are no transitions between sections, which is not good for readability.  9. Again, the experiments are overly limited so as to not be convincing. GPTD is a very simplistic algorithm which is not even guaranteed to pre- serve posterior consistency, aka it is a divergent Bayesian method. There- fore, it seems like a straw man comparison. And this comparison is con- ducted on a synthetic example, whereas most RL works at least consider a rudimentary OpenAI problem such as Mountain car, if not a real robotics, power systems, or _x000c_financial application.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_260_1", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Strengths 1, Considering dynamic programming problems in continuous time such that the methodologies and tools of dynamicalsystems and stochastic di_x000b_eren- tialeqations is interesting, and the authors do a good job of motivating the generalties of the problem context.", "2, The authors initialy describe problems/methods in very generalterms, which helps preserve understandability of the _x000c_first secions.", "Weaknesses 1, The parameterizations considered of the vale functions at the end of the day belong to discrete time, due to the need to discretize the SDEs and sample the state-action-reward triples.", "Given this discrete implementa- tion, and the fact that experimentaly the authors run into the conven- tionaldi_x000e_culties of discrete time alorithms with continuous state-action function approximation, I am a little bewildered as to what the actualbene_x000c_t is of this problem formulation, especialy since it reqires a re- de_x000c_nition of the vale function as one that is compatible with SDEs (eq (4) ).", "That is, the intrinsic theoreticalbene_x000c_ts of this perspective are not clear, especialy since the main theorem is expressed in terms of RKHS only.", "2, In the experiments, the authors mention kernel adaptive _x000c_filters (aka kernel LMS) or Gaussian processes as potentialavenues of pursuit for addressing the function estimation in continuous domains.", "However, these methods are fundamentaly limited by their sample complexity bottleneck, i e , the quadratic complexity in the sample size.", "There's some experimentalref- erence to forgetting factors, but this issue can be addressed in a rigorous manner that preserves convergence while breaking the bottleneck, see, e g , A Koppel, G Warnell, E Stump, and A Ribeiro, ``Parsimonious on- line learning with kernels via sparse projections in function space,\" arXiv preprint arXiv:1612.04111, 2016, Simply applying these methods without consideration for the fact that the sample size conceptualy is approaching in_x000c_nity, makes an update of the form (16) inapplicable to RL in general Evalating the Bellman operator reqires computing an expected vale.", "3, Moreover, the limited complexity of the numericalevalation is reflective of this complexity bottleneck, in my opinion.", "There are far more effective RKHS vale function estimation methods than GPTD in terms of vale function estimation qualty and memory efficiency: A Koppel, G Warnell, E Stump, P Stone, and A Ribeiro.", "``Policy Evalation in Continuous MDPs with E_x000e_cient Kernelized Gradient Tem- poralDi_x000b_fference,\" in IEEE Trans.", "Automatic Control (submitted), Dec.", "2017.\"", "It's strange that the authors only compare against a mediocre benchmark rather than the state of the art.", "4, The discussion at the beginning of secion 3 doesn't make sense or is written in a somewhat self-contradictory manner.", "The authors should take greater care to explain the di_x000b_erence between vale function estimation chalenges due to unobservability, and vale function estimation problems that come up directly from trying to solve Bellman's evalation eqation.", "I'm not sure what is meant in this discussion.", "5, Also, regarding L87-88: vale function estimation is NOT akin supervised learning unless one does Monte Carlo rollouts to do empiricalapproxima- tions of one of the expectations, due to the double sampling problem, as discussed in R S Sutton, H R Maei, and C Szepesvari, \\A convergent o(n) temporal di_x000b_erence alorithm for o_x000b_-policy learning with linear function approxi- mation,\" in Advances in neuralinformation processing systems, 2009, pp.", "1609?1616, and analzed in great detail in : V R Konda and J N Tsitsiklis, ``Convergence rate of linear two-timescal stochastic approximation,\" Annal of applied probability, pp.", "796- 819, 2004, 6, The Algorithm 1 pseudo-code is strangely broad so as to be hand-waving.", "There's no speci_x000c_cs of a method that could actualy be implemented, or even computed in the abstract.", "Algorithm 1 could just as well say \"train a deep network\" in the inner loop of an alorithm, which is unacceptable, and not how pseudo-code works.", "Specificaly, one can't simply \"choose\" at random\" an RKHS function estimation alorithm and plug it in and assume it works, since the lion-share of methods for doing so either re- quire in_x000c_nite memory in the limit or employ memory-reduction that cause divergence.", "7, L107-114 seems speculative or overly opinionated.", "This should be stated as a remark, or an aside in a Discussion secion, or removed.", "8, A generalcomment: there are no transitions between secions, which is not good for readability.", "9, Again, the experiments are overly limited so as to not be convincing.", "GPTD is a very simplistic alorithm which is not even guaranteed to pre- serve posterior consistency, aka it is a divergent Bayesian method.", "There- fore, it seems like a straw man comparison.", "And this comparison is con- ducted on a synthetic example, whereas most RL works at least consider a rudimentary OpenAI problem such as Mountain car, if not a realrobotics, power systems, or _x000c_financialapplication."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_260_1", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno3", "evidence": 4, "originality": 0, "metareview": "nota", "presentation": 1, "method": 1}]}, {"conference": "neurips18", "review_id": "NIPS_2018_243_1", "review_text": "This paper takes on the difficult task of estimating individual treatment effects in observational data.  The authors propose a framework, SITE, which both ensures global balance and local similarity using deep representation learning.  Results are demonstrated on benchmark datasets.  This is a high quality paper.  I have some quibbles and concerns with it, but it is tackling a difficult problem in an interesting way.  I realize that the authors are building on an existing literature in computer science on the subject (e.g. Shalit et al) but I don\u00e2\u0080\u0099t think framing this as estimation of the individual treatment effect is quite right.  The individual treatment effect is completely intractable with the standard assumptions that are typically used, because there is only the one observation.  What the paper really estimates is heterogeneous treatment effects for high-dimensional covariates x.  A symptom of this issue comes in equation 1.  The authors invoke the potential outcomes framework and define the ITE in terms of E[Y_1(i) | x_i] etc.  but what\u00e2\u0080\u0099s the expectation over?  In the potential outcomes framework, the potential outcomes aren\u00e2\u0080\u0099t random and its not clear what the conditioning is doing. At some level this is just a squabble over notation but I think it points to some subtleties in what is meant by individual treatment effect.    I also have some concerns about the stated assumptions.  It seems in addition to assumptions 2.1 and 2.2, there is some kind of SUTVA or consistency assumption needed, right?  I also think that the authors are not taking seriously enough the strength of the positivity assumption.  Presumably enforcing local similarity would not be necessary if positivity straightforwardly held.  In other words, if you weren\u00e2\u0080\u0099t trying to smooth over a high-dimensional space, you wouldn\u00e2\u0080\u0099t need the latent representation in the first place.  This general point has been made in the high dimensional case by a recent paper by D\u00e2\u0080\u0099Amour et al (https://arxiv.org/abs/1711.02582) but I think it also applies here in these relatively low-dimensional settings because the estimand is so specific to a narrow region of the space.  Ultimately these quibbles are fairly small though.  The core idea here seems to be a good one and the paper cleverly brings representation learning into causal inference which is both original and likely to have a significant impact by bringing two distinct communities closer together.  I found the paper to be quite clear although I do worry that there is a relatively small group of scholars who have training in both causal inference and deep learning such that they can properly appreciate this work.  That may ultimately be one of the challenges of bridging communities like this though.  *** Response to Author Feeedback*** I thank the authors for the feedback and the additional study.  In going through the other reviews, it is clear to me that Reviewer 3 and I essentially agree on the weaknesses of the paper and the way the response memo does and doesn't address them.  The difference in scores is attributable primarily to how strongly we feel about those weaknesses.    The primary concern with the paper is the clarity both in the analysis of the experimental results (although I agree that the PDDM study in the memo is great and should be added) and in the estimands/assumptions. I followed R3's excellent example and also revisited the prior work.  I still disagree about framing this as an individual treatment effect rather than a conditional average treatment effect - and notice further that the ITE is actually defined as a CATE in one of the prior papers (which I still disagree with, but that correspondence might be worth referencing).  Obviously space is always at a premium but I think the work will have greater impact if you can summarize some of the key elements of the prior work you are building on.      I look forward to the discussion of the recent work on positivity.  I also do encourage you to explicitly add the consistency/SUTVA assumption for completeness.", "gold_annotation": {"interpretation": 1, "review_id": "NIPS_2018_243_1", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}, "score": 5.0, "tokenized_review_text": ["This paper takes on the difficult task of estimating individualtreatment effects in observationaldata.", "The authors propose a framework, SITE, which both ensures globalbalnce and localsimilarity using deep representation learning.", "Results are demonstrated on benchmark datasets.", "This is a high qualty paper.", "I have some quibbles and concerns with it, but it is tackling a difficult problem in an interesting way.", "I realze that the authors are building on an existing literature in computer science on the subject (e g Shalt et al but I don\u00e2\u0080\u0099t think framing this as estimation of the individualtreatment effect is quite right.", "The individualtreatment effect is completely intractable with the standard assumptions that are typicaly used, because there is only the one observation.", "What the paper realy estimates is heterogeneous treatment effects for high-dimensionalcovariates x A symptom of this issue comes in eqation 1, The authors invoke the potentialoutcomes framework and define the ITE in terms of E[Y_1(i) | x_i] etc but what\u00e2\u0080\u0099s the expectation over?", "In the potentialoutcomes framework, the potentialoutcomes aren\u00e2\u0080\u0099t random and its not clear what the conditioning is doing.", "At some level this is just a squabble over notation but I think it points to some subtleties in what is meant by individualtreatment effect.", "I alo have some concerns about the stated assumptions.", "It seems in addition to assumptions 2 1 and 2 2, there is some kind of SUTVA or consistency assumption needed, right?", "I alo think that the authors are not taking seriously enough the strength of the positivity assumption.", "Presumably enforcing localsimilarity would not be necessary if positivity straightforwardly held.", "In other words, if you weren\u00e2\u0080\u0099t trying to smooth over a high-dimensionalspace, you wouldn\u00e2\u0080\u0099t need the latent representation in the first place.", "This generalpoint has been made in the high dimensionalcase by a recent paper by D\u00e2\u0080\u0099Amour et al(https://arxiv.org/abs/1711.02582) but I think it alo applies here in these relatively low-dimensionalsettings because the estimand is so specific to a narrow region of the space.", "Ultimately these quibbles are fairly smal though.", "The core idea here seems to be a good one and the paper cleverly brings representation learning into causalinference which is both originaland likely to have a significant impact by bringing two distinct communities closer together.", "I found the paper to be quite clear alhough I do worry that there is a relatively smal group of scholars who have training in both causalinference and deep learning such that they can properly appreciate this work.", "That may ultimately be one of the chalenges of bridging communities like this though.", "*** Response to Author Feeedback*** I thank the authors for the feedback and the additionalstudy.", "In going through the other reviews, it is clear to me that Reviewer 3 and I essentialy agree on the weaknesses of the paper and the way the response memo does and doesn't address them.", "The difference in scores is attributable primarily to how strongly we feel about those weaknesses.", "The primary concern with the paper is the clarity both in the analsis of the experimentalresults (alhough I agree that the PDDM study in the memo is great and should be added) and in the estimands/assumptions.", "I followed R3's excellent example and alo revisited the prior work.", "I still disagree about framing this as an individualtreatment effect rather than a conditionalaverage treatment effect - and notice further that the ITE is actualy defined as a CATE in one of the prior papers (which I still disagree with, but that correspondence might be worth referencing).", "Obviously space is alays at a premium but I think the work will have greater impact if you can summarize some of the key elements of the prior work you are building on.", "I look forward to the discussion of the recent work on positivity.", "I alo do encourage you to explicitly add the consistency/SUTVA assumption for completeness."], "all_annotations": [{"interpretation": 1, "review_id": "NIPS_2018_243_1", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno3", "evidence": 4, "originality": 1, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "BJ0qmr9xf", "review_text": "The paper solves the problem of how to do autonomous resets, which is an important problem in real world RL. The method is novel, the explanation is clear, and has good experimental results.\n \nPros:\n1. The approach is simple, solves a task of practical importance, and performs well in the experiments. \n2. The experimental section performs good ablation studies wrt fewer reset thresholds, reset attempts, use of ensembles.\n\nCons:\n1. The method is evaluated only for 3 tasks, which are all in simulation, and on no real world tasks. Additional tasks could be useful, especially for qualitative analysis of the learned reset policies.\n2. It seems that while the method does reduce hard resets, it would be more convincing if it can solve tasks which a model without a reset policy couldnt. Right now, the methods without the reset policy perform about equally well on final reward.\n3. The method wont be applicable to RL environments where we will need to take multiple non-invertible actions to achieve the goal (an analogy would be multiple levels in a game). In such situations, one might want to use the reset policy to go back to intermediate \u201cstart\u201d states from where we can continue again, rather than the original start state always.\n\nConclusion/Significance: The approach is a step in the right direction, and further refinements can make it a significant contribution to robotics work.\n\nRevision: Thanks to the authors for addressing the issues I raised, I revise my review to 7", "gold_annotation": {"interpretation": 0, "review_id": "BJ0qmr9xf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["The paper solves the problem of how to do autonomous resets, which is an important problem in realworld RL.", "The method is novel, the explanation is clear, and has good experimentalresults.", "Pros: 1, The approach is simple, solves a task of practicalimportance, and performs well in the experiments.", "2, The experimentalsecion performs good ablation studies wrt fewer reset thresholds, reset attempts, use of ensembles.", "Cons: 1, The method is evalated only for 3 tasks, which are al in simulation, and on no realworld tasks.", "Additionaltasks could be useful, especialy for qualtative analsis of the learned reset policies.", "2, It seems that while the method does reduce hard resets, it would be more convincing if it can solve tasks which a model without a reset policy couldnt.", "Right now, the methods without the reset policy perform about eqaly well on finalreward.", "3, The method wont be applicable to RL environments where we will need to take multiple non-invertible actions to achieve the goal(an analgy would be multiple levels in a game).", "In such situations, one might want to use the reset policy to go back to intermediate \u201cstart\u201d states from where we can continue again, rather than the originalstart state alays.", "Conclusion/Significance: The approach is a step in the right direction, and further refinements can make it a significant contribution to robotics work.", "Revision: Thanks to the authors for addressing the issues I raised, I revise my review to 7"], "all_annotations": [{"interpretation": 0, "review_id": "BJ0qmr9xf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "BJ2J7pFgf", "review_text": "This paper presents a method for classifying Tumblr posts with associated images according to associated single emotion word hashtags.  The method relies on sentiment pre-processing from GloVe and image pre-processing from Inception.  \n \nMy strongest criticism for this paper is against the claim that Tumblr post represent self-reported emotions and that this method sheds new insight on emotion representation and my secondary criticism is a lack of novelty in the method, which seems to be simply a combination of previously published sentiment analysis module and previously published image analysis module, fused in an output layer. \n\nThe authors claim that the hashtags represent self-reported emotions, but this is not true in the way that psychologists query participants regarding emotion words in psychology studies.  Instead these are emotion words that a person chooses to broadcast along with an associated announcement.  As the authors point out, hashtags and words may be used sarcastically or in different ways from what is understood in emotion theory.  It is quite common for everyday people to use emotion words this way e.g. using #love to express strong approval rather than an actual feeling of love.   \n\nIn their analysis the authors claim:\n\u201cThe 15 emotions retained were those with high relative frequencies on Tumblr among the PANAS-X scale (Watson & Clark, 1999)\u201d.\nHowever five of the words the authors retain: bored, annoyed, love, optimistic, and pensive are not in fact found in the PANAS-X scale:\n\nReference: The PANAS-X Scale: https://wiki.aalto.fi/download/attachments/50102838/PANAS-X-scale_spec.pdf Also the longer version that the authors cited: \nhttps://www2.psychology.uiowa.edu/faculty/clark/panas-x.pdf\n\nIt should also be noted that the PANAS (Positive and Negative Affect Scale) scale and the PANAS-X (the \u201cX\u201d is for eXtended) scale are questionnaires used to elicit from participants feelings of positive and negative affect, they are not collections of \"core\" emotion words, but rather words that are colloquially attached to either positive or negative sentiment.  For example PANAS-X includes words like:\u201cstrong\u201d ,\u201cactive\u201d, \u201chealthy\u201d, \u201csleepy\u201d which are not considered emotion words by psychology.  \n\nIf the authors stated goal is \"different than the standard sentiment analysis goal of predicting whether a sentence expresses positive or negative sentiment\" they should be aware that this is exactly what PANAS is designed to do - not to infer the latent emotional state of a person, except to the extent that their affect is positive or negative.\n\n\nThe work of representing emotions had been an field in psychology for over a hundred years and it is still continuing.  https://en.wikipedia.org/wiki/Contrasting_and_categorization_of_emotions.\n\nOne of the most popular theories of emotion is the theory that there exist \u201cbasic\u201d emotions: Anger, Disgust, Fear, Happiness (enjoyment), Sadness and Surprise (Paul Ekman, cited by the authors).  These are short duration sates lasting only seconds.  They are also fairly specific, for example \u201csurprise\u201d is sudden reaction to something unexpected, which is it exactly the same as seeing a flower on your car and expressing \u201cwhat a nice surprise.\u201d  The surprise would be the initial reaction of \u201cwhat\u2019s that on my car?  Is it dangerous?\u201d but after identifying the object as non-threatening, the emotion of \u201csurprise\u201d would likely pass and be replaced with appreciation.  \n\nThe Circumplex Model of Emotions (Posner et al 2005) the authors refer to actually stands in opposition to the theories of Ekman.  From the cited paper by Posner et al : \n\"The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion.\"\nFrom my reading of this paper, it is clear to me that the authors do not have a clear understanding of the current state of psychology\u2019s view of emotion representation and this work would not likely contribute to a new understanding of the latent structure of peoples\u2019 emotions.\n\nIn the PCA result, it is not \"clear\" that the first axis represents valence, as \"sad\" has a slight positive on this scale and \"sad\" is one of the emotions most clearly associated with negative valence.\n\nWith respect to the rest of the paper, the level of novelty and impact is \"ok, but not good enough.\"  This analysis does not seem very different from Twitter analysis, because although Tumblr posts are allowed to be longer than Twitter posts, the authors truncate the posts to 50 characters.  Additionally, the images do not seem to add very much to the classification.  The authors algorithm also seems to be essentially a combination of two other, previously published algorithms.\n\nFor me the novelty of this paper was in its application to the realm of emotion theory, but I do not feel there is a contribution here.  This paper is more about classifying Tumblr posts according to emotion word hashtags than a paper that generates a new insights into emotion representation or that can infer latent emotional state. \n\n\n\n\n\n\n\n\n\n\n\n", "gold_annotation": {"interpretation": 1, "review_id": "BJ2J7pFgf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper presents a method for classifying Tumblr posts with associated images according to associated single emotion word hashtags.", "The method relies on sentiment pre-processing from GloVe and image pre-processing from Inception.", "My strongest criticism for this paper is against the claim that Tumblr post represent self-reported emotions and that this method sheds new insight on emotion representation and my secndary criticism is a lack of novelty in the method, which seems to be simply a combination of previously published sentiment analsis module and previously published image analsis module, fused in an output layer.", "The authors claim that the hashtags represent self-reported emotions, but this is not true in the way that psychologists query participants regarding emotion words in psychology studies.", "Instead these are emotion words that a person chooses to broadcast alng with an associated announcement.", "As the authors point out, hashtags and words may be used sarcasticaly or in different ways from what is understood in emotion theory.", "It is quite common for everyday people to use emotion words this way e g using #love to express strong approvalrather than an actualfeeling of love.", "In their analsis the authors claim: \u201cThe 15 emotions retained were those with high relative freqencies on Tumblr among the PANAS-X scal (Watson & Clark, 1999)\u201d.", "However five of the words the authors retain: bored, annoyed, love, optimistic, and pensive are not in fact found in the PANAS-X scal: Reference: The PANAS-X Scal: https://wiki.aalo.fi/download/attachments/50102838/PANAS-X-scal_spec.pdf Also the longer version that the authors cited: https://www2.psychology.uiowa.edu/faculty/clark/panas-x pdf It should alo be noted that the PANAS (Positive and Negative Affect Scal) scal and the PANAS-X (the \u201cX\u201d is for eXtended) scal are questionnaires used to elicit from participants feelings of positive and negative affect, they are not collections of \"core\" emotion words, but rather words that are colloquialy attached to either positive or negative sentiment.", "For example PANAS-X includes words like:\u201cstrong\u201d ,\u201cactive\u201d, \u201chealhy\u201d, \u201csleepy\u201d which are not considered emotion words by psychology.", "If the authors stated goalis \"different than the standard sentiment analsis goalof predicting whether a sentence expresses positive or negative sentiment\" they should be aware that this is exactly what PANAS is designed to do - not to infer the latent emotionalstate of a person, except to the extent that their affect is positive or negative.", "The work of representing emotions had been an field in psychology for over a hundred years and it is still continuing.", "https://en.wikipedia.org/wiki/Contrasting_and_categorization_of_emotions.", "One of the most popular theories of emotion is the theory that there exist \u201cbasic\u201d emotions: Anger, Disgust, Fear, Happiness (enjoyment), Sadness and Surprise (Paul Ekman, cited by the authors).", "These are short duration sates lasting only secnds.", "They are alo fairly specific, for example \u201csurprise\u201d is sudden reaction to something unexpected, which is it exactly the same as seeing a flower on your car and expressing \u201cwhat a nice surprise.\u201d The surprise would be the initialreaction of \u201cwhat\u2019s that on my car?", "Is it dangerous?\u201d but after identifying the object as non-threatening, the emotion of \u201csurprise\u201d would likely pass and be replaced with appreciation.", "The Circumplex Model of Emotions (Posner et al2005) the authors refer to actualy stands in opposition to the theories of Ekman.", "From the cited paper by Posner et al: \"The circumplex model of affect proposes that al affective states arise from cognitive interpretations of core neuralsensations that are the product of two independent neurophysiologicalsystems.", "This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neuralsystem subserves every emotion.\"", "From my reading of this paper, it is clear to me that the authors do not have a clear understanding of the current state of psychology\u2019s view of emotion representation and this work would not likely contribute to a new understanding of the latent structure of peoples\u2019 emotions.", "In the PCA result, it is not \"clear\" that the first axis represents valnce, as \"sad\" has a slight positive on this scal and \"sad\" is one of the emotions most clearly associated with negative valnce.", "With respect to the rest of the paper, the level of novelty and impact is \"ok, but not good enough.\"", "This analsis does not seem very different from Twitter analsis, because alhough Tumblr posts are alowed to be longer than Twitter posts, the authors truncate the posts to 50 characters.", "Additionaly, the images do not seem to add very much to the classification.", "The authors alorithm alo seems to be essentialy a combination of two other, previously published alorithms.", "For me the novelty of this paper was in its application to the real of emotion theory, but I do not feel there is a contribution here.", "This paper is more about classifying Tumblr posts according to emotion word hashtags than a paper that generates a new insights into emotion representation or that can infer latent emotionalstate."], "all_annotations": [{"interpretation": 1, "review_id": "BJ2J7pFgf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "BJ3VB6_xG", "review_text": "The paper proposes an interesting alternative to recent approaches to learning from logged bandit feedback, and validates their contribution in a reasonable experimental comparison. The clarity of writing can be improved (several typos in the manuscript, notation used before defining, missing words, poorly formatted citations, etc.).\nImplementing the approach using recent f-GANs is an interesting contribution and may spur follow-up work. There are several lingering concerns about the approach (detailed below) that detract from the quality of their contributions.\n\n[Major] In Lemma 1, L(z) is used before defining it. Crucially, additional assumptions on L(z) are necessary (e.g. |L(z)| <= 1 for all z. If not, a trivial counter-example is: set L(z) >> 1 for all z and Lemma 1 is violated). It is unclear how crucially this additional assumption is required in practice (their expts with Hamming losses clearly do not satisfy such an assumption).\n\n[Minor] Typo: Section 3.2, first equation; the integral equals D_f(...) + 1 (not -1).\n\n[Crucial!] Eqn10: Expected some justification on why it is fruitful to *lower-bound* the divergence term, which contributes to an *upper-bound* on the true risk.\n\n[Crucial!] Algorithm1: How is the condition of the while loop checked in a tractable manner?\n\n[Minor] Typos: Initilization -> Initialization, Varitional -> Variational\n\n[Major] Expected an additional \"baseline\" in the expts -- Supervised but with the neural net policy architecture (NN approaches outperforming Supervised on LYRL dataset was baffling before realizing that Supervised is implemented using a linear CRF).\n\n[Major] Is there any guidance for picking the new regularization hyper-parameters (or at least, a sensible range for them)?\n\n[Minor] The derived bounds depend on M, an a priori upper bound on the Renyi divergence between the logging policy and any new policy. It's unclear that such a bound  can be tractably guessed (in contrast, prior work uses an upper bound on the importance weight -- which is simply 1/(Min action selection prob. by logging policy) ).", "gold_annotation": {"interpretation": 0, "review_id": "BJ3VB6_xG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper proposes an interesting alernative to recent approaches to learning from logged bandit feedback, and valdates their contribution in a reasonable experimentalcomparison.", "The clarity of writing can be improved (severaltypos in the manuscript, notation used before defining, missing words, poorly formatted citations, etc).", "Implementing the approach using recent f-GANs is an interesting contribution and may spur follow-up work.", "There are severallingering concerns about the approach (detailed below) that detract from the qualty of their contributions.", "[Major] In Lemma 1, L(z) is used before defining it.", "Crucialy, additionalassumptions on L(z) are necessary (e g |L(z)| <= 1 for al z If not, a trivialcounter-example is: set L(z) >> 1 for al z and Lemma 1 is violated).", "It is unclear how crucialy this additionalassumption is reqired in practice (their expts with Hamming losses clearly do not satisfy such an assumption).", "[Minor] Typo: secion 3 2, first eqation; the integraleqal D_f(...) + 1 (not -1).", "[Crucial] eq0: Expected some justification on why it is fruitful to *lower-bound* the divergence term, which contributes to an *upper-bound* on the true risk.", "[Crucial] Algorithm1: How is the condition of the while loop checked in a tractable manner?", "[Minor] Typos: Initilization -> Initialzation, Varitional-> Variational [Major] Expected an additional\"baseline\" in the expts -- Supervised but with the neuralnet policy architecture (NN approaches outperforming Supervised on LYRL dataset was baffling before realzing that Supervised is implemented using a linear CRF).", "[Major] Is there any guidance for picking the new regularization hyper-parameters (or at least, a sensible range for them)?", "[Minor] The derived bounds depend on M, an a priori upper bound on the Renyi divergence between the logging policy and any new policy.", "It's unclear that such a bound can be tractably guessed (in contrast, prior work uses an upper bound on the importance weight -- which is simply 1/(Min action selection prob.", "by logging policy) )."], "all_annotations": [{"interpretation": 0, "review_id": "BJ3VB6_xG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "BJ9DfkxWM", "review_text": "The paper is clear and well written.\nIt is an incremental modification of prior work (ResNeXt) that performs better on several experiments selected by the author; comparisons are only included relative to ResNeXt.\n\nThis paper is not about gating (c.f., gates in LSTMs, mixture of experts, etc) but rather about masking or perhaps a kind of block sparsity, as the \"gates\" of the paper do not depend upon the input: they are just fixed masking matrices (see eq (2)).\n\nThe main contribution appears to be the optimisation procedure for the binary masking tensor g. But this procedure is not justified: does each step minimise the loss? This seems unlikely due to the sampling. Can the authors show that the procedure will always converge? It would be good to contrast this with other attempts to learn discrete random variables (for example, The Concrete Distribution: Continuous Relaxation of Continuous Random Variables, Maddison et al, ICLR 2017).\n", "gold_annotation": {"interpretation": 0, "review_id": "BJ9DfkxWM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}, "score": 3.0, "tokenized_review_text": ["The paper is clear and well written.", "It is an incrementalmodification of prior work (ResNeXt) that performs better on severalexperiments selected by the author; comparisons are only included relative to ResNeXt.", "This paper is not about gating (c f , gates in LSTMs, mixture of experts, etc but rather about masking or perhaps a kind of block sparsity, as the \"gates\" of the paper do not depend upon the input: they are just fixed masking matrices (see eq(2)).", "The main contribution appears to be the optimisation procedure for the binary masking tensor g But this procedure is not justified: does each step minimise the loss?", "This seems unlikely due to the sampling.", "Can the authors show that the procedure will alays converge?", "It would be good to contrast this with other attempts to learn discrete random variables (for example, The Concrete Distribution: Continuous Relaxation of Continuous Random Variables, Maddison et al ICLR 2017)."], "all_annotations": [{"interpretation": 0, "review_id": "BJ9DfkxWM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "BJBU32dgz", "review_text": "The paper \u2018Deep learning for Physical Process: incorporating prior physical knowledge\u2019 proposes\nto question the use of data-intensive strategies such as deep learning in solving physical \ninverse problems that are traditionally solved through assimilation strategies. They notably show\nhow physical priors on a given phenomenon can be incorporated in the learning process and propose \nan application on the problem of estimating sea surface temperature directly from a given \ncollection of satellite images.\n\nAll in all the paper is very clear and interesting. The results obtained on the considered problem\nare clearly of great interest, especially when compared to state-of-the-art assimilation strategies\nsuch as the one of B\u00e9r\u00e9ziat. While the learning architecture is not original in itself, it is \nshown that a proper physical regularization greatly improves the performance. For these reasons I \nbelieve the paper has sufficient merits to be published at ICLR. That being said, I believe that \nsome discussions could strengthen the paper:\n - Most classical variational assimilation schemes are stochastic in nature, notably by incorporating\nuncertainties in the observation or physical evolution models. It is still unclear how those uncertainties \ncan be integrated in the model;\n - Assimilation methods are usually independent of the type of data at hand. It is not clear how the model\nlearnt on one particular type of data transpose to other data sequences. Notably, the question of transfer\nand generalization is of high relevance here. Does the learnt model performs well on other dataset (for instance,\nacquired on a different region or at a distant time). I believe this type of issue has to be examinated \nfor this type of approach to be widely use in inverse physical problems. \n", "gold_annotation": {"interpretation": 0, "review_id": "BJBU32dgz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper \u2018Deep learning for PhysicalProcess: incorporating prior physicalknowledge\u2019 proposes to question the use of data-intensive strategies such as deep learning in solving physical inverse problems that are traditionaly solved through assimilation strategies.", "They notably show how physicalpriors on a given phenomenon can be incorporated in the learning process and propose an application on the problem of estimating sea surface temperature directly from a given collection of satellite images.", "All in al the paper is very clear and interesting.", "The results obtained on the considered problem are clearly of great interest, especialy when compared to state-of-the-art assimilation strategies such as the one of B\u00e9r\u00e9ziat.", "While the learning architecture is not originalin itself, it is shown that a proper physicalregularization greatly improves the performance.", "For these reasons I believe the paper has sufficient merits to be published at ICLR.", "That being said, I believe that some discussions could strengthen the paper: - Most classicalvariationalassimilation schemes are stochastic in nature, notably by incorporating uncertainties in the observation or physicalevolution models.", "It is still unclear how those uncertainties can be integrated in the model; - Assimilation methods are usualy independent of the type of data at hand.", "It is not clear how the model learnt on one particular type of data transpose to other data seqences.", "Notably, the question of transfer and generalzation is of high relevance here.", "Does the learnt model performs well on other dataset (for instance, acquired on a different region or at a distant time).", "I believe this type of issue has to be examinated for this type of approach to be widely use in inverse physicalproblems."], "all_annotations": [{"interpretation": 0, "review_id": "BJBU32dgz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "BJBWMqqlf", "review_text": "This paper proposes a new theoretically-motivated method for combining reinforcement learning and imitation learning for acquiring policies that are as good as or superior to the expert. The method assumes access to an expert value function (which could be trained using expert roll-outs) and uses the value function to shape the reward function and allow for truncated-horizon policy search. The algorithm can gracefully handle suboptimal demonstrations/value functions, since the demonstrations are only used for reward shaping, and the experiments demonstrate faster convergence and better performance compared to RL and AggreVaTeD on a range of simulated control domains. The paper is well-written and easy to understand.\n\nMy main feedback is with regard to the experiments:\nI appreciate that the experiments used 25 random seeds! This provides a convincing evaluation.\nIt would be nice to see experimental results on even higher dimensional domains such as the ant, humanoid, or vision-based tasks, since the experiments seem to suggest that the benefit of the proposed method is diminished in the swimmer and hopper domains compared to the simpler settings.\nSince the method uses demonstrations, it would be nice to see three additional comparisons: (a) training with supervised learning on the expert roll-outs, (b) initializing THOR and AggreVaTeD (k=1) with a policy trained with supervised learning, and (c) initializing TRPO with a policy trained with supervised learning. There doesn't seem to be any reason not to initialize in such a way, when expert demonstrations are available, and such an initialization should likely provide a significant speed boost in training for all methods.\nHow many demonstrations were used for training the value function in each domain? I did not see this information in the paper.\n\nWith regard to the method and discussion:\nThe paper discusses the connection between the proposed method and short-horizon imitation and long-horizon RL, describing the method as a midway point. It would also be interesting to see a discussion of the relation to inverse RL, which considers long-term outcomes from expert demonstrations. For example, MacGlashn & Littman propose a midway point between imitation and inverse RL [1].\nTheoretically, would it make sense to anneal k from small to large? (to learn the most effectively from the smallest amount of experience)\n\n[1] https://www.ijcai.org/Proceedings/15/Papers/519.pdf\n\n\nMinor feedback:\n- The RHS of the first inequality in the proof of Thm 3.3 seems to have an error in the indexing of i and exponent, which differs from the line before and line after\n\n**Edit after rebuttal**: I have read the other reviews and the authors' responses. My score remains the same.", "gold_annotation": {"interpretation": 0, "review_id": "BJBWMqqlf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper proposes a new theoreticaly-motivated method for combining reinforcement learning and imitation learning for acquiring policies that are as good as or superior to the expert.", "The method assumes access to an expert vale function (which could be trained using expert roll-outs) and uses the vale function to shape the reward function and alow for truncated-horizon policy search.", "The alorithm can gracefully handle suboptimaldemonstrations/vale functions, since the demonstrations are only used for reward shaping, and the experiments demonstrate faster convergence and better performance compared to RL and AggreVaTeD on a range of simulated control domains.", "The paper is well-written and easy to understand.", "My main feedback is with regard to the experiments: I appreciate that the experiments used 25 random seeds!", "This provides a convincing evalation.", "It would be nice to see experimentalresults on even higher dimensionaldomains such as the ant, humanoid, or vision-based tasks, since the experiments seem to suggest that the benefit of the proposed method is diminished in the swimmer and hopper domains compared to the simpler settings.", "Since the method uses demonstrations, it would be nice to see three additionalcomparisons: (a) training with supervised learning on the expert roll-outs, (b) initialzing THOR and AggreVaTeD (k=1) with a policy trained with supervised learning, and (c) initialzing TRPO with a policy trained with supervised learning.", "There doesn't seem to be any reason not to initialze in such a way, when expert demonstrations are available, and such an initialzation should likely provide a significant speed boost in training for al methods.", "How many demonstrations were used for training the vale function in each domain?", "I did not see this information in the paper.", "With regard to the method and discussion: The paper discusses the connection between the proposed method and short-horizon imitation and long-horizon RL, describing the method as a midway point.", "It would alo be interesting to see a discussion of the relation to inverse RL, which considers long-term outcomes from expert demonstrations.", "For example, MacGlashn & Littman propose a midway point between imitation and inverse RL [1].", "Theoreticaly, would it make sense to annealk from smal to large?", "(to learn the most effectively from the smalest amount of experience) [1] https://www.ijcai.org/Proceedings/15/Papers/519.pdf Minor feedback: - The RHS of the first ineqalty in the proof of Thm 3 3 seems to have an error in the indexing of i and exponent, which differs from the line before and line after **Edit after rebuttal*: I have read the other reviews and the authors' responses.", "My score remains the same."], "all_annotations": [{"interpretation": 0, "review_id": "BJBWMqqlf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "BJCXSFZgz", "review_text": "This paper proposes leveraging labelled controlled data to accelerate reinforcement-based learning of a control policy.  It provides two main contributions: pre-training the policy network of a DDPG agent in a supervised manner so that it begins in reasonable state-action distribution and regalurizing the Q-updates of the q-network to be biased towards existing actions.  The authors use the TORCS enviroment to demonstrate the performance of their method both in final cumulative return of the policy and speed of learning.\n\nThis paper is easy to understand but has a couple shortcomings and some fatal (but reparable) flaws:.\n\n1) When using RL please try to standardize your notation to that used by the community, it makes things much easier to read.  I would strongly suggest avoiding your notation a(x|\\Theta) and using \\pi(x) (subscripting theta or making conditional is somewhat less important).  Your a(.) function seems to be the policy here, which is invariable denoted \\pi in the RL literature.  There has been recent effort to clean up RL notation which is presented here: https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf. You have no obligation to use this notation but it does make reading of your paper much easier on others in the community.  This is more of a shortcoming than a fundamental issue.\n\n2) More fatally, you have failed to compare your algorithm's performance against benchline implementations of similar algorithms.  It is almost trivial to run DDPG on Torcs using the openAI baselines package [https://github.com/openai/baselines].  I would have loved, for example, to see the effects of simply pre-training the DDPG actor on supervised data, vs. adding your mixture loss on the critic.  Using the baselines would have (maybe) made a very compelling graph showing DDPG, DDPG + actor pre-training, and then your complete method.\n\n3) And finally, perhaps complementary to point 2), you really need to provide examples on more than one environment.  Each of these simulated environments has its own pathologies linked to determenism, reward structure, and other environment particularities.  Almost every algorithm I've seen published will often beat baselines on one environment and then fail to improve or even be wors on others, so it is important to at least run on a series of these.  Mujoco + AI Gym should make this really easy to do (for reference, I have no relatinship with OpenAI).  Running at least cartpole (which is a very well understood control task), and then perhaps reacher, swimmer, half-cheetah etc. using a known contoller as your behavior policy (behavior policy is a good term for your data-generating policy.)\n\n4) In terms of state of the art you are very close to Todd Hester et. al's paper on imitation learning, and although you cite it, you should contrast your approach more clearly with the one in that paper.  Please also have a look at some more recent work my Matej Vecerik, Todd Hester & Jon Scholz: 'Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards' for an approach that is pretty similar to yours.\n\nOverall I think your intuitions and ideas are good, but the paper does not do a good enough job justifying empirically that your approach provides any advantages over existing methods.  The idea of pre-training the policy net has been tried before (although I can't find a published reference) and in my experience will help on certain problems, and hinder on others, primarily because the policy network is already 'overfit' somewhat to the expert, and may have a hard time moving to a more optimal space.  Because of this experience I would need more supporting evidence that your method actually generalizes to more than one RL environment.", "gold_annotation": {"interpretation": 0, "review_id": "BJCXSFZgz", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper proposes leveraging labelled controlled data to accelerate reinforcement-based learning of a control policy.", "It provides two main contributions: pre-training the policy network of a DDPG agent in a supervised manner so that it begins in reasonable state-action distribution and regalrizing the Q-updates of the q-network to be biased towards existing actions.", "The authors use the TORCS enviroment to demonstrate the performance of their method both in finalcumulative return of the policy and speed of learning.", "This paper is easy to understand but has a couple shortcomings and some fatal(but reparable) flaws:.", "1) When using RL please try to standardize your notation to that used by the community, it makes things much easier to read.", "I would strongly suggest avoiding your notation a(x|\\Theta) and using \\pi(x) (subscripting theta or making conditionalis somewhat less important).", "Your a(.)", "function seems to be the policy here, which is invariable denoted \\pi in the RL literature.", "There has been recent effort to clean up RL notation which is presented here: https://sites.ualerta.ca/~szepesva/papers/RLAlgsInMDPs.pdf.", "You have no obligation to use this notation but it does make reading of your paper much easier on others in the community.", "This is more of a shortcoming than a fundamentalissue.", "2) More fataly, you have failed to compare your alorithm's performance against benchline implementations of similar alorithms.", "It is alost trivialto run DDPG on Torcs using the openAI baselines package [https://github.com/openai/baselines].", "I would have loved, for example, to see the effects of simply pre-training the DDPG actor on supervised data, vs. adding your mixture loss on the critic.", "Using the baselines would have (maybe) made a very compelling graph showing DDPG, DDPG + actor pre-training, and then your complete method.", "3) And finaly, perhaps complementary to point 2), you realy need to provide examples on more than one environment.", "Each of these simulated environments has its own pathologies linked to determenism, reward structure, and other environment particularities.", "Almost every alorithm I've seen published will often beat baselines on one environment and then fail to improve or even be wors on others, so it is important to at least run on a series of these.", "Mujoco + AI Gym should make this realy easy to do (for reference, I have no relatinship with OpenAI).", "Running at least cartpole (which is a very well understood control task), and then perhaps reacher, swimmer, hal-cheetah etc using a known contoller as your behavior policy (behavior policy is a good term for your data-generating policy.)", "4) In terms of state of the art you are very close to Todd Hester et.", "als paper on imitation learning, and alhough you cite it, you should contrast your approach more clearly with the one in that paper.", "Please alo have a look at some more recent work my Matej Vecerik, Todd Hester & Jon Scholz: 'Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards' for an approach that is pretty similar to yours.", "Overal I think your intuitions and ideas are good, but the paper does not do a good enough job justifying empiricaly that your approach provides any advantages over existing methods.", "The idea of pre-training the policy net has been tried before (alhough I can't find a published reference) and in my experience will help on certain problems, and hinder on others, primarily because the policy network is aleady 'overfit' somewhat to the expert, and may have a hard time moving to a more optimalspace.", "Because of this experience I would need more supporting evidence that your method actualy generalzes to more than one RL environment."], "all_annotations": [{"interpretation": 0, "review_id": "BJCXSFZgz", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "BJDxbMvez", "review_text": "The authors propose a generative method that can produce images along a hierarchy of specificity, i.e. both when all relevant attributes are specified, and when some are left undefined, creating a more abstract generation task. \n\nPros:\n+ The results demonstrating the method's ability to generate results for (1) abstract and (2) novel/unseen attribute descriptions, are generally convincing. Both quantitative and qualitative results are provided. \n+ The paper is fairly clear.\n\nCons:\n- It is unclear how to judge diversity qualitatively, e.g. in Fig. 4(b).\n- Fig. 5 could be more convincing; \"bushy eyebrows\" is a difficult attribute to judge, and in the abstract generation when that is the only attribute specified, it is not clear how good the results are.\n", "gold_annotation": {"interpretation": 1, "review_id": "BJDxbMvez", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["The authors propose a generative method that can produce images alng a hierarchy of specificity, i e both when al relevant attributes are specified, and when some are left undefined, creating a more abstract generation task.", "Pros: + The results demonstrating the method's ability to generate results for (1) abstract and (2) novel/unseen attribute descriptions, are generaly convincing.", "Both quantitative and qualtative results are provided.", "+ The paper is fairly clear.", "Cons: - It is unclear how to judge diversity qualtatively, e g in fig 4(b).", "- fig 5 could be more convincing; \"bushy eyebrows\" is a difficult attribute to judge, and in the abstract generation when that is the only attribute specified, it is not clear how good the results are."], "all_annotations": [{"interpretation": 1, "review_id": "BJDxbMvez", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "BJGq_QclM", "review_text": "This paper leverages how deep Bayesian NNs, in the limit of infinite width, are Gaussian processes (GPs). After characterizing the kernel function, this allows us to use the GP framework for prediction, model selection, uncertainty estimation, etc.\n\n\n- Pros of this work\n\nThe paper provides a specific method to efficiently compute the covariance matrix of the equivalent GP and shows experimentally on CIFAR and MNIST the benefits of using the this GP as opposed to a finite-width non-Bayesian NN.\n\nThe provided phase analysis and its relation to the depth of the network is also very interesting.\n\nBoth are useful contributions as long as deep wide Bayesian NNs are concerned. A different question is whether that regime is actually useful.\n\n\n- Cons of this work\n\nAlthough this work introduces a new GP covariance function inspired by deep wide NNs, I am unconvinced of the usefulness of this regime for the cases in which deep learning is useful. \n\nFor instance, looking at the experiments, we can see that on MNIST-50k (the one with most data, and therefore, the one that best informs about the \"true\" underlying NN structure) the inferred depth is 1 for the GP and 2 for the NN, i.e., not deep. Similarly for CIFAR, where only up to depth 3 is used. None of these results beat state-of-the-art deep NNs.\n\nAlso, the results about the phase structure show how increased depth makes the parameter regime in which these networks work more and more constrained. \n\nIn [1], it is argued that kernel machines with fixed kernels do not learn a hierarchical representation. And such representation is generally regarded as essential for the success of deep learning. \n\nMy impression is that the present line of work will not be relevant for deep learning and will not beat state-of-the-art results because of the lack of a structured prior. In that sense, to me this work is more of a negative result informing that to be successful, deep Bayesian NNs should not be wide and should have more structure to avoid reaching the GP regime.\n\n\n- Other comments:\n\nIn Fig. 5, use a consistent naming for the axes (bias and variances).\n\nIn Fig. 1, I didn't find the meaning of the acronym NN with no specified width.\n\nDoes the unit norm normalization used to construct the covariance disallow ARD input selection?\n\n\n[1] Yoshua Bengio, Olivier Delalleau, and Nicolas Le Roux. The Curse of Dimensionality for Local Kernel Machines. 2005.", "gold_annotation": {"interpretation": 1, "review_id": "BJGq_QclM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["This paper leverages how deep Bayesian NNs, in the limit of infinite width, are Gaussian processes (GPs).", "After characterizing the kernel function, this alows us to use the GP framework for prediction, model selection, uncertainty estimation, etc - Pros of this work The paper provides a specific method to efficiently compute the covariance matrix of the eqivalnt GP and shows experimentaly on CIFAR and MNIST the benefits of using the this GP as opposed to a finite-width non-Bayesian NN.", "The provided phase analsis and its relation to the depth of the network is alo very interesting.", "Both are useful contributions as long as deep wide Bayesian NNs are concerned.", "A different question is whether that regime is actualy useful.", "- Cons of this work Although this work introduces a new GP covariance function inspired by deep wide NNs, I am unconvinced of the usefulness of this regime for the cases in which deep learning is useful.", "For instance, looking at the experiments, we can see that on MNIST-50k (the one with most data, and therefore, the one that best informs about the \"true\" underlying NN structure) the inferred depth is 1 for the GP and 2 for the NN, i e , not deep.", "Similarly for CIFAR, where only up to depth 3 is used.", "None of these results beat state-of-the-art deep NNs.", "Also, the results about the phase structure show how increased depth makes the parameter regime in which these networks work more and more constrained.", "In [1], it is argued that kernel machines with fixed kernels do not learn a hierarchicalrepresentation.", "And such representation is generaly regarded as essentialfor the success of deep learning.", "My impression is that the present line of work will not be relevant for deep learning and will not beat state-of-the-art results because of the lack of a structured prior.", "In that sense, to me this work is more of a negative result informing that to be successful, deep Bayesian NNs should not be wide and should have more structure to avoid reaching the GP regime.", "- Other comments: In fig 5, use a consistent naming for the axes (bias and variances).", "In fig 1, I didn't find the meaning of the acronym NN with no specified width.", "Does the unit norm normalzation used to construct the covariance disalow ARD input selection?", "[1] Yoshua Bengio, Olivier Delaleau, and Nicolas Le Roux.", "The Curse of Dimensionalty for LocalKernel Machines.", "2005."], "all_annotations": [{"interpretation": 1, "review_id": "BJGq_QclM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "BJHwtGogM", "review_text": "The paper proposes data augmentation as an alternative to commonly used regularisation techniques like weight decay and dropout, and shows for a few reference models / tasks that the same generalization performance can be achieved using only data augmentation.\n\nI think it's a great idea to investigate the effects of data augmentation more thoroughly. While it is a technique that is often used in literature, there hasn't really been any work that provides rigorous comparisons with alternative approaches and insights into its inner workings. Unfortunately I feel that this paper falls short of achieving this.\n\nExperiments are conducted on two fairly similar tasks (image classification on CIFAR-10 and CIFAR-100), with two different network architectures. This is a bit meager to be able to draw general conclusions about the properties of data augmentation. Given that this work tries to provide insight into an existing common practice, I think it is fair to expect a much stronger experimental section. In section 2.1.1 it is stated that this was a conscious choice because simplicity would lead to clearer conclusions, but I think the conclusions would be much more valuable if variety was the objective instead of simplicity, and if larger-scale tasks were also considered.\n\nAnother concern is that the narrative of the paper pits augmentation against all other regularisation techniques, whereas more typically these will be used in conjunction. It is however very interesting that some of the results show that augmentation alone can sometimes be enough.\n\nI think extending the analysis to larger datasets such as ImageNet, as is suggested at the end of section 3, and probably also to different problems than image classification, is going to be essential to ensure that the conclusions drawn hold weight.\n\n\n\nComments:\n\n- The distinction between \"explicit\" and \"implicit\" regularisation is never clearly enunciated. A bunch of examples are given for both, but I found it tricky to understand the difference from those. Initially I thought it reflected the intention behind the use of a given technique; i.e. weight decay is explicit because clearly regularisation is its primary purpose -- whereas batch normalisation is implicit because its regularisation properties are actually a side effect. However, the paper then goes on to treat data augmentation as distinct from other explicit regularisation techniques, so I guess this is not the intended meaning. Please clarify this, as the terms crop up quite often throughout the paper. I suspect that the distinction is somewhat arbitrary and not that meaningful.\n\n- In the abstract, it is already implied that data augmentation is superior to certain other regularisation techniques because it doesn't actually reduce the capacity of the model. But this ignores the fact that some of the model's excess capacity will be used to model out-of-distribution data (w.r.t. the original training distribution) instead. Data augmentation always modifies the distribution of the training data. I don't think it makes sense to imply that this is always preferable over reducing model capacity explicitly. This claim is referred to a few times throughout the work.\n\n- It could be more clearly stated that the reason for the regularising effect of batch normalisation is the noise in the batch estimates for mean and variance.\n\n- Some parts of the introduction could be removed because they are obvious, at least to an ICLR audience (like \"the model would not be regularised if alpha (the regularisation parameter) equals 0\").\n\n- The experiments with smaller dataset sizes would be more interesting if smaller percentages were used. 50% / 80% / 100% are all on the same order of magnitude and this setting is not very realistic. In practice, when a dataset is \"too small\" to be able to train a network that solves a problem reliably, it will generally be one or more orders of magnitude too small, not 2x too small.\n\n- The choices of hyperparameters for \"light\" and \"heavy\" motivation seem somewhat arbitrary and are not well motivated. Some parameters which are sampled uniformly at random should be probably be sampled log-uniformly instead, because they represent scale factors. It should also be noted that much more extreme augmentation strategies have been used for this particular task in literature, in combination with padding (for example by Graham). It would be interesting to include this setting in the experiments as well.\n\n- On page 7 it is stated that \"when combined with explicit regularization, the results are much worse than without it\", but these results are omitted from the table. This is unfortunate because it is a very interesting observation, that runs counter to the common practice of combining all these regularisation techniques together (e.g. L2 + dropout + data augmentation is a common combination). Delving deeper into this could make the paper a lot stronger.\n\n- It is not entirely true that augmentation parameters depend only on the training data and not the architecture (last paragraph of section 2.4). Clearly more elaborate architectures benefit more from data augmentation, and might need heavier augmentation to perform optimally because they are more prone to overfitting (this is in fact stated earlier on in the paper as well). It is of course true that these hyperparameters tend to be much more robust to architecture changes than those of other regularisation techniques such as dropout and weight decay. This increased robustness is definitely useful and I think this is also adequately demonstrated in the experiments.\n\n- Phrases like \"implicit regularization operates more effectively at capturing reality\" are too vague to be meaningful.\n\n- Note that weight decay has also been found to have side effects related to optimization (e.g. in \"Imagenet classification with deep convolutional neural networks\", Krizhevsky et al.)\n\nREVISION: I applaud the effort the authors have put in to address many of my and the other reviewers' comments. I think they have done so adequately for the most part, so I've decided to raise the rating from 3 to 5, for what it's worth.\n\nThe reason I have decided not to raise it beyond that, is that I still feel that for a paper like this, which studies an existing technique in detail, the experimental side needs to be significantly stronger. While ImageNet experiments may be a lot of work, some other (smaller) additional datasets would also have provided more interesting evidence. CIFAR-10 and CIFAR-100 are so similar that they may as well be considered variants of the same dataset, at least in the setting where they are used here.\n\nI do really appreciate the variety in the experiments in terms of network architectures, regularisation techniques, etc. but I think for real-world relevance, variety in problem settings (i.e. datasets) is simply much more important. I think it would be fine if additional experiments on other datasets were not varied along all these other axes, to cut down on the amount of work this would involve. But not including them at all unfortunately makes the results much less impactful.", "gold_annotation": {"interpretation": 1, "review_id": "BJHwtGogM", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["The paper proposes data augmentation as an alernative to commonly used regularisation techniques like weight decay and dropout, and shows for a few reference models / tasks that the same generalzation performance can be achieved using only data augmentation.", "I think it's a great idea to investigate the effects of data augmentation more thoroughly.", "While it is a technique that is often used in literature, there hasn't realy been any work that provides rigorous comparisons with alernative approaches and insights into its inner workings.", "Unfortunately I feel that this paper fals short of achieving this.", "Experiments are conducted on two fairly similar tasks (image classification on CIFAR-10 and CIFAR-100), with two different network architectures.", "This is a bit meager to be able to draw generalconclusions about the properties of data augmentation.", "Given that this work tries to provide insight into an existing common practice, I think it is fair to expect a much stronger experimentalsecion.", "In secion 2 1 1 it is stated that this was a conscious choice because simplicity would lead to clearer conclusions, but I think the conclusions would be much more valable if variety was the objective instead of simplicity, and if larger-scal tasks were alo considered.", "Another concern is that the narrative of the paper pits augmentation against al other regularisation techniques, whereas more typicaly these will be used in conjunction.", "It is however very interesting that some of the results show that augmentation alne can sometimes be enough.", "I think extending the analsis to larger datasets such as ImageNet, as is suggested at the end of secion 3, and probably alo to different problems than image classification, is going to be essentialto ensure that the conclusions drawn hold weight.", "Comments: - The distinction between \"explicit\" and \"implicit\" regularisation is never clearly enunciated.", "A bunch of examples are given for both, but I found it tricky to understand the difference from those.", "Initialy I thought it reflected the intention behind the use of a given technique; i e weight decay is explicit because clearly regularisation is its primary purpose -- whereas batch normalsation is implicit because its regularisation properties are actualy a side effect.", "However, the paper then goes on to treat data augmentation as distinct from other explicit regularisation techniques, so I guess this is not the intended meaning.", "Please clarify this, as the terms crop up quite often throughout the paper.", "I suspect that the distinction is somewhat arbitrary and not that meaningful.", "- In the abstract, it is aleady implied that data augmentation is superior to certain other regularisation techniques because it doesn't actualy reduce the capacity of the model.", "But this ignores the fact that some of the model's excess capacity will be used to model out-of-distribution data (w r t the originaltraining distribution) instead.", "Data augmentation alays modifies the distribution of the training data.", "I don't think it makes sense to imply that this is alays preferable over reducing model capacity explicitly.", "This claim is referred to a few times throughout the work.", "- It could be more clearly stated that the reason for the regularising effect of batch normalsation is the noise in the batch estimates for mean and variance.", "- Some parts of the introduction could be removed because they are obvious, at least to an ICLR audience (like \"the model would not be regularised if alha (the regularisation parameter) eqal 0\").", "- The experiments with smaler dataset sizes would be more interesting if smaler percentages were used.", "50% / 80% / 100% are al on the same order of magnitude and this setting is not very realstic.", "In practice, when a dataset is \"too smal\" to be able to train a network that solves a problem reliably, it will generaly be one or more orders of magnitude too smal, not 2x too smal.", "- The choices of hyperparameters for \"light\" and \"heavy\" motivation seem somewhat arbitrary and are not well motivated.", "Some parameters which are sampled uniformly at random should be probably be sampled log-uniformly instead, because they represent scal factors.", "It should alo be noted that much more extreme augmentation strategies have been used for this particular task in literature, in combination with padding (for example by Graham).", "It would be interesting to include this setting in the experiments as well.", "- On page 7 it is stated that \"when combined with explicit regularization, the results are much worse than without it\", but these results are omitted from the table.", "This is unfortunate because it is a very interesting observation, that runs counter to the common practice of combining al these regularisation techniques together (e g L2 + dropout + data augmentation is a common combination).", "Delving deeper into this could make the paper a lot stronger.", "- It is not entirely true that augmentation parameters depend only on the training data and not the architecture (last paragraph of secion 2 4).", "Clearly more elaborate architectures benefit more from data augmentation, and might need heavier augmentation to perform optimaly because they are more prone to overfitting (this is in fact stated earlier on in the paper as well).", "It is of course true that these hyperparameters tend to be much more robust to architecture changes than those of other regularisation techniques such as dropout and weight decay.", "This increased robustness is definitely useful and I think this is alo adeqately demonstrated in the experiments.", "- Phrases like \"implicit regularization operates more effectively at capturing realty\" are too vague to be meaningful.", "- Note that weight decay has alo been found to have side effects related to optimization (e g in \"Imagenet classification with deep convolutionalneuralnetworks\", Krizhevsky et al) REVISION: I applaud the effort the authors have put in to address many of my and the other reviewers' comments.", "I think they have done so adeqately for the most part, so I've decided to raise the rating from 3 to 5, for what it's worth.", "The reason I have decided not to raise it beyond that, is that I still feel that for a paper like this, which studies an existing technique in detail, the experimentalside needs to be significantly stronger.", "While ImageNet experiments may be a lot of work, some other (smaler) additionaldatasets would alo have provided more interesting evidence.", "CIFAR-10 and CIFAR-100 are so similar that they may as well be considered variants of the same dataset, at least in the setting where they are used here.", "I do realy appreciate the variety in the experiments in terms of network architectures, regularisation techniques, etc but I think for realworld relevance, variety in problem settings (i e datasets) is simply much more important.", "I think it would be fine if additionalexperiments on other datasets were not varied alng al these other axes, to cut down on the amount of work this would involve.", "But not including them at al unfortunately makes the results much less impactful."], "all_annotations": [{"interpretation": 1, "review_id": "BJHwtGogM", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "BJJTve9gM", "review_text": "This paper proposes to adapt convnet representations to new tasks while avoiding catastrophic forgetting by learning a per-task \u201ccontroller\u201d specifying weightings of the convolution-al filters throughout the network while keeping the filters themselves fixed.\n\n\nPros\n\nThe proposed approach is novel and broadly applicable.  By definition it maintains the exact performance on the original task, and enables the network to transfer to new tasks using a controller with a small number of parameters (asymptotically smaller than that of the base network).\n\nThe method is tested on a number of datasets (each used as source and target) and shows good transfer learning performance on each one.  A number of different fine-tuning regimes are explored.\n\nThe paper is mostly clear and well-written (though with a few typos that should be fixed).\n\n\nCons/Questions/Suggestions\n\nThe distinction between the convolutional and fully-connected layers (called \u201cclassifiers\u201d) in the approach description (sec 3) is somewhat arbitrary -- after all, convolutional layers are a generalization of fully-connected layers. (This is hinted at by the mention of fully convolutional networks.)  The method could just as easily be applied to learn a task-specific rotation of the fully-connected layer weights.  A more systematic set of experiments could compare learning the proposed weightings on the first K layers of the network (for K={0, 1, \u2026, N}) and learning independent weights for the latter N-K layers, but I understand this would be a rather large experimental burden.\n\nWhen discussing the controller initialization (sec 4.3), it\u2019s stated that the diagonal init works the best, and that this means one only needs to learn the diagonals to get the best results.  Is this implying that the gradients wrt off-diagonal entries of the controller weight matrix are 0 under the diagonal initialization, hence the off-diagonal entries remain zero after learning?  It\u2019s not immediately clear to me whether this is the case -- it could help to clarify this in the text.\n\nIf the off-diag gradients are indeed 0 under the diag init, it could also make sense to experiment with an \u201cidentity+noise\u201d initialization of the controller matrix, which might give the best of both worlds in terms of flexibility and inductive bias to maintain the original representation. (Equivalently, one could treat the controller-weighted filters as a \u201cresidual\u201d term on the original filters F with the controller weights W initialized to noise, with the final filters being F+(W\\crossF) rather than just W\\crossF.)\n\nThe dataset classifier (sec 4.3.4) could be learnt end-to-end by using a softmax output of the dataset classifier as the alpha weighting. It would be interesting to see how this compares with the hard thresholding method used here.  (As an intermediate step, the performance could also be measured with the dataset classifier trained in the same way but used as a soft weighting, rather than the hard version rounding alpha to 0 or 1.)\n\n\nOverall, the paper is clear and the proposed method is sensible, novel, and evaluated reasonably thoroughly.", "gold_annotation": {"interpretation": 0, "review_id": "BJJTve9gM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper proposes to adapt convnet representations to new tasks while avoiding catastrophic forgetting by learning a per-task \u201ccontroller\u201d specifying weightings of the convolution-alfilters throughout the network while keeping the filters themselves fixed.", "Pros The proposed approach is novel and broadly applicable.", "By definition it maintains the exact performance on the originaltask, and enables the network to transfer to new tasks using a controller with a smal number of parameters (asymptoticaly smaler than that of the base network).", "The method is tested on a number of datasets (each used as source and target) and shows good transfer learning performance on each one.", "A number of different fine-tuning regimes are explored.", "The paper is mostly clear and well-written (though with a few typos that should be fixed).", "Cons/Questions/Suggestions The distinction between the convolutionaland fully-connected layers (caled \u201cclassifiers\u201d) in the approach description (sec3) is somewhat arbitrary -- after al, convolutionallayers are a generalzation of fully-connected layers.", "(This is hinted at by the mention of fully convolutionalnetworks.)", "The method could just as easily be applied to learn a task-specific rotation of the fully-connected layer weights.", "A more systematic set of experiments could compare learning the proposed weightings on the first K layers of the network (for K={0, 1, \u2026, N}) and learning independent weights for the latter N-K layers, but I understand this would be a rather large experimentalburden.", "When discussing the controller initialzation (sec4 3), it\u2019s stated that the diagonalinit works the best, and that this means one only needs to learn the diagonal to get the best results.", "Is this implying that the gradients wrt off-diagonalentries of the controller weight matrix are 0 under the diagonalinitialzation, hence the off-diagonalentries remain zero after learning?", "It\u2019s not immediately clear to me whether this is the case -- it could help to clarify this in the text.", "If the off-diag gradients are indeed 0 under the diag init, it could alo make sense to experiment with an \u201cidentity+noise\u201d initialzation of the controller matrix, which might give the best of both worlds in terms of flexibility and inductive bias to maintain the originalrepresentation.", "(eqivalntly, one could treat the controller-weighted filters as a \u201cresidual term on the originalfilters F with the controller weights W initialzed to noise, with the finalfilters being F+(W\\crossF) rather than just W\\crossF.)", "The dataset classifier (sec4 3 4) could be learnt end-to-end by using a softmax output of the dataset classifier as the alha weighting.", "It would be interesting to see how this compares with the hard thresholding method used here.", "(As an intermediate step, the performance could alo be measured with the dataset classifier trained in the same way but used as a soft weighting, rather than the hard version rounding alha to 0 or 1 ) Overal, the paper is clear and the proposed method is sensible, novel, and evalated reasonably thoroughly."], "all_annotations": [{"interpretation": 0, "review_id": "BJJTve9gM", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "BJQD_I_eM", "review_text": "The paper proposes an analysis on different adaptive regularization techniques for deep transfer learning. \nSpecifically it focuses on the use of an L2-SP condition that constraints the new parameters to be close to the\nones previously learned when solving a source task. \n\n+ The paper is easy to read and well organized\n+ The advantage of the proposed regularization against the more standard L2 regularization is clearly visible \nfrom the experiments\n\n- The idea per se is not new: there is a list of shallow learning methods for transfer learning based \non the same L2 regularization choice\n[Cross-Domain Video Concept Detection using Adaptive SVMs, ACM Multimedia 2007]\n[Learning categories from few examples with multi model knowledge transfer, PAMI 2014]\n[From n to n+ 1: Multiclass transfer incremental learning, CVPR 2013]\nI believe this literature should be discussed in the related work section\n\n- It is true that the L2-SP-Fisher regularization was designed for life-long learning cases with a \nfixed task, however, this solution seems to work quite well in the proposed experimental settings. \nFrom my understanding L2-SP-Fisher can be considered the best competitor of L2-SP so I think\nthe paper should dedicate more space to the analysis of their difference and similarities both\nfrom the theoretical and experimental point of view. For instance:\n--  adding the L2-SP-Fisher results in table 2\n--  repeating the experiments of figure 2 and figure 3 with L2-SP-Fisher\n\n\n\n\n", "gold_annotation": {"interpretation": 0, "review_id": "BJQD_I_eM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper proposes an analsis on different adaptive regularization techniques for deep transfer learning.", "Specificaly it focuses on the use of an L2-SP condition that constraints the new parameters to be close to the ones previously learned when solving a source task.", "+ The paper is easy to read and well organized + The advantage of the proposed regularization against the more standard L2 regularization is clearly visible from the experiments - The idea per se is not new: there is a list of shalow learning methods for transfer learning based on the same L2 regularization choice [Cross-Domain Video Concept Detection using Adaptive SVMs, ACM Multimedia 2007] [Learning categories from few examples with multi model knowledge transfer, PAMI 2014] [From n to n+ 1: Multiclass transfer incrementallearning, CVPR 2013] I believe this literature should be discussed in the related work secion - It is true that the L2-SP-Fisher regularization was designed for life-long learning cases with a fixed task, however, this solution seems to work quite well in the proposed experimentalsettings.", "From my understanding L2-SP-Fisher can be considered the best competitor of L2-SP so I think the paper should dedicate more space to the analsis of their difference and similarities both from the theoreticaland experimentalpoint of view.", "For instance: -- adding the L2-SP-Fisher results in table 2 -- repeating the experiments of figre 2 and figre 3 with L2-SP-Fisher"], "all_annotations": [{"interpretation": 0, "review_id": "BJQD_I_eM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "BJSfkUNzf", "review_text": "The paper addresses the problem of tensor decomposition which is relevant and interesting. The paper proposes Tensor Ring (TR) decomposition which improves over and bases on the Tensor Train (TT) decomposition method. TT decomposes a tensor in to a sequences of latent tensors where the first and last tensors are a 2D matrices. \n\nThe proposed TR method generalizes TT in that the first and last tensors are also 3rd-order tensors instead of 2nd-order. I think such generalization is interesting but the innovation seems to be very limited. \n\nThe paper develops three different kinds of solvers for TR decomposition, i.e., SVD, ALS and SGD. All of these are well known methods. \n\nFinally, the paper provides experimental results on synthetic data (3 oscillated functions) and image data (few sampled images). I think the paper could be greatly improved by providing more experiments and ablations to validate the benefits of the proposed methods.\n\nPlease refer to below for more comments and questions.\n\n-- The rating has been updated.\n\nPros:\n1. The topic is interesting.\n2. The generalization over TT makes sense.\n\nCons:\n1. The writing of the paper could be improved and more clear: the conclusions on inner product and F-norm can be integrated into \"Theorem 5\". And those \"theorems\" in section 4 are just some properties from previous definitions; they are not theorems. \n2. The property of TR decomposition is that the tensors can be shifted (circular invariance). This is an interesting property and it seems to be the major strength of TR over TT. I think the paper could be significantly improved by providing more applications of this property in both theory and experiments.\n3. As the number of latent tensors increase, the ALS method becomes much worse approximation of the original optimization. Any insights or results on the optimization performance vs. the number of latent tensors?\n4. Also, the paper mentions Eq. 5 (ALS) is optimized by solving d subproblems alternatively. I think this only contains a single round of optimization. Should ALS be applied repeated (each round solves d problems) until convergence?\n5. What is the memory consumption for different solvers?\n6. SGD also needs to update at least d times for all d latent tensors. Why is the complexity O(r^3) independent of the parameter d?\n7. The ALS is so slow (if looking at the results in section 5.1), which becomes not practical. The experimental part could be improved by providing more results and description about a guidance on how to choose from different solvers.\n8. What does \"iteration\" mean in experimental results such as table 2? Different algorithms have different cost for \"each iteration\" so comparing that seems not fair. The results could make more sense by providing total time consumptions and time cost per iteration. also applies to table 4.\n9. Why is the \\epsion in table 3 not consistent? Why not choose \\epsion = 9e-4 and \\epsilon=2e-15 for tensorization?\n10. Also, table 3 could be greatly improved by providing more ablations such as results for (n=16, d=8), (n=4, d=4), etc. That could help readers to better understand the effect of TR.\n11. Section 5.3 could be improved by providing a curve (compression vs. error) instead of just providing a table of sampled operating points.\n12. The paper mentions the application of image representation but only experiment on 32x32 images. How does the proposed method handle large images? Otherwise, it does not seem to be a practical application.\n13. Figure 5: Are the RSE measures computed over the whole CIFAR-10 dataset or the displayed images?\n\nMinor:\n- Typo: Page 4 Line 7 \"Note that this algorithm use the similar strategy\": use -> uses", "gold_annotation": {"interpretation": 0, "review_id": "BJSfkUNzf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The paper addresses the problem of tensor decomposition which is relevant and interesting.", "The paper proposes Tensor Ring (TR) decomposition which improves over and bases on the Tensor Train (TT) decomposition method.", "TT decomposes a tensor in to a seqences of latent tensors where the first and last tensors are a 2D matrices.", "The proposed TR method generalzes TT in that the first and last tensors are alo 3rd-order tensors instead of 2nd-order.", "I think such generalzation is interesting but the innovation seems to be very limited.", "The paper develops three different kinds of solvers for TR decomposition, i e , SVD, ALS and SGD.", "All of these are well known methods.", "Finaly, the paper provides experimentalresults on synthetic data (3 oscillated functions) and image data (few sampled images).", "I think the paper could be greatly improved by providing more experiments and ablations to valdate the benefits of the proposed methods.", "Please refer to below for more comments and questions.", "-- The rating has been updated.", "Pros: 1, The topic is interesting.", "2, The generalzation over TT makes sense.", "Cons: 1, The writing of the paper could be improved and more clear: the conclusions on inner product and F-norm can be integrated into \"Theorem 5\".", "And those \"theorems\" in secion 4 are just some properties from previous definitions; they are not theorems.", "2, The property of TR decomposition is that the tensors can be shifted (circular invariance).", "This is an interesting property and it seems to be the major strength of TR over TT.", "I think the paper could be significantly improved by providing more applications of this property in both theory and experiments.", "3, As the number of latent tensors increase, the ALS method becomes much worse approximation of the originaloptimization.", "Any insights or results on the optimization performance vs. the number of latent tensors?", "4, Also, the paper mentions eq 5 (ALS) is optimized by solving d subproblems alernatively.", "I think this only contains a single round of optimization.", "Should ALS be applied repeated (each round solves d problems) until convergence?", "5, What is the memory consumption for different solvers?", "6, SGD alo needs to update at least d times for al d latent tensors.", "Why is the complexity O(r^3) independent of the parameter d?", "7, The ALS is so slow (if looking at the results in secion 5 1), which becomes not practical The experimentalpart could be improved by providing more results and description about a guidance on how to choose from different solvers.", "8, What does \"iteration\" mean in experimentalresults such as table 2?", "Different alorithms have different cost for \"each iteration\" so comparing that seems not fair.", "The results could make more sense by providing totaltime consumptions and time cost per iteration.", "alo applies to table 4, 9, Why is the \\epsion in table 3 not consistent?", "Why not choose \\epsion = 9e-4 and \\epsilon=2e-15 for tensorization?", "10, Also, table 3 could be greatly improved by providing more ablations such as results for (n=16, d=8), (n=4, d=4), etc That could help readers to better understand the effect of TR.", "11, secion 5 3 could be improved by providing a curve (compression vs. error) instead of just providing a table of sampled operating points.", "12, The paper mentions the application of image representation but only experiment on 32x32 images.", "How does the proposed method handle large images?", "Otherwise, it does not seem to be a practicalapplication.", "13, figre 5: Are the RSE measures computed over the whole CIFAR-10 dataset or the displayed images?", "Minor: - Typo: Page 4 Line 7 \"Note that this alorithm use the similar strategy\": use -> uses"], "all_annotations": [{"interpretation": 0, "review_id": "BJSfkUNzf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "BJfU-qDeG", "review_text": "After reading rebuttals from the authors: The authors have addressed all of my concerns. THe additional experiments are a good addition.\n\n************************\nThe authors provide an algorithm-agnostic active learning algorithm for multi-class classification. The core technique is to construct a coreset of points whose labels inform the labels of other points.  The coreset construction requires one to construct a set of  points which can cover the entire dataset. While this is NP-hard problem in general, the greedy algorithm is 2-approximate. The authors use a variant of the greedy algorithm along with bisection search to solve a series of feasibility problems to obtain a good cover of the dataset each time.  This cover tells us which points are to be queried. The reason why choosing the cover is a good idea is because under suitable Lipschitz continuity assumption the generalization error can be controlled via an appropriate value of the covering radius in the data space.  The authors use the coreset construction with a CNN to demonstrate an active learning algorithm for multi-class classification. \nThe experimental results are convincing enough to show that it outperforms other active learning algorithms. However, I have a few major and minor comments.\n\nMajor comments:\n\n1. The proof of Lemma 1 is incomplete. We need the Lipschitz constant of the loss function. The loss function is a function of the CNN function and the true label. The proof of lemma 1 only establishes the Lipschitz constant of the CNN function. Some more extra work is needed to derive the lipschitz constant of the loss function from the CNN function. \n\n2. The statement of Prop 1 seems a bit confusing to me. the hypothsis says that the loss on the coreset = 0. But the equation in proposition 1 also includes the loss on the coreset. Why is this term included. Is this term not equal to 0?\n\n3. Some important works are missing.  Especially works related to pool based active learning, and landmark results on labell complexity of agnostic active learning.\nUPAL: Unbiased Pool based active learning by Ganti & Gray. http://proceedings.mlr.press/v22/ganti12/ganti12.pdf\nEfficient active learning of half-spaces by Gonen et al. http://www.jmlr.org/papers/volume14/gonen13a/gonen13a.pdf\nA bound on the label complexity of agnostic active learning. http://www.machinelearning.org/proceedings/icml2007/papers/375.pdf\n\n4.  The authors use L_2 loss as their objective function. This is a bit of a weird choice given that they are dealing with multi-class classification and the output layer is a sigmoid layer, making it a natural fit to work with something like a cross-entropy loss function. I guess the theoretical results do not extend to cross-entropy loss, but the authors do not mention these points anywhere in the paper. For example, the ladder network, which is one of the networks used by the authors is a network that uses cross-entropy for training.\n\nMinor-comment: \n1. The feasibility program in (6) is an MILP. However, the way it is written it does not look like an MILP. It would have been great had the authors mentioned that u_j \\in {0,1}. \n\n2. The authors write on page 4, \"Moreover, zero training error can be enforced by converting average loss into maximal loss\". It is not clear to me what the authors mean here. For example, can I replace the average error in proposition 1, by maximal loss? Why can I do that? Why would that result in zero training error?\n\nOn the whole this is interesting work and the results are very nice. But, the proof for Lemma 1 seems incomplete to me, and some choices (such as choice of loss function) are unjustified. Also, important references in active learning literature are missing.", "gold_annotation": {"interpretation": 0, "review_id": "BJfU-qDeG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["After reading rebuttal from the authors: The authors have addressed al of my concerns.", "THe additionalexperiments are a good addition.", "************************ The authors provide an alorithm-agnostic active learning alorithm for multi-class classification.", "The core technique is to construct a coreset of points whose labels inform the labels of other points.", "The coreset construction reqires one to construct a set of points which can cover the entire dataset.", "While this is NP-hard problem in general the greedy alorithm is 2-approximate.", "The authors use a variant of the greedy alorithm alng with bisecion search to solve a series of feasibility problems to obtain a good cover of the dataset each time.", "This cover tells us which points are to be queried.", "The reason why choosing the cover is a good idea is because under suitable Lipschitz continuity assumption the generalzation error can be controlled via an appropriate vale of the covering radius in the data space.", "The authors use the coreset construction with a CNN to demonstrate an active learning alorithm for multi-class classification.", "The experimentalresults are convincing enough to show that it outperforms other active learning alorithms.", "However, I have a few major and minor comments.", "Major comments: 1, The proof of Lemma 1 is incomplete.", "We need the Lipschitz constant of the loss function.", "The loss function is a function of the CNN function and the true label.", "The proof of lemma 1 only establishes the Lipschitz constant of the CNN function.", "Some more extra work is needed to derive the lipschitz constant of the loss function from the CNN function.", "2, The statement of Prop 1 seems a bit confusing to me.", "the hypothsis says that the loss on the coreset = 0, But the eqation in proposition 1 alo includes the loss on the coreset.", "Why is this term included.", "Is this term not eqalto 0?", "3, Some important works are missing.", "Especialy works related to pool based active learning, and landmark results on labell complexity of agnostic active learning.", "UPAL: Unbiased Pool based active learning by Ganti & Gray.", "http://proceedings.mlr.press/v22/ganti12/ganti12.pdf Efficient active learning of hal-spaces by Gonen et al http://www.jmlr.org/papers/volume14/gonen13a/gonen13a.pdf A bound on the label complexity of agnostic active learning.", "http://www.machinelearning.org/proceedings/icml2007/papers/375.pdf 4, The authors use L_2 loss as their objective function.", "This is a bit of a weird choice given that they are dealng with multi-class classification and the output layer is a sigmoid layer, making it a naturalfit to work with something like a cross-entropy loss function.", "I guess the theoreticalresults do not extend to cross-entropy loss, but the authors do not mention these points anywhere in the paper.", "For example, the ladder network, which is one of the networks used by the authors is a network that uses cross-entropy for training.", "Minor-comment: 1, The feasibility program in (6) is an MILP.", "However, the way it is written it does not look like an MILP.", "It would have been great had the authors mentioned that u_j \\in {0,1}.", "2, The authors write on page 4, \"Moreover, zero training error can be enforced by converting average loss into maximalloss\".", "It is not clear to me what the authors mean here.", "For example, can I replace the average error in proposition 1, by maximalloss?", "Why can I do that?", "Why would that result in zero training error?", "On the whole this is interesting work and the results are very nice.", "But, the proof for Lemma 1 seems incomplete to me, and some choices (such as choice of loss function) are unjustified.", "Also, important references in active learning literature are missing."], "all_annotations": [{"interpretation": 0, "review_id": "BJfU-qDeG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "BJiW7IkZM", "review_text": "In this work, the objective is to analyze the robustness of a neural network to any sort of attack.\n\nThis is measured by naturally linking the robustness of the network to the local Lipschitz properties of the network function. This approach is quite standard in learning theory, I am not aware of how original this point of view is within the deep learning community.\n\nThis is estimated by obtaining values of the norm of the gradient (also naturally linked to the Lipschitz properties of the function) by backpropagation. This is again a natural idea.", "gold_annotation": {"interpretation": 0, "review_id": "BJiW7IkZM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["In this work, the objective is to analze the robustness of a neuralnetwork to any sort of attack.", "This is measured by naturaly linking the robustness of the network to the localLipschitz properties of the network function.", "This approach is quite standard in learning theory, I am not aware of how originalthis point of view is within the deep learning community.", "This is estimated by obtaining vales of the norm of the gradient (alo naturaly linked to the Lipschitz properties of the function) by backpropagation.", "This is again a naturalidea."], "all_annotations": [{"interpretation": 0, "review_id": "BJiW7IkZM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "BJovaI9gf", "review_text": "This is an interesting paper that builds a parameterized network to select actions for a robot in a simulated environment, with the objective of quickly reaching an internal belief state that is predictive of the true state.  This is an interesting idea and it works much better than I would have expected.  \n\nIn more careful examination it is clear that the authors have done a good job of designing a network that is partly pre-specified and partly free, in a way that makes the learning effective.  In particular\n- the transition model is known and fixed (in the way it is used in the belief update process)\n- the belief state representation is known and fixed (in the way it is used to decide whether the agent should be rewarded)\n- the reward function is known and fixed (as above)\n- the mechanics of belief update\nBut we learn\n- the observation model\n- the control policy\n\nI'm not sure that global localization is still an open problem with known models.  Or, at least, it's not one of our worst.\n\nEarly work by Cassandra, Kurien, et al used POMDP models and solvers for active localization with known transition and observation models.   It was computationally slow but effective.\n\nSimilarly, although the online speed of your learned method is much better than for active Markov localization, the offline training cost is dramatically higher;  it's important to remember to be clear on this point.\n\nIt is not obvious to me that it is sensible to take the cosine similarity between the feature representation of the observation and the feature representation of the state to get the entry in the likelihood map.   It would be good to make it clear this is the right measure.\n\nHow is exploration done during the RL phase?  These domains are still not huge.\n\nPlease explain in more detail what the memory images are doing.\n\nIn general, the experiments seem to be well designed and well carried out, with several interesting extensions.\n\nI have one more major concern:  it is not the job of a localizer to arrive at a belief state with high probability mass on the true state---it is the job of a localizer to have an accurate approximation of the true posterior under the prior and observations.   There are situations (in which, for example, the robot has gotten an unusual string of observations) in which it is correct for the robot to have more probability mass on a \"wrong\" state.  Or, it seems that this model may earn rewards for learning to make its beliefs overconfident.  It would be very interesting to see if you could find an objective that would actually cause the model to learn to compute the appropriate posterior.\n\nIn the end, I have trouble making a recommendation:\nCon:  I'm not convinced that an end-to-end approach to this problem is the best one\nPro: It's actually a nice idea that seems to have worked out well\nCon: I remain concerned that the objective is not the right one\n\nMy rating would really be something like 6.5 if that were possible.\n\n\n\n\n", "gold_annotation": {"interpretation": 1, "review_id": "BJovaI9gf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["This is an interesting paper that builds a parameterized network to select actions for a robot in a simulated environment, with the objective of quickly reaching an internalbelief state that is predictive of the true state.", "This is an interesting idea and it works much better than I would have expected.", "In more careful examination it is clear that the authors have done a good job of designing a network that is partly pre-specified and partly free, in a way that makes the learning effective.", "In particular - the transition model is known and fixed (in the way it is used in the belief update process) - the belief state representation is known and fixed (in the way it is used to decide whether the agent should be rewarded) - the reward function is known and fixed (as above) - the mechanics of belief update But we learn - the observation model - the control policy I'm not sure that globallocalzation is still an open problem with known models.", "Or, at least, it's not one of our worst.", "Early work by Cassandra, Kurien, et alused POMDP models and solvers for active localzation with known transition and observation models.", "It was computationaly slow but effective.", "Similarly, alhough the online speed of your learned method is much better than for active Markov localzation, the offline training cost is dramaticaly higher; it's important to remember to be clear on this point.", "It is not obvious to me that it is sensible to take the cosine similarity between the feature representation of the observation and the feature representation of the state to get the entry in the likelihood map.", "It would be good to make it clear this is the right measure.", "How is exploration done during the RL phase?", "These domains are still not huge.", "Please explain in more detail what the memory images are doing.", "In general the experiments seem to be well designed and well carried out, with severalinteresting extensions.", "I have one more major concern: it is not the job of a localzer to arrive at a belief state with high probability mass on the true state---it is the job of a localzer to have an accurate approximation of the true posterior under the prior and observations.", "There are situations (in which, for example, the robot has gotten an unusualstring of observations) in which it is correct for the robot to have more probability mass on a \"wrong\" state.", "Or, it seems that this model may earn rewards for learning to make its beliefs overconfident.", "It would be very interesting to see if you could find an objective that would actualy cause the model to learn to compute the appropriate posterior.", "In the end, I have trouble making a recommendation: Con: I'm not convinced that an end-to-end approach to this problem is the best one Pro: It's actualy a nice idea that seems to have worked out well Con: I remain concerned that the objective is not the right one My rating would realy be something like 6 5 if that were possible."], "all_annotations": [{"interpretation": 1, "review_id": "BJovaI9gf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "BJu6VdYlf", "review_text": "The paper suggests an importance sampling based Coreset construction for Support Vector Machines (SVM). To understand the results, we need to understand Coreset and importance sampling: \n\nCoreset: In the context of SVMs, a Coreset is a (weighted) subset of given dataset such that for any linear separator, the cost of the separator with respect to the given dataset X is approximately (there is an error parameter \\eps) the same as the cost with respect to the weighted subset. The main idea is that if one can find a small coreset, then finding the optimal separator (maximum margin etc.) over the coreset might be sufficient. Since the computation is done over a small subset of points, one hopes to gain in terms of the running time.\n\nImportance sampling: This is based on the theory developed in Feldman and Langberg, 2011 (and some of the previous works such as Langberg and Schulman 2010, the reference of which is missing). The idea is to define a quantity called sensitivity of a data-point that captures how important this datapoint is with respect to contributing to the cost function. Then a subset of datapoint are sampled based on the sensitivity and the sampled data point is given weight proportional to inverse of the sampling probability. As per the theory developed in these past works, sampling a subset of size proportional to the sum of sensitivities gives a coreset for the given problem.\n\nSo, the main contribution of the paper is to do all the sensitivity calculations with respect to SVM problem and then use the importance sampling theory to obtain bounds on the coreset size. One interesting point of this construction is that Coreset construction involves solving the SVM problem on the given dataset which may seem like beating the purpose. However, the authors note that one only needs to compute the Coreset of small batches of the given dataset and then use standard procedures (available in streaming literature) to combine the Coresets into a single Coreset. This should give significant running time benefits. The paper also compares the results against the simple procedure where a small uniform sample from the dataset is used for computation. \n\n\nEvaluation: \nSignificance: Coresets give significant running time benefits when working with very big datasets. Coreset construction in the context of SVMs is a relevant problem and should be considered significant.\n\nClarity: The paper is reasonably well-written. The problem has been well motivated and all the relevant issues point out for the reader. The theoretical results are clearly stated as lemmas a theorems that one can follow without looking at proofs. \n\nOriginality: The paper uses previously developed theory of importance sampling. However, the sensitivity calculations in the SVM context is new as per my knowledge. It is nice to know the bounds given in the paper and to understand the theoretical conditions under which we can obtain running time benefits using corsets. \n\nQuality: The paper gives nice theoretical bounds in the context of SVMs. One aspect in which the paper is lacking is the empirical analysis. The paper compares the Coreset construction with simple uniform sampling. Since Coreset construction is being sold as a fast alternative to previous methods for training SVMs, it would have been nice to see the running time and cost comparison with other training methods that have been discussed in section 2.\n", "gold_annotation": {"interpretation": 0, "review_id": "BJu6VdYlf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 3.0, "tokenized_review_text": ["The paper suggests an importance sampling based Coreset construction for Support Vector Machines (SVM).", "To understand the results, we need to understand Coreset and importance sampling: Coreset: In the context of SVMs, a Coreset is a (weighted) subset of given dataset such that for any linear separator, the cost of the separator with respect to the given dataset X is approximately (there is an error parameter \\eps) the same as the cost with respect to the weighted subset.", "The main idea is that if one can find a smal coreset, then finding the optimalseparator (maximum margin etc) over the coreset might be sufficient.", "Since the computation is done over a smal subset of points, one hopes to gain in terms of the running time.", "Importance sampling: This is based on the theory developed in Feldman and Langberg, 2011 (and some of the previous works such as Langberg and Schulman 2010, the reference of which is missing).", "The idea is to define a quantity caled sensitivity of a data-point that captures how important this datapoint is with respect to contributing to the cost function.", "Then a subset of datapoint are sampled based on the sensitivity and the sampled data point is given weight proportionalto inverse of the sampling probability.", "As per the theory developed in these past works, sampling a subset of size proportionalto the sum of sensitivities gives a coreset for the given problem.", "So, the main contribution of the paper is to do al the sensitivity calulations with respect to SVM problem and then use the importance sampling theory to obtain bounds on the coreset size.", "One interesting point of this construction is that Coreset construction involves solving the SVM problem on the given dataset which may seem like beating the purpose.", "However, the authors note that one only needs to compute the Coreset of smal batches of the given dataset and then use standard procedures (available in streaming literature) to combine the Coresets into a single Coreset.", "This should give significant running time benefits.", "The paper alo compares the results against the simple procedure where a smal uniform sample from the dataset is used for computation.", "Evalation: Significance: Coresets give significant running time benefits when working with very big datasets.", "Coreset construction in the context of SVMs is a relevant problem and should be considered significant.", "Clarity: The paper is reasonably well-written.", "The problem has been well motivated and al the relevant issues point out for the reader.", "The theoreticalresults are clearly stated as lemmas a theorems that one can follow without looking at proofs.", "Originalty: The paper uses previously developed theory of importance sampling.", "However, the sensitivity calulations in the SVM context is new as per my knowledge.", "It is nice to know the bounds given in the paper and to understand the theoreticalconditions under which we can obtain running time benefits using corsets.", "Qualty: The paper gives nice theoreticalbounds in the context of SVMs.", "One aspect in which the paper is lacking is the empiricalanalsis.", "The paper compares the Coreset construction with simple uniform sampling.", "Since Coreset construction is being sold as a fast alernative to previous methods for training SVMs, it would have been nice to see the running time and cost comparison with other training methods that have been discussed in secion 2,"], "all_annotations": [{"interpretation": 0, "review_id": "BJu6VdYlf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "Bk-6h6Txz", "review_text": "The article \"Contextual Explanation Networks\" introduces the class of models which learn the intermediate explanations in order to make final predictions. The contexts can be learned by, in principle, any model including neural networks, while the final predictions are supposed to be made by some simple models like linear ones. The probabilistic model allows for the simultaneous training of explanation and prediction parts as opposed to some recent post-hoc methods.\n\nThe experimental part of the paper considers variety of experiments, including classification on MNIST, CIFAR-10, IMDB and also some experiments on survival analysis. I should note, that the quality of the algorithm is in general similar to other methods considered (as expected). However, while in some cases the CEN algorithm is slightly better, in other cases it appears to sufficiently loose, see for example left part of Figure 3(b) for MNIST data set. It would be interesting to know the explanation. Also, it would be interesting to have more examples of qualitative analysis to see, that the learned explanations are really useful. I am a bit worried, that while we have interpretability with respect to intermediate features, these features theirselves might be very hard to interpret.\n\nTo sum up, I think that the general idea looks very natural and the results are quite supportive. However, I don't feel myself confident enough in this area of research to make strong conclusion on the quality of the paper.", "gold_annotation": {"interpretation": 0, "review_id": "Bk-6h6Txz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The article \"ContextualExplanation Networks\" introduces the class of models which learn the intermediate explanations in order to make finalpredictions.", "The contexts can be learned by, in principle, any model including neuralnetworks, while the finalpredictions are supposed to be made by some simple models like linear ones.", "The probabilistic model alows for the simultaneous training of explanation and prediction parts as opposed to some recent post-hoc methods.", "The experimentalpart of the paper considers variety of experiments, including classification on MNIST, CIFAR-10, IMDB and alo some experiments on survivalanalsis.", "I should note, that the qualty of the alorithm is in generalsimilar to other methods considered (as expected).", "However, while in some cases the CEN alorithm is slightly better, in other cases it appears to sufficiently loose, see for example left part of figre 3(b) for MNIST data set.", "It would be interesting to know the explanation.", "Also, it would be interesting to have more examples of qualtative analsis to see, that the learned explanations are realy useful.", "I am a bit worried, that while we have interpretability with respect to intermediate features, these features theirselves might be very hard to interpret.", "To sum up, I think that the generalidea looks very naturaland the results are quite supportive.", "However, I don't feel myself confident enough in this area of research to make strong conclusion on the qualty of the paper."], "all_annotations": [{"interpretation": 0, "review_id": "Bk-6h6Txz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "Bk-lFRWWz", "review_text": "The authors propose reducing the number of parameters learned by a deep network by setting up sparse connection weights in classification layers. Numerical experiments show that such sparse networks can have similar performance to fully connected ones. They introduce a concept of \u201cscatter\u201d that correlates with network performance. Although  I found the results useful and potentially promising, I did not find much insight in this paper.\nIt was not clear to me why scatter (the way it is defined in the paper) would be a useful performance proxy anywhere but the first classification layer. Once the signals from different windows are intermixed, how do you even define the windows?  \nMinor\nSecond line of Section 2.1: \u201clesser\u201d -> less or fewer\n", "gold_annotation": {"interpretation": 0, "review_id": "Bk-lFRWWz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["The authors propose reducing the number of parameters learned by a deep network by setting up sparse connection weights in classification layers.", "Numericalexperiments show that such sparse networks can have similar performance to fully connected ones.", "They introduce a concept of \u201cscatter\u201d that correlates with network performance.", "Although I found the results useful and potentialy promising, I did not find much insight in this paper.", "It was not clear to me why scatter (the way it is defined in the paper) would be a useful performance proxy anywhere but the first classification layer.", "Once the signal from different windows are intermixed, how do you even define the windows?", "Minor secnd line of secion 2 1: \u201clesser\u201d -> less or fewer"], "all_annotations": [{"interpretation": 0, "review_id": "Bk-lFRWWz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "Bk1-V2plG", "review_text": "The paper proposes a technique for training quantized neural networks, where the precision (number of bits) varies per layer and is learned in an end-to-end fashion. The idea is to add two terms to the loss, one representing quantization error, and the other representing the number of discrete values the quantization can support (or alternatively the number of bits used). Updates are made to the parameter representing the # of bits via the sign of its gradient. Experiments are conducted using a LeNet-inspired architecture on MNIST and CIFAR10.\n\nOverall, the idea is interesting, as providing an end-to-end trainable technique for distributing the precision across layers of a network would indeed be quite useful. I have a few concerns: First, I find the discussion around the training methodology insufficient. Inherently, the objective is discontinuous since # of bits is a discrete parameter. This is worked around by updating the parameter using the sign of its gradient. This is assuming the local linear approximation given by the derivative is accurate enough one integer away; this may or may not be true, but it's not clear and there is little discussion of whether this is reasonable to assume.\n\nIt's also difficult for me to understand how this interacts with the other terms in the objective (quantization error and loss). We'd like the number of bits parameter to trade off between accuracy (at least in terms of quantization error, and ideally overall loss as well) and precision. But it's not at all clear that the gradient of either the loss or the quantization error w.r.t. the number of bits will in general suggest increasing the number of bit (thus requiring the bit regularization term). This will clearly not be the case when the continuous weights coincide with the quantized values for the current bit setting. More generally, the direction of the gradient will be highly dependent on the specific setting of the current weights. It's unclear to me how effectively accuracy and precision are balanced by this training strategy, and there isn't any discussion of this point either.\n\nI would be less concerned about the above points if I found the experiments compelling. Unfortunately, although I am quite sympathetic to the argument that state of the art results or architectures aren't necessary for a paper of this kind, the results on MNIST and CIFAR10 are so poor that they give me some concern about how the training was performed and whether the results are meaningful. Performance on MNIST in the 7-11% test error range is comparable to a simple linear logistic regression model; for a CNN that is extremely bad. Similarly, 40% error on CIFAR10 is worse than what some very simple fully connected models can achieve.\n\nOverall, while I like the and think the goal is good, I think the motivation and discussion for the training methodology is insufficient, and the empirical work is concerning. I can't recommend acceptance. ", "gold_annotation": {"interpretation": 0, "review_id": "Bk1-V2plG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper proposes a technique for training quantized neuralnetworks, where the precision (number of bits) varies per layer and is learned in an end-to-end fashion.", "The idea is to add two terms to the loss, one representing quantization error, and the other representing the number of discrete vales the quantization can support (or alernatively the number of bits used).", "Updates are made to the parameter representing the # of bits via the sign of its gradient.", "Experiments are conducted using a LeNet-inspired architecture on MNIST and CIFAR10, Overal, the idea is interesting, as providing an end-to-end trainable technique for distributing the precision across layers of a network would indeed be quite useful.", "I have a few concerns: First, I find the discussion around the training methodology insufficient.", "Inherently, the objective is discontinuous since # of bits is a discrete parameter.", "This is worked around by updating the parameter using the sign of its gradient.", "This is assuming the locallinear approximation given by the derivative is accurate enough one integer away; this may or may not be true, but it's not clear and there is little discussion of whether this is reasonable to assume.", "It's alo difficult for me to understand how this interacts with the other terms in the objective (quantization error and loss).", "We'd like the number of bits parameter to trade off between accuracy (at least in terms of quantization error, and idealy overal loss as well) and precision.", "But it's not at al clear that the gradient of either the loss or the quantization error w r t the number of bits will in generalsuggest increasing the number of bit (thus reqiring the bit regularization term).", "This will clearly not be the case when the continuous weights coincide with the quantized vales for the current bit setting.", "More generaly, the direction of the gradient will be highly dependent on the specific setting of the current weights.", "It's unclear to me how effectively accuracy and precision are balnced by this training strategy, and there isn't any discussion of this point either.", "I would be less concerned about the above points if I found the experiments compelling.", "Unfortunately, alhough I am quite sympathetic to the argument that state of the art results or architectures aren't necessary for a paper of this kind, the results on MNIST and CIFAR10 are so poor that they give me some concern about how the training was performed and whether the results are meaningful.", "Performance on MNIST in the 7-11% test error range is comparable to a simple linear logistic regression model; for a CNN that is extremely bad.", "Similarly, 40% error on CIFAR10 is worse than what some very simple fully connected models can achieve.", "Overal, while I like the and think the goalis good, I think the motivation and discussion for the training methodology is insufficient, and the empiricalwork is concerning.", "I can't recommend acceptance."], "all_annotations": [{"interpretation": 0, "review_id": "Bk1-V2plG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "Bk15lpF1G", "review_text": "This paper studies the adjustment of dropout rates which is a useful tool to prevent the overfitting of deep neural networks. The authors derive a generalization error bound in terms of dropout rates. Based on this, the authors propose a regularization framework to adaptively select dropout rates. Experimental results are also given to verify the theory.\n\nMajor comments:\n(1) The Empirical Rademacher complexity is not defined. For completeness, it would be better to define it at least in the appendix.\n(2) I can not follow the inequality (5). Especially, according to the main text, f^L is a vector-valued function . Therefore, it is not clear to me the meaning of \\sum\\sigma_if^L(x_i,w) in (5).\n(3) I can also not see clearly the third equality in (9). Note that f^l is a vector-valued function. It is not clear to me how it is related to a summation over j there.\n(4) There is a linear dependency on the number of classes in Theorem 3.1. Is it possible to further improve this dependency?\n\nMinor comments:\n(1) Section 4: 1e-3,1e-4,1e-5 is not consistent with 1e^{-3}, 1e^{-4},1e^{-5}\n(2) Abstract: there should be a space before \"Experiments\".\n(3) It would be better to give more details (e.g., page, section) in citing a book in the proof of Theorem 3.1\n\nSummary:\nThe mathematical analysis in the present version is not rigorous. The authors should improve the mathematical analysis.\n\n----------------------------\nAfter Rebuttal:\nThank you for revising the paper. I think there are still some possible problems. \nLet us consider eq (12) in the appendix on the contraction property of Rademacher complexity (RC).\n(1) Since you consider a variant of RC with absolute value inside the supermum, to my best knowledge, the contraction property (12) should involve an additional factor of 2, see, e.g., Theorem 12 of \"Rademacher and Gaussian Complexities: Risk Bounds and Structural Results\" by Bartlett and Mendelson. Since you need to apply this contraction property L times, there should be a factor of 2^L in the error bound. This make the bound not appealing for neural networks with a moderate L.\n(2) Second, the function g involves an expectation w.r.t. r before the activation function. I am not sure whether this existence of expectation w.r.t. r would make the contraction property applicable in this case.", "gold_annotation": {"interpretation": 0, "review_id": "Bk15lpF1G", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "yes-disagree", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["This paper studies the adjustment of dropout rates which is a useful tool to prevent the overfitting of deep neuralnetworks.", "The authors derive a generalzation error bound in terms of dropout rates.", "Based on this, the authors propose a regularization framework to adaptively select dropout rates.", "Experimentalresults are alo given to verify the theory.", "Major comments: (1) The EmpiricalRademacher complexity is not defined.", "For completeness, it would be better to define it at least in the appendix.", "(2) I can not follow the ineqalty (5).", "Especialy, according to the main text, f^L is a vector-valed function .", "Therefore, it is not clear to me the meaning of \\sum\\sigma_if^L(x_i,w) in (5).", "(3) I can alo not see clearly the third eqalty in (9).", "Note that f^l is a vector-valed function.", "It is not clear to me how it is related to a summation over j there.", "(4) There is a linear dependency on the number of classes in Theorem 3 1, Is it possible to further improve this dependency?", "Minor comments: (1) secion 4: 1e-3,1e-4,1e-5 is not consistent with 1e^{-3}, 1e^{-4},1e^{-5} (2) Abstract: there should be a space before \"Experiments\".", "(3) It would be better to give more details (e g , page, secion) in citing a book in the proof of Theorem 3 1 Summary: The mathematicalanalsis in the present version is not rigorous.", "The authors should improve the mathematicalanalsis.", "---------------------------- After Rebuttal Thank you for revising the paper.", "I think there are still some possible problems.", "Let us consider eq(12) in the appendix on the contraction property of Rademacher complexity (RC).", "(1) Since you consider a variant of RC with absolute vale inside the supermum, to my best knowledge, the contraction property (12) should involve an additionalfactor of 2, see, e g , Theorem 12 of \"Rademacher and Gaussian Complexities: Risk Bounds and StructuralResults\" by Bartlett and Mendelson.", "Since you need to apply this contraction property L times, there should be a factor of 2^L in the error bound.", "This make the bound not appealng for neuralnetworks with a moderate L (2) secnd, the function g involves an expectation w r t r before the activation function.", "I am not sure whether this existence of expectation w r t r would make the contraction property applicable in this case."], "all_annotations": [{"interpretation": 0, "review_id": "Bk15lpF1G", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "yes-disagree", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "Bk2K_F9lz", "review_text": "The paper presents an off-policy actor-critic method for learning a stochastic policy with entropy regularization. It is a direct extension of maximum entropy reinforcement learning for Q-learning (recently called soft-Q learning), and named soft actor-critic (SAC). Empirically SAC is shown to outperform DDPG significantly in terms of stability and sample efficiency, and can solve relatively difficult tasks that previously only on-policy (or hybrid on-policy/off-policy) method such as TRPO/PPO can solve stably. Besides entropy regularization, it also introduces multi-modal policy parameterization through mixture of Gaussians that enables diverse, on-policy exploration.     \n\nThe main appeal of the paper is the strong empirical performance of this new off-policy method in continuous action benchmarks. Several design choices could be the key, so it is encouraged to provide more ablation studies on these, which would be highly valuable for the community. In particular,\n\n- Amortization of Q and \\pi through fitting state value function\n\n- On-policy exploration vs OU process based off-policy exploration\n\n- Mixture vs non-mixture-based stochastic policy\n\n- SAC vs soft Q-learning\n\nAnother valuable discussion to be had is the stability of off-policy algorithm comparing Q-learning versus actor-critic method.\n \nPros:\n\n- Simple off-policy algorithm that achieves significantly better performance than existing off-policy baseline algorithms\n\n- It allows on-policy exploration in off-policy learning, partially thanks to entropy regularization that prevents variance from shrinking to 0. It could be considered a major success of off-policy algorithm that removes heuristic exploration noise.\n\nCons:\n\n- Method is relatively simple extension from existing work in maximum entropy reinforcement learning. It is unclear what aspects lead to significant improvements in performance due to insufficient ablation studies. \n\n\nOther question:\n\n- Above Eq. 7 it discusses that fitting a state value function wrt Q and \\pi is shown to improve the stability significantly. Is this comparison with directly estimating state value using finite samples? If so, is the primary instability due to variance of the estimate, which can be avoided by drawing a lot of samples or do full integration (still reasonably tractable for finite mixture model)? Or, is the instability from elsewhere? By having SGD-based fitting of state value function, it appears to simulate slowly changing target values (similar role as target networks). If so, could a similar technique be used with DDPG and get more stable performance? \n\n", "gold_annotation": {"interpretation": 0, "review_id": "Bk2K_F9lz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["The paper presents an off-policy actor-critic method for learning a stochastic policy with entropy regularization.", "It is a direct extension of maximum entropy reinforcement learning for Q-learning (recently caled soft-Q learning), and named soft actor-critic (SAC).", "Empiricaly SAC is shown to outperform DDPG significantly in terms of stability and sample efficiency, and can solve relatively difficult tasks that previously only on-policy (or hybrid on-policy/off-policy) method such as TRPO/PPO can solve stably.", "Besides entropy regularization, it alo introduces multi-modalpolicy parameterization through mixture of Gaussians that enables diverse, on-policy exploration.", "The main appealof the paper is the strong empiricalperformance of this new off-policy method in continuous action benchmarks.", "Severaldesign choices could be the key, so it is encouraged to provide more ablation studies on these, which would be highly valable for the community.", "In particular, - Amortization of Q and \\pi through fitting state vale function - On-policy exploration vs OU process based off-policy exploration - Mixture vs non-mixture-based stochastic policy - SAC vs soft Q-learning Another valable discussion to be had is the stability of off-policy alorithm comparing Q-learning versus actor-critic method.", "Pros: - Simple off-policy alorithm that achieves significantly better performance than existing off-policy baseline alorithms - It alows on-policy exploration in off-policy learning, partialy thanks to entropy regularization that prevents variance from shrinking to 0, It could be considered a major success of off-policy alorithm that removes heuristic exploration noise.", "Cons: - Method is relatively simple extension from existing work in maximum entropy reinforcement learning.", "It is unclear what aspects lead to significant improvements in performance due to insufficient ablation studies.", "Other question: - Above eq 7 it discusses that fitting a state vale function wrt Q and \\pi is shown to improve the stability significantly.", "Is this comparison with directly estimating state vale using finite samples?", "If so, is the primary instability due to variance of the estimate, which can be avoided by drawing a lot of samples or do full integration (still reasonably tractable for finite mixture model)?", "Or, is the instability from elsewhere?", "By having SGD-based fitting of state vale function, it appears to simulate slowly changing target vales (similar role as target networks).", "If so, could a similar technique be used with DDPG and get more stable performance?"], "all_annotations": [{"interpretation": 0, "review_id": "Bk2K_F9lz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "Bk3B7T5gf", "review_text": "The authors present a deep neural network that evaluates plate numbers. The relevance of this problem is that there are auctions for plate numbers in Hong Kong, and predicting their value is a sensible activity in that context. I find that the description of the applied problem is quite interesting; in fact overall the paper is well written and very easy to follow. There are some typos and grammatical problems (indicated below), but nothing really serious.\n\nSo, the paper is relevant and well presented. However, I find that the proposed solution is an application of existing techniques, so it lacks on novelty and originality. Even though the significance of the work is apparent given the good results of the proposed neural network, I believe that such material is more appropriate to a focused applied meeting. However, even for that sort of setting I think the paper requires some additional work, as some final parts of the paper have not been tested yet (the interesting part of explanations). Hence I don't think the submission is ready for publication at this moment.\n\nConcerning the text, some questions/suggestions:\n- Abstract, line 1: I suppose \"In the Chinese society...\"--- are there many Chinese societies?\n- The references are not properly formatted; they should appear at (XXX YYY) but appear as XXX (YYY) in many cases, mixed with the main text. \n- Footnote 1, line 2: \"an exchange\".\n- Page 2, line 12: \"prices. Among\".\n- Please add commas/periods at the end of equations.\n- There are problems with capitalization in the references. ", "gold_annotation": {"interpretation": 0, "review_id": "Bk3B7T5gf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["The authors present a deep neuralnetwork that evalates plate numbers.", "The relevance of this problem is that there are auctions for plate numbers in Hong Kong, and predicting their vale is a sensible activity in that context.", "I find that the description of the applied problem is quite interesting; in fact overal the paper is well written and very easy to follow.", "There are some typos and grammaticalproblems (indicated below), but nothing realy serious.", "So, the paper is relevant and well presented.", "However, I find that the proposed solution is an application of existing techniques, so it lacks on novelty and originalty.", "Even though the significance of the work is apparent given the good results of the proposed neuralnetwork, I believe that such materialis more appropriate to a focused applied meeting.", "However, even for that sort of setting I think the paper reqires some additionalwork, as some finalparts of the paper have not been tested yet (the interesting part of explanations).", "Hence I don't think the submission is ready for publication at this moment.", "Concerning the text, some questions/suggestions: - Abstract, line 1: I suppose \"In the Chinese society...\"--- are there many Chinese societies?", "- The references are not properly formatted; they should appear at (XXX YYY) but appear as XXX (YYY) in many cases, mixed with the main text.", "- Footnote 1, line 2: \"an exchange\".", "- Page 2, line 12: \"prices.", "Among\".", "- Please add commas/periods at the end of eqations.", "- There are problems with capitalzation in the references."], "all_annotations": [{"interpretation": 0, "review_id": "Bk3B7T5gf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "Bk6nbuf-M", "review_text": "The authors use deep learning to learn a surrogate model for the motion vector in the advection-diffusion equation that they use to forecast sea surface temperature. In particular, they use a CNN encoder-decoder to learn a motion field, and a warping function from the last component to provide forecasting. \n\nI like the idea of using deep learning for physical equations. I would like to see a description of the algorithm with the pseudo-code in order to understand the flow of the method. I got confused at several points because it was not clear what was exactly being estimated with the CNN. Having an algorithmic environment would make the description easier. I know that authors are going to publish the code, but this is not enough at this point of the revision. \n\nPhysical processes in Machine learning have been studied from the perspective of Gaussian processes. Just to mention a couple of references \u201cLinear latent force models using Gaussian processes\u201d and \"Numerical Gaussian Processes for Time-dependent and Non-linear Partial Differential Equations\"\n\nIn Theorem 2, do you need to care about boundary conditions for your equation? I didn\u2019t see any mention to those in the definition for I(x,t). You only mention initial conditions. How do you estimate the diffusion parameter D? Are you assuming isotropic diffusion? Is that realistic? Can you provide more details about how you run the data assimilation model in the experiments? Did you use your own code?\n", "gold_annotation": {"interpretation": 0, "review_id": "Bk6nbuf-M", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The authors use deep learning to learn a surrogate model for the motion vector in the advection-diffusion eqation that they use to forecast sea surface temperature.", "In particular, they use a CNN encoder-decoder to learn a motion field, and a warping function from the last component to provide forecasting.", "I like the idea of using deep learning for physicaleqations.", "I would like to see a description of the alorithm with the pseudo-code in order to understand the flow of the method.", "I got confused at severalpoints because it was not clear what was exactly being estimated with the CNN.", "Having an alorithmic environment would make the description easier.", "I know that authors are going to publish the code, but this is not enough at this point of the revision.", "Physicalprocesses in Machine learning have been studied from the perspective of Gaussian processes.", "Just to mention a couple of references \u201cLinear latent force models using Gaussian processes\u201d and \"NumericalGaussian Processes for Time-dependent and Non-linear PartialDifferentialeqations\" In Theorem 2, do you need to care about boundary conditions for your eqation?", "I didn\u2019t see any mention to those in the definition for I(x,t).", "You only mention initialconditions.", "How do you estimate the diffusion parameter D?", "Are you assuming isotropic diffusion?", "Is that realstic?", "Can you provide more details about how you run the data assimilation model in the experiments?", "Did you use your own code?"], "all_annotations": [{"interpretation": 0, "review_id": "Bk6nbuf-M", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "Bk8FeZjgf", "review_text": "Instead of either optimization-based variational EM or an amortized inference scheme implemented via a neural network as in standard VAE models, this paper proposes a hybrid approach that essentially combines the two.  In particular, the VAE inference step, i.e., estimation of q(z|x), is conducted via application of a recent learning-to-learn paradigm (Andrychowicz et al., 2016), whereby direct gradient ascent on the ELBO criteria with respect to moments of q(z|x) is replaced with a neural network that iteratively outputs new parameter estimates using these gradients.  The resulting iterative inference framework is applied to a couple of small datasets and shown to produce both faster convergence and a better likelihood estimate.\n\nAlthough probably difficult for someone to understand that is not already familiar with VAE models, I felt that this paper was nonetheless clear and well-presented, with a fair amount of useful background information and context.  From a novelty standpoint though, the paper is not especially strong given that it represents a fairly straightforward application of (Andrychowicz et al., 2016).  Indeed the paper perhaps anticipates this perspective and preemptively offers that \"variational inference is a qualitatively different optimization problem\" than that considered in (Andrychowicz et al., 2016), and also that non-recurrent optimization models are being used for the inference task, unlike prior work.  But to me, these are rather minor differentiating factors, since learning-to-learn is a quite general concept already, and the exact model structure is not the key novel ingredient.  That being said, the present use for variational inference nonetheless seems like a nice application, and the paper presents some useful insights such as Section 4.1 about approximating posterior gradients.\n\nBeyond background and model development, the paper presents a few experiments comparing the proposed iterative inference scheme against both variational EM, and pure amortized inference as in the original, standard VAE.  While these results are enlightening, most of the conclusions are not entirely unexpected.  For example, given that the model is directly trained with the iterative inference criteria in place, the reconstructions from Fig. 4 seem like exactly what we would anticipate, with the last iteration producing the best result.  It would certainly seem strange if this were not the case.  And there is no demonstration of reconstruction quality relative to existing models, which could be helpful for evaluating relative performance.  Likewise for Fig. 6, where faster convergence over traditional first-order methods is demonstrated; but again, these results are entirely expected as this phenomena has already been well-documented in (Andrychowicz et al., 2016).\n\nIn terms of Fig. 5(b) and Table 1, the proposed approach does produce significantly better values of the ELBO critera; however, is this really an apples-to-apples comparison?  For example, does the standard VAE have the same number of parameters/degrees-of-freedom as the iterative inference model, or might eq. (4) involve fewer parameters than eq. (5) since there are fewer inputs?  Overall, I wonder whether iterative inference is better than standard inference with eq. (4), or whether the recurrent structure from eq. (5) just happens to implicitly create a better neural network architecture for the few examples under consideration.  In other words, if one plays around with the standard inference architecture a bit, perhaps similar results could be obtained.\n\n\nOther minor comment:\n* In Fig. 5(a), it seems like the performance of the standard inference model is still improving but the iterative inference model has mostly saturated.\n* A downside of the iterative inference model not discussed in the paper is that it requires computing gradients of the objective even at test time, whereas the standard VAE model would not.", "gold_annotation": {"interpretation": 1, "review_id": "Bk8FeZjgf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Instead of either optimization-based variationalEM or an amortized inference scheme implemented via a neuralnetwork as in standard VAE models, this paper proposes a hybrid approach that essentialy combines the two.", "In particular, the VAE inference step, i e , estimation of q(z|x), is conducted via application of a recent learning-to-learn paradigm (Andrychowicz et al, 2016), whereby direct gradient ascent on the ELBO criteria with respect to moments of q(z|x) is replaced with a neuralnetwork that iteratively outputs new parameter estimates using these gradients.", "The resulting iterative inference framework is applied to a couple of smal datasets and shown to produce both faster convergence and a better likelihood estimate.", "Although probably difficult for someone to understand that is not aleady familiar with VAE models, I felt that this paper was nonetheless clear and well-presented, with a fair amount of useful background information and context.", "From a novelty standpoint though, the paper is not especialy strong given that it represents a fairly straightforward application of (Andrychowicz et al, 2016).", "Indeed the paper perhaps anticipates this perspective and preemptively offers that \"variationalinference is a qualtatively different optimization problem\" than that considered in (Andrychowicz et al, 2016), and alo that non-recurrent optimization models are being used for the inference task, unlike prior work.", "But to me, these are rather minor differentiating factors, since learning-to-learn is a quite generalconcept aleady, and the exact model structure is not the key novel ingredient.", "That being said, the present use for variationalinference nonetheless seems like a nice application, and the paper presents some useful insights such as secion 4 1 about approximating posterior gradients.", "Beyond background and model development, the paper presents a few experiments comparing the proposed iterative inference scheme against both variationalEM, and pure amortized inference as in the original standard VAE.", "While these results are enlightening, most of the conclusions are not entirely unexpected.", "For example, given that the model is directly trained with the iterative inference criteria in place, the reconstructions from fig 4 seem like exactly what we would anticipate, with the last iteration producing the best result.", "It would certainly seem strange if this were not the case.", "And there is no demonstration of reconstruction qualty relative to existing models, which could be helpful for evalating relative performance.", "Likewise for fig 6, where faster convergence over traditionalfirst-order methods is demonstrated; but again, these results are entirely expected as this phenomena has aleady been well-documented in (Andrychowicz et al, 2016).", "In terms of fig 5(b) and Table 1, the proposed approach does produce significantly better vales of the ELBO critera; however, is this realy an apples-to-apples comparison?", "For example, does the standard VAE have the same number of parameters/degrees-of-freedom as the iterative inference model, or might eq (4) involve fewer parameters than eq (5) since there are fewer inputs?", "Overal, I wonder whether iterative inference is better than standard inference with eq (4), or whether the recurrent structure from eq (5) just happens to implicitly create a better neuralnetwork architecture for the few examples under consideration.", "In other words, if one plays around with the standard inference architecture a bit, perhaps similar results could be obtained.", "Other minor comment: * In fig 5(a), it seems like the performance of the standard inference model is still improving but the iterative inference model has mostly saturated.", "* A downside of the iterative inference model not discussed in the paper is that it reqires computing gradients of the objective even at test time, whereas the standard VAE model would not."], "all_annotations": [{"interpretation": 1, "review_id": "Bk8FeZjgf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "Bk9oIe5gG", "review_text": "The paper investigates different representation learning methods to create a latent space for intrinsic goal generation in guided exploration algorithms.  The research is in principle very important and interesting.\n\nThe introduction discusses a great deal about intrinsic motivations and about goal generating algorithms. This is really great, just that the paper only focuses on a very small aspect of learning a state representation in an agent that has no intrinsic motivation other than trying to achieve random goals.\nI think the paper (not only the Intro) could be a bit condensed to more concentrate on the actual contribution. \n\nThe contribution is that the quality of the representation and the sampling of goals is important for the exploration performance and that classical methods like ISOMap are better than Autoencoder-type methods. \n\nAlso, it is written in the Conclusions (and in other places): \"[..] we propose a new intrinsically Motivated goal exploration strategy....\". This is not really true.  There is nothing new with the intrinsically motivated selection of goals here, just that they are in another space. Also, there is no intrinsic motivation. I also think the title is misleading.\n\nThe paper is in principle interesting. However, I doubt that the experimental evaluations are substantial enough for profound conclusion. \n\nSeveral points of critic: \n- the input space was very simple in all experiments, not suitable for distinguishing between the algorithms, for instance, ISOMap typically suffers from noise and higher dimensional manifolds, etc.\n- only the ball/arrow was in the input image, not the robotic arm. I understand this because in phase 1 the robot would not move, but this connects to the next point:\n- The representation learning is only a preprocessing step requiring a magic first phase.\n    -> Representation is not updated during exploration\n- The performance of any algorithm (except FI) in the Arm-Arrow task is really bad but without comment. \n- I am skeptical about the VAE  and RFVAE results. The difference between Gaussian sampling and the KDE is a bit alarming, as the KL in the VAE training is supposed to match the p(z) with N(0,1). Given the power of the encoder/decoder it should be possible to properly represent the simple embedded 2D/3D manifold and not just a very small part of it as suggested by Fig 10. \nI have a hard time believing these results. I urge you to check for any potential errors made. If there are not mistakes then this is indeed alarming.\n\nQuestions:\n- Is it true that the robot always starts from same initial condition?! Context=Emptyset. \n- For ISOMap etc, you also used a 10dim embedding?\n\nSuggestion:\n- The main problem seems to be that some algorithms are not representing the whole input space.\n- an additional measure that quantifies the difference between true input distribution and reproduced input distribution could tier the algorithms apart and would measure more what seems to be relevant here.  One could for instance measure the KL-divergence between the true input and the sampled (reconstructed) input (using samples and KDE or the like). \n- This could be evaluated on many different inputs (also those with a bit more complicated structure) without actually performing the goal finding.\n- BTW: I think Fig 10 is rather illustrative and should be somehow in the main part of the paper\n \nOn the positive side, the paper provides lots of details in the Appendix.\nAlso, it uses many different Representation Learning algorithms and uses measures from manifold learning to access their quality.\n\nIn the related literature, in particular concerning the intrinsic motivation, I think the following papers are relevant:\nJ. Schmidhuber, PowerPlay: training an increasingly general problem solver by continually searching for the simplest still unsolvable problem. Front. Psychol., 2013.\n\nand\n\nG. Martius, R. Der, and N. Ay. Information driven self-organization of complex robotic behaviors. PLoS ONE, 8(5):e63400, 2013.\n\n\nTypos and small details:\np3 par2: for PCA you cited Bishop. Not critical, but either cite one the original papers or maybe remove the cite altogether\np4 par-2: has multiple interests...: interests -> purposes?\np4 par-1: Outcome Space to the agent is is ...\nSec 2.2 par1: are rapidly mentioned... -> briefly\nSec 2.3 ...Outcome Space O, we can rewrite the architecture as:\n  and then comes the algorithm. This is a bit weird\nSec 3: par1: experimental campaign -> experiments?\np7: Context Space: the object was reset to a random position or always to the same position?\nFootnote 14: superior to -> larger than\np8 par2: Exploration Ratio Ratio_expl... probably also want to add (ER) as it is later used\nSec 4: slightly underneath -> slightly below\np9 par1: unfinished sentence: It is worth noting that the....\none sentence later: RP architecture? RPE?\nFig 3: the error of the methods (except FI) are really bad. An MSE of 1 means hardly any performance!\np11 par2: for e.g. with the SAGG..... grammar?\n\nPlots in general: use bigger font sizes.\n\n", "gold_annotation": {"interpretation": 1, "review_id": "Bk9oIe5gG", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["The paper investigates different representation learning methods to create a latent space for intrinsic goalgeneration in guided exploration alorithms.", "The research is in principle very important and interesting.", "The introduction discusses a great dealabout intrinsic motivations and about goalgenerating alorithms.", "This is realy great, just that the paper only focuses on a very smal aspect of learning a state representation in an agent that has no intrinsic motivation other than trying to achieve random goal.", "I think the paper (not only the Intro) could be a bit condensed to more concentrate on the actualcontribution.", "The contribution is that the qualty of the representation and the sampling of goal is important for the exploration performance and that classicalmethods like ISOMap are better than Autoencoder-type methods.", "Also, it is written in the Conclusions (and in other places): \"[..] we propose a new intrinsicaly Motivated goalexploration strategy....\".", "This is not realy true.", "There is nothing new with the intrinsicaly motivated selection of goal here, just that they are in another space.", "Also, there is no intrinsic motivation.", "I alo think the title is misleading.", "The paper is in principle interesting.", "However, I doubt that the experimentalevalations are substantialenough for profound conclusion.", "Severalpoints of critic: - the input space was very simple in al experiments, not suitable for distinguishing between the alorithms, for instance, ISOMap typicaly suffers from noise and higher dimensionalmanifolds, etc - only the bal/arrow was in the input image, not the robotic arm.", "I understand this because in phase 1 the robot would not move, but this connects to the next point: - The representation learning is only a preprocessing step reqiring a magic first phase.", "-> Representation is not updated during exploration - The performance of any alorithm (except FI) in the Arm-Arrow task is realy bad but without comment.", "- I am skepticalabout the VAE and RFVAE results.", "The difference between Gaussian sampling and the KDE is a bit alrming, as the KL in the VAE training is supposed to match the p(z) with N(0,1).", "Given the power of the encoder/decoder it should be possible to properly represent the simple embedded 2D/3D manifold and not just a very smal part of it as suggested by fig10, I have a hard time believing these results.", "I urge you to check for any potentialerrors made.", "If there are not mistakes then this is indeed alrming.", "Questions: - Is it true that the robot alays starts from same initialcondition?!", "Context=Emptyset.", "- For ISOMap etc you alo used a 10dim embedding?", "Suggestion: - The main problem seems to be that some alorithms are not representing the whole input space.", "- an additionalmeasure that quantifies the difference between true input distribution and reproduced input distribution could tier the alorithms apart and would measure more what seems to be relevant here.", "One could for instance measure the KL-divergence between the true input and the sampled (reconstructed) input (using samples and KDE or the like).", "- This could be evalated on many different inputs (alo those with a bit more complicated structure) without actualy performing the goalfinding.", "- BTW: I think fig10 is rather illustrative and should be somehow in the main part of the paper On the positive side, the paper provides lots of details in the Appendix.", "Also, it uses many different Representation Learning alorithms and uses measures from manifold learning to access their qualty.", "In the related literature, in particular concerning the intrinsic motivation, I think the following papers are relevant: J Schmidhuber, PowerPlay: training an increasingly generalproblem solver by continualy searching for the simplest still unsolvable problem.", "Front.", "Psychol., 2013, and G Martius, R Der, and N Ay.", "Information driven self-organization of complex robotic behaviors.", "PLoS ONE, 8(5):e63400, 2013, Typos and smal details: p3 par2: for PCA you cited Bishop.", "Not critical but either cite one the originalpapers or maybe remove the cite alogether p4 par-2: has multiple interests...: interests -> purposes?", "p4 par-1: Outcome Space to the agent is is ... sec2 2 par1: are rapidly mentioned... -> briefly sec2 3 ...Outcome Space O, we can rewrite the architecture as: and then comes the alorithm.", "This is a bit weird sec3: par1: experimentalcampaign -> experiments?", "p7: Context Space: the object was reset to a random position or alays to the same position?", "Footnote 14: superior to -> larger than p8 par2: Exploration Ratio Ratio_expl... probably alo want to add (ER) as it is later used sec4: slightly underneath -> slightly below p9 par1: unfinished sentence: It is worth noting that the.... one sentence later: RP architecture?", "RPE?", "fig3: the error of the methods (except FI) are realy bad.", "An MSE of 1 means hardly any performance!", "p11 par2: for e g with the SAGG..... grammar?", "Plots in general use bigger font sizes."], "all_annotations": [{"interpretation": 1, "review_id": "Bk9oIe5gG", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "BkMvqjYgG", "review_text": "This paper focuses on the problem of \"machine teaching\", i.e., how to select a good strategy to select training data points to pass to a machine learning algorithm, for faster learning. The proposed approach leverages reinforcement learning by defining the reward as how fast the learner learns, and use policy gradient to update the teacher parameters. I find the definition of the \"state\" in this case very interesting. The experimental results seem to show that such a learned teacher strategy makes machine learning algorithms learn faster. \n\nOverall I think that this paper is decent. The angle the authors took is interesting (essentially replacing one level of the bi-level optimization problem in machine teaching works with a reinforcement learning setup). The problem formulation is mostly reasonable, and the evaluation seems quite convincing. The paper is well-written: I enjoyed the mathematical formulation (Section 3). The authors did a good job of using different experiments (filtration number analysis, and teaching both the same architecture and a different architecture) to intuitively explain what their method actually does. \n\nAt the same time, though, I see several important issues that need to be addressed if this paper is to be accepted. Details below. \n\n1. As much as I enjoyed reading Section 3, it is very redundant. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining \"teaching\" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). However, I do not see it being the case here. In my opinion, selecting good loss functions and hypothesis spaces are much harder problems than data teaching - except maybe when one use a pre-defined set of possible loss functions and select from it. But that is not very interesting (if you can propose new loss functions, that would be way cooler). I also do not see how to define an intuitive set of \"states\" in that case. Therefore, I think this section should be shortened. I also think that the authors should not discuss the general framework and rather focus on \"data teaching\", which is the only focus of the current paper. The abstract and introduction should also be modified accordingly to more honestly reflect the current contributions. \n2. The authors should do a better job at explaining the details of the state definition, especially the student model features and the combination of data and current learner model. \n3. There is only one definition of the reward - related to batch number when the accuracy first exceeds a threshold. Is accuracy stable, can it drop back down below the threshold in the next epoch? The accuracy on a held-out test set is not guaranteed to be monotonically increasing, right? Is this a problem in practice (it seems to happen on your curves)? What about other potential reward definitions? And what would they potentially lead to? \n4. Experimental results are averaged over 5 repeated runs - a bit too small in my opinion. \n5. Can the authors show convergence of the teacher parameter \\theta? I think it is important to see how fast the teacher model converges, too. \n6. In some of your experiments, every training method converges to the same accuracy after enough training (Fig.2b), while in others, not quite (Fig. 2a and 2c). Why is this the case? Does it mean that you have not run enough iterations for the baseline methods? My intuition is that if the learner algorithm is convex, then ultimately they will all get to the same accuracy level, so the task is just to get there quicker. I understand that since the learner algorithm is an NN, this is not the case - but more explanation is necessary here - does your method also reduces the empirical possibility to get stuck in local minima? \n7. More explanation is needed towards Fig.4c. In this case, using a teacher model trained on a harder task (CIFAR10) leads to much improved student training on a simpler task (MNIST). Why?\n8. Although in terms of \"effective training data points\" the proposed method outperforms the other methods, in terms of time (Fig.5) the difference between it and say, NoTeach, is not that significant (especially at very high desired accuracy). More explanation needed here. \n\nRead the rebuttal and revision and slightly increased my rating.", "gold_annotation": {"interpretation": 1, "review_id": "BkMvqjYgG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper focuses on the problem of \"machine teaching\", i e , how to select a good strategy to select training data points to pass to a machine learning alorithm, for faster learning.", "The proposed approach leverages reinforcement learning by defining the reward as how fast the learner learns, and use policy gradient to update the teacher parameters.", "I find the definition of the \"state\" in this case very interesting.", "The experimentalresults seem to show that such a learned teacher strategy makes machine learning alorithms learn faster.", "Overal I think that this paper is decent.", "The angle the authors took is interesting (essentialy replacing one level of the bi-level optimization problem in machine teaching works with a reinforcement learning setup).", "The problem formulation is mostly reasonable, and the evalation seems quite convincing.", "The paper is well-written: I enjoyed the mathematicalformulation (secion 3).", "The authors did a good job of using different experiments (filtration number analsis, and teaching both the same architecture and a different architecture) to intuitively explain what their method actualy does.", "At the same time, though, I see severalimportant issues that need to be addressed if this paper is to be accepted.", "Details below.", "1, As much as I enjoyed reading secion 3, it is very redundant.", "In some cases it is good to outline a powerful and generic framework (like the authors did here with defining \"teaching\" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points).", "However, I do not see it being the case here.", "In my opinion, selecting good loss functions and hypothesis spaces are much harder problems than data teaching - except maybe when one use a pre-defined set of possible loss functions and select from it.", "But that is not very interesting (if you can propose new loss functions, that would be way cooler).", "I alo do not see how to define an intuitive set of \"states\" in that case.", "Therefore, I think this secion should be shortened.", "I alo think that the authors should not discuss the generalframework and rather focus on \"data teaching\", which is the only focus of the current paper.", "The abstract and introduction should alo be modified accordingly to more honestly reflect the current contributions.", "2, The authors should do a better job at explaining the details of the state definition, especialy the student model features and the combination of data and current learner model.", "3, There is only one definition of the reward - related to batch number when the accuracy first exceeds a threshold.", "Is accuracy stable, can it drop back down below the threshold in the next epoch?", "The accuracy on a held-out test set is not guaranteed to be monotonicaly increasing, right?", "Is this a problem in practice (it seems to happen on your curves)?", "What about other potentialreward definitions?", "And what would they potentialy lead to?", "4, Experimentalresults are averaged over 5 repeated runs - a bit too smal in my opinion.", "5, Can the authors show convergence of the teacher parameter \\theta?", "I think it is important to see how fast the teacher model converges, too.", "6, In some of your experiments, every training method converges to the same accuracy after enough training (fig2b), while in others, not quite (fig 2a and 2c).", "Why is this the case?", "Does it mean that you have not run enough iterations for the baseline methods?", "My intuition is that if the learner alorithm is convex, then ultimately they will al get to the same accuracy level, so the task is just to get there quicker.", "I understand that since the learner alorithm is an NN, this is not the case - but more explanation is necessary here - does your method alo reduces the empiricalpossibility to get stuck in localminima?", "7, More explanation is needed towards fig4c.", "In this case, using a teacher model trained on a harder task (CIFAR10) leads to much improved student training on a simpler task (MNIST).", "Why?", "8, Although in terms of \"effective training data points\" the proposed method outperforms the other methods, in terms of time (fig5) the difference between it and say, NoTeach, is not that significant (especialy at very high desired accuracy).", "More explanation needed here.", "Read the rebuttaland revision and slightly increased my rating."], "all_annotations": [{"interpretation": 1, "review_id": "BkMvqjYgG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "BkOfh_eWM", "review_text": "The paper discusses the problem of optimizing neural networks with hard threshold and proposes a novel solution to it. The problem is of significance because in many applications one requires deep networks which uses reduced computation and limited energy. The authors frame the problem of optimizing such networks to fit the training data as a convex combinatorial problems. However since the complexity of such a problem is exponential, the authors propose a collection of heuristics/approximations to solve the problem. These include, a heuristic for setting the targets at each layer, using a soft hinge loss, mini-batch training and such. Using these modifications the authors propose an algorithm (Algorithm 2 in appendix) to train such models efficiently. They compare the performance of a bunch of models trained by their algorithm against the ones trained using straight-through-estimator (SSTE) on a couple of datasets, namely, CIFAR-10 and ImageNet. They show superiority of their algorithm over SSTE. \n\nI thought the paper is very well written and provides a really nice exposition of the problem of training deep networks with hard thresholds. The authors formulation of the problem as one of combinatorial optimization and proposing Algorithm 1 is also quite interesting. The results are moderately convincing in favor of the proposed approach. Though a disclaimer here is that I'm not 100% sure that SSTE is the state of the art for this problem. Overall i like the originality of the paper and feel that it has a potential of reasonable impact within the research community. \n\nThere are a few flaws/weaknesses in the paper though, making it somewhat lose. \n- The authors start of by posing the problem as a clean combinatorial optimization problem and propose Algorithm 1. Realizing the limitations of the proposed algorithm, given the assumptions under which it was conceived in, the authors relax those assumptions in the couple of paragraphs before section 3.1 and pretty much throw away all the nice guarantees, such as checks for feasibility, discussed earlier. \n- The result of this is another algorithm (I guess the main result of the paper), which is strangely presented in the appendix as opposed to the main text, which has no such guarantees.  \n- There is no theoretical proof that the heuristic for setting the target is a good one, other than a rough intuition\n- The authors do not discuss at all the impact on generalization ability of the model trained using the proposed approach. The entire discussion revolves around fitting the training set and somehow magically everything seem to generalize and not overfit. \n", "gold_annotation": {"interpretation": 0, "review_id": "BkOfh_eWM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 2.5, "tokenized_review_text": ["The paper discusses the problem of optimizing neuralnetworks with hard threshold and proposes a novel solution to it.", "The problem is of significance because in many applications one reqires deep networks which uses reduced computation and limited energy.", "The authors frame the problem of optimizing such networks to fit the training data as a convex combinatorialproblems.", "However since the complexity of such a problem is exponential the authors propose a collection of heuristics/approximations to solve the problem.", "These include, a heuristic for setting the targets at each layer, using a soft hinge loss, mini-batch training and such.", "Using these modifications the authors propose an alorithm (Algorithm 2 in appendix) to train such models efficiently.", "They compare the performance of a bunch of models trained by their alorithm against the ones trained using straight-through-estimator (SSTE) on a couple of datasets, namely, CIFAR-10 and ImageNet.", "They show superiority of their alorithm over SSTE.", "I thought the paper is very well written and provides a realy nice exposition of the problem of training deep networks with hard thresholds.", "The authors formulation of the problem as one of combinatorialoptimization and proposing Algorithm 1 is alo quite interesting.", "The results are moderately convincing in favor of the proposed approach.", "Though a disclaimer here is that I'm not 100% sure that SSTE is the state of the art for this problem.", "Overal i like the originalty of the paper and feel that it has a potentialof reasonable impact within the research community.", "There are a few flaws/weaknesses in the paper though, making it somewhat lose.", "- The authors start of by posing the problem as a clean combinatorialoptimization problem and propose Algorithm 1, Realzing the limitations of the proposed alorithm, given the assumptions under which it was conceived in, the authors relax those assumptions in the couple of paragraphs before secion 3 1 and pretty much throw away al the nice guarantees, such as checks for feasibility, discussed earlier.", "- The result of this is another alorithm (I guess the main result of the paper), which is strangely presented in the appendix as opposed to the main text, which has no such guarantees.", "- There is no theoreticalproof that the heuristic for setting the target is a good one, other than a rough intuition - The authors do not discuss at al the impact on generalzation ability of the model trained using the proposed approach.", "The entire discussion revolves around fitting the training set and somehow magicaly everything seem to generalze and not overfit."], "all_annotations": [{"interpretation": 0, "review_id": "BkOfh_eWM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "By-CxBKgz", "review_text": "This paper presents Defense-GAN: a GAN that used at test time to map the input generate an image (G(z)) close (in MSE(G(z), x)) to the input image (x), by applying several steps of gradient descent of this MSE. The GAN is a WGAN trained on the train set (only to keep the generator). The goal of the whole approach is to be robust to adversarial examples, without having to change the (downstream task) classifier, only swapping in the G(z) for the x.\n\n+ The paper is easy to follow.\n+ It seems (but I am not an expert in adversarial examples) to cite the relevant litterature (that I know of) and compare to reasonably established attacks and defenses.\n+ Simple/directly applicable approach that seems to work experimentally, but\n- A missing baseline is to take the nearest neighbour of the (perturbed) x from the training set.\n- Only MNIST-sized images, and MNIST-like (60k train set, 10 labels) datasets: MNIST and F-MNIST.\n- Between 0.043sec and 0.825 sec to reconstruct an MNIST-sized image.\n? MagNet results were very often worse than no defense in Table 4, could you comment on that?\n- In white-box attacks, it seems to me like L steps of gradient descent on MSE(G(z), x) should be directly extended to L steps of (at least) FGSM-based attacks, at least as a control.", "gold_annotation": {"interpretation": 0, "review_id": "By-CxBKgz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, "score": 2.5, "tokenized_review_text": ["This paper presents Defense-GAN: a GAN that used at test time to map the input generate an image (G(z)) close (in MSE(G(z), x)) to the input image (x), by applying severalsteps of gradient descent of this MSE.", "The GAN is a WGAN trained on the train set (only to keep the generator).", "The goalof the whole approach is to be robust to adversarialexamples, without having to change the (downstream task) classifier, only swapping in the G(z) for the x + The paper is easy to follow.", "+ It seems (but I am not an expert in adversarialexamples) to cite the relevant litterature (that I know of) and compare to reasonably established attacks and defenses.", "+ Simple/directly applicable approach that seems to work experimentaly, but - A missing baseline is to take the nearest neighbour of the (perturbed) x from the training set.", "- Only MNIST-sized images, and MNIST-like (60k train set, 10 labels) datasets: MNIST and F-MNIST.", "- Between 0 043secand 0 825 secto reconstruct an MNIST-sized image.", "?", "MagNet results were very often worse than no defense in Table 4, could you comment on that?", "- In white-box attacks, it seems to me like L steps of gradient descent on MSE(G(z), x) should be directly extended to L steps of (at least) FGSM-based attacks, at least as a control."], "all_annotations": [{"interpretation": 0, "review_id": "By-CxBKgz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "By2zFR_gz", "review_text": "Quality: Although the research problem is an interesting direction the quality of the work is not of a high standard. My main conservation is that the idea of perturbation in semantic latent space has not been described in an explicit way. How different it will be compared to a perturbation in an input space? \n\nClarity: The use of the term \"adversarial\" is not quite clear in the context as in many of those example classification problems the perturbation completely changes the class label (e.g. from \"church\" to \"tower\" or vice-versa)\n\nOriginality: The generation of adversarial examples in black-box classifiers has been looked in GAN literature as well and gradient based perturbations are studied too. What is the main benefit of the proposed mechanism compared to the existing ones?\n\nSignificance: The research problem is indeed a significant one as it is very important to understand the robustness of the modern machine learning methods by exposing them to adversarial scenarios where they might fail.\n\npros:\n(a) An interesting problem to evaluate the robustness of black-box classifier systems\n(b) generating adversarial examples for image classification as well as text analysis.\n(c) exploiting the recent developments in GAN literature to build the framework forge generating adversarial examples.\n\ncons:\n(a) The proposed search algorithm in the semantic latent space could be computationally intensive. any remedy for this problem?\n(b) Searching in the latent space z could be strongly dependent on the matching inverter $I_\\gamma(.)$. any comment on this?\n(c) The application of the search algorithm in case of imbalanced classes could be something that require further investigation.", "gold_annotation": {"interpretation": 0, "review_id": "By2zFR_gz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Qualty: Although the research problem is an interesting direction the qualty of the work is not of a high standard.", "My main conservation is that the idea of perturbation in semantic latent space has not been described in an explicit way.", "How different it will be compared to a perturbation in an input space?", "Clarity: The use of the term \"adversarial is not quite clear in the context as in many of those example classification problems the perturbation completely changes the class label (e g from \"church\" to \"tower\" or vice-versa) Originalty: The generation of adversarialexamples in black-box classifiers has been looked in GAN literature as well and gradient based perturbations are studied too.", "What is the main benefit of the proposed mechanism compared to the existing ones?", "Significance: The research problem is indeed a significant one as it is very important to understand the robustness of the modern machine learning methods by exposing them to adversarialscenarios where they might fail.", "pros: (a) An interesting problem to evalate the robustness of black-box classifier systems (b) generating adversarialexamples for image classification as well as text analsis.", "(c) exploiting the recent developments in GAN literature to build the framework forge generating adversarialexamples.", "cons: (a) The proposed search alorithm in the semantic latent space could be computationaly intensive.", "any remedy for this problem?", "(b) Searching in the latent space z could be strongly dependent on the matching inverter $I_\\gamma(.)$.", "any comment on this?", "(c) The application of the search alorithm in case of imbalnced classes could be something that reqire further investigation."], "all_annotations": [{"interpretation": 0, "review_id": "By2zFR_gz", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "ByC55Gcxz", "review_text": "Clearly presented paper, including a number of reasonable techniques to improve LSTM-LMs. The proposed techniques are heuristic, but are reasonable and appear to yield improvements in perplexity. Some specific comments follow.\n\nre. \"ASGD\" for Averaged SGD: ASGD usually stands for Asynchronous SGD, have the authors considered an alternative acronym? AvSGD?\n\nre. Optimization criterion on page 2, note that SGD is usually taken to minimizing expected loss, not just empirical loss (Bottou thesis 1991).\n\nIs there any theoretical analysis of convergence for Averaged SGD?\n\nre. paragraph starting with \"To prevent such inefficient data usage, we randomly select the sequence length for the forward and backward pass in two steps\": the explanation is a bit unclear. What is the \"base sequence length\" exactly? Also, re. the motivation above this paragraph, I'm not sure what \"elements\" really refers to, though I can guess.\n\nWhat is the number of training tokens of the datasets used, PTB and WT2?\n\nCan the authors provide more explanation for what \"neural cache models\" are, and how they relate to \"pointer models\"?\n\nWhy do the sections \"Pointer models\", \"Ablation analysis\", and \"AWD-QRNN\" come after the Experiments section?", "gold_annotation": {"interpretation": 0, "review_id": "ByC55Gcxz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, "score": 2.5, "tokenized_review_text": ["Clearly presented paper, including a number of reasonable techniques to improve LSTM-LMs.", "The proposed techniques are heuristic, but are reasonable and appear to yield improvements in perplexity.", "Some specific comments follow.", "re.", "\"ASGD\" for Averaged SGD: ASGD usualy stands for Asynchronous SGD, have the authors considered an alernative acronym?", "AvSGD?", "re.", "Optimization criterion on page 2, note that SGD is usualy taken to minimizing expected loss, not just empiricalloss (Bottou thesis 1991).", "Is there any theoreticalanalsis of convergence for Averaged SGD?", "re.", "paragraph starting with \"To prevent such inefficient data usage, we randomly select the seqence length for the forward and backward pass in two steps\": the explanation is a bit unclear.", "What is the \"base seqence length\" exactly?", "Also, re.", "the motivation above this paragraph, I'm not sure what \"elements\" realy refers to, though I can guess.", "What is the number of training tokens of the datasets used, PTB and WT2?", "Can the authors provide more explanation for what \"neuralcache models\" are, and how they relate to \"pointer models\"?", "Why do the secions \"Pointer models\", \"Ablation analsis\", and \"AWD-QRNN\" come after the Experiments secion?"], "all_annotations": [{"interpretation": 0, "review_id": "ByC55Gcxz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "ByCeFUNgz", "review_text": "The authors propose a new episodic reinforcement learning algorithm based on contextual bandit oracles.\nThe key specificity of this algorithm is its ability to deal with the credit assignment problem by learning automatically a progressive \"reward shaping\" (the residual losses) from a feedback that is only provided at the end of the epochs.\n\nThe paper is dense but well written. \n\nThe theoretical grounding is a bit thin or hard to follow.\nThe authors provide a few regret theoretical results (that I did not check deeply) obtained by reduction to \"value-aware\" contextual bandits.\n\nThe experimental section is solid. The method is evaluated on several RL environments against state of the art RL algorithms. It is also evaluated on bandit structured prediction tasks.\nAn interesting synthetic experiment (Figure 4) is also proposed to study the ability of the algorithm to work on both decomposable and non-decomposable structured prediction tasks.\n\n\nQuestion 1: The credit assignment approach you propose seems way more sophisticated than eligibility traces in TD learning. But sometimes old and simple methods are not that bad. Could you develop a bit on the relation between RESLOPE and eligibility traces ?\n\nQuestion 2: RESLOPE is built upon contextual bandits which require a stationary environment. Does RESLOPE inherit from this assumption?\n\n\nTypos:\npage 1 \n\"scalar loss that output.\" -> \"scalar loss.\"\n\", effectively a representation\" -> \". By effective we mean effective in term of credit assignment.\"\npage 5\n\"and MTR\" -> \"and DR\"\npage 6\n\"in simultaneously.\" -> ???\n\".In greedy\" -> \". In greedy\"\n", "gold_annotation": {"interpretation": 0, "review_id": "ByCeFUNgz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The authors propose a new episodic reinforcement learning alorithm based on contextualbandit oracles.", "The key specificity of this alorithm is its ability to dealwith the credit assignment problem by learning automaticaly a progressive \"reward shaping\" (the residuallosses) from a feedback that is only provided at the end of the epochs.", "The paper is dense but well written.", "The theoreticalgrounding is a bit thin or hard to follow.", "The authors provide a few regret theoreticalresults (that I did not check deeply) obtained by reduction to \"vale-aware\" contextualbandits.", "The experimentalsecion is solid.", "The method is evalated on severalRL environments against state of the art RL alorithms.", "It is alo evalated on bandit structured prediction tasks.", "An interesting synthetic experiment (figre 4) is alo proposed to study the ability of the alorithm to work on both decomposable and non-decomposable structured prediction tasks.", "Question 1: The credit assignment approach you propose seems way more sophisticated than eligibility traces in TD learning.", "But sometimes old and simple methods are not that bad.", "Could you develop a bit on the relation between RESLOPE and eligibility traces ?", "Question 2: RESLOPE is built upon contextualbandits which reqire a stationary environment.", "Does RESLOPE inherit from this assumption?", "Typos: page 1 \"scalr loss that output.\"", "-> \"scalr loss.\"", "\", effectively a representation\" -> \".", "By effective we mean effective in term of credit assignment.\"", "page 5 \"and MTR\" -> \"and DR\" page 6 \"in simultaneously.\"", "-> ???", "\".In greedy\" -> \".", "In greedy\""], "all_annotations": [{"interpretation": 0, "review_id": "ByCeFUNgz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "ByFZUzFlf", "review_text": "Active learning for deep learning is an interesting topic and there is few useful tool available in the literature. It is happy to see such paper in the field. This paper proposes a batch mode active learning algorithm for CNN as a core-set problem. The authors provide an upper bound of the core-set loss, which is the gap between the training loss on the whole set and the core-set. By minimizing this upper bound, the problem becomes a K-center problem which can be solved by using a greedy approximation method, 2-OPT. The experiments are performed on image classification problem (CIFAR, CALTECH, SVHN datasets), under either supervised setting or weakly-supervised setting. Results show that the proposed method outperforms the random sampling and uncertainty sampling by a large margin. Moreover, the authors show that 2-OPT can save tractable amount of time in practice with a small accuracy drop.\n\nThe proposed algorithm is new and writing is clear. However, the paper is not flawless. The proposed active learning framework is under ERM and cover-set, which are currently not supported by deep learning. To validate such theoretical result, a non-deep-learning model should be adopted. The ERM for active learning has been investigated in the literature, such as \"Querying discriminative and representative samples for batch mode active learning\" in KDD 2013, which also provided an upper bound loss of the batch mode active learning and seems applicable for the problem in this paper. Another interesting question is most of the competing algorithm is myoptic active learning algorithms. The comparison is not fair enough. The authors should provide more competing algorithms in batch mode active learning.", "gold_annotation": {"interpretation": 0, "review_id": "ByFZUzFlf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Active learning for deep learning is an interesting topic and there is few useful tool available in the literature.", "It is happy to see such paper in the field.", "This paper proposes a batch mode active learning alorithm for CNN as a core-set problem.", "The authors provide an upper bound of the core-set loss, which is the gap between the training loss on the whole set and the core-set.", "By minimizing this upper bound, the problem becomes a K-center problem which can be solved by using a greedy approximation method, 2-OPT.", "The experiments are performed on image classification problem (CIFAR, CALTECH, SVHN datasets), under either supervised setting or weakly-supervised setting.", "Results show that the proposed method outperforms the random sampling and uncertainty sampling by a large margin.", "Moreover, the authors show that 2-OPT can save tractable amount of time in practice with a smal accuracy drop.", "The proposed alorithm is new and writing is clear.", "However, the paper is not flawless.", "The proposed active learning framework is under ERM and cover-set, which are currently not supported by deep learning.", "To valdate such theoreticalresult, a non-deep-learning model should be adopted.", "The ERM for active learning has been investigated in the literature, such as \"Querying discriminative and representative samples for batch mode active learning\" in KDD 2013, which alo provided an upper bound loss of the batch mode active learning and seems applicable for the problem in this paper.", "Another interesting question is most of the competing alorithm is myoptic active learning alorithms.", "The comparison is not fair enough.", "The authors should provide more competing alorithms in batch mode active learning."], "all_annotations": [{"interpretation": 0, "review_id": "ByFZUzFlf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "ByGPUUYgz", "review_text": "This paper attacks an important problems with an interesting and promising methodology.  The authors deal with inference in models of collective behavior, specifically at how to infer the parameters of a mean field game representation of collective behavior. The technique the authors innovate is to specify a mean field game as a model, and then use inverse reinforcement learning to learn the reward functions of agents in the mean field game.\n\nThis work has many virtues, and could be an impactful piece. There is still minimal work at the intersection of machine learning and collective behavior, and this paper could help to stimulate the growth of that intersection.  The application to collective behavior could be an interesting novel application to many in machine learning, and conversely the inference techniques that are innovated should be novel to many researchers in collective behavior.\n\nAt the same time, the scientific content of the work has critical conceptual flaws.  Most fundamentally, the authors appear to implicitly center their work around highly controversial claims about the ontological status of group optimization, without the careful justification necessary to make this kind of argument.  In addition to that, the authors appear to implicitly assume that utility function inference can be used for causal inference. \n\nThat is, there are two distinct mistakes the authors make in their scientific claims:\n1) The authors write as if mean field games represent population optimization (Mean field games are not about what a _group_ optimizes; they are about what _individuals_ optimize, and this individual optimization leads to certain patterns in collective behaviors)\n2) The authors write as if utility/reward function inference alone can provide causal understanding of collective or individual behavior\n\n1 - \n\nI should say that I am highly sympathetic to the claim that many types of collective behavior can be viewed as optimizing some kind of objective function.  However, this claim is far from mainstream, and is in fact highly contested.  For instance, many prominent pieces of work in the study of collective behavior have highlighted its irrational aspects, from the madness of crowds to herding in financial markets.\n\nSince it is so fringe to attribute causal agency to groups, let alone optimal agency, in the remainder of my review I will give the authors the benefit of the doubt and assume when they say things like \"population behavior may be optimal\", they mean \"the behavior of individuals within a population may be optimal\".  If the authors do mean to say this, they should be more careful about their language use in this regard (individuals are the actors, not populations).  If the authors do indeed mean to attribute causal agency to groups (as suggested in their MDP representation), they will run into all the criticisms I would have about an individual-level analysis and more.  Suffice it to say, mean field games themselves don't make claims about aggregate-level optimization.  A Nash equilibrium achieves a balance between individual-level reward functions. These reward functions are only interpretable at the individual level.  There is no objective function the group itself in aggregate is optimizing in mean field games.  For instance, even though the mean field game model of the Mexican wave produces wave solutions, the model is premised on people having individual utility functions that lead to emergent wave behavior.  The model does not have the representational capacity to explain that people actually intend to create the emergent behavior of a wave (even though in this case they do).  Furthermore, the fact that mean field games aggregate to a single-agent MDP does not imply that that the group can rightfully be thought of as an agent optimizing the reward function, because there is an exact correspondence between the rewards of the individual agents in the MFG and of the aggregate agent in the MDP by construction.\n\n2 -\n\nThe authors also claim that their inference methods can help explain why people choose to talk about certain topics. As far as the extent to which utility / reward function inference can provide causal explanations of individual (or collective) behavior, the argument that is invariably brought against a claim of optimization is that almost any behavior can be explained as optimal post-hoc with enough degrees of freedom in the utiliy function of the behavioral model. Since optimization frameworks are so flexible, they have little explanatory power and are hard to falsify.  In fact, there is literally no way that the modeling framework of the authors even affords the possibility that individual/collective behavior is not optimal.  Optimality is taken as an assumption that allows the authors to infer what reward function is being optimized. \n\nThe authors state that the reward function they infer helps to interpret collective behavior because it reveals what people are optimizing.  However, the reward function actually discovered is not interpretable at all. It is simply a summary of the statistical properties of changes in popularity of the topics of conversation in the Twitter data the authors' study. To quote the authors' insights: \"The learned reward function reveals that a real social media population favors states characterized by a highly non-uniform distribution with negative mass gradient in decreasing order of topic popularity, as well as transitions that increase this distribution imbalance.\"  The authors might as well have simply visualized the topic popularities and changes in popularities to arrive at such an insight. To take the authors claims literally, we would say that people have an intrinsic preference for everyone to arbitrarily be talking about the same thing, regardless of the content or relevance of that topic.  To draw an analogy, this is like observing that on some days everybody on the street is carrying open umbrellas and on other days not, and inferring that the people on the street have a preference for everyone having their umbrellas open together (and the model would then predict that if one person opens an umbrella on a sunny day, everybody else will too).\n\nTo the authors credit, they do make a brief attempt to present empirical evidence for their optimization view, stating succinctly: \"The high prediction accuracy of the learned policy provides evidence that real population behavior can be understood and modeled as the result of an emergent population-level optimization with respect to a reward function.\" Needless to say, this one-sentence argument for a highly controversial scientific claims falls flat on closer inspection. Setting aside the issues of correlation versus causation, predictive accuracy does not in and of itself provide scientific plausibility. When an n-gram model produces text that is in the style of a particular writer, we do not conclude that the writer must have been composing based on the n-gram's generative mechanism.  Predictive accuracy only provides evidence when combined in the first place with scientific plausibility through other avenues of evidence.\n\nThe authors could attempt to address these issues by making what is called an \"as-if\" argument, but it's not even clear such an argument could work here in general.  \n\nWith all this in mind, it would be more instructive to show that the inference method the authors introduce could infer the correct utility functions used in standard mean field games, such as modeling traffic congestion and the Mexican wave.  \n\n--\n\nAll that said, the general approach taken in the authors' work is highly promising, and there are many fruitful directions I would be exicted to see this work taken --- e.g., combining endogenous and exogenous rewards or looking at more complex applications.  As a technical contribution, the paper is wonderful, and I would enthusiastically support acceptance.  The authors simply either need to be much more careful with the scientific claims about collective behavior they make, or limit the scope of the contribution of the paper to be modeling / inference  in the area of collective behavior.  Mean field games are an important class of models in collective behavior, and being able to infer their parameters is a nice step forward purely due to the importance of that class of games.  Identifying where the authors' inference method could be applied to draw valid scientific conclusions about collective behavior could then be an avenue for future work.  Examples of plausible scientific applications might include parameter inference in settings where mean field games are already typically applied in order to improve the fit of those models or to learn about trade-offs people make in their utility functions in those settings.\n\n--\n\nOther minor comments:\n- (Introduction) It is not clear at all how the Arab Spring, Black Lives Matter, and fake news are similar --- i.e., whether a single model could provide insight into these highly heterogeneous events --- nor is it clear what end the authors hope to achieve by modeling them --- the ethics of modeling protests in a field crowded with powerful institutional actors is worth carefully considering.\n- If I understand correctly, the fact that the authors assume a factored reward function seems limiting. Isn't the major benefit of game theory it's ability to accommodate utility functions that depend on the actions of others?\n- The authors state that one of their essential insights is that \"solving the optimization problem of a single-agent MDP is equivalent to solving the inference problem of an MFG.\" This statement feels a bit too cute at the expense of clarity. The authors perform inference via inverse-RL, so it's more clear to say the authors are attempting to use statistical inference to figure out what is being optimized.\n- The relationship between MFGs and a single-agent MDP is nice and a fine observation, but not as surprising as the authors frame it as. Any multiagent MDP can be naively represented as a single-agent MDP where the agent has control over the entire population, and we already know that stochastic games are closely related to MDPs.  It's therefore hard to imagine that there woudn't be some sort of correspondence. ", "gold_annotation": {"interpretation": 1, "review_id": "ByGPUUYgz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-disagree", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper attacks an important problems with an interesting and promising methodology.", "The authors dealwith inference in models of collective behavior, specificaly at how to infer the parameters of a mean field game representation of collective behavior.", "The technique the authors innovate is to specify a mean field game as a model, and then use inverse reinforcement learning to learn the reward functions of agents in the mean field game.", "This work has many virtues, and could be an impactful piece.", "There is still minimalwork at the intersecion of machine learning and collective behavior, and this paper could help to stimulate the growth of that intersecion.", "The application to collective behavior could be an interesting novel application to many in machine learning, and conversely the inference techniques that are innovated should be novel to many researchers in collective behavior.", "At the same time, the scientific content of the work has criticalconceptualflaws.", "Most fundamentaly, the authors appear to implicitly center their work around highly controversialclaims about the ontologicalstatus of group optimization, without the careful justification necessary to make this kind of argument.", "In addition to that, the authors appear to implicitly assume that utility function inference can be used for causalinference.", "That is, there are two distinct mistakes the authors make in their scientific claims: 1) The authors write as if mean field games represent population optimization (Mean field games are not about what a _group_ optimizes; they are about what _individual_ optimize, and this individualoptimization leads to certain patterns in collective behaviors) 2) The authors write as if utility/reward function inference alne can provide causalunderstanding of collective or individualbehavior 1 - I should say that I am highly sympathetic to the claim that many types of collective behavior can be viewed as optimizing some kind of objective function.", "However, this claim is far from mainstream, and is in fact highly contested.", "For instance, many prominent pieces of work in the study of collective behavior have highlighted its irrationalaspects, from the madness of crowds to herding in financialmarkets.", "Since it is so fringe to attribute causalagency to groups, let alne optimalagency, in the remainder of my review I will give the authors the benefit of the doubt and assume when they say things like \"population behavior may be optimal, they mean \"the behavior of individual within a population may be optimal.", "If the authors do mean to say this, they should be more careful about their language use in this regard (individual are the actors, not populations).", "If the authors do indeed mean to attribute causalagency to groups (as suggested in their MDP representation), they will run into al the criticisms I would have about an individuallevel analsis and more.", "Suffice it to say, mean field games themselves don't make claims about aggregate-level optimization.", "A Nash eqilibrium achieves a balnce between individuallevel reward functions.", "These reward functions are only interpretable at the individuallevel.", "There is no objective function the group itself in aggregate is optimizing in mean field games.", "For instance, even though the mean field game model of the Mexican wave produces wave solutions, the model is premised on people having individualutility functions that lead to emergent wave behavior.", "The model does not have the representationalcapacity to explain that people actualy intend to create the emergent behavior of a wave (even though in this case they do).", "Furthermore, the fact that mean field games aggregate to a single-agent MDP does not imply that that the group can rightfully be thought of as an agent optimizing the reward function, because there is an exact correspondence between the rewards of the individualagents in the MFG and of the aggregate agent in the MDP by construction.", "2 - The authors alo claim that their inference methods can help explain why people choose to tal about certain topics.", "As far as the extent to which utility / reward function inference can provide causalexplanations of individual(or collective) behavior, the argument that is invariably brought against a claim of optimization is that alost any behavior can be explained as optimalpost-hoc with enough degrees of freedom in the utiliy function of the behavioralmodel.", "Since optimization frameworks are so flexible, they have little explanatory power and are hard to falify.", "In fact, there is literaly no way that the modeling framework of the authors even affords the possibility that individualcollective behavior is not optimal Optimalty is taken as an assumption that alows the authors to infer what reward function is being optimized.", "The authors state that the reward function they infer helps to interpret collective behavior because it reveal what people are optimizing.", "However, the reward function actualy discovered is not interpretable at al.", "It is simply a summary of the statisticalproperties of changes in popularity of the topics of conversation in the Twitter data the authors' study.", "To quote the authors' insights: \"The learned reward function reveal that a realsocialmedia population favors states characterized by a highly non-uniform distribution with negative mass gradient in decreasing order of topic popularity, as well as transitions that increase this distribution imbalnce.\"", "The authors might as well have simply visualzed the topic popularities and changes in popularities to arrive at such an insight.", "To take the authors claims literaly, we would say that people have an intrinsic preference for everyone to arbitrarily be taling about the same thing, regardless of the content or relevance of that topic.", "To draw an analgy, this is like observing that on some days everybody on the street is carrying open umbrellas and on other days not, and inferring that the people on the street have a preference for everyone having their umbrellas open together (and the model would then predict that if one person opens an umbrella on a sunny day, everybody else will too).", "To the authors credit, they do make a brief attempt to present empiricalevidence for their optimization view, stating succinctly: \"The high prediction accuracy of the learned policy provides evidence that realpopulation behavior can be understood and modeled as the result of an emergent population-level optimization with respect to a reward function.\"", "Needless to say, this one-sentence argument for a highly controversialscientific claims fals flat on closer inspection.", "Setting aside the issues of correlation versus causation, predictive accuracy does not in and of itself provide scientific plausibility.", "When an n-gram model produces text that is in the style of a particular writer, we do not conclude that the writer must have been composing based on the n-gram's generative mechanism.", "Predictive accuracy only provides evidence when combined in the first place with scientific plausibility through other avenues of evidence.", "The authors could attempt to address these issues by making what is caled an \"as-if\" argument, but it's not even clear such an argument could work here in general With al this in mind, it would be more instructive to show that the inference method the authors introduce could infer the correct utility functions used in standard mean field games, such as modeling traffic congestion and the Mexican wave.", "-- All that said, the generalapproach taken in the authors' work is highly promising, and there are many fruitful directions I would be exicted to see this work taken --- e g , combining endogenous and exogenous rewards or looking at more complex applications.", "As a technicalcontribution, the paper is wonderful, and I would enthusiasticaly support acceptance.", "The authors simply either need to be much more careful with the scientific claims about collective behavior they make, or limit the scope of the contribution of the paper to be modeling / inference in the area of collective behavior.", "Mean field games are an important class of models in collective behavior, and being able to infer their parameters is a nice step forward purely due to the importance of that class of games.", "Identifying where the authors' inference method could be applied to draw vald scientific conclusions about collective behavior could then be an avenue for future work.", "Examples of plausible scientific applications might include parameter inference in settings where mean field games are aleady typicaly applied in order to improve the fit of those models or to learn about trade-offs people make in their utility functions in those settings.", "-- Other minor comments: - (Introduction) It is not clear at al how the Arab Spring, Black Lives Matter, and fake news are similar --- i e , whether a single model could provide insight into these highly heterogeneous events --- nor is it clear what end the authors hope to achieve by modeling them --- the ethics of modeling protests in a field crowded with powerful institutionalactors is worth carefully considering.", "- If I understand correctly, the fact that the authors assume a factored reward function seems limiting.", "Isn't the major benefit of game theory it's ability to accommodate utility functions that depend on the actions of others?", "- The authors state that one of their essentialinsights is that \"solving the optimization problem of a single-agent MDP is eqivalnt to solving the inference problem of an MFG.\"", "This statement feels a bit too cute at the expense of clarity.", "The authors perform inference via inverse-RL, so it's more clear to say the authors are attempting to use statisticalinference to figre out what is being optimized.", "- The relationship between MFGs and a single-agent MDP is nice and a fine observation, but not as surprising as the authors frame it as.", "Any multiagent MDP can be naively represented as a single-agent MDP where the agent has control over the entire population, and we aleady know that stochastic games are closely related to MDPs.", "It's therefore hard to imagine that there woudn't be some sort of correspondence."], "all_annotations": [{"interpretation": 1, "review_id": "ByGPUUYgz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-disagree", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "ByHD_eqxf", "review_text": "Let me first note that I am not very familiar with the literature on program generation, \nmolecule design or compiler theory, which this paper draws heavily from, so my review is an educated guess. \n\nThis paper proposes to include additional constraints into a VAE which generates discrete sequences, \nnamely constraints enforcing both semantic and syntactic validity. \nThis is an extension to the Grammar VAE of Kusner et. al, which includes syntactic constraints but not semantic ones.\nThese semantic constraints are formalized in the form of an attribute grammar, which is provided in addition to the context-free grammar.\nThe authors evaluate their methods on two tasks, program generation and molecule generation. \n\nTheir method makes use of additional prior knowledge of semantics, which seems task-specific and limits the generality of their model. \nThey report that their method outperforms the Character VAE (CVAE) and Grammar VAE (GVAE) of Kusner et. al.  \nHowever, it isn't clear whether the comparison is appropriate: the authors report in the appendix that they use the kekulised version of the Zinc dataset of Kusner et. al, whereas Kusner et. al do not make any mention of this. \nThe baselines they compare against for CVAE and GVAE in Table 1 are taken directly from Kusner et. al though. \nCan the authors clarify whether the different methods they compare in Table 1 are all run on the same dataset format?\n\nTypos:\n- Page 5: \"while in sampling procedure\" -> \"while in the sampling procedure\"\n- Page 6: \"a deep convolution neural networks\" -> \"a deep convolutional neural network\"\n- Page 6: \"KL-divergence that proposed in\" -> \"KL-divergence that was proposed in\" \n- Page 6: \"since in training time\" -> \"since at training time\"\n- Page 6: \"can effectively computed\" -> \"can effectively be computed\"\n- Page 7: \"reset for training\" -> \"rest for training\" ", "gold_annotation": {"interpretation": 1, "review_id": "ByHD_eqxf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}, "score": 2.0, "tokenized_review_text": ["Let me first note that I am not very familiar with the literature on program generation, molecule design or compiler theory, which this paper draws heavily from, so my review is an educated guess.", "This paper proposes to include additionalconstraints into a VAE which generates discrete seqences, namely constraints enforcing both semantic and syntactic valdity.", "This is an extension to the Grammar VAE of Kusner et.", "al which includes syntactic constraints but not semantic ones.", "These semantic constraints are formalzed in the form of an attribute grammar, which is provided in addition to the context-free grammar.", "The authors evalate their methods on two tasks, program generation and molecule generation.", "Their method makes use of additionalprior knowledge of semantics, which seems task-specific and limits the generalty of their model.", "They report that their method outperforms the Character VAE (CVAE) and Grammar VAE (GVAE) of Kusner et.", "al However, it isn't clear whether the comparison is appropriate: the authors report in the appendix that they use the kekulised version of the Zinc dataset of Kusner et.", "al whereas Kusner et.", "aldo not make any mention of this.", "The baselines they compare against for CVAE and GVAE in Table 1 are taken directly from Kusner et.", "although.", "Can the authors clarify whether the different methods they compare in Table 1 are al run on the same dataset format?", "Typos: - Page 5: \"while in sampling procedure\" -> \"while in the sampling procedure\" - Page 6: \"a deep convolution neuralnetworks\" -> \"a deep convolutionalneuralnetwork\" - Page 6: \"KL-divergence that proposed in\" -> \"KL-divergence that was proposed in\" - Page 6: \"since in training time\" -> \"since at training time\" - Page 6: \"can effectively computed\" -> \"can effectively be computed\" - Page 7: \"reset for training\" -> \"rest for training\""], "all_annotations": [{"interpretation": 1, "review_id": "ByHD_eqxf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "ByRWmWAxM", "review_text": "This paper proposes an extremely simple methodology to improve the network's performance by adding extra random perturbations (resizing/padding) at evaluation time.\n\nAlthough the paper is very basic, it creates a good baseline for defending about various types of attacks and got good results in kaggle competition.\n\nThe main merit of the paper is to study this simple but efficient baseline method extensively and shows how adversarial attacks can be mitigated by some extent.\n\nCons of the paper: there is not much novel insight or really exciting new ideas presented.\n\nPros: It gives a convincing very simple baseline and the evaluation of all subsequent results on defending against adversaries will need to incorporate this simple defense method in addition to any future proposed defenses, since it is very easy to implement and evaluate and seems to improve the defense capabilities of the network to a significant degree. So I assume that this paper will be influential in the future just by the virtue of its easy applicability and effectiveness.\n\n", "gold_annotation": {"interpretation": 0, "review_id": "ByRWmWAxM", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["This paper proposes an extremely simple methodology to improve the network's performance by adding extra random perturbations (resizing/padding) at evalation time.", "Although the paper is very basic, it creates a good baseline for defending about various types of attacks and got good results in kaggle competition.", "The main merit of the paper is to study this simple but efficient baseline method extensively and shows how adversarialattacks can be mitigated by some extent.", "Cons of the paper: there is not much novel insight or realy exciting new ideas presented.", "Pros: It gives a convincing very simple baseline and the evalation of al subseqent results on defending against adversaries will need to incorporate this simple defense method in addition to any future proposed defenses, since it is very easy to implement and evalate and seems to improve the defense capabilities of the network to a significant degree.", "So I assume that this paper will be influentialin the future just by the virtue of its easy applicability and effectiveness."], "all_annotations": [{"interpretation": 0, "review_id": "ByRWmWAxM", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "BympCwwgf", "review_text": "This paper presents a method to cope with adversarial examples in classification tasks, leveraging a generative model of the inputs.  Given an accurate generative model of the input, this approach first projects the input onto the manifold learned by the generative model (the idea being that inputs on this manifold reflect the non-adversarial input distribution).  This projected input is then used to produce the classification probabilities.  The authors test their method on various adversarially constructed inputs (with varying degrees of noise). \n\nQuestions/Comments:\n\n- I am interested in unpacking the improvement of Defense-GAN over the MagNet auto-encoder based method.  Is the MagNet auto-encoder suffering lower accuracy because the projection of an adversarial image is based on an encoding function that is learned only on true data?  If the decoder from the MagNet approach were treated purely as a generative model, and the same optimization-based projection approach (proposed in this work) was followed, would the results be comparable?  \n\n- Is there anything special about the GAN approach, versus other generative approaches? \n\n- In the black-box vs. white-box scenarios, can the attacker know the GAN parameters?  Is that what is meant by the \"defense network\" (in experiments bullet 2)?\n\n- How computationally expensive is this approach take compared to MagNet or other adversarial approaches? \n\nQuality: The method appears to be technically correct.\n\nClarity: This paper clearly written; both method and experiments are presented well. \n\nOriginality: I am not familiar enough with adversarial learning to assess the novelty of this approach. \n\nSignificance: I believe the main contribution of this method is the optimization-based approach to project onto a generative model's manifold.  I think this kernel has the potential to be explored further (e.g. computational speed-up, projection metrics).", "gold_annotation": {"interpretation": 1, "review_id": "BympCwwgf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper presents a method to cope with adversarialexamples in classification tasks, leveraging a generative model of the inputs.", "Given an accurate generative model of the input, this approach first projects the input onto the manifold learned by the generative model (the idea being that inputs on this manifold reflect the non-adversarialinput distribution).", "This projected input is then used to produce the classification probabilities.", "The authors test their method on various adversarialy constructed inputs (with varying degrees of noise).", "Questions/Comments: - I am interested in unpacking the improvement of Defense-GAN over the MagNet auto-encoder based method.", "Is the MagNet auto-encoder suffering lower accuracy because the projection of an adversarialimage is based on an encoding function that is learned only on true data?", "If the decoder from the MagNet approach were treated purely as a generative model, and the same optimization-based projection approach (proposed in this work) was followed, would the results be comparable?", "- Is there anything specialabout the GAN approach, versus other generative approaches?", "- In the black-box vs. white-box scenarios, can the attacker know the GAN parameters?", "Is that what is meant by the \"defense network\" (in experiments bullet 2)?", "- How computationaly expensive is this approach take compared to MagNet or other adversarialapproaches?", "Qualty: The method appears to be technicaly correct.", "Clarity: This paper clearly written; both method and experiments are presented well.", "Originalty: I am not familiar enough with adversariallearning to assess the novelty of this approach.", "Significance: I believe the main contribution of this method is the optimization-based approach to project onto a generative model's manifold.", "I think this kernel has the potentialto be explored further (e g computationalspeed-up, projection metrics)."], "all_annotations": [{"interpretation": 1, "review_id": "BympCwwgf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "Byqj1QtlM", "review_text": "A DeepRL algorithm is presented that represents distributions over Q values, as applied to DDPG,\nand in conjunction with distributed evaluation across multiple actors, prioritized experience replay, and \nN-step look-aheads. The algorithm is called Distributed Distributional Deep Deterministic Policy Gradient algorithm, D4PG.\nSOTA results are generated for a number of challenging continuous domain learning problems,\nas compared to benchmarks that include DDPG and PPO, in terms of wall-clock time, and also (most often) in terms\nof sample efficiency.\n\npros/cons\n+ the paper provides a thorough investigation of the distributional approach, as applied to difficult continuous\n  action problems, and in conjunction with a set of other improvements (with ablation tests)\n- the story is a bit mixed in terms of the benefits, as compared to the non-distributional approach, D3PG\n- it is not clear which of the baselines are covered in detail in the cited paper:\n  \"Anonymous. Distributed prioritized experience replay. In submission, 2017.\", \n   i.e., should readers assume that D3PG already exists and is attributable to this other submission?\n\nOverall, I believe that the community will find this to be interesting work.\n\nIs a video of the results available?\n\nIt seems that the distributional model often does not make much of a difference, \nas compared to D3PG non-prioritized.  However, sometimes it does make a big difference, i.e., 3D parkour; acrobot.\nDo the examples where it yields the largest payoff share a particular characteristic?\n\nThe benefit of the distributional models is quite different between the 1-step and 5-step versions. Any ideas why?\n\nOccasionally, D4PG with N=1 fails very badly, e.g., fish, manipulator (bring ball), swimmer.\nWhy would that be? Shouldn't it do at least as well as D3PG in general?\n\nHow many atoms are used for the categorical representation?\nAs many as [Bellemare et al.], i.e., 51 ?\nHow much \"resolution\" is necessary here in order to gain most of the benefits of the distributional representation?\n\nAs far as I understand, V_min and V_max are not the global values, but are specific to the current distribution.\nHence the need for the projection. Is that correct?\n\nWould increasing the exploration noise result in a larger benefit for the distributional approach?\n\nFigure 2: DDPG performs suprisingly poorly in most examples. Any comments on this,\nor is DDPG best avoided in normal circumstances for continuous problems? :-)\n\nIs the humanoid stand so easy because of large (or unlimited) torque limits?\n\nThe wall-clock times are for a cluster with K=32 cores for Figure 1?\n\n\"we utilize a network architecture as specified in Figure 1 which processes the terrain info in order to reduce its dimensionality\"\nFigure 1 provides no information about the reduced dimensionality of the terrain representation, unless I am somehow failing to see this.\n\n\"the full critic architecture is completed by attaching a critic head as defined in Section A\"\nI could find no further documenation in the paper with regard to the \"head\" or a separate critic for the \"head\".\nIt is not clear to me why multiple critics are needed.\n\nDo you have an intuition as to why prioritized replay might be reducing performance in many cases?\n", "gold_annotation": {"interpretation": 1, "review_id": "Byqj1QtlM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["A DeepRL alorithm is presented that represents distributions over Q vales, as applied to DDPG, and in conjunction with distributed evalation across multiple actors, prioritized experience replay, and N-step look-aheads.", "The alorithm is caled Distributed DistributionalDeep Deterministic Policy Gradient alorithm, D4PG.", "SOTA results are generated for a number of chalenging continuous domain learning problems, as compared to benchmarks that include DDPG and PPO, in terms of wal-clock time, and alo (most often) in terms of sample efficiency.", "pros/cons + the paper provides a thorough investigation of the distributionalapproach, as applied to difficult continuous action problems, and in conjunction with a set of other improvements (with ablation tests) - the story is a bit mixed in terms of the benefits, as compared to the non-distributionalapproach, D3PG - it is not clear which of the baselines are covered in detail in the cited paper: \"Anonymous.", "Distributed prioritized experience replay.", "In submission, 2017.", "\", i e , should readers assume that D3PG aleady exists and is attributable to this other submission?", "Overal, I believe that the community will find this to be interesting work.", "Is a video of the results available?", "It seems that the distributionalmodel often does not make much of a difference, as compared to D3PG non-prioritized.", "However, sometimes it does make a big difference, i e , 3D parkour; acrobot.", "Do the examples where it yields the largest payoff share a particular characteristic?", "The benefit of the distributionalmodels is quite different between the 1-step and 5-step versions.", "Any ideas why?", "Occasionaly, D4PG with N=1 fails very badly, e g , fish, manipulator (bring bal), swimmer.", "Why would that be?", "Shouldn't it do at least as well as D3PG in general How many atoms are used for the categoricalrepresentation?", "As many as [Bellemare et al], i e , 51 ?", "How much \"resolution\" is necessary here in order to gain most of the benefits of the distributionalrepresentation?", "As far as I understand, V_min and V_max are not the globalvales, but are specific to the current distribution.", "Hence the need for the projection.", "Is that correct?", "Would increasing the exploration noise result in a larger benefit for the distributionalapproach?", "figre 2: DDPG performs suprisingly poorly in most examples.", "Any comments on this, or is DDPG best avoided in normalcircumstances for continuous problems?", ":-) Is the humanoid stand so easy because of large (or unlimited) torque limits?", "The wal-clock times are for a cluster with K=32 cores for figre 1?", "\"we utilize a network architecture as specified in figre 1 which processes the terrain info in order to reduce its dimensionalty\" figre 1 provides no information about the reduced dimensionalty of the terrain representation, unless I am somehow failing to see this.", "\"the full critic architecture is completed by attaching a critic head as defined in secion A\" I could find no further documenation in the paper with regard to the \"head\" or a separate critic for the \"head\".", "It is not clear to me why multiple critics are needed.", "Do you have an intuition as to why prioritized replay might be reducing performance in many cases?"], "all_annotations": [{"interpretation": 1, "review_id": "Byqj1QtlM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "BytyNwclz", "review_text": "This paper presents an analysis of the communication systems that arose when neural network based agents played simple referential games. The set up is that a speaker and a listener engage in a game where both can see a set of possible referents (either represented symbolically in terms of features, or represented as simple images) and the speaker produces a message consisting of a sequence of numbers while the listener has to make the choice of which referent the speaker intends. This is a set up that has been used in a large amount of previous work, and the authors summarize some of this work. The main novelty in this paper is the choice of models to be used by speaker and listener, which are based on LSTMs and convolutional neural networks. The results show that the agents generate effective communication systems, and some analysis is given of the extent to which these communications systems develop compositional properties \u2013 a question that is currently being explored in the literature on language creation.\n\nThis is an interesting question, and it is nice to see worker playing modern neural network models to his question and exploring the properties of the solutions of the phone. However, there are also a number of issues with the work.\n\n1. One of the key question is the extent to which the constructed communication systems demonstrate compositionality. The authors note that there is not a good quantitative measure of this. However, this is been the topic of much research of the literature and language evolution. This work has resulted in some measures that could be applied here, see for example Carr et al. (2016): http://www.research.ed.ac.uk/portal/files/25091325/Carr_et_al_2016_Cognitive_Science.pdf\n\n2. In general the results occurred be more quantitative. In section 3.3.2 it would be nice to see statistical tests used to evaluate the claims. Minimally I think it is necessary to calculate a null distribution for the statistics that are reported.\n\n3. As noted above the main novelty of this work is the use of contemporary network models. One of the advantages of this is that it makes it possible to work with more complex data stimuli, such as images. However, unfortunately the image example that is used is still very artificial being based on a small set of synthetically generated images.\n\nOverall, I see this as an interesting piece of work that may be of interest to researchers exploring questions around language creation and language evolution, but I think the results require more careful analysis and the novelty is relatively limited, at least in the way that the results are presented here.", "gold_annotation": {"interpretation": 0, "review_id": "BytyNwclz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper presents an analsis of the communication systems that arose when neuralnetwork based agents played simple referentialgames.", "The set up is that a speaker and a listener engage in a game where both can see a set of possible referents (either represented symbolicaly in terms of features, or represented as simple images) and the speaker produces a message consisting of a seqence of numbers while the listener has to make the choice of which referent the speaker intends.", "This is a set up that has been used in a large amount of previous work, and the authors summarize some of this work.", "The main novelty in this paper is the choice of models to be used by speaker and listener, which are based on LSTMs and convolutionalneuralnetworks.", "The results show that the agents generate effective communication systems, and some analsis is given of the extent to which these communications systems develop compositionalproperties \u2013 a question that is currently being explored in the literature on language creation.", "This is an interesting question, and it is nice to see worker playing modern neuralnetwork models to his question and exploring the properties of the solutions of the phone.", "However, there are alo a number of issues with the work.", "1, One of the key question is the extent to which the constructed communication systems demonstrate compositionalty.", "The authors note that there is not a good quantitative measure of this.", "However, this is been the topic of much research of the literature and language evolution.", "This work has resulted in some measures that could be applied here, see for example Carr et al (2016): http://www.research.ed.ac.uk/portalfiles/25091325/Carr_et_al2016_Cognitive_Science.pdf 2, In generalthe results occurred be more quantitative.", "In secion 3 3 2 it would be nice to see statisticaltests used to evalate the claims.", "Minimaly I think it is necessary to calulate a null distribution for the statistics that are reported.", "3, As noted above the main novelty of this work is the use of contemporary network models.", "One of the advantages of this is that it makes it possible to work with more complex data stimuli, such as images.", "However, unfortunately the image example that is used is still very artificialbeing based on a smal set of syntheticaly generated images.", "Overal, I see this as an interesting piece of work that may be of interest to researchers exploring questions around language creation and language evolution, but I think the results reqire more careful analsis and the novelty is relatively limited, at least in the way that the results are presented here."], "all_annotations": [{"interpretation": 0, "review_id": "BytyNwclz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "ByvABDcxz", "review_text": "The authors present an algorithm for training ensembles of policy networks that regularly mixes different policies in the ensemble together by distilling a mixture of two policies into a single policy network, adding it to the ensemble and selecting the strongest networks to remain (under certain definitions of a \"strong\" network). The experiments compare favorably against PPO and A2C baselines on a variety of MuJoCo tasks, although I would appreciate a wall-time comparison as well, as training the \"crossover\" network is presumably time-consuming.\n\nIt seems that for much of the paper, the authors could dispense with the genetic terminology altogether - and I mean that as a compliment. There are few if any valuable ideas in the field of evolutionary computing and I am glad to see the authors use sensible gradient-based learning for GPO, even if it makes it depart from what many in the field would consider \"evolutionary\" computing. Another point on terminology that is important to emphasize - the method for training the crossover network by direct supervised learning from expert trajectories is technically not imitation learning but behavioral cloning. I would perhaps even call this a distillation network rather than a crossover network. In many robotics tasks behavioral cloning is known for overfitting to expert trajectories, but that may not be a problem in this setting as \"expert\" trajectories can be generated in unlimited quantities.", "gold_annotation": {"interpretation": 0, "review_id": "ByvABDcxz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["The authors present an alorithm for training ensembles of policy networks that regularly mixes different policies in the ensemble together by distilling a mixture of two policies into a single policy network, adding it to the ensemble and selecting the strongest networks to remain (under certain definitions of a \"strong\" network).", "The experiments compare favorably against PPO and A2C baselines on a variety of MuJoCo tasks, alhough I would appreciate a wal-time comparison as well, as training the \"crossover\" network is presumably time-consuming.", "It seems that for much of the paper, the authors could dispense with the genetic terminology alogether - and I mean that as a compliment.", "There are few if any valable ideas in the field of evolutionary computing and I am glad to see the authors use sensible gradient-based learning for GPO, even if it makes it depart from what many in the field would consider \"evolutionary\" computing.", "Another point on terminology that is important to emphasize - the method for training the crossover network by direct supervised learning from expert trajectories is technicaly not imitation learning but behavioralcloning.", "I would perhaps even cal this a distillation network rather than a crossover network.", "In many robotics tasks behavioralcloning is known for overfitting to expert trajectories, but that may not be a problem in this setting as \"expert\" trajectories can be generated in unlimited quantities."], "all_annotations": [{"interpretation": 0, "review_id": "ByvABDcxz", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "H13MWgq4M", "review_text": "This paper identifies and proposes a fix for a shortcoming of the Deep Information Bottleneck approach, namely that the induced representation is not invariant to monotonic transform of the marginal distributions (as opposed to the mutual information on which it is based). The authors address this shortcoming by applying the DIB to a transformation of the data, obtained by a copula transform. This explicit approach is shown on synthetic experiments to preserve more information about the target, yield better reconstruction and converge faster than the baseline. The authors further develop a sparse extension to this Deep Copula Information Bottleneck (DCIB), which yields improved representations (in terms of disentangling and sparsity) on a UCI dataset.\n\n(significance) This is a promising idea. This paper builds on the information theoretic perspective of representation learning, and makes progress towards characterizing what makes for a good representation. Invariance to transforms of the marginal distributions is clearly a useful property, and the proposed method seems effective in this regard.\nUnfortunately, I do not believe the paper is ready for publication as it stands, as it suffers from lack of clarity and the experimentation is limited in scope.\n\n(clarity) While Section 3.3 clearly defines the explicit form of the algorithm (where data and labels are essentially pre-processed via a copula transform), details regarding the \u201cimplicit form\u201d are very scarce. From Section 3.4, it seems as though the authors are optimizing the form of the gaussian information bottleneck I(x,t), in the hopes of recovering an encoder $f_\\beta(x)$ which gaussianizes the input (thus emulating the explicit transform) ? Could the authors clarify whether this interpretation is correct, or alternatively provide additional clarifying details ? There are also many missing details in the experimental section: how were the number of \u201cactive\u201d components selected ? Which versions of the algorithm (explicit/implicit) were used for which experiments ? I believe explicit was used for Section 4.1, and implicit for 4.2 but again this needs to be spelled out more clearly. I would also like to see a discussion (and perhaps experimental comparison) to standard preprocessing techniques, such as PCA-whitening.\n\n(quality) The experiments are interesting and seem well executed. Unfortunately, I do not think their scope (single synthetic, plus a single UCI dataset) is sufficient. While the gap in performance is significant on the synthetic task, this gap appears to shrink significantly when moving to the UCI dataset. How does this method perform for more realistic data, even e.g. MNIST ? I think it is crucial to highlight that the deficiencies of DIB matter in practice, and are not simply a theoretical consideration. Similarly, the representation analyzed in Figure 7 is promising, but again the authors could have targeted other common datasets for disentangling, e.g. the simple sprites dataset used in the beta-VAE paper. I would have also liked to see a more direct and systemic validation of the claims made in the paper. For example, the shortcomings of DIB identified in Section 3.1, 3.2 could have been verified more directly by plotting I(y,t) for various monotonic transformations of x. A direct comparison of the explicit and implicit forms of the algorithms would also also make for a stronger paper in my opinion.\n\nPros:\n* Theoretically well motivated\n* Promising results on synthetic task\n* Potential for impact\nCons:\n* Paper suffers from lack of clarity (method and experimental section)\n* Lack of ablative / introspective experiments\n* Weak empirical results (small or toy datasets only).", "gold_annotation": {"interpretation": 0, "review_id": "H13MWgq4M", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper identifies and proposes a fix for a shortcoming of the Deep Information Bottleneck approach, namely that the induced representation is not invariant to monotonic transform of the marginaldistributions (as opposed to the mutualinformation on which it is based).", "The authors address this shortcoming by applying the DIB to a transformation of the data, obtained by a copula transform.", "This explicit approach is shown on synthetic experiments to preserve more information about the target, yield better reconstruction and converge faster than the baseline.", "The authors further develop a sparse extension to this Deep Copula Information Bottleneck (DCIB), which yields improved representations (in terms of disentangling and sparsity) on a UCI dataset.", "(significance) This is a promising idea.", "This paper builds on the information theoretic perspective of representation learning, and makes progress towards characterizing what makes for a good representation.", "Invariance to transforms of the marginaldistributions is clearly a useful property, and the proposed method seems effective in this regard.", "Unfortunately, I do not believe the paper is ready for publication as it stands, as it suffers from lack of clarity and the experimentation is limited in scope.", "(clarity) While secion 3 3 clearly defines the explicit form of the alorithm (where data and labels are essentialy pre-processed via a copula transform), details regarding the \u201cimplicit form\u201d are very scarce.", "From secion 3 4, it seems as though the authors are optimizing the form of the gaussian information bottleneck I(x,t), in the hopes of recovering an encoder $f_\\beta(x)$ which gaussianizes the input (thus emulating the explicit transform) ?", "Could the authors clarify whether this interpretation is correct, or alernatively provide additionalclarifying details ?", "There are alo many missing details in the experimentalsecion: how were the number of \u201cactive\u201d components selected ?", "Which versions of the alorithm (explicit/implicit) were used for which experiments ?", "I believe explicit was used for secion 4 1, and implicit for 4 2 but again this needs to be spelled out more clearly.", "I would alo like to see a discussion (and perhaps experimentalcomparison) to standard preprocessing techniques, such as PCA-whitening.", "(qualty) The experiments are interesting and seem well executed.", "Unfortunately, I do not think their scope (single synthetic, plus a single UCI dataset) is sufficient.", "While the gap in performance is significant on the synthetic task, this gap appears to shrink significantly when moving to the UCI dataset.", "How does this method perform for more realstic data, even e g MNIST ?", "I think it is crucialto highlight that the deficiencies of DIB matter in practice, and are not simply a theoreticalconsideration.", "Similarly, the representation analzed in figre 7 is promising, but again the authors could have targeted other common datasets for disentangling, e g the simple sprites dataset used in the beta-VAE paper.", "I would have alo liked to see a more direct and systemic valdation of the claims made in the paper.", "For example, the shortcomings of DIB identified in secion 3 1, 3 2 could have been verified more directly by plotting I(y,t) for various monotonic transformations of x A direct comparison of the explicit and implicit forms of the alorithms would alo alo make for a stronger paper in my opinion.", "Pros: * Theoreticaly well motivated * Promising results on synthetic task * Potentialfor impact Cons: * Paper suffers from lack of clarity (method and experimentalsecion) * Lack of ablative / introspective experiments * Weak empiricalresults (smal or toy datasets only)."], "all_annotations": [{"interpretation": 0, "review_id": "H13MWgq4M", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "HJ3OcT3gG", "review_text": "In this paper, the authors propose a novel method for generating adversarial examples when the model is a black-box and we only have access to its decisions (and a positive example).  It iteratively takes steps along the decision boundary while trying to minimize the distance to the original positive example.\n\n\nPros:\n- Novel method that works under much stricter and more realistic assumptions.\n- Fairly thorough evaluation.\n- The paper is clearly written.\n\n\nCons:\n- Need a fair number of calls to generate a small perturbation.  Would like to see more analysis of this.\n- Attack works for making something outside the boundary (not X), but is less clear how to generate image to meet a specific classification (X).  3.2 attempts this slightly by using an image in the class, but is less clear for something like FaceID.\n- Unclear how often the images generated look reasonable.  Do different random initializations given different quality examples?\n", "gold_annotation": {"interpretation": 0, "review_id": "HJ3OcT3gG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["In this paper, the authors propose a novel method for generating adversarialexamples when the model is a black-box and we only have access to its decisions (and a positive example).", "It iteratively takes steps alng the decision boundary while trying to minimize the distance to the originalpositive example.", "Pros: - Novel method that works under much stricter and more realstic assumptions.", "- Fairly thorough evalation.", "- The paper is clearly written.", "Cons: - Need a fair number of cals to generate a smal perturbation.", "Would like to see more analsis of this.", "- Attack works for making something outside the boundary (not X), but is less clear how to generate image to meet a specific classification (X).", "3 2 attempts this slightly by using an image in the class, but is less clear for something like FaceID.", "- Unclear how often the images generated look reasonable.", "Do different random initialzations given different qualty examples?"], "all_annotations": [{"interpretation": 0, "review_id": "HJ3OcT3gG", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HJpgrTKxf", "review_text": "Summary: The paper proposes a learnable skimming mechanism for RNN. The model decides whether to send the word to a larger heavy-weight RNN or a light-weight RNN. The heavy-weight and the light-weight RNN each controls a portion of the hidden state. The paper finds that with the proposed skimming method, they achieve a significant reduction in terms of FLOPS. Although it doesn\u2019t contribute to much speedup on modern GPU hardware, there is a good speedup on CPU, and it is more power efficient.\n\nContribution:\n- The paper proposes to use a small RNN to read unimportant text. Unlike (Yu et al., 2017), which skips the text, here the model decides between small and large RNN.\n\nPros:\n- Models that dynamically decide the amount of computation make intuitive sense and are of general interests.\n- The paper presents solid experimentation on various text classification and question answering datasets.\n- The proposed method has shown reasonable reduction in FLOPS and CPU speedup with no significant accuracy degradation (increase in accuracy in some tasks).\n- The paper is well written, and the presentation is good.\n\nCons:\n- Each model component is not novel. The authors propose to use Gumbel softmax, but does compare other gradient estimators. It would be good to use REINFORCE to do a fair comparison with (Yu et al., 2017 ) to see the benefit of using small RNN.\n- The authors report that training from scratch results in unstable skim rate, while Half pretrain seems to always work better than fully pretrained ones. This makes the success of training a bit adhoc, as one need to actively tune the number of pretraining steps.\n- Although there is difference from (Yu et al., 2017), the contribution of this paper is still incremental.\n\nQuestions:\n- Although it is out of the scope for this paper to achieve GPU level speedup, I am curious to know some numbers on GPU speedup.\n- One recommended task would probably be text summarization, in which the attended text can contribute to the output of the summary.\n\nConclusion:\n- Based on the comments above, I recommend Accept", "gold_annotation": {"interpretation": 1, "review_id": "HJpgrTKxf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary: The paper proposes a learnable skimming mechanism for RNN.", "The model decides whether to send the word to a larger heavy-weight RNN or a light-weight RNN.", "The heavy-weight and the light-weight RNN each controls a portion of the hidden state.", "The paper finds that with the proposed skimming method, they achieve a significant reduction in terms of FLOPS.", "Although it doesn\u2019t contribute to much speedup on modern GPU hardware, there is a good speedup on CPU, and it is more power efficient.", "Contribution: - The paper proposes to use a smal RNN to read unimportant text.", "Unlike (Yu et al, 2017), which skips the text, here the model decides between smal and large RNN.", "Pros: - Models that dynamicaly decide the amount of computation make intuitive sense and are of generalinterests.", "- The paper presents solid experimentation on various text classification and question answering datasets.", "- The proposed method has shown reasonable reduction in FLOPS and CPU speedup with no significant accuracy degradation (increase in accuracy in some tasks).", "- The paper is well written, and the presentation is good.", "Cons: - Each model component is not novel.", "The authors propose to use Gumbel softmax, but does compare other gradient estimators.", "It would be good to use REINFORCE to do a fair comparison with (Yu et al, 2017 ) to see the benefit of using smal RNN.", "- The authors report that training from scratch results in unstable skim rate, while Hal pretrain seems to alays work better than fully pretrained ones.", "This makes the success of training a bit adhoc, as one need to actively tune the number of pretraining steps.", "- Although there is difference from (Yu et al, 2017), the contribution of this paper is still incremental Questions: - Although it is out of the scope for this paper to achieve GPU level speedup, I am curious to know some numbers on GPU speedup.", "- One recommended task would probably be text summarization, in which the attended text can contribute to the output of the summary.", "Conclusion: - Based on the comments above, I recommend Accept"], "all_annotations": [{"interpretation": 1, "review_id": "HJpgrTKxf", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HJyXsRtef", "review_text": "This paper presents a new approach to determining what to measure and when to measure it, using a novel deep learning architecture. The problem addressed is important and timely and advances here may have an impact on many application areas outside medicine. The approach is evaluated on real-world medical datasets and has increased accuracy over the other methods compared against.\n\n+ A key advantage of the approach is that it continually learns from the collected data, using new measurements to update the model, and that it runs efficiently even on large real-world datasets.\n\n-However, the related work section is significantly underdeveloped, making it difficult to really compare the approach to the state of the art. The paper is ambitious and claims to address a variety of problems, but as a result each segment of related work seems to have been shortchanged. In particular, the section on missing data is missing a large amount of recent and related work. Normally, methods for handling missing data are categorized based on the missingness model (MAR/MCAR/MNAR). The paper seems to assume all data are missing at random, which is also a significant limitation of the methods.\n\n-The paper is organized in a nonstandard way, with the methods split across two sections, separated by the related work. It would be easier to follow with a more common intro/related work/methods structure.\n\nQuestions:\n-One of the key motivations for the approach is sensing in medicine. However, many tests come as a group (e.g. the chem-7 or other panels). In this case, even if the only desired measurement is glucose, others will be included as well. Is it possible to incorporate this? It may change the threshold for the decision, as a combination of measures can be obtained for the same cost.", "gold_annotation": {"interpretation": 0, "review_id": "HJyXsRtef", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["This paper presents a new approach to determining what to measure and when to measure it, using a novel deep learning architecture.", "The problem addressed is important and timely and advances here may have an impact on many application areas outside medicine.", "The approach is evalated on realworld medicaldatasets and has increased accuracy over the other methods compared against.", "+ A key advantage of the approach is that it continualy learns from the collected data, using new measurements to update the model, and that it runs efficiently even on large realworld datasets.", "-However, the related work secion is significantly underdeveloped, making it difficult to realy compare the approach to the state of the art.", "The paper is ambitious and claims to address a variety of problems, but as a result each segment of related work seems to have been shortchanged.", "In particular, the secion on missing data is missing a large amount of recent and related work.", "Normaly, methods for handling missing data are categorized based on the missingness model (MAR/MCAR/MNAR).", "The paper seems to assume al data are missing at random, which is alo a significant limitation of the methods.", "-The paper is organized in a nonstandard way, with the methods split across two secions, separated by the related work.", "It would be easier to follow with a more common intro/related work/methods structure.", "Questions: -One of the key motivations for the approach is sensing in medicine.", "However, many tests come as a group (e g the chem-7 or other panels).", "In this case, even if the only desired measurement is glucose, others will be included as well.", "Is it possible to incorporate this?", "It may change the threshold for the decision, as a combination of measures can be obtained for the same cost."], "all_annotations": [{"interpretation": 0, "review_id": "HJyXsRtef", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "H15qgiFgf", "review_text": "This work identifies a mistake in the existing proof of convergence of\nAdam, which is among the most popular optimization methods in deep\nlearning. Moreover, it gives a simple 1-dimensional counterexample with\nlinear losses on which Adam does not converge. The same issue also\naffects RMSprop, which may be viewed as a special case of Adam without\nmomentum. The problem with Adam is that the \"learning rate\" matrices\nV_t^{1/2}/alpha_t are not monotonically decreasing. A new method, called\nAMSGrad is therefore proposed, which modifies Adam by forcing these\nmatrices to be decreasing. It is then shown that AMSGrad does satisfy\nessentially the same convergence bound as the one previously claimed for\nAdam. Experiments and simulations are provided that support the\ntheoretical analysis.\n\nApart from some issues with the technical presentation (see below), the\npaper is well-written.\n\nGiven the popularity of Adam, I consider this paper to make a very\ninteresting observation. I further believe all issues with the technical\npresentation can be readily addressed.\n\n\n\nIssues with Technical Presentation:\n\n- All theorems should explicitly state the conditions they require\n  instead of referring to \"all the conditions in (Kingma & Ba, 2015)\".\n- Theorem 2 is a repetition of Theorem 1 (except for additional\n  conditions).\n- The proof of Theorem 3 assumes there are no projections, so this\n  should be stated as part of its conditions. (The claim in footnote 2\n  that they can be handled seems highly plausible, but you should be up\n  front about the limitations of your results.)\n- The regret bound Theorem 4 establishes convergence of the optimization\n  method, so it plays the role of a sanity check. However, it is\n  strictly worse than the regret bound O(sqrt{T}) for online gradient\n  descent [Zinkevich,2003], so it cannot explain why the proposed\n  AMSgrad method might be adaptive. (The method may indeed be adaptive\n  in some sense; I am just saying the *bound* does not express that.\n  This is also not a criticism of the current paper; the same remark\n  also applies to the previously claimed regret bound for Adam.)\n- The discussion following Corollary 1 suggests that sum_i\n  hat{v}_{T,i}^{1/2} might be much smaller than d G_infty. This is true,\n  but we should always expect it to be at least a constant, because\n  hat{v}_{t,i} is monotonically increasing by definition of the\n  algorithm, so the bound does not get better than O(sqrt(T)).\n  It is also suggested that sum_i ||g_{1:T,i}|| = sqrt{sum_{t=1}^T\n  g_{t,i}^2} might be much smaller than dG_infty, but this is very\n  unlikely, because this term will typically grow like O(sqrt{T}),\n  unless the data are extremely sparse, so we should at least expect\n  some dependence on T.\n- In the proof of Theorem 1, the initial point is taken to be x_1 = 1,\n  which is perfectly fine, but it is not \"without loss of generality\",\n  as claimed. This should be stated in the statement of the Theorem.\n- The proof of Theorem 6 in appendix B only covers epsilon=1. If it is\n  \"easy to show\" that the same construction also works for other\n  epsilon, as claimed, then please provide the proof for general\n  epsilon.\n\n\nOther remarks:\n\n- Theoretically, nonconvergence of Adam seems a severe problem. Can you\n  speculate on why this issue has not prevented its widespread adoption?\n  Which factors might mitigate the issue in practice?\n- Please define g_t \\circ g_t and g_{1:T,i}\n- I would recommend sticking with standard linear algebra notation for\n  the sqrt and the inverse of a matrix and simply using A^{-1} and\n  A^{1/2} instead of 1/A and sqrt{A}.\n- In theorems 1,2,3, I would recommend stating the dimension (d=1) of\n  your counterexamples, which makes them very nice!\n\nMinor issues:\n\n- Check accent on Nicol\\`o Cesa-Bianchi in bibliography.\n- Near the end of the proof of Theorem 6: I believe you mean Adam\n  suffers a \"regret\" instead of a \"loss\" of at least 2C-4.\n  Also 2C-4=2C-4 is trivial in the second but last display.\n", "gold_annotation": {"interpretation": 1, "review_id": "H15qgiFgf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.5, "tokenized_review_text": ["This work identifies a mistake in the existing proof of convergence of Adam, which is among the most popular optimization methods in deep learning.", "Moreover, it gives a simple 1-dimensionalcounterexample with linear losses on which Adam does not converge.", "The same issue alo affects RMSprop, which may be viewed as a specialcase of Adam without momentum.", "The problem with Adam is that the \"learning rate\" matrices V_t^{1/2}/alha_t are not monotonicaly decreasing.", "A new method, caled AMSGrad is therefore proposed, which modifies Adam by forcing these matrices to be decreasing.", "It is then shown that AMSGrad does satisfy essentialy the same convergence bound as the one previously claimed for Adam.", "Experiments and simulations are provided that support the theoreticalanalsis.", "Apart from some issues with the technicalpresentation (see below), the paper is well-written.", "Given the popularity of Adam, I consider this paper to make a very interesting observation.", "I further believe al issues with the technicalpresentation can be readily addressed.", "Issues with TechnicalPresentation: - All theorems should explicitly state the conditions they reqire instead of referring to \"al the conditions in (Kingma & Ba, 2015)\".", "- Theorem 2 is a repetition of Theorem 1 (except for additional conditions).", "- The proof of Theorem 3 assumes there are no projections, so this should be stated as part of its conditions.", "(The claim in footnote 2 that they can be handled seems highly plausible, but you should be up front about the limitations of your results.)", "- The regret bound Theorem 4 establishes convergence of the optimization method, so it plays the role of a sanity check.", "However, it is strictly worse than the regret bound O(sqrt{T}) for online gradient descent [Zinkevich,2003], so it cannot explain why the proposed AMSgrad method might be adaptive.", "(The method may indeed be adaptive in some sense; I am just saying the *bound* does not express that.", "This is alo not a criticism of the current paper; the same remark alo applies to the previously claimed regret bound for Adam.)", "- The discussion following Corollary 1 suggests that sum_i hat{v}_{T,i}^{1/2} might be much smaler than d G_infty.", "This is true, but we should alays expect it to be at least a constant, because hat{v}_{t,i} is monotonicaly increasing by definition of the alorithm, so the bound does not get better than O(sqrt(T)).", "It is alo suggested that sum_i ||g_{1:T,i}|| = sqrt{sum_{t=1}^T g_{t,i}^2} might be much smaler than dG_infty, but this is very unlikely, because this term will typicaly grow like O(sqrt{T}), unless the data are extremely sparse, so we should at least expect some dependence on T - In the proof of Theorem 1, the initialpoint is taken to be x_1 = 1, which is perfectly fine, but it is not \"without loss of generalty\", as claimed.", "This should be stated in the statement of the Theorem.", "- The proof of Theorem 6 in appendix B only covers epsilon=1, If it is \"easy to show\" that the same construction alo works for other epsilon, as claimed, then please provide the proof for general epsilon.", "Other remarks: - Theoreticaly, nonconvergence of Adam seems a severe problem.", "Can you speculate on why this issue has not prevented its widespread adoption?", "Which factors might mitigate the issue in practice?", "- Please define g_t \\circ g_t and g_{1:T,i} - I would recommend sticking with standard linear alebra notation for the sqrt and the inverse of a matrix and simply using A^{-1} and A^{1/2} instead of 1/A and sqrt{A}.", "- In theorems 1,2,3, I would recommend stating the dimension (d=1) of your counterexamples, which makes them very nice!", "Minor issues: - Check accent on Nicol\\`o Cesa-Bianchi in bibliography.", "- Near the end of the proof of Theorem 6: I believe you mean Adam suffers a \"regret\" instead of a \"loss\" of at least 2C-4, Also 2C-4=2C-4 is trivialin the secnd but last display."], "all_annotations": [{"interpretation": 1, "review_id": "H15qgiFgf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "H1E1RgqxM", "review_text": "# Summary\nThis paper presents a new external-memory-based neural network (Neural Map) for handling partial observability in reinforcement learning. The proposed memory architecture is spatially-structured so that the agent can read/write from/to specific positions in the memory. The results on several memory-related tasks in 2D and 3D environments show that the proposed method outperforms existing baselines such as LSTM and MQN/FRMQN. \n\n[Pros]\n- The overall direction toward more flexible/scalable memory is an important research direction in RL.\n- The proposed memory architecture is new. \n- The paper is well-written.\n\n[Cons]\n- The proposed memory architecture is new but a bit limited to 2D/3D navigation tasks.\n- Lack of analysis of the learned memory behavior.\n\n# Novelty and Significance\nThe proposed idea is novel in general. Though [Gupta et al.] proposed an ego-centric neural memory in the RL context, the proposed memory architecture is still new in that read/write operations are flexible enough for the agent to write any information to the memory, whereas [Gupta et al.] designed the memory specifically for predicting free space. On the other hand, the proposed method is also specific to navigation tasks in 2D or 3D environment, which is hard to apply to more general memory-related tasks in non-spatial environments. But, it is still interesting to see that the ego-centric neural memory works well on challenging tasks in a 3D environment.\n\n# Quality\nThe experiment does not show any analysis of the learned memory read/write behavior especially for ego-centric neural map and the 3D environment. It is hard to understand how the agent utilizes the external memory without such an analysis. \n\n# Clarity\nThe paper is overall clear and easy-to-follow except for the following. In the introduction section, the paper claims that \"the expert must set M to a value that is larger than the time horizon of the currently considered task\" when mentioning the limitation of the previous work. In some sense, however, Neural Map also requires an expert to specify the proper size of the memory based on prior knowledge about the task. ", "gold_annotation": {"interpretation": 0, "review_id": "H1E1RgqxM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 3.5, "tokenized_review_text": ["# Summary This paper presents a new externalmemory-based neuralnetwork (NeuralMap) for handling partialobservability in reinforcement learning.", "The proposed memory architecture is spatialy-structured so that the agent can read/write from/to specific positions in the memory.", "The results on severalmemory-related tasks in 2D and 3D environments show that the proposed method outperforms existing baselines such as LSTM and MQN/FRMQN.", "[Pros] - The overal direction toward more flexible/scalble memory is an important research direction in RL.", "- The proposed memory architecture is new.", "- The paper is well-written.", "[Cons] - The proposed memory architecture is new but a bit limited to 2D/3D navigation tasks.", "- Lack of analsis of the learned memory behavior.", "# Novelty and Significance The proposed idea is novel in general Though [Gupta et al] proposed an ego-centric neuralmemory in the RL context, the proposed memory architecture is still new in that read/write operations are flexible enough for the agent to write any information to the memory, whereas [Gupta et al] designed the memory specificaly for predicting free space.", "On the other hand, the proposed method is alo specific to navigation tasks in 2D or 3D environment, which is hard to apply to more generalmemory-related tasks in non-spatialenvironments.", "But, it is still interesting to see that the ego-centric neuralmemory works well on chalenging tasks in a 3D environment.", "# Qualty The experiment does not show any analsis of the learned memory read/write behavior especialy for ego-centric neuralmap and the 3D environment.", "It is hard to understand how the agent utilizes the externalmemory without such an analsis.", "# Clarity The paper is overal clear and easy-to-follow except for the following.", "In the introduction secion, the paper claims that \"the expert must set M to a vale that is larger than the time horizon of the currently considered task\" when mentioning the limitation of the previous work.", "In some sense, however, NeuralMap alo reqires an expert to specify the proper size of the memory based on prior knowledge about the task."], "all_annotations": [{"interpretation": 0, "review_id": "H1E1RgqxM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "H1GhmwqgG", "review_text": "\nSummary: \n- This paper proposes a hand-designed network architecture on a graph of object proposals to perform soft non-maximum suppression to get object count.\n\nContribution:\n- This paper proposes a new object counting module which operates on a graph of object proposals.\n\nClarity:\n- The paper is well written and clarity is good. Figure 2 & 3 helps the readers understand the core algorithm.\n\nPros:\n- De-duplication modules of inter and intra object edges are interesting.\n- The proposed method improves the baseline by 5% on counting questions.\n\nCons:\n- The proposed model is pretty hand-crafted. I would recommend the authors to use something more general, like graph convolutional neural networks (Kipf & Welling, 2017) or graph gated neural networks (Li et al., 2016).\n- One major bottleneck of the model is that the proposals are not jointly finetuned. So if the proposals are missing a single object, this cannot really be counted. In short, if the proposals don\u2019t have 100% recall, then the model is then trained with a biased loss function which asks it to count all the objects even if some are already missing from the proposals. The paper didn\u2019t study what is the recall of the proposals and how sensitive the threshold is.\n- The paper doesn\u2019t study a simple baseline that just does NMS on the proposal domain.\n- The paper doesn\u2019t compare experiment numbers with (Chattopadhyay et al., 2017).\n- The proposed algorithm doesn\u2019t handle symmetry breaking when two edges are equally confident (in 4.2.2 it basically scales down both edges). This is similar to a density map approach and the problem is that the model doesn\u2019t develop a notion of instance.\n- Compared to (Zhou et al., 2017), the proposed model does not improve much on the counting questions.\n- Since the authors have mentioned in the related work, it would also be more convincing if they show experimental results on CL\n\nConclusion:\n- I feel that the motivation is good, but the proposed model is too hand-crafted. Also, key experiments are missing: 1) NMS baseline 2) Comparison with VQA counting work  (Chattopadhyay et al., 2017). Therefore I recommend reject.\n\nReferences:\n- Kipf, T.N., Welling, M., Semi-Supervised Classification with Graph Convolutional Networks. ICLR 2017.\n- Li, Y., Tarlow, D., Brockschmidt, M., Zemel, R. Gated Graph Sequence Neural Networks. ICLR 2016.\n\nUpdate:\nThank you for the rebuttal. The paper is revised and I saw NMS baseline is added. I understood the reason not to compare with certain related work. The rebuttal is convincing and I decided to increase my rating, because adding the proposed counting module achieve 5% increase in counting accuracy. However, I am a little worried that the proposed model may be hard to reproduce due to its complexity and therefore choose to give a 6.", "gold_annotation": {"interpretation": 0, "review_id": "H1GhmwqgG", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": [" Summary: - This paper proposes a hand-designed network architecture on a graph of object proposal to perform soft non-maximum suppression to get object count.", "Contribution: - This paper proposes a new object counting module which operates on a graph of object proposal.", "Clarity: - The paper is well written and clarity is good.", "figre 2 & 3 helps the readers understand the core alorithm.", "Pros: - De-duplication modules of inter and intra object edges are interesting.", "- The proposed method improves the baseline by 5% on counting questions.", "Cons: - The proposed model is pretty hand-crafted.", "I would recommend the authors to use something more general like graph convolutionalneuralnetworks (Kipf & Welling, 2017) or graph gated neuralnetworks (Li et al, 2016).", "- One major bottleneck of the model is that the proposal are not jointly finetuned.", "So if the proposal are missing a single object, this cannot realy be counted.", "In short, if the proposal don\u2019t have 100% recal, then the model is then trained with a biased loss function which asks it to count al the objects even if some are aleady missing from the proposal.", "The paper didn\u2019t study what is the recal of the proposal and how sensitive the threshold is.", "- The paper doesn\u2019t study a simple baseline that just does NMS on the proposaldomain.", "- The paper doesn\u2019t compare experiment numbers with (Chattopadhyay et al, 2017).", "- The proposed alorithm doesn\u2019t handle symmetry breaking when two edges are eqaly confident (in 4 2 2 it basicaly scals down both edges).", "This is similar to a density map approach and the problem is that the model doesn\u2019t develop a notion of instance.", "- Compared to (Zhou et al, 2017), the proposed model does not improve much on the counting questions.", "- Since the authors have mentioned in the related work, it would alo be more convincing if they show experimentalresults on CL Conclusion: - I feel that the motivation is good, but the proposed model is too hand-crafted.", "Also, key experiments are missing: 1) NMS baseline 2) Comparison with VQA counting work (Chattopadhyay et al, 2017).", "Therefore I recommend reject.", "References: - Kipf, T N , Welling, M , Semi-Supervised Classification with Graph ConvolutionalNetworks.", "ICLR 2017, - Li, Y , Tarlow, D , Brockschmidt, M , Zemel, R Gated Graph Seqence NeuralNetworks.", "ICLR 2016, Update: Thank you for the rebuttal The paper is revised and I saw NMS baseline is added.", "I understood the reason not to compare with certain related work.", "The rebuttalis convincing and I decided to increase my rating, because adding the proposed counting module achieve 5% increase in counting accuracy.", "However, I am a little worried that the proposed model may be hard to reproduce due to its complexity and therefore choose to give a 6"], "all_annotations": [{"interpretation": 0, "review_id": "H1GhmwqgG", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "H1JAev9gz", "review_text": "The authors present 3 architectures for learning representations of programs from execution traces. In the variable trace embedding, the input to the model is given by a sequence of variable values. The state trace embedding combines embeddings for variable traces using a second recurrent encoder. The dependency enforcement embedding performs element-wise multiplication of embeddings for parent variables to compute the input of the GRU to compute the new hidden state of a variable. The authors evaluate their architectures on the task of predicting error patterns for programming assignments from Microsoft DEV204.1X (an introduction to C# offered on edx) and problems on the Microsoft CodeHunt platform. They additionally use their embeddings to decrease the search time for the Sarfgen program repair system.\n\nThis is a fairly strong paper. The proposed models make sense and the writing is for the most part clear, though there are a few places where ambiguity arises:\n\n- The variable \"Evidence\" in equation (4) is never defined. \n\n- The authors refer to \"predicting the error patterns\", but again don't define what an error pattern is. The appendix seems to suggest that the authors are simply performing multilabel classification based on a predefined set of classes of errors, is this correct? \n\n- It is not immediately clear from Figures 3 and 4 that the architectures employed are in fact recurrent.\n\n- Figure 5 seems to suggest that dependencies are only enforced at points in a program where assignment is performed for a variable, is this correct?\n\nAssuming that the authors can address these clarity issues, I would in principle be happy for the paper to appear. ", "gold_annotation": {"interpretation": 0, "review_id": "H1JAev9gz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["The authors present 3 architectures for learning representations of programs from execution traces.", "In the variable trace embedding, the input to the model is given by a seqence of variable vales.", "The state trace embedding combines embeddings for variable traces using a secnd recurrent encoder.", "The dependency enforcement embedding performs element-wise multiplication of embeddings for parent variables to compute the input of the GRU to compute the new hidden state of a variable.", "The authors evalate their architectures on the task of predicting error patterns for programming assignments from Microsoft DEV204.1X (an introduction to C# offered on edx) and problems on the Microsoft CodeHunt platform.", "They additionaly use their embeddings to decrease the search time for the Sarfgen program repair system.", "This is a fairly strong paper.", "The proposed models make sense and the writing is for the most part clear, though there are a few places where ambiguity arises: - The variable \"Evidence\" in eqation (4) is never defined.", "- The authors refer to \"predicting the error patterns\", but again don't define what an error pattern is.", "The appendix seems to suggest that the authors are simply performing multilabel classification based on a predefined set of classes of errors, is this correct?", "- It is not immediately clear from figres 3 and 4 that the architectures employed are in fact recurrent.", "- figre 5 seems to suggest that dependencies are only enforced at points in a program where assignment is performed for a variable, is this correct?", "Assuming that the authors can address these clarity issues, I would in principle be happy for the paper to appear."], "all_annotations": [{"interpretation": 0, "review_id": "H1JAev9gz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "H1JzYwcxM", "review_text": "=== SUMMARY ===\n\nThe paper considers a combination of Reinforcement Learning (RL) and Imitation Learning (IL), in the infinite horizon discounted MDP setting.\nThe IL part is in the form of an oracle that returns a value function V^e, which is an approximation of the optimal value function. The paper defines a new cost (or reward) function based on V^e, through shaping (Eq. 1). It is known that shaping does not change the optimal policy.\n\nA key aspect of this paper is to consider a truncated horizon problem (say horizon k) with the reshaped cost function, instead of an infinite horizon MDP.\nFor this truncated problem, one can write the (dis)advantage function as a k-step sum of reward plus the value returned by the oracle at the k-th step (cf. Eq. 5).\nTheorem 3.3 shows that the value of the optimal policy of the truncated MDP w.r.t. the original MDP is only O(gamma^k eps) worse than the optimal policy of the original problem (gamma is the discount factor and eps is the error between V^e and V*).\n\nThis suggests two things: \n1) Having an oracle that is accurate (small eps) leads to good performance. If oracle is the same as the optimal value function, we do not need to plan more than a single step ahead.\n2) By planning for k steps ahead, one can decrease the error in the oracle geometrically fast. In the limit of k \u2014> inf, the error in the oracle does not matter.\n\nBased on this insight, the paper suggests an actor-critic-like algorithm called THOR (Truncated HORizon policy search) that minimizes the total cost over a truncated horizon with a modified cost function.\n\nThrough a series of experiments on several benchmark problems (inverted pendulum, swimmer, etc.), the paper shows the effect of planning horizon k.\n\n\n\n=== EVALUATION & COMMENTS ===\n\nI like the main idea of this paper. The paper is also well-written. But one of the main ideas of this paper (truncating the planning horizon and replacing it with approximation of the optimal value function) is not new and has been studied before, but has not been properly cited and discussed.\n\nThere are a few papers that discuss truncated planning. Most closely is the following paper:\n\nFarahmand, Nikovski, Igarashi, and Konaka, \u201cTruncated Approximate Dynamic Programming With Task-Dependent Terminal Value,\u201d AAAI, 2016.\n\nThe motivation of AAAI 2016 paper is different from this work. The goal there is to speedup the computation of finite, but large, horizon problem with a truncated horizon planning. The setting there is not the combination of RL and IL, but multi-task RL. An approximation of optimal value function for each task is learned off-line and then used as the terminal cost. \nThe important point is that the learned function there plays the same role as the value provided by the oracle V^e in this work. They both are used to shorten the planning horizon. That paper theoretically shows the effect of various error terms, including terms related to the approximation in the planning process (this paper does not do that).\n\nNonetheless, the resulting algorithms are quite different. The result of this work is an actor-critic type of algorithm. AAAI 2016 paper is an approximate dynamic programming type of algorithm.\n\nThere are some other papers that have ideas similar to this work in relation to truncating the horizon. For example, the multi-step lookahead policies and the use of approximate value function as the terminal cost in the following paper:\n\nBertsekas, \u201cDynamic Programming and Suboptimal Control: A Survey from ADP to MPC,\u201d European Journal of Control, 2005.\n\nThe use of learned value function to truncate the rollout trajectory in a classification-based approximate policy iteration method has been studied by\n\nGabillon, Lazaric, Ghavamzadeh, and Scherrer, \u201cClassification-based Policy Iteration with a Critic,\u201d ICML, 2011.\n\nOr in the context of Monte Carlo Tree Search planning, the following paper is relevant:\n\nSilver et al., \u201cMastering the game of Go with deep neural networks and tree search,\u201d Nature, 2016.\n\nTheir \u201cvalue network\u201d has a similar role to V^e. It provides an estimate of the states at the truncated horizon to shorten the planning depth.\n\nNote that even though these aforementioned papers are not about IL, this paper\u2019s stringent requirement of having access to V^e essentially make it similar to those papers.\n\n\nIn short, a significant part of this work\u2019s novelty has been explored before. Even though not being completely novel is totally acceptable, it is important that the paper better position itself compared to the prior art.\n\n\nAside this main issue, there are some other comments:\n\n\n- Theorem 3.1 is not stated clearly and may suggest more than what is actually shown in the proof. The problem is that it is not clear about the fact the choice of eps is not arbitrary.\nThe proof works only for eps that is larger than 0.5. With the construction of the proof, if eps is smaller than 0.5, there would not be any error, i.e., J(\\hat{pi}^*) = J(pi^*).\n\nThe theorem basically states that if the error is very large (half of the range of value function), the agent does not not perform well. Is this an interesting case?\n\n\n- In addition to the papers I mentioned earlier, there are some results suggesting that shorter horizons might be beneficial and/or sufficient under certain conditions. A related work is a theorem in the PhD dissertation of Ng:\n\nAndrew Ng, Shaping and Policy Search in Reinforcement Learning, PhD Dissertation, 2003.\n(Theorem 5 in Appendix 3.B: Learning with a smaller horizon).\n\nIt is shown that if the error between Phi (equivalent to V^e here) and V* is small, one may choose a discount factor gamma\u2019 that is smaller than gamma of the original MDP, and still have some guarantees. As the discount factor has an interpretation of the effective planning horizon, this result is relevant. The result, however, is not directly comparable to this work as the planning horizon appears implicitly in the form of 1/(1-gamma\u2019) instead of k, but I believe it is worth to mention and possibly compare.\n\n- The IL setting in this work is that an oracle provides V^e, which is the same as (Ross & Bagnell, 2014). I believe this setting is relatively restrictive as in many problems we only have access to (state, action) pairs, or sequence thereof, and not the associated value function. For example, if a human is showing how a robot or a car should move, we do not easily have access to V^e (unless the reward function is known and we estimate the value with rollouts; which requires us having a long trajectory). This is not a deal breaker, and I would not consider this as a weakness of the work, but the paper should be more clear and upfront about this.\n\n\n- The use of differential operator nabla instead of gradient of a function (a vector field) in Equations (10), (14), (15) is non-standard.\n\n- Figures are difficult to read, as the colors corresponding to confidence regions of different curves are all mixed up. Maybe it is better to use standard error instead of standard deviation.\n\n\n===\nAfter Rebuttal: Thank you for your answer. The revised paper has been improved. I increase my score accordingly.\n", "gold_annotation": {"interpretation": 1, "review_id": "H1JzYwcxM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["=== SUMMARY === The paper considers a combination of Reinforcement Learning (RL) and Imitation Learning (IL), in the infinite horizon discounted MDP setting.", "The IL part is in the form of an oracle that returns a vale function V^e, which is an approximation of the optimalvale function.", "The paper defines a new cost (or reward) function based on V^e, through shaping (eq 1).", "It is known that shaping does not change the optimalpolicy.", "A key aspect of this paper is to consider a truncated horizon problem (say horizon k) with the reshaped cost function, instead of an infinite horizon MDP.", "For this truncated problem, one can write the (dis)advantage function as a k-step sum of reward plus the vale returned by the oracle at the k-th step (cf.", "eq 5).", "Theorem 3 3 shows that the vale of the optimalpolicy of the truncated MDP w r t the originalMDP is only O(gamma^k eps) worse than the optimalpolicy of the originalproblem (gamma is the discount factor and eps is the error between V^e and V*).", "This suggests two things: 1) Having an oracle that is accurate (smal eps) leads to good performance.", "If oracle is the same as the optimalvale function, we do not need to plan more than a single step ahead.", "2) By planning for k steps ahead, one can decrease the error in the oracle geometricaly fast.", "In the limit of k \u2014> inf, the error in the oracle does not matter.", "Based on this insight, the paper suggests an actor-critic-like alorithm caled THOR (Truncated HORizon policy search) that minimizes the totalcost over a truncated horizon with a modified cost function.", "Through a series of experiments on severalbenchmark problems (inverted pendulum, swimmer, etc), the paper shows the effect of planning horizon k === EVALUATION & COMMENTS === I like the main idea of this paper.", "The paper is alo well-written.", "But one of the main ideas of this paper (truncating the planning horizon and replacing it with approximation of the optimalvale function) is not new and has been studied before, but has not been properly cited and discussed.", "There are a few papers that discuss truncated planning.", "Most closely is the following paper: Farahmand, Nikovski, Igarashi, and Konaka, \u201cTruncated Approximate Dynamic Programming With Task-Dependent TerminalVale,\u201d AAAI, 2016, The motivation of AAAI 2016 paper is different from this work.", "The goalthere is to speedup the computation of finite, but large, horizon problem with a truncated horizon planning.", "The setting there is not the combination of RL and IL, but multi-task RL.", "An approximation of optimalvale function for each task is learned off-line and then used as the terminalcost.", "The important point is that the learned function there plays the same role as the vale provided by the oracle V^e in this work.", "They both are used to shorten the planning horizon.", "That paper theoreticaly shows the effect of various error terms, including terms related to the approximation in the planning process (this paper does not do that).", "Nonetheless, the resulting alorithms are quite different.", "The result of this work is an actor-critic type of alorithm.", "AAAI 2016 paper is an approximate dynamic programming type of alorithm.", "There are some other papers that have ideas similar to this work in relation to truncating the horizon.", "For example, the multi-step lookahead policies and the use of approximate vale function as the terminalcost in the following paper: Bertsekas, \u201cDynamic Programming and SuboptimalControl: A Survey from ADP to MPC,\u201d European Journalof Control, 2005, The use of learned vale function to truncate the rollout trajectory in a classification-based approximate policy iteration method has been studied by Gabillon, Lazaric, Ghavamzadeh, and Scherrer, \u201cClassification-based Policy Iteration with a Critic,\u201d ICML, 2011, Or in the context of Monte Carlo Tree Search planning, the following paper is relevant: Silver et al, \u201cMastering the game of Go with deep neuralnetworks and tree search,\u201d Nature, 2016, Their \u201cvale network\u201d has a similar role to V^e It provides an estimate of the states at the truncated horizon to shorten the planning depth.", "Note that even though these aforementioned papers are not about IL, this paper\u2019s stringent reqirement of having access to V^e essentialy make it similar to those papers.", "In short, a significant part of this work\u2019s novelty has been explored before.", "Even though not being completely novel is totaly acceptable, it is important that the paper better position itself compared to the prior art.", "Aside this main issue, there are some other comments: - Theorem 3 1 is not stated clearly and may suggest more than what is actualy shown in the proof.", "The problem is that it is not clear about the fact the choice of eps is not arbitrary.", "The proof works only for eps that is larger than 0 5, With the construction of the proof, if eps is smaler than 0 5, there would not be any error, i e , J(\\hat{pi}^*) = J(pi^*).", "The theorem basicaly states that if the error is very large (hal of the range of vale function), the agent does not not perform well.", "Is this an interesting case?", "- In addition to the papers I mentioned earlier, there are some results suggesting that shorter horizons might be beneficialand/or sufficient under certain conditions.", "A related work is a theorem in the PhD dissertation of Ng: Andrew Ng, Shaping and Policy Search in Reinforcement Learning, PhD Dissertation, 2003, (Theorem 5 in Appendix 3 B: Learning with a smaler horizon).", "It is shown that if the error between Phi (eqivalnt to V^e here) and V* is smal, one may choose a discount factor gamma\u2019 that is smaler than gamma of the originalMDP, and still have some guarantees.", "As the discount factor has an interpretation of the effective planning horizon, this result is relevant.", "The result, however, is not directly comparable to this work as the planning horizon appears implicitly in the form of 1/(1-gamma\u2019) instead of k, but I believe it is worth to mention and possibly compare.", "- The IL setting in this work is that an oracle provides V^e, which is the same as (Ross & Bagnell, 2014).", "I believe this setting is relatively restrictive as in many problems we only have access to (state, action) pairs, or seqence thereof, and not the associated vale function.", "For example, if a human is showing how a robot or a car should move, we do not easily have access to V^e (unless the reward function is known and we estimate the vale with rollouts; which reqires us having a long trajectory).", "This is not a dealbreaker, and I would not consider this as a weakness of the work, but the paper should be more clear and upfront about this.", "- The use of differentialoperator nabla instead of gradient of a function (a vector field) in eqations (10), (14), (15) is non-standard.", "- figres are difficult to read, as the colors corresponding to confidence regions of different curves are al mixed up.", "Maybe it is better to use standard error instead of standard deviation.", "=== After Rebuttal Thank you for your answer.", "The revised paper has been improved.", "I increase my score accordingly."], "all_annotations": [{"interpretation": 1, "review_id": "H1JzYwcxM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "H1NffmKgz", "review_text": "This paper proposes the use of optimistic mirror descent to train Wasserstein Generative Adversarial Networks (WGANS). The authors remark that the current training of GANs, which amounts to solving a zero-sum game between a generator and discriminator, is often unstable, and they argue that one source of instability is due to limit cycles, which can occur for FTRL-based algorithms even in convex-concave zero-sum games. Motivated by recent results that use Optimistic Mirror Descent  (OMD) to achieve faster convergence rates (than standard gradient descent) in convex-concave zero-sum games and normal form games, they suggest using these techniques for WGAN training as well. The authors prove that, using OMD, the last iterate converges to an equilibrium and use this as motivation that OMD methods should be more stable for WGAN training. They then compare OMD against GD on both toy simulations and a DNA sequence task before finally introducing an adaptive generalization of OMD, Optimistic Adam, that they test on CIFAR10. \n\nThis paper is relatively well-written and clear, and the authors do a good job of introducing the problem of GAN training instability as well as the OMD algorithm, in particular highlighting its differences with standard gradient descent as well as discussing existing work that has applied it to zero-sum games. Given the recent work on OMD for zero-sum and normal form games, it is natural to study its effectiveness in training GANs.The issue of last iterate versus average iterate for non convex-concave problems is also presented well.  \n\nThe theoretical result on last-iterate convergence of OMD for bilinear games is interesting, but somewhat wanting as it does not provide an explicit convergence rate as in Rakhlin and Sridharan, 2013. Moreover, the result is only at best a motivation for using OMD in WGAN training since the WGAN optimization problem is not a bilinear game. \n\nThe experimental results seem to indicate that OMD is at least roughly competitive with GD-based methods, although they seem less compelling than the prior discussion in the paper would suggest. In particular, they are matched by SGD with momentum when evaluated by last epoch performance (albeit while being less sensitive to learning rates). OMD does seem to outperform SGD-based methods when using the lowest discriminator loss, but there doesn't seem to be even an attempt at explaining this in the paper. \n\nI found it a bit odd that Adam was not used as a point of comparison in Section 5, that optimistic Adam was only introduced and tested for CIFAR but not for the DNA sequence problem, and that the discriminator was trained for 5 iterations in Section 5 but only once in Section 6, despite the fact that the reasoning provided in Section 6 seems like it would have also applied for Section 5. This gives the impression that the experimental results might have been at least slightly \"gamed\". \n\nFor the reasons above, I give the paper high marks on clarity, and slightly above average marks on originality, significance, and quality.\n\nSpecific comments:\nPage 1, \"no-regret dynamics in zero-sum games can very often lead to limit cycles\": I don't think limit cycles are actually ever formally defined in the entire paper.  \nPage 3, \"standard results in game theory and no-regret learning\": These results should be either proven or cited.\nPage 3: Don't the parameter spaces need to be bounded for these convergence results to hold? \nPage 4, \"it is well known that GD is equivalent to the Follow-the-Regularized-Leader algorithm\": For completeness, this should probably either be (quickly) proven or a reference should be provided.\nPage 5, \"the unique equilibrium of the above game is...for the discriminator to choose w=0\": Why is w=0 necessary here?\nPage 6, \"We remark that the set of equilibrium solutions of this minimax problem are pairs (x,y) such that x is in the null space of A^T and y is in the null space of A\": Why is this true? This should either be proven or cited.\nPage 6, Initialization and Theorem 1: It would be good to discuss the necessity of this particular choice of initialization for the theoretical result. In the Initialization section, it appears simply to be out of convenience.\nPage 6, Theorem 1: It should be explicitly stated that this result doesn't provide a convergence rate, in contrast to the existing OMD results cited in the paper.   \nPage 7, \"we considered momentum, Nesterov momentum and AdaGrad\": Why isn't Adam used in this section if it is used in  later experiments?\nPage 7-8, \"When evaluated by....the lowest discriminator loss on the validation set, WGAN trained with Stochastic OMD (SOMD) achieved significantly lower KL divergence than the competing SGD variants.\": Can you explain why SOMD outperforms the other methods when using the lowest discriminator loss on the validation set? None of the theoretical arguments presented earlier in the paper seem to even hint at this. The only result that one might expect from the earlier discussion and results is that SOMD would outperform the other methods when evaluating by the last epoch. However, this doesn't even really hold, since there exist learning rates in which SGD with momentum matches the performance of SOMD.\nPage 8, \"Evaluated by the last epoch, SOMD is much less sensitive to the choice of learning rate than the SGD variants\": Learning rate sensitivity doesn't seem to be touched upon in the earlier discussion. Can these results be explained by theory?\nPage 8, \"we see that optimistic Adam achieves high numbers of inception scores after very few epochs of training\": These results don't mean much without error bars.\nPage 8, \"we only trained the discriminator once after one iteration of generator training. The latter is inline with the intuition behind the use of optimism....\": Why didn't this logic apply to the previous section on DNA sequences, where the discriminator was trained multiple times?\n\n\nAfter reading the response of the authors (in particular their clarification of some technical results and the extra experiments they carried out during the rebuttal period), I have decided to upgrade my rating of the paper from a 6 to a 7. Just as a note, Figure 3b is now very difficult to read. \n\n", "gold_annotation": {"interpretation": 1, "review_id": "H1NffmKgz", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 5.0, "tokenized_review_text": ["This paper proposes the use of optimistic mirror descent to train Wasserstein Generative AdversarialNetworks (WGANS).", "The authors remark that the current training of GANs, which amounts to solving a zero-sum game between a generator and discriminator, is often unstable, and they argue that one source of instability is due to limit cycles, which can occur for FTRL-based alorithms even in convex-concave zero-sum games.", "Motivated by recent results that use Optimistic Mirror Descent (OMD) to achieve faster convergence rates (than standard gradient descent) in convex-concave zero-sum games and normalform games, they suggest using these techniques for WGAN training as well.", "The authors prove that, using OMD, the last iterate converges to an eqilibrium and use this as motivation that OMD methods should be more stable for WGAN training.", "They then compare OMD against GD on both toy simulations and a DNA seqence task before finaly introducing an adaptive generalzation of OMD, Optimistic Adam, that they test on CIFAR10, This paper is relatively well-written and clear, and the authors do a good job of introducing the problem of GAN training instability as well as the OMD alorithm, in particular highlighting its differences with standard gradient descent as well as discussing existing work that has applied it to zero-sum games.", "Given the recent work on OMD for zero-sum and normalform games, it is naturalto study its effectiveness in training GANs.The issue of last iterate versus average iterate for non convex-concave problems is alo presented well.", "The theoreticalresult on last-iterate convergence of OMD for bilinear games is interesting, but somewhat wanting as it does not provide an explicit convergence rate as in Rakhlin and Sridharan, 2013, Moreover, the result is only at best a motivation for using OMD in WGAN training since the WGAN optimization problem is not a bilinear game.", "The experimentalresults seem to indicate that OMD is at least roughly competitive with GD-based methods, alhough they seem less compelling than the prior discussion in the paper would suggest.", "In particular, they are matched by SGD with momentum when evalated by last epoch performance (aleit while being less sensitive to learning rates).", "OMD does seem to outperform SGD-based methods when using the lowest discriminator loss, but there doesn't seem to be even an attempt at explaining this in the paper.", "I found it a bit odd that Adam was not used as a point of comparison in secion 5, that optimistic Adam was only introduced and tested for CIFAR but not for the DNA seqence problem, and that the discriminator was trained for 5 iterations in secion 5 but only once in secion 6, despite the fact that the reasoning provided in secion 6 seems like it would have alo applied for secion 5, This gives the impression that the experimentalresults might have been at least slightly \"gamed\".", "For the reasons above, I give the paper high marks on clarity, and slightly above average marks on originalty, significance, and qualty.", "Specific comments: Page 1, \"no-regret dynamics in zero-sum games can very often lead to limit cycles\": I don't think limit cycles are actualy ever formaly defined in the entire paper.", "Page 3, \"standard results in game theory and no-regret learning\": These results should be either proven or cited.", "Page 3: Don't the parameter spaces need to be bounded for these convergence results to hold?", "Page 4, \"it is well known that GD is eqivalnt to the Follow-the-Regularized-Leader alorithm\": For completeness, this should probably either be (quickly) proven or a reference should be provided.", "Page 5, \"the unique eqilibrium of the above game is...for the discriminator to choose w=0\": Why is w=0 necessary here?", "Page 6, \"We remark that the set of eqilibrium solutions of this minimax problem are pairs (x,y) such that x is in the null space of A^T and y is in the null space of A\": Why is this true?", "This should either be proven or cited.", "Page 6, Initialzation and Theorem 1: It would be good to discuss the necessity of this particular choice of initialzation for the theoreticalresult.", "In the Initialzation secion, it appears simply to be out of convenience.", "Page 6, Theorem 1: It should be explicitly stated that this result doesn't provide a convergence rate, in contrast to the existing OMD results cited in the paper.", "Page 7, \"we considered momentum, Nesterov momentum and AdaGrad\": Why isn't Adam used in this secion if it is used in later experiments?", "Page 7-8, \"When evalated by....the lowest discriminator loss on the valdation set, WGAN trained with Stochastic OMD (SOMD) achieved significantly lower KL divergence than the competing SGD variants.", "\": Can you explain why SOMD outperforms the other methods when using the lowest discriminator loss on the valdation set?", "None of the theoreticalarguments presented earlier in the paper seem to even hint at this.", "The only result that one might expect from the earlier discussion and results is that SOMD would outperform the other methods when evalating by the last epoch.", "However, this doesn't even realy hold, since there exist learning rates in which SGD with momentum matches the performance of SOMD.", "Page 8, \"Evalated by the last epoch, SOMD is much less sensitive to the choice of learning rate than the SGD variants\": Learning rate sensitivity doesn't seem to be touched upon in the earlier discussion.", "Can these results be explained by theory?", "Page 8, \"we see that optimistic Adam achieves high numbers of inception scores after very few epochs of training\": These results don't mean much without error bars.", "Page 8, \"we only trained the discriminator once after one iteration of generator training.", "The latter is inline with the intuition behind the use of optimism....\": Why didn't this logic apply to the previous secion on DNA seqences, where the discriminator was trained multiple times?", "After reading the response of the authors (in particular their clarification of some technicalresults and the extra experiments they carried out during the rebuttalperiod), I have decided to upgrade my rating of the paper from a 6 to a 7, Just as a note, figre 3b is now very difficult to read."], "all_annotations": [{"interpretation": 1, "review_id": "H1NffmKgz", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "H1Pyl4sxM", "review_text": "Summary of paper: The paper proposes an RNN-based neural network architecture for embedding programs, focusing on the semantics of the program rather than the syntax. The application is to predict errors made by students on programming tasks. This is achieved by creating training data based on program traces obtained by instrumenting the program by adding print statements. The neural network is trained using this program traces with an objective for classifying the student error pattern (e.g. list indexing, branching conditions, looping bounds).\n\n---\n\nQuality: The experiments compare the three proposed neural network architectures with two syntax-based architectures. It would be good to see a comparison with some techniques from Reed & De Freitas (2015) as this work also focuses on semantics-based embeddings.\nClarity: The paper is clearly written.\nOriginality: This work doesn't seem that original from an algorithmic point of view since Reed & De Freitas (2015) and Cai et. al (2017) among others have considered using execution traces. However the application to program repair is novel (as far as I know).\nSignificance: This work can be very useful for an educational platform though a limitation is the need for adding instrumentation print statements by hand.\n\n---\n\nSome questions/comments:\n- Do we need to add the print statements for any new programs that the students submit? What if the structure of the submitted program doesn't match the structure of the intended solution and hence adding print statements cannot be automated?\n\n---\n\nReferences \n\nCai, J., Shin, R., & Song, D. (2017). Making Neural Programming Architectures Generalize via Recursion. In International Conference on Learning Representations (ICLR).", "gold_annotation": {"interpretation": 0, "review_id": "H1Pyl4sxM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary of paper: The paper proposes an RNN-based neuralnetwork architecture for embedding programs, focusing on the semantics of the program rather than the syntax.", "The application is to predict errors made by students on programming tasks.", "This is achieved by creating training data based on program traces obtained by instrumenting the program by adding print statements.", "The neuralnetwork is trained using this program traces with an objective for classifying the student error pattern (e g list indexing, branching conditions, looping bounds).", "--- Qualty: The experiments compare the three proposed neuralnetwork architectures with two syntax-based architectures.", "It would be good to see a comparison with some techniques from Reed & De Freitas (2015) as this work alo focuses on semantics-based embeddings.", "Clarity: The paper is clearly written.", "Originalty: This work doesn't seem that originalfrom an alorithmic point of view since Reed & De Freitas (2015) and Cai et.", "al(2017) among others have considered using execution traces.", "However the application to program repair is novel (as far as I know).", "Significance: This work can be very useful for an educationalplatform though a limitation is the need for adding instrumentation print statements by hand.", "--- Some questions/comments: - Do we need to add the print statements for any new programs that the students submit?", "What if the structure of the submitted program doesn't match the structure of the intended solution and hence adding print statements cannot be automated?", "--- References Cai, J , Shin, R , & Song, D (2017).", "Making NeuralProgramming Architectures Generalze via Recursion.", "In InternationalConference on Learning Representations (ICLR)."], "all_annotations": [{"interpretation": 0, "review_id": "H1Pyl4sxM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "H1WORsdlG", "review_text": "After a first manuscript that needed majors edits, the revised version\noffers an interesting GAN approach based the scattering transform.\n\nApproach is well motivated with proper references to the recent literature.\n\nExperiments are not state of the art but clearly demonstrate that the\nproposed approach does provide meaningful results.", "gold_annotation": {"interpretation": 0, "review_id": "H1WORsdlG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "yes-agree", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["After a first manuscript that needed majors edits, the revised version offers an interesting GAN approach based the scattering transform.", "Approach is well motivated with proper references to the recent literature.", "Experiments are not state of the art but clearly demonstrate that the proposed approach does provide meaningful results."], "all_annotations": [{"interpretation": 0, "review_id": "H1WORsdlG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "yes-agree", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "H1_YBgxZz", "review_text": "This paper presents a method for clustering based on latent representations learned from the classification of transformed data after pseudo-labellisation corresponding to applied transformation. Pipeline: -Data are augmented with domain-specific transformations. For instance, in the case of MNIST, rotations with different degrees are applied. All data are then labelled as \"original\" or \"transformed by ...(specific transformation)\". -Classification task is performed with a neural network on augmented dataset according to the pseudo-labels. -In parallel of the classification, the neural network also learns the latent representation in an unsupervised fashion. -k-means clustering is performed on the representation space observed in the hidden layer preceding the augmented softmax layer. \n\nDetailed Comments:\n(*) Pros\n-The method outperforms the state-of-art regarding unsupervised methods for handwritten digits clustering on MNIST.\n-Use of ACOL and GAR is interesting, also the idea to make \"labeled\" data from unlabelled ones by using data augmentation.\n\n(*) Cons\n-minor: in the title, I find the expression \"unsupervised clustering\" uselessly redundant since clustering is by definition unsupervised.\n-Choice of datasets: we already obtained very good accuracy for the classification or clustering of handwritten digits. This is not a very challenging task.\nAnd just because something works on MNIST, does not mean it works in general. \nWhat are the performances on more challenging datasets like colored images (CIFAR-10, labelMe, ImageNet, etc.)?\n-This is not clear what is novel here since ACOL and GAR already exist. The novelty seems to be in the adaptation to GAR from the semi-supervised to the unsupervised setting with labels indicating if data have been transformed or not.\n\n\nMy main problem  was about the lack of novelty. The authors clarified this point, and it turned out that ACOL and GAR have never published elsewhere except in ArXiv.  The other issue concerned the validation of the approach on databases other than MNIST. The author also addressed this point, and I changed my scores accordingly. ", "gold_annotation": {"interpretation": 0, "review_id": "H1_YBgxZz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper presents a method for clustering based on latent representations learned from the classification of transformed data after pseudo-labellisation corresponding to applied transformation.", "Pipeline: -Data are augmented with domain-specific transformations.", "For instance, in the case of MNIST, rotations with different degrees are applied.", "All data are then labelled as \"original or \"transformed by ...(specific transformation)\".", "-Classification task is performed with a neuralnetwork on augmented dataset according to the pseudo-labels.", "-In paralel of the classification, the neuralnetwork alo learns the latent representation in an unsupervised fashion.", "-k-means clustering is performed on the representation space observed in the hidden layer preceding the augmented softmax layer.", "Detailed Comments: (*) Pros -The method outperforms the state-of-art regarding unsupervised methods for handwritten digits clustering on MNIST.", "-Use of ACOL and GAR is interesting, alo the idea to make \"labeled\" data from unlabelled ones by using data augmentation.", "(*) Cons -minor: in the title, I find the expression \"unsupervised clustering\" uselessly redundant since clustering is by definition unsupervised.", "-Choice of datasets: we aleady obtained very good accuracy for the classification or clustering of handwritten digits.", "This is not a very chalenging task.", "And just because something works on MNIST, does not mean it works in general What are the performances on more chalenging datasets like colored images (CIFAR-10, labelMe, ImageNet, etc)?", "-This is not clear what is novel here since ACOL and GAR aleady exist.", "The novelty seems to be in the adaptation to GAR from the semi-supervised to the unsupervised setting with labels indicating if data have been transformed or not.", "My main problem was about the lack of novelty.", "The authors clarified this point, and it turned out that ACOL and GAR have never published elsewhere except in ArXiv.", "The other issue concerned the valdation of the approach on databases other than MNIST.", "The author alo addressed this point, and I changed my scores accordingly."], "all_annotations": [{"interpretation": 0, "review_id": "H1_YBgxZz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "H1asng9lG", "review_text": "This paper introduces a new exploration policy for Reinforcement Learning for agents on the web called \"Workflow Guided Exploration\". Workflows are defined through a DSL unique to the domain.\n\nThe paper is clear, very well written, and well-motivated. Exploration is still a challenging problem for RL. The workflows remind me of options though in this paper they appear to be hand-crafted. In that sense, I wonder if this has been done before in another domain. The results suggest that WGE sometimes helps but not consistently. While the experiments show that DOMNET improves over Shi et al, that could be explained as not having to train on raw pixels or not enough episodes.", "gold_annotation": {"interpretation": 1, "review_id": "H1asng9lG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["This paper introduces a new exploration policy for Reinforcement Learning for agents on the web caled \"Workflow Guided Exploration\".", "Workflows are defined through a DSL unique to the domain.", "The paper is clear, very well written, and well-motivated.", "Exploration is still a chalenging problem for RL.", "The workflows remind me of options though in this paper they appear to be hand-crafted.", "In that sense, I wonder if this has been done before in another domain.", "The results suggest that WGE sometimes helps but not consistently.", "While the experiments show that DOMNET improves over Shi et al that could be explained as not having to train on raw pixels or not enough episodes."], "all_annotations": [{"interpretation": 1, "review_id": "H1asng9lG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 2, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "H1wVDrtgM", "review_text": "This paper tried to analyze the subspaces of the adversarial examples neighborhood. More specifically, the authors used Local Intrinsic Dimensionality to analyze the intrinsic dimensional property of the subspaces. The characteristics and theoretical analysis of the proposed method are discussed and explained. This paper helps others to better understand the vulnerabilities of DNNs.", "gold_annotation": {"interpretation": 0, "review_id": "H1wVDrtgM", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}, "score": 1.0, "tokenized_review_text": ["This paper tried to analze the subspaces of the adversarialexamples neighborhood.", "More specificaly, the authors used LocalIntrinsic Dimensionalty to analze the intrinsic dimensionalproperty of the subspaces.", "The characteristics and theoreticalanalsis of the proposed method are discussed and explained.", "This paper helps others to better understand the vulnerabilities of DNNs."], "all_annotations": [{"interpretation": 0, "review_id": "H1wVDrtgM", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 1, "annotator": "anno0", "evidence": 2, "originality": 0, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "HJ1MEAYxG", "review_text": "The authors are motivated by two problems: Inputting non-Euclidean data (such as graphs) into deep CNNs, and analyzing optimization properties of deep networks. In particular, they look at the problem of maze testing, where, given a grid of black and white pixels, the goal is to answer whether there is a path from a designated starting point to an ending point. \n\nThey choose to analyze mazes because they have many nice statistical properties from percolation theory. For one, the problem is solvable with breadth first search in O(L^2) time, for an L x L maze. They show that a CNN can essentially encode a BFS, so theoretically a CNN should be able to solve the problem. Their architecture is a deep feedforward network where each layer takes as input two images: one corresponding to the original maze (a skip connection), and the output of the previous layer. Layers alternate between convolutional and sigmoidal. The authors discuss how this architecture can solve the problem exactly. The pictorial explanation for how the CNN can mimic BFS is interesting but I got a little lost in the 3 cases on page 4. For example, what is r? And what is the relation of the black/white and orange squares? I thought this could use a little more clarity. \n\nThough experiments, they show that there are two kinds of minima, depending on whether we allow negative initializations in the convolution kernels. When positive initializations are enforced, the network can more or less mimic the BFS behavior, but never when initializations can be negative. They offer a rigorous analysis into the behavior of optimization in each of these cases, concluding that there is an essential singularity in the cost function around the exact solution, yet learning succumbs to poor optima due to poor initial predictions in training. \n\nI thought this was an impressive paper that looked at theoretical properties of CNNs. The problem was very well-motivated, and the analysis was sharp and offered interesting insights into the problem of maze solving. What I thought was especially interesting is how their analysis can be extended to other graph problems; while their analysis was specific to the problem of maze solving, they offer an approach -- e.g. that of finding \"bugs\" when dealing with graph objects -- that can extend to other problems. I would be excited to see similar analysis of other toy problems involving graphs.\n\nOne complaint I had was inconsistent clarity: while a lot was well-motivated and straightforward to understand, I got lost in some of the details (as an example, the figure on page 4 did not initially make much sense to me). Also, in the experiments, the authors mention multiple attempt with the same settings -- are these experiments differentiated only by their initialization? Finally, there were various typos throughout (one example is \"neglect minimua\" on page 2 should be \"neglect minima\").\n\nPros: Rigorous analysis, well motivated problem, generalizable results to deep learning theory\nCons: Clarity ", "gold_annotation": {"interpretation": 0, "review_id": "HJ1MEAYxG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The authors are motivated by two problems: Inputting non-Euclidean data (such as graphs) into deep CNNs, and analzing optimization properties of deep networks.", "In particular, they look at the problem of maze testing, where, given a grid of black and white pixels, the goalis to answer whether there is a path from a designated starting point to an ending point.", "They choose to analze mazes because they have many nice statisticalproperties from percolation theory.", "For one, the problem is solvable with breadth first search in O(L^2) time, for an L x L maze.", "They show that a CNN can essentialy encode a BFS, so theoreticaly a CNN should be able to solve the problem.", "Their architecture is a deep feedforward network where each layer takes as input two images: one corresponding to the originalmaze (a skip connection), and the output of the previous layer.", "Layers alernate between convolutionaland sigmoidal The authors discuss how this architecture can solve the problem exactly.", "The pictorialexplanation for how the CNN can mimic BFS is interesting but I got a little lost in the 3 cases on page 4, For example, what is r?", "And what is the relation of the black/white and orange squares?", "I thought this could use a little more clarity.", "Though experiments, they show that there are two kinds of minima, depending on whether we alow negative initialzations in the convolution kernels.", "When positive initialzations are enforced, the network can more or less mimic the BFS behavior, but never when initialzations can be negative.", "They offer a rigorous analsis into the behavior of optimization in each of these cases, concluding that there is an essentialsingularity in the cost function around the exact solution, yet learning succumbs to poor optima due to poor initialpredictions in training.", "I thought this was an impressive paper that looked at theoreticalproperties of CNNs.", "The problem was very well-motivated, and the analsis was sharp and offered interesting insights into the problem of maze solving.", "What I thought was especialy interesting is how their analsis can be extended to other graph problems; while their analsis was specific to the problem of maze solving, they offer an approach -- e g that of finding \"bugs\" when dealng with graph objects -- that can extend to other problems.", "I would be excited to see similar analsis of other toy problems involving graphs.", "One complaint I had was inconsistent clarity: while a lot was well-motivated and straightforward to understand, I got lost in some of the details (as an example, the figre on page 4 did not initialy make much sense to me).", "Also, in the experiments, the authors mention multiple attempt with the same settings -- are these experiments differentiated only by their initialzation?", "Finaly, there were various typos throughout (one example is \"neglect minimua\" on page 2 should be \"neglect minima\").", "Pros: Rigorous analsis, well motivated problem, generalzable results to deep learning theory Cons: Clarity"], "all_annotations": [{"interpretation": 0, "review_id": "HJ1MEAYxG", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "HJzVc2sxf", "review_text": "\n\nThis paper proposes a new method to train residual networks in which one starts by training shallow ResNets, doubling the depth and warm starting from the previous smaller model in a certain way, and iterating.  The authors relate this idea to a recent dynamical systems view of ResNets in which residual blocks are viewed as taking steps in an Euler discretization of a certain differential equation.  This interpretation plays a role in the proposed training method by informing how the \u201cstep sizes\u201d in the Euler discretization should change when doubling the depth of the network.  The punchline of the paper is that the authors are able to achieve similar performance as \u201cfull ResNet training\u201d but with significantly reduced training time.\n\nOverall, the proposed method is novel \u2014 even though this idea of going from shallow to deep is natural for residual networks, tying the idea to the dynamical systems perspective is elegant.  Moreover the paper is clearly written.  Experimental results are decent \u2014 there are clear speedups to be had based on the authors' experiments.  However it is unclear if these gains in training speed are significant enough for people to flock to using this (more complicated) method of training.\n\nI only have a few small questions/comments:\n* A more naive way to do multi-level training would be to again iteratively double the depth, but perhaps not halve the step size.  This might be a good baseline to compare against to demonstrate the value of the dynamical systems viewpoint.\n* One thing I\u2019m unclear on is how convergence was assessed\u2026 my understanding is that the training proceeds for a fixed number of epochs (?) - but shouldn\u2019t this also depend on the depth in some way? \n* Would the speedups be more dramatic for a larger dataset like Imagenet?\n* Finally, not being very familiar with multigrid methods from the numerical methods literature \u2014 I would have liked to hear about whether there are deeper connections to these methods.\n\n\n", "gold_annotation": {"interpretation": 0, "review_id": "HJzVc2sxf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": [" This paper proposes a new method to train residualnetworks in which one starts by training shalow ResNets, doubling the depth and warm starting from the previous smaler model in a certain way, and iterating.", "The authors relate this idea to a recent dynamicalsystems view of ResNets in which residualblocks are viewed as taking steps in an Euler discretization of a certain differentialeqation.", "This interpretation plays a role in the proposed training method by informing how the \u201cstep sizes\u201d in the Euler discretization should change when doubling the depth of the network.", "The punchline of the paper is that the authors are able to achieve similar performance as \u201cfull ResNet training\u201d but with significantly reduced training time.", "Overal, the proposed method is novel \u2014 even though this idea of going from shalow to deep is naturalfor residualnetworks, tying the idea to the dynamicalsystems perspective is elegant.", "Moreover the paper is clearly written.", "Experimentalresults are decent \u2014 there are clear speedups to be had based on the authors' experiments.", "However it is unclear if these gains in training speed are significant enough for people to flock to using this (more complicated) method of training.", "I only have a few smal questions/comments: * A more naive way to do multi-level training would be to again iteratively double the depth, but perhaps not hale the step size.", "This might be a good baseline to compare against to demonstrate the vale of the dynamicalsystems viewpoint.", "* One thing I\u2019m unclear on is how convergence was assessed\u2026 my understanding is that the training proceeds for a fixed number of epochs (?)", "- but shouldn\u2019t this alo depend on the depth in some way?", "* Would the speedups be more dramatic for a larger dataset like Imagenet?", "* Finaly, not being very familiar with multigrid methods from the numericalmethods literature \u2014 I would have liked to hear about whether there are deeper connections to these methods."], "all_annotations": [{"interpretation": 0, "review_id": "HJzVc2sxf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HJzYCPDlf", "review_text": "Twin Networks: Using the Future as a Regularizer\n\n** PAPER SUMMARY **\n\nThe authors propose to regularize RNN for sequence prediction by forcing states of the main forward RNN to match the state of a secondary backward RNN. Both RNNs are trained jointly and only the forward model is used at test time. Experiments on conditional generation (speech recognition, image captioning), and unconditional generation (MNIST pixel RNN, language models) show the effectiveness of the regularizer.\n\n** REVIEW SUMMARY **\n\nThe paper reads well, has sufficient reference. The idea is simple and well explained. Positive empirial results support the proposed regularizer.\n\n** DETAILED REVIEW **\n\nOverall, this is a good paper. I have a few suggestions along the text but nothing major.\n\nIn related work, I would cite co-training approaches. In effect, you have two view of a point in time, its past and its future and you force these two views to agree, see  (Blum and Mitchell, 1998) or Xu, Chang, Dacheng Tao, and Chao Xu. \"A survey on multi-view learning.\" arXiv preprint arXiv:1304.5634 (2013). I would also relate your work to distillation/model compression which tries to get one network to behave like another. On that point, is it important to train the forward and backward network jointly or could the backward network be pre-trained? \n\nIn section 2, it is not obvious to me that the regularizer (4) would not be ignored in absence of regularization on the output matrix. I mean, the regularizer could push h^b to small norm, compensating with higher norm for the output word embeddings. Could you comment why this would not happen?\n\nIn Section 4.2, you need to refer to Table 2 in the text. You also need to define the evaluation metrics used. In this section, why are you not reporting the results from the original Show&Tell paper? How does your implementation compare to the original work?\n\nOn unconditional generation, your hypothesis on uncertainty is interesting and could be tested. You could inject uncertainty in the captioning task for instance, e.g. consider that multiple version of each word e.g. dogA, dogB, docC which are alternatively used instead of dog with predefined substitution rates. Would your regularizer still be helpful there? At which point would it break?", "gold_annotation": {"interpretation": 0, "review_id": "HJzYCPDlf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Twin Networks: Using the Future as a Regularizer ** PAPER SUMMARY ** The authors propose to regularize RNN for seqence prediction by forcing states of the main forward RNN to match the state of a secndary backward RNN.", "Both RNNs are trained jointly and only the forward model is used at test time.", "Experiments on conditionalgeneration (speech recognition, image captioning), and unconditionalgeneration (MNIST pixel RNN, language models) show the effectiveness of the regularizer.", "** REVIEW SUMMARY ** The paper reads well, has sufficient reference.", "The idea is simple and well explained.", "Positive empirialresults support the proposed regularizer.", "** DETAILED REVIEW ** Overal, this is a good paper.", "I have a few suggestions alng the text but nothing major.", "In related work, I would cite co-training approaches.", "In effect, you have two view of a point in time, its past and its future and you force these two views to agree, see (Blum and Mitchell, 1998) or Xu, Chang, Dacheng Tao, and Chao Xu.", "\"A survey on multi-view learning.\"", "arXiv preprint arXiv:1304.5634 (2013).", "I would alo relate your work to distillation/model compression which tries to get one network to behave like another.", "On that point, is it important to train the forward and backward network jointly or could the backward network be pre-trained?", "In secion 2, it is not obvious to me that the regularizer (4) would not be ignored in absence of regularization on the output matrix.", "I mean, the regularizer could push h^b to smal norm, compensating with higher norm for the output word embeddings.", "Could you comment why this would not happen?", "In secion 4 2, you need to refer to Table 2 in the text.", "You alo need to define the evalation metrics used.", "In this secion, why are you not reporting the results from the originalShow&Tell paper?", "How does your implementation compare to the originalwork?", "On unconditionalgeneration, your hypothesis on uncertainty is interesting and could be tested.", "You could inject uncertainty in the captioning task for instance, e g consider that multiple version of each word e g dogA, dogB, docC which are alernatively used instead of dog with predefined substitution rates.", "Would your regularizer still be helpful there?", "At which point would it break?"], "all_annotations": [{"interpretation": 0, "review_id": "HJzYCPDlf", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Hk0lS3teG", "review_text": "The authors analyze show theoretical shortcomings in previous methods of explaining neural networks and propose an elegant way to remove these shortcomings in their methods PatternNet and PatternAttribution.\n\nThe quest of visualizing neural network decision is now a very active field with many contributions. The contribution made by the authors stands out due to its elegant combination of theoretical insights and improved performance in application. The work is very detailed and reads very well.\n\nI am missing at least one figure with comparison with more state-of-the-art methods (e.g. I would love to see results from the method by Zintgraf et al. 2017 which unlike all included prior methods seems to produce much crisper visualizations and also is very related because it learns from the data, too).\n\nMinor questions and comments:\n* Fig 3: Why is the random method so good at removing correlation from fc6? And the S_w even better? Something seems special about fc6.\n* Fig 4: Why is the identical estimator better than the weights estimator and that one better than S_a?\n* It would be nice to compare the image degradation experiment with using the ranking provided by the work from Zintgraf which should by definition function as a kind of gold standard\n* Figure 5, 4th row (mailbox): It looks like the umbrella significantly contributes to the network decision to classify the image as \"mailbox\" which doesn't make too much sense. Is is a problem of the visualization  (maybe there is next to no weight on the umbrella), of PatternAttribution or a strange but interesting a artifact of the analyzed network?\n* page 8 \"... closed form solutions (Eq (4) and Eq. (7))\" The first reference seems to be wrong. I guess Eq 4. should instead reference the unnumbered equation after Eq. 3.\n\nUpdate 2018-01-12: Upgraded Rating from 7 to 8 (see comment below)", "gold_annotation": {"interpretation": 0, "review_id": "Hk0lS3teG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The authors analze show theoreticalshortcomings in previous methods of explaining neuralnetworks and propose an elegant way to remove these shortcomings in their methods PatternNet and PatternAttribution.", "The quest of visualzing neuralnetwork decision is now a very active field with many contributions.", "The contribution made by the authors stands out due to its elegant combination of theoreticalinsights and improved performance in application.", "The work is very detailed and reads very well.", "I am missing at least one figre with comparison with more state-of-the-art methods (e g I would love to see results from the method by Zintgraf et al 2017 which unlike al included prior methods seems to produce much crisper visualzations and alo is very related because it learns from the data, too).", "Minor questions and comments: * fig3: Why is the random method so good at removing correlation from fc6?", "And the S_w even better?", "Something seems specialabout fc6, * fig4: Why is the identicalestimator better than the weights estimator and that one better than S_a?", "* It would be nice to compare the image degradation experiment with using the ranking provided by the work from Zintgraf which should by definition function as a kind of gold standard * figre 5, 4th row (mailbox): It looks like the umbrella significantly contributes to the network decision to classify the image as \"mailbox\" which doesn't make too much sense.", "Is is a problem of the visualzation (maybe there is next to no weight on the umbrella), of PatternAttribution or a strange but interesting a artifact of the analzed network?", "* page 8 \"... closed form solutions (eq(4) and eq (7))\" The first reference seems to be wrong.", "I guess eq4, should instead reference the unnumbered eqation after eq 3, Update 2018-01-12: Upgraded Rating from 7 to 8 (see comment below)"], "all_annotations": [{"interpretation": 0, "review_id": "Hk0lS3teG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Hk2dO8ngz", "review_text": "This very well written paper covers the span between W-GAN and VAE. For a reviewer who is not an expert in the domain, it reads very well, and would have been of tutorial quality if space had allowed for more detailed explanations. The appendix are very useful, and tutorial paper material (especially A). \n\nWhile I am not sure description would be enough to reproduce and no code is provided, every aspect of the architecture, if not described, if referred as similar to some previous work. There are also some notation shortcuts (not explained) in the proof of theorems that can lead to initial confusion, but they turn out to be non-ambiguous. One that could be improved is P(P_X, P_G) where one loses the fact that the second random variable is Y.\n\n\nThis work contains plenty of novel material, which is clearly compared to previous work:\n- The main consequence of the use of Wasserstein distance is the surprisingly simple and useful Theorem 1. I could not verify its novelty, but this seems to be a great contribution.\n- Blending GAN and auto-encoders has been tried in the past, but the authors claim better theoretical foundations that lead to solutions that do not rquire min-max\n- The use of MMD in the context of GANs has also been tried. The authors claim that their use in the latent space makes it more practival\n\nThe experiments are very convincing, both numerically and visually.\n\nSource of confusion: in algorithm 1 and 2, \\tilde{z} is \"sampled\" from Q_TH(Z|xi), some one is lead to believe that this is the sampling process as in VAEs, while in reality Q_TH(Z|xi) is deterministic in the experiments.", "gold_annotation": {"interpretation": 0, "review_id": "Hk2dO8ngz", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This very well written paper covers the span between W-GAN and VAE.", "For a reviewer who is not an expert in the domain, it reads very well, and would have been of tutorialqualty if space had alowed for more detailed explanations.", "The appendix are very useful, and tutorialpaper material(especialy A).", "While I am not sure description would be enough to reproduce and no code is provided, every aspect of the architecture, if not described, if referred as similar to some previous work.", "There are alo some notation shortcuts (not explained) in the proof of theorems that can lead to initialconfusion, but they turn out to be non-ambiguous.", "One that could be improved is P(P_X, P_G) where one loses the fact that the secnd random variable is Y This work contains plenty of novel material which is clearly compared to previous work: - The main conseqence of the use of Wasserstein distance is the surprisingly simple and useful Theorem 1, I could not verify its novelty, but this seems to be a great contribution.", "- Blending GAN and auto-encoders has been tried in the past, but the authors claim better theoreticalfoundations that lead to solutions that do not rquire min-max - The use of MMD in the context of GANs has alo been tried.", "The authors claim that their use in the latent space makes it more practival The experiments are very convincing, both numericaly and visualy.", "Source of confusion: in alorithm 1 and 2, \\tilde{z} is \"sampled\" from Q_TH(Z|xi), some one is lead to believe that this is the sampling process as in VAEs, while in realty Q_TH(Z|xi) is deterministic in the experiments."], "all_annotations": [{"interpretation": 0, "review_id": "Hk2dO8ngz", "importance": 0, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Hk9a7-qlG", "review_text": "The submission tackles an important problem of learning and transferring multiple motor skills. The approach relies on using an embedding space defined by latent variables and entropy-regularized policy gradient / variational inference formulation that encourages diversity and identifiability in latent space.\n\nThe exposition is clear and the method is well-motivated. I see no issues with the mathematical correctness of the claims made in the paper. The experimental results are both instructive of how the algorithm operates (in the particle example), and contain impressive robotic results. I appreciated the experiments that investigated cases where true number of tasks and the parameter T differ, showing that the approach is robust to choice of T.\n\nThe submission focuses particularly on discrete tasks and learning to sequence discrete tasks (as training requires a one-hot task ID input). I would like a bit of discussion on whether parameterized skills (that have continuous space of target location, or environment parameters, for example) can be supported in the current formulation, and what would be necessary if not.\n\nOverall, I believe this is in interesting piece of work at a fruitful intersection of reinforcement learning and variational inference, and I believe would be of interest to ICLR community.", "gold_annotation": {"interpretation": 0, "review_id": "Hk9a7-qlG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["The submission tackles an important problem of learning and transferring multiple motor skills.", "The approach relies on using an embedding space defined by latent variables and entropy-regularized policy gradient / variationalinference formulation that encourages diversity and identifiability in latent space.", "The exposition is clear and the method is well-motivated.", "I see no issues with the mathematicalcorrectness of the claims made in the paper.", "The experimentalresults are both instructive of how the alorithm operates (in the particle example), and contain impressive robotic results.", "I appreciated the experiments that investigated cases where true number of tasks and the parameter T differ, showing that the approach is robust to choice of T The submission focuses particularly on discrete tasks and learning to seqence discrete tasks (as training reqires a one-hot task ID input).", "I would like a bit of discussion on whether parameterized skills (that have continuous space of target location, or environment parameters, for example) can be supported in the current formulation, and what would be necessary if not.", "Overal, I believe this is in interesting piece of work at a fruitful intersecion of reinforcement learning and variationalinference, and I believe would be of interest to ICLR community."], "all_annotations": [{"interpretation": 0, "review_id": "Hk9a7-qlG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "HkJ6DWtgf", "review_text": "This paper studies a new architecture DualAC. The author give strong and convincing justifications based on the Lagrangian dual of the Bellman equation (although not new, introducing this as the justification for the architecture design is plausible).\n\nThere are several drawbacks of the current format of the paper:\n1. The algorithm is vague. Alg 1 line 5: 'closed form': there is no closed form in Eq(14). It is just an MC approximation.\nline 6: Decay O(1/t^\\beta). This is indeed vague albeit easy to understand. The algorithm requires that every step is crystal clear.\n\n2. Also, there are several format error which may be due to compiling, e.g., line 2 of Abstract,'Dual-AC ' (an extra space). There are many format errors like this throughout the paper. The author is suggested to do a careful format check.\n\n3. The author is suggested to explain more about the necessity of introducing path regularization and SDA. The current justification is reasonable but too brief.\n\n4. The experimental part is ok to me, but not very impressive.\n\nOverall, this seems to be a nice paper to me.", "gold_annotation": {"interpretation": 0, "review_id": "HkJ6DWtgf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 2.0, "tokenized_review_text": ["This paper studies a new architecture DualC.", "The author give strong and convincing justifications based on the Lagrangian dualof the Bellman eqation (alhough not new, introducing this as the justification for the architecture design is plausible).", "There are severaldrawbacks of the current format of the paper: 1, The alorithm is vague.", "Alg 1 line 5: 'closed form': there is no closed form in eq14).", "It is just an MC approximation.", "line 6: Decay O(1/t^\\beta).", "This is indeed vague aleit easy to understand.", "The alorithm reqires that every step is crystalclear.", "2, Also, there are severalformat error which may be due to compiling, e g , line 2 of Abstract,'DualAC ' (an extra space).", "There are many format errors like this throughout the paper.", "The author is suggested to do a careful format check.", "3, The author is suggested to explain more about the necessity of introducing path regularization and SDA.", "The current justification is reasonable but too brief.", "4, The experimentalpart is ok to me, but not very impressive.", "Overal, this seems to be a nice paper to me."], "all_annotations": [{"interpretation": 0, "review_id": "HkJ6DWtgf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Hkcb6tG-M", "review_text": "Revised Review:\n\nThe authors have addressed most of my concerns with the revised manuscript. I now think the paper does just enough to warrant acceptance, although I remain a bit concerned that since the benefits are only achievable with customized hardware, the relevance/applicability of the work is somewhat limited.\n\nOriginal Review:\n\nThe paper proposes a technique for quantizing the weights of a neural network, with bit-depth/precision varying on a per-parameter basis. The main idea is to minimize the number of bits used in the quantization while constraining the loss to remain below a specified upper bound. This is achieved by formulating an upper bound on the number of bits used via a set of \"tolerances\"; this upper bound is then minimized while estimating any increase in loss using a first order Taylor approximation.\n\nI have a number of questions and concerns about the proposed approach. First, at a high level, there are many details that aren't clear from the text. Quantization has some bookkeeping associated with it: In a per-parameter quantization setup it will be necessary to store not just the quantized parameter, but also the number of bits used in the quantization (takes e.g. 4-5 extra bits), and there will be some metadata necessary to encode how the quantized value should be converted back to floating point (e.g., for 8-bit quantization of a layer of weights, usually the min and max are stored). From Algorithm 1 it appears the quantization assumes parameters in the range [0, 1]. Don't negative values require another bit? What happens to values larger than 1? How are even bit depths and associated asymmetries w.r.t. 0 handled (e.g., three bits can represent -1, 0, and 1, but 4 must choose to either not represent 0 or drop e.g. -1)? None of these details are clearly discussed in the paper, and it's not at all clear that the estimates of compression are correct if these bookkeeping matters aren't taken into account properly.\n\nAdditionally the paper implies that this style of quantization has benefits for compute in addition to memory savings. This is highly dubious, since the method will require converting all parameters to a standard bit-depth on the fly (probably back to floating point, since some parameters may have been quantized with bit depth up to 32). Alternatively custom GEMM/conv routines would be required which are impossible to make efficient for weights with varying bit depths. So there are likely not runtime compute or memory savings from such an approach.\n\nI have a few other specific questions: Are the gradients used to compute \\mu computed on the whole dataset or minibatches? How would this scale to larger datasets? I am confused by the equality in Equation 8: What happens for values shared by many different quantization bit depths (e.g., representing 0 presumably requires 1 bit, but may be associated with a much finer tolerance)? Should \"minimization in equation 4\" refer to equation 3?\n\nIn the end, while do like the general idea of utilizing the gradient to identify how sensitive the model might be to quantization of various parameters, there are significant clarity issues in the paper, I am a bit uneasy about some of the compression results claimed without clearer description of the bookkeeping, and I don't believe an approach of this kind has any significant practical relevance for saving runtime memory or compute resources. ", "gold_annotation": {"interpretation": 1, "review_id": "Hkcb6tG-M", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 2.0, "tokenized_review_text": ["Revised Review: The authors have addressed most of my concerns with the revised manuscript.", "I now think the paper does just enough to warrant acceptance, alhough I remain a bit concerned that since the benefits are only achievable with customized hardware, the relevance/applicability of the work is somewhat limited.", "OriginalReview: The paper proposes a technique for quantizing the weights of a neuralnetwork, with bit-depth/precision varying on a per-parameter basis.", "The main idea is to minimize the number of bits used in the quantization while constraining the loss to remain below a specified upper bound.", "This is achieved by formulating an upper bound on the number of bits used via a set of \"tolerances\"; this upper bound is then minimized while estimating any increase in loss using a first order Taylor approximation.", "I have a number of questions and concerns about the proposed approach.", "First, at a high level, there are many details that aren't clear from the text.", "Quantization has some bookkeeping associated with it: In a per-parameter quantization setup it will be necessary to store not just the quantized parameter, but alo the number of bits used in the quantization (takes e g 4-5 extra bits), and there will be some metadata necessary to encode how the quantized vale should be converted back to floating point (e g , for 8-bit quantization of a layer of weights, usualy the min and max are stored).", "From Algorithm 1 it appears the quantization assumes parameters in the range [0, 1].", "Don't negative vales reqire another bit?", "What happens to vales larger than 1?", "How are even bit depths and associated asymmetries w r t 0 handled (e g , three bits can represent -1, 0, and 1, but 4 must choose to either not represent 0 or drop e g -1)?", "None of these details are clearly discussed in the paper, and it's not at al clear that the estimates of compression are correct if these bookkeeping matters aren't taken into account properly.", "Additionaly the paper implies that this style of quantization has benefits for compute in addition to memory savings.", "This is highly dubious, since the method will reqire converting al parameters to a standard bit-depth on the fly (probably back to floating point, since some parameters may have been quantized with bit depth up to 32).", "Alternatively custom GEMM/conv routines would be reqired which are impossible to make efficient for weights with varying bit depths.", "So there are likely not runtime compute or memory savings from such an approach.", "I have a few other specific questions: Are the gradients used to compute \\mu computed on the whole dataset or minibatches?", "How would this scal to larger datasets?", "I am confused by the eqalty in eqation 8: What happens for vales shared by many different quantization bit depths (e g , representing 0 presumably reqires 1 bit, but may be associated with a much finer tolerance)?", "Should \"minimization in eqation 4\" refer to eqation 3?", "In the end, while do like the generalidea of utilizing the gradient to identify how sensitive the model might be to quantization of various parameters, there are significant clarity issues in the paper, I am a bit uneasy about some of the compression results claimed without clearer description of the bookkeeping, and I don't believe an approach of this kind has any significant practicalrelevance for saving runtime memory or compute resources."], "all_annotations": [{"interpretation": 1, "review_id": "Hkcb6tG-M", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "HkdTXw1bM", "review_text": "The paper takes an interesting approach to solve the existing problems of GAN training, using Coulomb potential for addressing the learning problem. It is also well written with a clear presentation of the motivation of the problems it is trying to address, the background and proves the optimality of the suggested solution. My understanding and validity of the proof is still an educated guess. I have been through section A.2 , but I'm unfamiliar with the earlier literature on the similar topics so I would not be able to comment on it. \n\nOverall, I think this is a good paper that provides a novel way of looking at and solving problems in GANs. I just had a couple of points in the paper that I would like some clarification on : \n\n* In section 2.2.1 : The notion of the generated a_i not disappearing is something I did not follow. What does it mean for a generated sample to \"not disappear\" ? and this directly extends to the continuity equation in (2). \n\n* In section 1 : in the explanation of the 3rd problem that GANs exhibit i.e.  the generator not being able to generalize the distribution of the input samples, I was hoping if you could give a bit more motivation as to why this happens. I don't think this needs to be included in the paper, but would like to have it for a personal clarification. ", "gold_annotation": {"interpretation": 0, "review_id": "HkdTXw1bM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper takes an interesting approach to solve the existing problems of GAN training, using Coulomb potentialfor addressing the learning problem.", "It is alo well written with a clear presentation of the motivation of the problems it is trying to address, the background and proves the optimalty of the suggested solution.", "My understanding and valdity of the proof is still an educated guess.", "I have been through secion A 2 , but I'm unfamiliar with the earlier literature on the similar topics so I would not be able to comment on it.", "Overal, I think this is a good paper that provides a novel way of looking at and solving problems in GANs.", "I just had a couple of points in the paper that I would like some clarification on : * In secion 2 2 1 : The notion of the generated a_i not disappearing is something I did not follow.", "What does it mean for a generated sample to \"not disappear\" ?", "and this directly extends to the continuity eqation in (2).", "* In secion 1 : in the explanation of the 3rd problem that GANs exhibit i e the generator not being able to generalze the distribution of the input samples, I was hoping if you could give a bit more motivation as to why this happens.", "I don't think this needs to be included in the paper, but would like to have it for a personalclarification."], "all_annotations": [{"interpretation": 0, "review_id": "HkdTXw1bM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "HkeOU0qgf", "review_text": "The author unveils some properties of the resnets, for example, the cosine loss and l2 ratio of the layers. \nI think the author should place more focus to study \"real\" iterative inference with shared parameters rather than analyzing original resnets.\n\nIn resnet without sharing parameters, it is quite ambiguous to say whether it is doing representation learning or iterative refinement.\n\n1. The cosine loss is not meaningful in the sense that the classification layer is trained on the output of the last residual block and fixed. Moving the classification layer to early layers will definitely result in accuracy loss. Even in non-residual network, we can always say that the vector h_{i+1} - h_i is refining h_i towards the negative gradient direction. The motivation of iterative inference would be to generate a feature that is easier to classify rather than to match the current fixed classifier. Thus the final classification layer should be retrained for every addition or removal of residual blocks.\n\n2. The l2 ratio. The l2 ratio is small for higher residual layers, I'm not sure how much this phenomenon can prove that resnet is actually doing iterative inference.\n\n3. In section 4.4 it is shown that unrolling the layers can improve the performance of the network. However, the same can be achieved by adding more unshared layers. I think the study should focus more on whether shared or unshared is better.\n\n4. Section 4.5 is a bit weak in experiments, my conclusion is that currently it is still limited by batch normalization and optimization, the evidence is still not strong enough to show that iterative inference is advantageous / disadvantageous.\n\nThe the above said, I think the more important thing is how we can benefit from iterative inference interpretation, which is relatively weak in this paper.", "gold_annotation": {"interpretation": 1, "review_id": "HkeOU0qgf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}, "score": 2.0, "tokenized_review_text": ["The author unveils some properties of the resnets, for example, the cosine loss and l2 ratio of the layers.", "I think the author should place more focus to study \"real iterative inference with shared parameters rather than analzing originalresnets.", "In resnet without sharing parameters, it is quite ambiguous to say whether it is doing representation learning or iterative refinement.", "1, The cosine loss is not meaningful in the sense that the classification layer is trained on the output of the last residualblock and fixed.", "Moving the classification layer to early layers will definitely result in accuracy loss.", "Even in non-residualnetwork, we can alays say that the vector h_{i+1} - h_i is refining h_i towards the negative gradient direction.", "The motivation of iterative inference would be to generate a feature that is easier to classify rather than to match the current fixed classifier.", "Thus the finalclassification layer should be retrained for every addition or removalof residualblocks.", "2, The l2 ratio.", "The l2 ratio is smal for higher residuallayers, I'm not sure how much this phenomenon can prove that resnet is actualy doing iterative inference.", "3, In secion 4 4 it is shown that unrolling the layers can improve the performance of the network.", "However, the same can be achieved by adding more unshared layers.", "I think the study should focus more on whether shared or unshared is better.", "4, secion 4 5 is a bit weak in experiments, my conclusion is that currently it is still limited by batch normalzation and optimization, the evidence is still not strong enough to show that iterative inference is advantageous / disadvantageous.", "The the above said, I think the more important thing is how we can benefit from iterative inference interpretation, which is relatively weak in this paper."], "all_annotations": [{"interpretation": 1, "review_id": "HkeOU0qgf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno0", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "Hy4_ANE-f", "review_text": "This paper studies new off-policy policy optimization algorithm using relative entropy objective and use EM algorithm to solve it. The general idea is not new, aka, formulating the MDP problem as a probabilistic inference problem. \n\nThere are some technical questions:\n1. For parametric EM case, there is asymptotic convergence guarantee to local optima case; However, for nonparametric EM case, there is no guarantee for that. This is the biggest concern I have for the theoretical justification of the paper.\n\n2. In section 4, it is said that Retrace algorithm from Munos et al. (2016) is used for policy evaluation. This is not true. The Retrace algorithm, is per se, a value iteration algorithm. I think the author could say using the policy evaluation version of Retrace, or use the truncated importance weights technique as used in Retrace algorithm, which is more accurate.\n\nBesides, a minor point: Retrace algorithm is not off-policy stable with function approximation, as shown in several recent papers, such as \n\u201cConvergent Tree-Backup and Retrace with Function Approximation\u201d. But this is a minor point if the author doesn\u2019t emphasize too much about off-policy stability.\n\n3. The shifting between the unconstrained multiplier formulation in Eq.9 to the constrained optimization formulation in Eq.10 should be clarified. Usually, an in-depth analysis between the choice of \\lambda in multiplier formulation and the \\epsilon in the constraint should be discussed, which is necessary for further theoretical analysis. \n\n4. The experimental conclusions are conducted without sound evidence. For example, the author claims the method to be 'highly data efficient' compared with existing approaches, however, there is no strong evidence supporting this claim. \n\n\nOverall, although the motivation of this paper is interesting, I think there is still a lot of details to improve. ", "gold_annotation": {"interpretation": 1, "review_id": "Hy4_ANE-f", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper studies new off-policy policy optimization alorithm using relative entropy objective and use EM alorithm to solve it.", "The generalidea is not new, aka, formulating the MDP problem as a probabilistic inference problem.", "There are some technicalquestions: 1, For parametric EM case, there is asymptotic convergence guarantee to localoptima case; However, for nonparametric EM case, there is no guarantee for that.", "This is the biggest concern I have for the theoreticaljustification of the paper.", "2, In secion 4, it is said that Retrace alorithm from Munos et al (2016) is used for policy evalation.", "This is not true.", "The Retrace alorithm, is per se, a vale iteration alorithm.", "I think the author could say using the policy evalation version of Retrace, or use the truncated importance weights technique as used in Retrace alorithm, which is more accurate.", "Besides, a minor point: Retrace alorithm is not off-policy stable with function approximation, as shown in severalrecent papers, such as \u201cConvergent Tree-Backup and Retrace with Function Approximation\u201d.", "But this is a minor point if the author doesn\u2019t emphasize too much about off-policy stability.", "3, The shifting between the unconstrained multiplier formulation in eq9 to the constrained optimization formulation in eq10 should be clarified.", "Usualy, an in-depth analsis between the choice of \\lambda in multiplier formulation and the \\epsilon in the constraint should be discussed, which is necessary for further theoreticalanalsis.", "4, The experimentalconclusions are conducted without sound evidence.", "For example, the author claims the method to be 'highly data efficient' compared with existing approaches, however, there is no strong evidence supporting this claim.", "Overal, alhough the motivation of this paper is interesting, I think there is still a lot of details to improve."], "all_annotations": [{"interpretation": 1, "review_id": "Hy4_ANE-f", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno0", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "ryv9d98lf", "review_text": "This should be the first work which introduces in the causal structure into the GAN, to solve the label dependency problem. The idea is interesting and insightful. The proposed method is theoretically analyzed and experimentally tested.  Two minor concerns are 1) what is the relationship between the anti-labeler and and discriminator? 2) how the tune related weight of the different objective functions.  ", "gold_annotation": {"interpretation": 0, "review_id": "ryv9d98lf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 1.0, "tokenized_review_text": ["This should be the first work which introduces in the causalstructure into the GAN, to solve the label dependency problem.", "The idea is interesting and insightful.", "The proposed method is theoreticaly analzed and experimentaly tested.", "Two minor concerns are 1) what is the relationship between the anti-labeler and and discriminator?", "2) how the tune related weight of the different objective functions."], "all_annotations": [{"interpretation": 0, "review_id": "ryv9d98lf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 1, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "ryjxrEwlM", "review_text": "The authors propose a mechanism for learning task-specific region embeddings for use in text classification. Specifically, this comprises a standard word embedding an accompanying local context embedding. \n\nThe key idea here is the introduction of a (h x c x v) tensor K, where h is the embedding dim (same as the word embedding size), c is a fixed window size around a target word, and v is the vocabulary size. Each word in v is then associated with an (h x c) matrix that is meant to encode how it affects nearby words, in particular this may be viewed as parameterizing a projection to be applied to surrounding word embeddings. The authors propose two specific variants of this approach, which combine the K matrix and constituent word embeddings (in a given region) in different ways. Region embeddings are then composed (summed) and fed through a standard model. \n\nStrong points\n---\n+ The proposed approach is simple and largely intuitive: essentially the context matrix allows word-specific contextualization. Further, the work is clearly presented.\n\n+ At the very least the model does seem comparable in performance to various recent methods (as per Table 2), however as noted below the gains are marginal and I have some questions on the setup.\n\n+ The authors perform ablation experiments, which are always nice to see. \n\nWeak points\n---\n- I have a critical question for clarification in the experiments. The authors write 'Optimal hyperparameters are tuned with 10% of the training set on Yelp Review Full dataset, and identical hyperparameters are applied to all datasets' -- is this true for *all* models, or only the proposed approach? \n\n- The gains here appear to be consistent, but they seem marginal. The biggest gain achieved over all datasets is apparently .7, and most of the time the model very narrowly performs better (.2-.4 range). Moreoever, it is not clear if these results are averaged over multiple runs of SGD or not (variation due to initialization and stochastic estimation can account for up to 1 point in variance -- see \"A sensitivity analysis of (and practitioners guide to) CNNs...\" Zhang and Wallace, 2015.)\n\n- The related work section seems light. For instance, there is no discussion at all of LSTMs and their application to text classificatio (e.g., Tang et al., EMNLP 2015) -- although it is noted that the authors do compare against D-LSTM,  or char-level CNNs for the same (see Zhang et al., NIPs 2015). Other relevant work not discussed includes Iyyer et al. (ACL 2015). In their respective ways, these papers address some of the same issues the authors consider here. \n\n- The two approaches to inducing the final region embedding (word-context and then context-word in sections 3.2 and 3.3, respectively) feel a bit ad-hoc. I would have appreciated more intuition behind these approaches. \n\nSmall comments\n---\nThere is a typo in Figure 4 -- \"Howerver\" should be \"However\"\n\n*** Update after author response ***\n\nThanks to the authors for their responses. My score is unchanged.", "gold_annotation": {"interpretation": 0, "review_id": "ryjxrEwlM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The authors propose a mechanism for learning task-specific region embeddings for use in text classification.", "Specificaly, this comprises a standard word embedding an accompanying localcontext embedding.", "The key idea here is the introduction of a (h x c x v) tensor K, where h is the embedding dim (same as the word embedding size), c is a fixed window size around a target word, and v is the vocabulary size.", "Each word in v is then associated with an (h x c) matrix that is meant to encode how it affects nearby words, in particular this may be viewed as parameterizing a projection to be applied to surrounding word embeddings.", "The authors propose two specific variants of this approach, which combine the K matrix and constituent word embeddings (in a given region) in different ways.", "Region embeddings are then composed (summed) and fed through a standard model.", "Strong points --- + The proposed approach is simple and largely intuitive: essentialy the context matrix alows word-specific contextualzation.", "Further, the work is clearly presented.", "+ At the very least the model does seem comparable in performance to various recent methods (as per Table 2), however as noted below the gains are marginaland I have some questions on the setup.", "+ The authors perform ablation experiments, which are alays nice to see.", "Weak points --- - I have a criticalquestion for clarification in the experiments.", "The authors write 'Optimalhyperparameters are tuned with 10% of the training set on Yelp Review Full dataset, and identicalhyperparameters are applied to al datasets' -- is this true for *al* models, or only the proposed approach?", "- The gains here appear to be consistent, but they seem marginal The biggest gain achieved over al datasets is apparently .7, and most of the time the model very narrowly performs better (.2-.4 range).", "Moreoever, it is not clear if these results are averaged over multiple runs of SGD or not (variation due to initialzation and stochastic estimation can account for up to 1 point in variance -- see \"A sensitivity analsis of (and practitioners guide to) CNNs...\" Zhang and Walace, 2015.)", "- The related work secion seems light.", "For instance, there is no discussion at al of LSTMs and their application to text classificatio (e g , Tang et al, EMNLP 2015) -- alhough it is noted that the authors do compare against D-LSTM, or char-level CNNs for the same (see Zhang et al, NIPs 2015).", "Other relevant work not discussed includes Iyyer et al (ACL 2015).", "In their respective ways, these papers address some of the same issues the authors consider here.", "- The two approaches to inducing the finalregion embedding (word-context and then context-word in secions 3 2 and 3 3, respectively) feel a bit ad-hoc.", "I would have appreciated more intuition behind these approaches.", "Smal comments --- There is a typo in figre 4 -- \"Howerver\" should be \"However\" *** Update after author response *** Thanks to the authors for their responses.", "My score is unchanged."], "all_annotations": [{"interpretation": 0, "review_id": "ryjxrEwlM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "ry_xOQ5ef", "review_text": "This paper creates adversarial images by imposing a flow field on an image such that the new spatially transformed image fools the classifier. They minimize a total variation loss in addition to the adversarial loss to create perceptually plausible adversarial images, this is claimed to be better than the normal L2 loss functions.\n\nExperiments were done on MNIST, CIFAR-10, and ImageNet, which is very useful to see that the attack works with high dimensional images. However, some numbers on ImageNet would be helpful as the high resolution of it make it potentially different than the low-resolution MNIST and CIFAR.\n\nIt is a bit concerning to see some parts of Fig. 2. Some of Fig. 2 (especially (b)) became so dotted that it no longer seems an adversarial that a human eye cannot detect. And model B in the appendix looks pretty much like a normal model. It might needs some experiments, either human studies, or to test it against an adversarial detector, to ensure that the resulting adversarials are still indeed adversarials to the human eye. Another good thing to run would be to try the 3x3 average pooling restoration mechanism in the following paper:\n\nXin Li, Fuxin Li. Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics . ICCV 2017.\n\nto see whether this new type of adversarial example can still be restored by a 3x3 average pooling the image (I suspect that this is harder to restore by such a simple method than the previous FGSM or OPT-type, but we need some numbers).\n\nI also don't think FGSM and OPT are this bad in Fig. 4. Are the authors sure that if more regularization are used these 2 methods no longer fool the corresponding classifiers?\n\nI like the experiment showing the attention heat maps for different attacks. This experiment shows that the spatial transforming attack (stAdv) changes the attention of the classifier for each target class, and is robust to adversarially trained Inception v3 unlike other attacks like FGSM and CW. \n\nI would likely upgrade to a 7 if those concerns are addressed.\n\nAfter rebuttal: I am happy with the additional experiments and would like to upgrade to an accept.", "gold_annotation": {"interpretation": 1, "review_id": "ry_xOQ5ef", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper creates adversarialimages by imposing a flow field on an image such that the new spatialy transformed image fools the classifier.", "They minimize a totalvariation loss in addition to the adversarialloss to create perceptualy plausible adversarialimages, this is claimed to be better than the normalL2 loss functions.", "Experiments were done on MNIST, CIFAR-10, and ImageNet, which is very useful to see that the attack works with high dimensionalimages.", "However, some numbers on ImageNet would be helpful as the high resolution of it make it potentialy different than the low-resolution MNIST and CIFAR.", "It is a bit concerning to see some parts of fig 2, Some of fig 2 (especialy (b)) became so dotted that it no longer seems an adversarialthat a human eye cannot detect.", "And model B in the appendix looks pretty much like a normalmodel.", "It might needs some experiments, either human studies, or to test it against an adversarialdetector, to ensure that the resulting adversarial are still indeed adversarial to the human eye.", "Another good thing to run would be to try the 3x3 average pooling restoration mechanism in the following paper: Xin Li, Fuxin Li.", "AdversarialExamples Detection in Deep Networks with ConvolutionalFilter Statistics .", "ICCV 2017, to see whether this new type of adversarialexample can still be restored by a 3x3 average pooling the image (I suspect that this is harder to restore by such a simple method than the previous FGSM or OPT-type, but we need some numbers).", "I alo don't think FGSM and OPT are this bad in fig 4, Are the authors sure that if more regularization are used these 2 methods no longer fool the corresponding classifiers?", "I like the experiment showing the attention heat maps for different attacks.", "This experiment shows that the spatialtransforming attack (stAdv) changes the attention of the classifier for each target class, and is robust to adversarialy trained Inception v3 unlike other attacks like FGSM and CW.", "I would likely upgrade to a 7 if those concerns are addressed.", "After rebuttal I am happy with the additionalexperiments and would like to upgrade to an accept."], "all_annotations": [{"interpretation": 1, "review_id": "ry_xOQ5ef", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "ryVd3dFgf", "review_text": "This paper proposes a method for parameter space noise in exploration.\nRather than the \"baseline\" epsilon-greedy (that sometimes takes a single action at random)... this paper presents an method for perturbations to the policy.\nIn some domains this can be a much better approach and this is supported by experimentation.\n\nThere are several things to like about the paper:\n- Efficient exploration is a big problem for deep reinforcement learning (epsilon-greedy or Boltzmann is the de-facto baseline) and there are clearly some examples where this approach does much better.\n- The noise-scaling approach is (to my knowledge) novel, good and in my view the most valuable part of the paper.\n- This is clearly a very practical and extensible idea... the authors present good results on a whole suite of tasks.\n- The paper is clear and well written, it has a narrative and the plots/experiments tend to back this up.\n- I like the algorithm, it's pretty simple/clean and there's something obviously *right* about it (in SOME circumstances).\n\nHowever, there are also a few things to be cautious of... and some of them serious:\n- At many points in the paper the claims are quite overstated. Parameter noise on the policy won't necessarily get you efficient exploration... and in some cases it can even be *worse* than epsilon-greedy... if you just read this paper you might think that this was a truly general \"statistically efficient\" method for exploration (in the style of UCRL or even E^3/Rmax etc).\n- For instance, the example in 4.2 only works because the optimal solution is to go \"right\" in every timestep... if you had the network parameterized in a different way (or the actions left/right were relabelled) then this parameter noise approach would *not* work... By contrast, methods such as UCRL/PSRL and RLSVI https://arxiv.org/abs/1402.0635 *are* able to learn polynomially in this type of environment. I think the claim/motivation for this example in the bootstrapped DQN paper is more along the lines of \"deep exploration\" and you should be clear that your parameter noise does *not* address this issue.\n- That said I think that the example in 4.2 is *great* to include... you just need to be more upfront about how/why it works and  what you are banking on with the parameter-space exploration. Essentially you perform a local exploration rule in parameter space... and sometimes this is great - but you should be careful to distinguish this type of method from other approaches. This must be mentioned in section 4.2 \"does parameter space noise explore efficiently\" because the answer you seem to imply is \"yes\" ... when the answer is clearly NOT IN GENERAL... but it can still be good sometimes ;D\n- The demarcation of \"RL\" and \"evolutionary strategies\" suggests a pretty poor understanding of the literature and associated concepts. I can't really support the conclusion \"RL with parameter noise exploration learns more efficiently than both RL and evolutionary strategies individually\". This sort of sentence is clearly wrong and for many separate reasons:\n    - Parameter noise exploration is not a separate/new thing from RL... it's even been around for ages! It feels like you are talking about DQN/A3C/(whatever algorithm got good scores in Atari last year) as \"RL\" and that's just really not a good way to think about it.\n    - Parameter noise exploration can be *extremely* bad relative to efficient exploration methods (see section 2.4.3 https://searchworks.stanford.edu/view/11891201)\n\n\nOverall, I like the paper, I like the algorithm and I think it is a valuable contribution.\nI think the value in this paper comes from a practical/simple way to do policy randomization in deep RL.\nIn some (maybe even many of the ones you actually care about) settings this can be a really great approach, especially when compared to epsilon-greedy.\n\nHowever, I hope that you address some of the concerns I have raised in this review.\nYou shouldn't claim such a universal revolution to exploration / RL / evolution because I don't think that it's correct.\nFurther, I don't think that clarifying that this method is *not* universal/general really hurts the paper... you could just add a section in 4.2 pointing out that the \"chain\" example wouldn't work if you needed to do different actions at each timestep (this algorithm does *not* perform \"deep exploration\").\n\nI vote accept.", "gold_annotation": {"interpretation": 1, "review_id": "ryVd3dFgf", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper proposes a method for parameter space noise in exploration.", "Rather than the \"baseline\" epsilon-greedy (that sometimes takes a single action at random)... this paper presents an method for perturbations to the policy.", "In some domains this can be a much better approach and this is supported by experimentation.", "There are severalthings to like about the paper: - Efficient exploration is a big problem for deep reinforcement learning (epsilon-greedy or Boltzmann is the de-facto baseline) and there are clearly some examples where this approach does much better.", "- The noise-scalng approach is (to my knowledge) novel, good and in my view the most valable part of the paper.", "- This is clearly a very practicaland extensible idea... the authors present good results on a whole suite of tasks.", "- The paper is clear and well written, it has a narrative and the plots/experiments tend to back this up.", "- I like the alorithm, it's pretty simple/clean and there's something obviously *right* about it (in SOME circumstances).", "However, there are alo a few things to be cautious of... and some of them serious: - At many points in the paper the claims are quite overstated.", "Parameter noise on the policy won't necessarily get you efficient exploration... and in some cases it can even be *worse* than epsilon-greedy... if you just read this paper you might think that this was a truly general\"statisticaly efficient\" method for exploration (in the style of UCRL or even E^3/Rmax etc.", "- For instance, the example in 4 2 only works because the optimalsolution is to go \"right\" in every timestep... if you had the network parameterized in a different way (or the actions left/right were relabelled) then this parameter noise approach would *not* work... By contrast, methods such as UCRL/PSRL and RLSVI https://arxiv.org/abs/1402.0635 *are* able to learn polynomialy in this type of environment.", "I think the claim/motivation for this example in the bootstrapped DQN paper is more alng the lines of \"deep exploration\" and you should be clear that your parameter noise does *not* address this issue.", "- That said I think that the example in 4 2 is *great* to include... you just need to be more upfront about how/why it works and what you are banking on with the parameter-space exploration.", "Essentialy you perform a localexploration rule in parameter space... and sometimes this is great - but you should be careful to distinguish this type of method from other approaches.", "This must be mentioned in secion 4 2 \"does parameter space noise explore efficiently\" because the answer you seem to imply is \"yes\" ... when the answer is clearly NOT IN GENERAL... but it can still be good sometimes ;D - The demarcation of \"RL\" and \"evolutionary strategies\" suggests a pretty poor understanding of the literature and associated concepts.", "I can't realy support the conclusion \"RL with parameter noise exploration learns more efficiently than both RL and evolutionary strategies individualy\".", "This sort of sentence is clearly wrong and for many separate reasons: - Parameter noise exploration is not a separate/new thing from RL... it's even been around for ages!", "It feels like you are taling about DQN/A3C/(whatever alorithm got good scores in Atari last year) as \"RL\" and that's just realy not a good way to think about it.", "- Parameter noise exploration can be *extremely* bad relative to efficient exploration methods (see secion 2 4 3 https://searchworks.stanford.edu/view/11891201) Overal, I like the paper, I like the alorithm and I think it is a valable contribution.", "I think the vale in this paper comes from a practicalsimple way to do policy randomization in deep RL.", "In some (maybe even many of the ones you actualy care about) settings this can be a realy great approach, especialy when compared to epsilon-greedy.", "However, I hope that you address some of the concerns I have raised in this review.", "You shouldn't claim such a universalrevolution to exploration / RL / evolution because I don't think that it's correct.", "Further, I don't think that clarifying that this method is *not* universalgeneralrealy hurts the paper... you could just add a secion in 4 2 pointing out that the \"chain\" example wouldn't work if you needed to do different actions at each timestep (this alorithm does *not* perform \"deep exploration\").", "I vote accept."], "all_annotations": [{"interpretation": 1, "review_id": "ryVd3dFgf", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "yes-agree", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "ryT2f8KgM", "review_text": "This paper continues a trend of incremental improvements to Wasserstein GANs (WGAN), where the latter were proposed in order to alleviate the difficulties encountered in training GANs. Originally, Arjovsky et al.  [1] argued that the Wasserstein distance was superior to many others typically used for GANs. An important feature of WGANs is the requirement for the discriminator to be 1-Lipschitz, which [1] achieved simply by clipping the network weights. Recently, Gulrajani et al. [2] proposed a gradient penalty \"encouraging\" the discriminator to be 1-Lipschitz. However, their approach estimated continuity on points between the generated and the real samples, and thus could fail to guarantee Lipschitz-ness at the early training stages. The paper under review overcomes this drawback by estimating the continuity on perturbations of the real samples. Together with various technical improvements, this leads to state-of-the-art practical performance both in terms of generated images and in semi-supervised learning.  \n\nIn terms of novelty, the paper provides one core conceptual idea followed by several tweaks aimed at improving the practical performance of GANs. The key conceptual idea is to perturb each data point twice and use a Lipschitz constant to bound the difference in the discriminator\u2019s response on the perturbed points.  The proposed method is used in eq. (6) together with the gradient penalty from [2]. The authors found that directly perturbing the data with Gaussian noise led to inferior results and therefore propose to perturb the hidden layers using dropout. For supervised learning they demonstrate less overfitting for both MNIST and CIFAR 10.  They also extend their framework to the semi-supervised setting of Salismans et al 2016 and report improved image generation. \n\nThe authors do an excellent comparative job in presenting their experiments. They compare numerous techniques (e.g., Gaussian noise, dropout) and demonstrates the applicability of the approach for a wide range of tasks. They use several criteria to evaluate their performance (images, inception score, semi-supervised learning, overfitting, weight histogram) and compare against a wide range of competing papers. \n\nWhere the paper could perhaps be slightly improved is writing clarity. In particular, the discussion of M and M' is vital to the point of the paper, but could be written in a more transparent manner. The same goes for the semi-supervised experiment details and the CIFAR-10 augmentation process. Finally, the title seems uninformative. Almost all progress is incremental, and the authors modestly give credit to both [1] and [2], but the title is neither memorable nor useful in expressing the novel idea. \n[1] Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein gan.\n\n[2] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. Improved training of wasserstein gans. \n\n", "gold_annotation": {"interpretation": 0, "review_id": "ryT2f8KgM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper continues a trend of incrementalimprovements to Wasserstein GANs (WGAN), where the latter were proposed in order to aleviate the difficulties encountered in training GANs.", "Originaly, Arjovsky et al [1] argued that the Wasserstein distance was superior to many others typicaly used for GANs.", "An important feature of WGANs is the reqirement for the discriminator to be 1-Lipschitz, which [1] achieved simply by clipping the network weights.", "Recently, Gulrajani et al [2] proposed a gradient penaly \"encouraging\" the discriminator to be 1-Lipschitz.", "However, their approach estimated continuity on points between the generated and the realsamples, and thus could fail to guarantee Lipschitz-ness at the early training stages.", "The paper under review overcomes this drawback by estimating the continuity on perturbations of the realsamples.", "Together with various technicalimprovements, this leads to state-of-the-art practicalperformance both in terms of generated images and in semi-supervised learning.", "In terms of novelty, the paper provides one core conceptualidea followed by severaltweaks aimed at improving the practicalperformance of GANs.", "The key conceptualidea is to perturb each data point twice and use a Lipschitz constant to bound the difference in the discriminator\u2019s response on the perturbed points.", "The proposed method is used in eq (6) together with the gradient penaly from [2].", "The authors found that directly perturbing the data with Gaussian noise led to inferior results and therefore propose to perturb the hidden layers using dropout.", "For supervised learning they demonstrate less overfitting for both MNIST and CIFAR 10, They alo extend their framework to the semi-supervised setting of Salsmans et al2016 and report improved image generation.", "The authors do an excellent comparative job in presenting their experiments.", "They compare numerous techniques (e g , Gaussian noise, dropout) and demonstrates the applicability of the approach for a wide range of tasks.", "They use severalcriteria to evalate their performance (images, inception score, semi-supervised learning, overfitting, weight histogram) and compare against a wide range of competing papers.", "Where the paper could perhaps be slightly improved is writing clarity.", "In particular, the discussion of M and M' is vitalto the point of the paper, but could be written in a more transparent manner.", "The same goes for the semi-supervised experiment details and the CIFAR-10 augmentation process.", "Finaly, the title seems uninformative.", "Almost al progress is incremental and the authors modestly give credit to both [1] and [2], but the title is neither memorable nor useful in expressing the novel idea.", "[1] Martin Arjovsky, Soumith Chintal, and Leon Bottou.", "Wasserstein gan.", "[2] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville.", "Improved training of wasserstein gans."], "all_annotations": [{"interpretation": 0, "review_id": "ryT2f8KgM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "ryOWEcdlM", "review_text": "This paper studies the critical points of shallow and deep linear networks. The authors give a (necessary and sufficient) characterization of the form of critical points and use this to derive necessary and sufficient conditions for which critical points are global optima. Essentially this paper revisits a classic paper by Baldi and Hornik (1989) and relaxes a few requires assumptions on the matrices. I have not checked the proofs in detail but the general strategy seems sound. While the exposition of the paper can be improved in my view this is a neat and concise result and merits publication in ICLR. The authors also study the analytic form of critical points of a single-hidden layer ReLU network. However, given the form of the necessary and sufficient conditions the usefulness of of these results is less clear.\n\n\nDetailed comments:\n\n- I think in the title/abstract/intro the use of Neural nets is somewhat misleading as neural nets are typically nonlinear. This paper is mostly about linear networks. While a result has been stated for single-hidden ReLU networks. In my view this particular result is an immediate corollary of the result for linear networks. As I explain further below given the combinatorial form of the result, the usefulness of this particular extension to ReLU network is not very clear. I would suggest rewording title/abstract/intro\n\n- Theorem 1 is neat, well done!\n\n- Page 4 p_i\u2019s in proposition 1\nFrom my understanding the p_i have been introduced in Theorem 1 but given their prominent role in this proposition they merit a separate definition (and ideally in terms of the A_i directly). \n\n- Theorems 1, prop 1, prop 2, prop 3, Theorem 3, prop 4 and 5\n\tAre these characterizations computable i.e. given X and Y can one run an algorithm to find all the critical points or at least the parameters used in the characterization p_i, V_i etc?\n\n- Theorems 1, prop 1, prop 2, prop 3, Theorem 3, prop 4 and 5\n\tWould recommend a better exposition why these theorems are useful. What insights do you gain by knowing these theorems etc. Are less sufficient conditions that is more intuitive or useful. (an insightful sufficient condition in some cases is much more valuable than an unintuitive necessary and sufficient one).\n\n- Page 5 Theorem 2\n\tDoes this theorem have any computational implications? Does it imply that the global optima can be found efficiently, e.g. are saddles strict with a quantifiable bound?\n\n- Page 7 proposition 6 seems like an immediate consequence of Theorem 1 however given the combinatorial nature of the K_{I,J} it is not clear why this theorem is useful. e.g . back to my earlier comment w.r.t. Linear networks given Y and X can you find the parameters of this characterization with a computationally efficient algorithm? \n", "gold_annotation": {"interpretation": 1, "review_id": "ryOWEcdlM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["This paper studies the criticalpoints of shalow and deep linear networks.", "The authors give a (necessary and sufficient) characterization of the form of criticalpoints and use this to derive necessary and sufficient conditions for which criticalpoints are globaloptima.", "Essentialy this paper revisits a classic paper by Bali and Hornik (1989) and relaxes a few reqires assumptions on the matrices.", "I have not checked the proofs in detail but the generalstrategy seems sound.", "While the exposition of the paper can be improved in my view this is a neat and concise result and merits publication in ICLR.", "The authors alo study the analtic form of criticalpoints of a single-hidden layer ReLU network.", "However, given the form of the necessary and sufficient conditions the usefulness of of these results is less clear.", "Detailed comments: - I think in the title/abstract/intro the use of Neuralnets is somewhat misleading as neuralnets are typicaly nonlinear.", "This paper is mostly about linear networks.", "While a result has been stated for single-hidden ReLU networks.", "In my view this particular result is an immediate corollary of the result for linear networks.", "As I explain further below given the combinatorialform of the result, the usefulness of this particular extension to ReLU network is not very clear.", "I would suggest rewording title/abstract/intro - Theorem 1 is neat, well done!", "- Page 4 p_i\u2019s in proposition 1 From my understanding the p_i have been introduced in Theorem 1 but given their prominent role in this proposition they merit a separate definition (and idealy in terms of the A_i directly).", "- Theorems 1, prop 1, prop 2, prop 3, Theorem 3, prop 4 and 5 \tAre these characterizations computable i e given X and Y can one run an alorithm to find al the criticalpoints or at least the parameters used in the characterization p_i, V_i etc - Theorems 1, prop 1, prop 2, prop 3, Theorem 3, prop 4 and 5 \tWould recommend a better exposition why these theorems are useful.", "What insights do you gain by knowing these theorems etc Are less sufficient conditions that is more intuitive or useful.", "(an insightful sufficient condition in some cases is much more valable than an unintuitive necessary and sufficient one).", "- Page 5 Theorem 2 \tDoes this theorem have any computationalimplications?", "Does it imply that the globaloptima can be found efficiently, e g are saddles strict with a quantifiable bound?", "- Page 7 proposition 6 seems like an immediate conseqence of Theorem 1 however given the combinatorialnature of the K_{I,J} it is not clear why this theorem is useful.", "e g .", "back to my earlier comment w r t Linear networks given Y and X can you find the parameters of this characterization with a computationaly efficient alorithm?"], "all_annotations": [{"interpretation": 1, "review_id": "ryOWEcdlM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "ryCv5QFgz", "review_text": "Motivated via Talor approximation of the Residual network on a local minima, this paper proposed a warp operator that can replace a block of a consecutive number of residual layers. While having the same number of parameters as the original residual network, the new operator has the property that the computation can be parallelized. As demonstrated in the paper, this improves the training time with multi-GPU parallelization, while maintaining similar performance on CIFAR-10 and CIFAR-100.\n\nOne thing that is currently not very clear to me is about the rotational symmetry. The paper mentioned rotated filters, but continue to talk about the rotation in the sense of an orthogonal matrix applying to the weight matrix of a convolution layer. The rotation of the filters (as 2D images or images with depth) seem to be quite different from \"rotating\" a general N-dim vectors in an abstract Euclidean space. It would be helpful to make the description here more explicit and clear.", "gold_annotation": {"interpretation": 0, "review_id": "ryCv5QFgz", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["Motivated via Talr approximation of the Residualnetwork on a localminima, this paper proposed a warp operator that can replace a block of a consective number of residuallayers.", "While having the same number of parameters as the originalresidualnetwork, the new operator has the property that the computation can be paralelized.", "As demonstrated in the paper, this improves the training time with multi-GPU paralelization, while maintaining similar performance on CIFAR-10 and CIFAR-100, One thing that is currently not very clear to me is about the rotationalsymmetry.", "The paper mentioned rotated filters, but continue to tal about the rotation in the sense of an orthogonalmatrix applying to the weight matrix of a convolution layer.", "The rotation of the filters (as 2D images or images with depth) seem to be quite different from \"rotating\" a generalN-dim vectors in an abstract Euclidean space.", "It would be helpful to make the description here more explicit and clear."], "all_annotations": [{"interpretation": 0, "review_id": "ryCv5QFgz", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "ryBakJUlz", "review_text": "This is a dense, rich, and impressive paper on rapid meta-learning. It is already highly polished, so I have mostly minor comments.\n\nRelated work: I think there is a distinction between continual and life-long learning, and I think that your proposed setup is a form of continual learning (see Ring \u201894/\u201897). Given the proliferation of terminology for very related setups, I\u2019d encourage you to reuse the old term.\n\nTerminology: I find it confusing which bits are \u201cmeta\u201d and which are not, and the paper could gain clarity by making this consistent. In particular, it would be good to explicitly name the \u201cmeta-loss\u201d (currently the unnamed triple expectation in (3)). By definition, then, the \u201cmeta-gradient\u201d is the gradient of the meta-loss -- and not the one in (2), which is the gradient of the regular loss.\n\nNotation: there\u2019s redundancy/inconsistency in the reward definition: pick either R_T or \\bold{r}, not both, and maybe include R_T in the task tuple definition? It is also confusing that \\mathcal{R} is a loss, not a reward (and is minimized) -- maybe use another symbol?\n\nA question about the importance sampling correction: given that this spans multiple (long) trajectories, don\u2019t the correction weights become really small in practice? Do you have some ballpark numbers?\n\nTypos:\n- \u201cevent their learning\u201d\n- \u201cin such setting\u201d\n- \u201cexperience to for\u201d\n", "gold_annotation": {"interpretation": 0, "review_id": "ryBakJUlz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["This is a dense, rich, and impressive paper on rapid meta-learning.", "It is aleady highly polished, so I have mostly minor comments.", "Related work: I think there is a distinction between continualand life-long learning, and I think that your proposed setup is a form of continuallearning (see Ring \u201894/\u201897).", "Given the proliferation of terminology for very related setups, I\u2019d encourage you to reuse the old term.", "Terminology: I find it confusing which bits are \u201cmeta\u201d and which are not, and the paper could gain clarity by making this consistent.", "In particular, it would be good to explicitly name the \u201cmeta-loss\u201d (currently the unnamed triple expectation in (3)).", "By definition, then, the \u201cmeta-gradient\u201d is the gradient of the meta-loss -- and not the one in (2), which is the gradient of the regular loss.", "Notation: there\u2019s redundancy/inconsistency in the reward definition: pick either R_T or \\bold{r}, not both, and maybe include R_T in the task tuple definition?", "It is alo confusing that \\mathcalR} is a loss, not a reward (and is minimized) -- maybe use another symbol?", "A question about the importance sampling correction: given that this spans multiple (long) trajectories, don\u2019t the correction weights become realy smal in practice?", "Do you have some balpark numbers?", "Typos: - \u201cevent their learning\u201d - \u201cin such setting\u201d - \u201cexperience to for\u201d"], "all_annotations": [{"interpretation": 0, "review_id": "ryBakJUlz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "ry-q9ZOlf", "review_text": "This paper proposes a simple modification to the standard alternating stochastic gradient method for GAN training, which stabilizes training, by adding a prediction step. \n\nThis is a clever and useful idea, and the paper is very well written. The proposed method is very clearly motivated, both intuitively and mathematically, and the authors also provide theoretical guarantees on its convergence behavior. I particularly liked the analogy with the damped harmonic oscillator.  \n\nThe experiments are well designed and provide clear evidence in favor of the usefulness of the proposed technique. I believe that the method proposed in this paper will have a significant impact in the area of GAN training.\n\nI have only one minor question: in the prediction step, why not use a step size, say \n$\\bar{u}_k+1 = u_{k+1} + \\gamma_k (u_{k+1} \u2212 u_k)$, such that the \"amount of predition\" may be adjusted?\n", "gold_annotation": {"interpretation": 0, "review_id": "ry-q9ZOlf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 2.0, "tokenized_review_text": ["This paper proposes a simple modification to the standard alernating stochastic gradient method for GAN training, which stabilizes training, by adding a prediction step.", "This is a clever and useful idea, and the paper is very well written.", "The proposed method is very clearly motivated, both intuitively and mathematicaly, and the authors alo provide theoreticalguarantees on its convergence behavior.", "I particularly liked the analgy with the damped harmonic oscillator.", "The experiments are well designed and provide clear evidence in favor of the usefulness of the proposed technique.", "I believe that the method proposed in this paper will have a significant impact in the area of GAN training.", "I have only one minor question: in the prediction step, why not use a step size, say $\\bar{u}_k+1 = u_{k+1} + \\gamma_k (u_{k+1} \u2212 u_k)$, such that the \"amount of predition\" may be adjusted?"], "all_annotations": [{"interpretation": 0, "review_id": "ry-q9ZOlf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rksMwz9xG", "review_text": "This paper presents a new reinforcement learning architecture called Reactor by combining various improvements in\ndeep reinforcement learning algorithms and architectures into a single model. The main contributions of the paper\nare to achieve a better bias-variance trade-off in policy gradient updates, multi-step off-policy updates with\ndistributional RL, and prioritized experience replay for transition sequences. The different modules are integrated\nwell and the empirical results are very promising. The experiments (though limited to Atari) are well carried out and\nthe evaluation is performed on both sample efficiency and training time.\n\nPros:\n1. Nice integration of several recent improvements in deep RL, along with a few novel tricks to improve training.\n2. The empirical results on 57 Atari games are impressive, in terms of final scores as well as real-time training speed.\n\nCons:\n1. Reactor is still less sample-efficient than Rainbow, with significantly lower scores after 200M frames. While the\nreactor trains much faster, it does use more parallel compute, so the comparison with Rainbow on wall clock time is\n not entirely fair. Would a distributed version of Rainbow perform better in this respect?\n2. Empirical comparisons are restricted to the Atari domain. The conclusions of the paper will be much stronger if\nresults are also shown on other environments like Mujoco/Vizdoom/Deepmind Lab.\n3. Since the paper introduces a few new ideas like prioritized sequence replay, it would help if a more detailed analysis\n was performed on the impact of these individual schemes, even if in a model simpler than the Reactor. For instance, one could investigate the impact of prioritized sequence replay in models like multi-step DQN or recurrent DQN. This will help us understand  the impact of each of these ideas in a more comprehensive fashion.\n\n\n", "gold_annotation": {"interpretation": 1, "review_id": "rksMwz9xG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.5, "tokenized_review_text": ["This paper presents a new reinforcement learning architecture caled Reactor by combining various improvements in deep reinforcement learning alorithms and architectures into a single model.", "The main contributions of the paper are to achieve a better bias-variance trade-off in policy gradient updates, multi-step off-policy updates with distributionalRL, and prioritized experience replay for transition seqences.", "The different modules are integrated well and the empiricalresults are very promising.", "The experiments (though limited to Atari) are well carried out and the evalation is performed on both sample efficiency and training time.", "Pros: 1, Nice integration of severalrecent improvements in deep RL, alng with a few novel tricks to improve training.", "2, The empiricalresults on 57 Atari games are impressive, in terms of finalscores as well as realtime training speed.", "Cons: 1, Reactor is still less sample-efficient than Rainbow, with significantly lower scores after 200M frames.", "While the reactor trains much faster, it does use more paralel compute, so the comparison with Rainbow on wal clock time is not entirely fair.", "Would a distributed version of Rainbow perform better in this respect?", "2, Empiricalcomparisons are restricted to the Atari domain.", "The conclusions of the paper will be much stronger if results are alo shown on other environments like Mujoco/Vizdoom/Deepmind Lab.", "3, Since the paper introduces a few new ideas like prioritized seqence replay, it would help if a more detailed analsis was performed on the impact of these individualschemes, even if in a model simpler than the Reactor.", "For instance, one could investigate the impact of prioritized seqence replay in models like multi-step DQN or recurrent DQN.", "This will help us understand the impact of each of these ideas in a more comprehensive fashion."], "all_annotations": [{"interpretation": 1, "review_id": "rksMwz9xG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "rk_xMk8ef", "review_text": "Summary\n\nThis paper presents a dataset of mathematical equations and applies TreeLSTMs to two tasks: verifying and completing mathematical equations. For these tasks, TreeLSTMs outperform TreeNNs and RNNs. In my opinion, the main contribution of this paper is this potentially useful dataset, as well as an interesting way of representing fixed-precision floats. However, the application of TreeNNs and TreeLSTMs is rather straight-forward, so in my (subjective) view there are only a few insights salvageable for the ICLR community and compared to Allamanis et al. (2017) this paper is a rather incremental extension.\n\nStrengths\n\nThe authors present a new datasets for mathematical identities. The method for generating additional correct identities could be useful for future research in this area.\nI find the representation of fixed-precision floats presented in this paper intriguing. I believe this contribution should be emphasized more as it allows the model to generalize to unseen numbers and I am wondering whether the authors see some wider application of this representation for neural programming models.\nI liked the categorization of the related work.\n\nWeaknesses\n\np2: It is mentioned that the framework is the first to combine symbolic expressions with black-box function evaluations, but I would argue that Neural Programmer-Interpreters (NPI; Reed & De Freitas) are already doing that (see Fig 1 in that paper where the execution trace is a symbolic expression and some expressions \"Act(LEFT)\" are black-box function applications directly changing the image).\nThe differences to Allamanis et al. (2017) are not worked out well. For instance, the authors use the TreeNN model from that paper as a baseline but the EqNet model is not mentioned at all. The obvious question is whether EqNets can be applied to the two tasks (verifying and completing mathematical equations) and if so why this has not been done.\nThe contribution regarding black box function application is unclear to me. On page 6, it is unclear to me what \"handles [\u2026] function evaluation expressions\". As far as I understand, the TreeLSTM learns to the return value of function evaluation expressions in order to predict equality of equations, but this should be clarified.\nI find the connection of the proposed model and task to \"neural programming\" weak. For instance, as far as I understand there is no support for stateful programs. Furthermore, it would be interesting to hear how this work can be applied to existing programming languages such as Haskell. What are the limitations of the architecture? Could it learn to identify equality of two lists in Haskell?\np6: The paragraph on baseline models is rather uninformative. TreeLSTMs have been shown to outperform Tree NN's in various prior work. The statement that \"LSTM cell [\u2026] helps the model to have a better understanding of the underlying functions in the domain\" is vague. LSTM cells compared to fully-connected layers in Tree NNs ameliorate vanishing and exploding gradients along paths in the tree. Furthermore, I would like to see a qualitative analysis of the reasoning capabilities that are mentioned here. Did you observe any systematic differences in the ~4% of equations where the TreeLSTM fails to generalize (Table 3; first column).\n\nMinor Comments\n\nAbstract: \"Our framework generalizes significantly better\" I think it would be good to already mention in comparison to what this statement is.\np1: \"aim to solve tasks such as learn mathematical\" -> \"aim to solve tasks such as learning mathematical\"\np2: You could add a citation for Theano, Tensorflow and Mxnet.\np2: Could you elaborate how equation completion is used in Mathematical Q&A?\np3: Could you expand on \"mathematical equation verification and completion [\u2026] has broader applicability\" by maybe giving some concrete examples.\np3 Eq. 5: What precision do you consider? Two digits?\np3: \"division because that they can\" -> \"division because they can\"\np4 Fig. 1: Is there a reason 1 is represented as 10^0 here? Do you need the distinction between 1 (the integer) and 1.0 (the float)?\np5: \"we include set of changes\" -> \"we include the set of changes\"\np5: In my view there is enough space to move appendix A to section 2. In addition, it would be great to see more examples of generated identities at this stage (including negative ones).\np5: \"We generate all possible equations (with high probability)\" \u2013 what is probabilistic about this?\np5: I don't understand why function evaluation results in identities of depth 2 and 3. Is it both or one of them?\np6: The modules \"symbol\" and \"number\" are not shown in the figure. I assume they refer to projections using Wsymb and Wnum?\np6: \"tree structures neural networks\" -> \"tree structured neural networks\"\np6: A reference for the ADAM optimizer should be added.\np6: Which method was used for optimizing these hyperparameters? If a grid search was used, what intervals were used?\np7: \"the superiority of Tree LSTM to Tree NN shows that is important to incorporate cells that have memory\" is not a novel insight.\np8: When you mention \"you give this set of equations to the models look at the top k predictions\" I assume you ranked the substituted equations by the probability that the respective model assigns to it?\np8: Do you have an intuition why prediction function evaluations for \"cos\" seem to plateau certain points? Furthermore, it would be interesting to see what effect the choice of non-linearity on the output of the TreeLSTM has on how accurately it can learn to evaluate functions. For instance, one could replace the tanh with cos and might expect that the model has now an easy time to learn to evaluate cos(x).\np8 Fig 4b; p9: Relating to the question regarding plateaus in the function evaluation: \"in Figure 4b [\u2026] the top prediction (0.28) is the correct value for tan with precision 2, but even other predictions are quite close\" \u2013 they are all the same and this bad, right?\np9: \"of the state-of-the-art neural reasoning systems\" is very broad and in my opinion misleading too. First, there are other reasoning tasks (machine reading/Q&A, Visual Q&A, knowledge base inference etc.) too and it is not obvious how ideas from this paper translate to these domains. Second, for other tasks TreeLSTMs are likely not state-of-the-art (see for example models on the SQuAD leaderboard: https://rajpurkar.github.io/SQuAD-explorer/) .\np9: \"exploring recent neural models that explicitly use memory cells\" \u2013 I think what you mean is models with addressable differentiable memory.\n\n# Update after the rebuttal\nThank you for the in-depth response and clarifications. I am increasing my score by one point. I have looked at the revised paper and I strongly suggest that you add the clarifications and in particular comments regarding comparison to related work (NPI, EqNet etc) to the paper. Regarding Fig. 4b, I am still not sure why all scores are the same (0.9977) -- I assume this is not the desired behavior?", "gold_annotation": {"interpretation": 1, "review_id": "rk_xMk8ef", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Summary This paper presents a dataset of mathematicaleqations and applies TreeLSTMs to two tasks: verifying and completing mathematicaleqations.", "For these tasks, TreeLSTMs outperform TreeNNs and RNNs.", "In my opinion, the main contribution of this paper is this potentialy useful dataset, as well as an interesting way of representing fixed-precision floats.", "However, the application of TreeNNs and TreeLSTMs is rather straight-forward, so in my (subjective) view there are only a few insights salageable for the ICLR community and compared to Allamanis et al (2017) this paper is a rather incrementalextension.", "Strengths The authors present a new datasets for mathematicalidentities.", "The method for generating additionalcorrect identities could be useful for future research in this area.", "I find the representation of fixed-precision floats presented in this paper intriguing.", "I believe this contribution should be emphasized more as it alows the model to generalze to unseen numbers and I am wondering whether the authors see some wider application of this representation for neuralprogramming models.", "I liked the categorization of the related work.", "Weaknesses p2: It is mentioned that the framework is the first to combine symbolic expressions with black-box function evalations, but I would argue that NeuralProgrammer-Interpreters (NPI; Reed & De Freitas) are aleady doing that (see fig1 in that paper where the execution trace is a symbolic expression and some expressions \"Act(LEFT)\" are black-box function applications directly changing the image).", "The differences to Allamanis et al (2017) are not worked out well.", "For instance, the authors use the TreeNN model from that paper as a baseline but the eqt model is not mentioned at al.", "The obvious question is whether eqts can be applied to the two tasks (verifying and completing mathematicaleqations) and if so why this has not been done.", "The contribution regarding black box function application is unclear to me.", "On page 6, it is unclear to me what \"handles [\u2026] function evalation expressions\".", "As far as I understand, the TreeLSTM learns to the return vale of function evalation expressions in order to predict eqalty of eqations, but this should be clarified.", "I find the connection of the proposed model and task to \"neuralprogramming\" weak.", "For instance, as far as I understand there is no support for stateful programs.", "Furthermore, it would be interesting to hear how this work can be applied to existing programming languages such as Haskell.", "What are the limitations of the architecture?", "Could it learn to identify eqalty of two lists in Haskell?", "p6: The paragraph on baseline models is rather uninformative.", "TreeLSTMs have been shown to outperform Tree NN's in various prior work.", "The statement that \"LSTM cell [\u2026] helps the model to have a better understanding of the underlying functions in the domain\" is vague.", "LSTM cells compared to fully-connected layers in Tree NNs ameliorate vanishing and exploding gradients alng paths in the tree.", "Furthermore, I would like to see a qualtative analsis of the reasoning capabilities that are mentioned here.", "Did you observe any systematic differences in the ~4% of eqations where the TreeLSTM fails to generalze (Table 3; first column).", "Minor Comments Abstract: \"Our framework generalzes significantly better\" I think it would be good to aleady mention in comparison to what this statement is.", "p1: \"aim to solve tasks such as learn mathematical -> \"aim to solve tasks such as learning mathematical p2: You could add a citation for Theano, Tensorflow and Mxnet.", "p2: Could you elaborate how eqation completion is used in MathematicalQ&A?", "p3: Could you expand on \"mathematicaleqation verification and completion [\u2026] has broader applicability\" by maybe giving some concrete examples.", "p3 eq 5: What precision do you consider?", "Two digits?", "p3: \"division because that they can\" -> \"division because they can\" p4 fig 1: Is there a reason 1 is represented as 10^0 here?", "Do you need the distinction between 1 (the integer) and 1 0 (the float)?", "p5: \"we include set of changes\" -> \"we include the set of changes\" p5: In my view there is enough space to move appendix A to secion 2, In addition, it would be great to see more examples of generated identities at this stage (including negative ones).", "p5: \"We generate al possible eqations (with high probability)\" \u2013 what is probabilistic about this?", "p5: I don't understand why function evalation results in identities of depth 2 and 3, Is it both or one of them?", "p6: The modules \"symbol\" and \"number\" are not shown in the figre.", "I assume they refer to projections using Wsymb and Wnum?", "p6: \"tree structures neuralnetworks\" -> \"tree structured neuralnetworks\" p6: A reference for the ADAM optimizer should be added.", "p6: Which method was used for optimizing these hyperparameters?", "If a grid search was used, what interval were used?", "p7: \"the superiority of Tree LSTM to Tree NN shows that is important to incorporate cells that have memory\" is not a novel insight.", "p8: When you mention \"you give this set of eqations to the models look at the top k predictions\" I assume you ranked the substituted eqations by the probability that the respective model assigns to it?", "p8: Do you have an intuition why prediction function evalations for \"cos\" seem to plateau certain points?", "Furthermore, it would be interesting to see what effect the choice of non-linearity on the output of the TreeLSTM has on how accurately it can learn to evalate functions.", "For instance, one could replace the tanh with cos and might expect that the model has now an easy time to learn to evalate cos(x).", "p8 fig4b; p9: Relating to the question regarding plateaus in the function evalation: \"in figre 4b [\u2026] the top prediction (0 28) is the correct vale for tan with precision 2, but even other predictions are quite close\" \u2013 they are al the same and this bad, right?", "p9: \"of the state-of-the-art neuralreasoning systems\" is very broad and in my opinion misleading too.", "First, there are other reasoning tasks (machine reading/Q&A, VisualQ&A, knowledge base inference etc) too and it is not obvious how ideas from this paper translate to these domains.", "secnd, for other tasks TreeLSTMs are likely not state-of-the-art (see for example models on the SQuAD leaderboard: https://rajpurkar.github.io/SQuAD-explorer/) .", "p9: \"exploring recent neuralmodels that explicitly use memory cells\" \u2013 I think what you mean is models with addressable differentiable memory.", "# Update after the rebuttalThank you for the in-depth response and clarifications.", "I am increasing my score by one point.", "I have looked at the revised paper and I strongly suggest that you add the clarifications and in particular comments regarding comparison to related work (NPI, eqt etc to the paper.", "Regarding fig 4b, I am still not sure why al scores are the same (0 9977) -- I assume this is not the desired behavior?"], "all_annotations": [{"interpretation": 1, "review_id": "rk_xMk8ef", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rkSREOYgM", "review_text": "This paper proposes a device placement algorithm to place operations of tensorflow on devices. \n\nPros:\n\n1. It is a novel approach which trains the placement end to end.\n2. The experiments are solid to demonstrate this method works very well.\n3. The writing is easy to follow.\n4. This would be a very useful tool for the community if open sourced.\n\nCons:\n\n1. It is not very clear in the paper whether the training happens for each model yielding separate agents, or a shared agent is trained and used for all kinds of models. The latter would be more exciting. The adjacency matrix varies size for different graphs, so I guess a separate agent is trained for each graph? However, if the agent is not shared, why not just use integer to represent each operation in the graph, since overfitting would be more desirable in this case.\n2. Averaging the embedding is hard to understand especially for the output sizes and number of outputs.\n3. It is not clear how the adjacency information is used.\n", "gold_annotation": {"interpretation": 0, "review_id": "rkSREOYgM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.5, "tokenized_review_text": ["This paper proposes a device placement alorithm to place operations of tensorflow on devices.", "Pros: 1, It is a novel approach which trains the placement end to end.", "2, The experiments are solid to demonstrate this method works very well.", "3, The writing is easy to follow.", "4, This would be a very useful tool for the community if open sourced.", "Cons: 1, It is not very clear in the paper whether the training happens for each model yielding separate agents, or a shared agent is trained and used for al kinds of models.", "The latter would be more exciting.", "The adjacency matrix varies size for different graphs, so I guess a separate agent is trained for each graph?", "However, if the agent is not shared, why not just use integer to represent each operation in the graph, since overfitting would be more desirable in this case.", "2, Averaging the embedding is hard to understand especialy for the output sizes and number of outputs.", "3, It is not clear how the adjacency information is used."], "all_annotations": [{"interpretation": 0, "review_id": "rkSREOYgM", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "rkBmo9ryM", "review_text": "In their paper \"CausalGAN: Learning Causal implicit Generative Models with adv. training\" the authors address the following issue: Given a causal structure between \"labels\" of an image (e.g. gender, mustache, smiling, etc.), one tries to learn a causal model between these variables and the image itself from observational data. Here, the image is considered to be an effect of all the labels. Such a causal model allows us to not only sample from conditional observational distributions, but also from intervention distributions. These tasks are clearly different, as nicely shown by the authors' example of \"do(mustache = 1)\" versus \"given mustache = 1\" (a sample from the latter distribution contains only men). The paper does not aim at learning causal structure from data (as clearly stated by the authors). The example images look convincing to me.\n\nI like the idea of this paper. IMO, it is a very nice, clean, and useful approach of combining causality and the expressive power of neural networks. The paper has the potential of conveying the message of causality into the ICLR community and thereby trigger other ideas in that area. For me, it is not easy to judge the novelty of the approach, but the authors list related works, none of which seems to solve the same task. The presentation of the paper, however, should be improved significantly before publication. (In fact, because of the presentation of the paper, I was hesitating whether I should suggest acceptance.) Below, I give some examples (and suggest improvements), but there are many others. There is a risk that in its current state the paper will not generate much impact, and that would be a pity. I would therefore like to ask the authors to put a lot of effort into improving the presentation of the paper. \n\n\n- I believe that I understand the authors' intention of the caption of Fig. 1, but \"samples outside the dataset\" is a misleading formulation. Any reasonable model does more than just reproducing the data points. I find the argumentation the authors give in Figure 6 much sharper. Even better: add the expression \"P(male = 1 | mustache = 1) = 1\". Then, the difference is crystal clear.\n- The difference between Figures 1, 4, and 6 could be clarified.    \n- The list of \"prior work on learning causal graphs\" seems a bit random. I would add Spirtes et al 2000, Heckermann et al 1999, Peters et al 2016, and Chickering et al 2002. \n- Male -> Bald does not make much sense causally (it should be Gender -> Baldness)... Aha, now I understand: The authors seem to switch between \"Gender\" and \"Male\" being random variables. Make this consistent, please. \n- There are many typos and comma mistakes. \n- I would introduce the do-notation much earlier. The paragraph on p. 2 is now written without do-notation (\"intervening Mustache = 1 would not change the distribution\"). But this way, the statements are at least very confusing (which one is \"the distribution\"?).\n- I would get rid of the concept of CiGM. To me, it seems that this is a causal model with a neural network (NN) modeling the functions that appear in the SCM. This means, it's \"just\" using NNs as a model class. Instead, one could just say that one wants to learn a causal model and the proposed procedure is called CausalGAN? (This would also clarify the paper's contribution.)\n- many realizations = one sample (not samples), I think. \n- Fig 1: which model is used to generate the conditional sample?  \n- The notation changes between E and N and Z for the noises. I believe that N is supposed to be the noise in the SCM, but then maybe it should not be called E at the beginning. \n- I believe Prop 1 (as it is stated) is wrong. For a reference, see Peters, Janzing, Scholkopf: Elements of Causal Inference: Foundations and Learning Algorithms (available as pdf), Definition 6.32. One requires the strict positivity of the densities (to properly define conditionals). Also, I believe the Z should be a vector, not a set. \n- Below eq. (1), I am not sure what the V in P_V refers to.\n- The concept of data probability density function seems weird to me. Either it is referring to the fitted model, then it's a bad name, or it's an empirical distribution, then there is no pdf, but a pmf.\n- Many subscripts are used without explanation. r -> real? g -> generating? G -> generating? Sometimes, no subscripts are used (e.g., Fig 4 or figures in Sec. 8.13)\n- I would get rid of Theorem 1 and explain it in words for the following reasons. (1) What is an \"informal\" theorem? (2) It refers to equations appearing much later. (3) It is stated again later as Theorem 2. \n- Also: the name P_g does not appear anywhere else in the theorem, I think. \n- Furthermore, I would reformulate the theorem. The main point is that the intervention distributions are correct (this fact seems to be there, but is \"hidden\" in the CIGN notation in the corollary).\n- Re. the formulation in Thm 2: is it clear that there is a unique global optimum (my intuition would say there could be several), thus: better write \"_a_ global minimum\"?\n- Fig. 3 was not very clear to me. I suggest to put more information into its caption. \n- In particular, why is the dataset not used for the causal controller? I thought, that it should model the joint (empirical) distribution over the labels, and this is part of the dataset. Am I missing sth?\n- IMO, the structure of the paper can be improved. Currently, Section 3 is called \"Background\" which does not say much. Section 4 contains CIGMs, Section 5 Causal GANs, 5.1. Causal Controller, 5.2. CausalGAN, 5.2.1. Architecture (which the causal controller is part of) etc. An alternative could be: \nSec 1: Introduction \nSec 1.1: Related Work\nSec 2: Causal Models\nSec 2.1: Causal Models using Generative Models (old: CIGM)\nSec 3: Causal GANs\nSec 3.1: Architecture (including controller)\nSec 3.2: loss functions \n...\nSec 4: Empricial Results (old: Sec. 6: Results)\n- \"Causal Graph 1\" is not a proper reference (it's Fig 23 I guess). Also, it is quite important for the paper, I think it should be in the main part. \n- There are different references to the \"Appendix\", \"Suppl. Material\", or \"Sec. 8\" -- please be consistent (and try to avoid ambiguity by being more specific -- the appendix contains ~20 pages). Have I missed the reference to the proof of Thm 2?\n- 8.1. contains copy-paste from the main text.\n- \"proposition from Goodfellow\" -> please be more precise\n- What is Fig 8 used for? Is it not sufficient to have and discuss Fig 23? \n- IMO, Section 5.3. should be rewritten (also, maybe include another reference for BEGAN).\n- There is a reference to Lemma 15. However, I have not found that lemma.\n- I think it's quite interesting that the framework seems to also allow answering counterfactual questions for realizations that have been sampled from the model, see Fig 16. This is the case since for the generated realizations, the noise values are known. The authors may think about including a comment on that issue.\n- Since this paper's main proposal is a methodological one, I would make the publication conditional on the fact that code is released. \n\n\n", "gold_annotation": {"interpretation": 0, "review_id": "rkBmo9ryM", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 3.5, "tokenized_review_text": ["In their paper \"CausalAN: Learning Causalimplicit Generative Models with adv.", "training\" the authors address the following issue: Given a causalstructure between \"labels\" of an image (e g gender, mustache, smiling, etc), one tries to learn a causalmodel between these variables and the image itself from observationaldata.", "Here, the image is considered to be an effect of al the labels.", "Such a causalmodel alows us to not only sample from conditionalobservationaldistributions, but alo from intervention distributions.", "These tasks are clearly different, as nicely shown by the authors' example of \"do(mustache = 1)\" versus \"given mustache = 1\" (a sample from the latter distribution contains only men).", "The paper does not aim at learning causalstructure from data (as clearly stated by the authors).", "The example images look convincing to me.", "I like the idea of this paper.", "IMO, it is a very nice, clean, and useful approach of combining causalty and the expressive power of neuralnetworks.", "The paper has the potentialof conveying the message of causalty into the ICLR community and thereby trigger other ideas in that area.", "For me, it is not easy to judge the novelty of the approach, but the authors list related works, none of which seems to solve the same task.", "The presentation of the paper, however, should be improved significantly before publication.", "(In fact, because of the presentation of the paper, I was hesitating whether I should suggest acceptance.)", "Below, I give some examples (and suggest improvements), but there are many others.", "There is a risk that in its current state the paper will not generate much impact, and that would be a pity.", "I would therefore like to ask the authors to put a lot of effort into improving the presentation of the paper.", "- I believe that I understand the authors' intention of the caption of fig 1, but \"samples outside the dataset\" is a misleading formulation.", "Any reasonable model does more than just reproducing the data points.", "I find the argumentation the authors give in figre 6 much sharper.", "Even better: add the expression \"P(mal = 1 | mustache = 1) = 1\".", "Then, the difference is crystalclear.", "- The difference between figres 1, 4, and 6 could be clarified.", "- The list of \"prior work on learning causalgraphs\" seems a bit random.", "I would add Spirtes et al2000, Heckermann et al1999, Peters et al2016, and Chickering et al2002, - Mal -> Bal does not make much sense causaly (it should be Gender -> Balness)... Aha, now I understand: The authors seem to switch between \"Gender\" and \"Mal\" being random variables.", "Make this consistent, please.", "- There are many typos and comma mistakes.", "- I would introduce the do-notation much earlier.", "The paragraph on p 2 is now written without do-notation (\"intervening Mustache = 1 would not change the distribution\").", "But this way, the statements are at least very confusing (which one is \"the distribution\"?).", "- I would get rid of the concept of CiGM.", "To me, it seems that this is a causalmodel with a neuralnetwork (NN) modeling the functions that appear in the SCM.", "This means, it's \"just\" using NNs as a model class.", "Instead, one could just say that one wants to learn a causalmodel and the proposed procedure is caled CausalAN?", "(This would alo clarify the paper's contribution.)", "- many realzations = one sample (not samples), I think.", "- fig1: which model is used to generate the conditionalsample?", "- The notation changes between E and N and Z for the noises.", "I believe that N is supposed to be the noise in the SCM, but then maybe it should not be caled E at the beginning.", "- I believe Prop 1 (as it is stated) is wrong.", "For a reference, see Peters, Janzing, Scholkopf: Elements of CausalInference: Foundations and Learning Algorithms (available as pdf), Definition 6 32, One reqires the strict positivity of the densities (to properly define conditional).", "Also, I believe the Z should be a vector, not a set.", "- Below eq (1), I am not sure what the V in P_V refers to.", "- The concept of data probability density function seems weird to me.", "Either it is referring to the fitted model, then it's a bad name, or it's an empiricaldistribution, then there is no pdf, but a pmf.", "- Many subscripts are used without explanation.", "r -> real g -> generating?", "G -> generating?", "Sometimes, no subscripts are used (e g , fig4 or figres in sec 8 13) - I would get rid of Theorem 1 and explain it in words for the following reasons.", "(1) What is an \"informal theorem?", "(2) It refers to eqations appearing much later.", "(3) It is stated again later as Theorem 2, - Also: the name P_g does not appear anywhere else in the theorem, I think.", "- Furthermore, I would reformulate the theorem.", "The main point is that the intervention distributions are correct (this fact seems to be there, but is \"hidden\" in the CIGN notation in the corollary).", "- Re.", "the formulation in Thm 2: is it clear that there is a unique globaloptimum (my intuition would say there could be several, thus: better write \"_a_ globalminimum\"?", "- fig 3 was not very clear to me.", "I suggest to put more information into its caption.", "- In particular, why is the dataset not used for the causalcontroller?", "I thought, that it should model the joint (empirical distribution over the labels, and this is part of the dataset.", "Am I missing sth?", "- IMO, the structure of the paper can be improved.", "Currently, secion 3 is caled \"Background\" which does not say much.", "secion 4 contains CIGMs, secion 5 CausalGANs, 5 1, CausalController, 5 2, CausalAN, 5 2 1, Architecture (which the causalcontroller is part of) etc An alernative could be: sec1: Introduction sec1 1: Related Work sec2: CausalModels sec2 1: CausalModels using Generative Models (old: CIGM) sec3: CausalGANs sec3 1: Architecture (including controller) sec3 2: loss functions ... sec4: EmpricialResults (old: sec 6: Results) - \"CausalGraph 1\" is not a proper reference (it's fig23 I guess).", "Also, it is quite important for the paper, I think it should be in the main part.", "- There are different references to the \"Appendix\", \"Suppl.", "Material, or \"sec 8\" -- please be consistent (and try to avoid ambiguity by being more specific -- the appendix contains ~20 pages).", "Have I missed the reference to the proof of Thm 2?", "- 8 1, contains copy-paste from the main text.", "- \"proposition from Goodfellow\" -> please be more precise - What is fig8 used for?", "Is it not sufficient to have and discuss fig23?", "- IMO, secion 5 3, should be rewritten (alo, maybe include another reference for BEGAN).", "- There is a reference to Lemma 15, However, I have not found that lemma.", "- I think it's quite interesting that the framework seems to alo alow answering counterfactualquestions for realzations that have been sampled from the model, see fig16, This is the case since for the generated realzations, the noise vales are known.", "The authors may think about including a comment on that issue.", "- Since this paper's main proposalis a methodologicalone, I would make the publication conditionalon the fact that code is released."], "all_annotations": [{"interpretation": 0, "review_id": "rkBmo9ryM", "importance": 1, "reproducibility": 0, "constructiveness": 5, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rk-GXLRgz", "review_text": "This paper suggests a simple yet effective approach for learning with weak supervision. This learning scenario involves two datasets, one with clean data (i.e., labeled by the true function) and one with noisy data, collected using a weak source of supervision.  The suggested approach assumes a teacher and student networks, and builds the final representation incrementally, by taking into account the \"fidelity\" of the weak label when training the student at the final step. The fidelity score is given by the teacher, after being trained over the clean data, and it's used to build a cost-sensitive loss function for the students. The suggested method seems to work well on several document classification tasks. \n\nOverall, I liked the paper.  I would like the authors to consider the following questions - \n\n- Over the last 10 years or so, many different frameworks for learning with weak supervision were suggested (e.g., indirect supervision, distant supervision, response-based, constraint-based, to name a few).  First, I'd suggest acknowledging these works and discussing the differences to your work. Second - Is your approach applicable to these frameworks?  It would be an interesting to compare to one of those methods  (e.g., distant supervision for relation extraction using a knowledge base), and see if by incorporating fidelity score, results improve. \n\n- Can this approach be applied to semi-supervised learning? Is there a reason to assume the fidelity scores computed by the teacher would not improve the student in a self-training framework?\n\n- The paper emphasizes that the teacher uses the student's initial representation, when trained over the clean data.  Is it clear that this step in needed? Can you add an additional variant of your framework when the fidelity score are  computed by the teacher when trained from scratch? using different architecture than the student?\n \n - I went over the authors comments and I appreciate their efforts to help clarify the issues raised.", "gold_annotation": {"interpretation": 0, "review_id": "rk-GXLRgz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno2", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 2.5, "tokenized_review_text": ["This paper suggests a simple yet effective approach for learning with weak supervision.", "This learning scenario involves two datasets, one with clean data (i e , labeled by the true function) and one with noisy data, collected using a weak source of supervision.", "The suggested approach assumes a teacher and student networks, and builds the finalrepresentation incrementaly, by taking into account the \"fidelity\" of the weak label when training the student at the finalstep.", "The fidelity score is given by the teacher, after being trained over the clean data, and it's used to build a cost-sensitive loss function for the students.", "The suggested method seems to work well on severaldocument classification tasks.", "Overal, I liked the paper.", "I would like the authors to consider the following questions - - Over the last 10 years or so, many different frameworks for learning with weak supervision were suggested (e g , indirect supervision, distant supervision, response-based, constraint-based, to name a few).", "First, I'd suggest acknowledging these works and discussing the differences to your work.", "secnd - Is your approach applicable to these frameworks?", "It would be an interesting to compare to one of those methods (e g , distant supervision for relation extraction using a knowledge base), and see if by incorporating fidelity score, results improve.", "- Can this approach be applied to semi-supervised learning?", "Is there a reason to assume the fidelity scores computed by the teacher would not improve the student in a self-training framework?", "- The paper emphasizes that the teacher uses the student's initialrepresentation, when trained over the clean data.", "Is it clear that this step in needed?", "Can you add an additionalvariant of your framework when the fidelity score are computed by the teacher when trained from scratch?", "using different architecture than the student?", "- I went over the authors comments and I appreciate their efforts to help clarify the issues raised."], "all_annotations": [{"interpretation": 0, "review_id": "rk-GXLRgz", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 2, "annotator": "anno2", "evidence": 3, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "rJwXkeOgM", "review_text": "The paper considers the problem of training neural networks in mixed precision (MP), using both 16-bit floating point (FP16) and 32-bit floating point (FP32). The paper proposes three techniques for training networks in mixed precision: first, keep a master copy of network parameters in FP32; second, use loss scaling to ensure that gradients are representable using the limited range of FP16; third, compute dot products and reductions with FP32 accumulation. \n\nUsing these techniques allows the authors to match the results of traditional FP32 training on a wide variety of tasks without modifying any training hyperparameters. The authors show results on ImageNet classification (with AlexNet, VGG, GoogLeNet, Inception-v1, Inception-v3, and ResNet-50), VOC object detection (with Faster R-CNN and Multibox SSD), speech recognition in English and Mandarin (with CNN+GRU), English to French machine translation (with multilayer LSTMs), language modeling on the 1 Billion Words dataset (with a bigLSTM), and generative adversarial networks on CelebFaces (with DCGAN).\n\nPros:\n- Three simple techniques to use for mixed-precision training\n- Matches performance of traditional FP32 training without modifying any hyperparameters\n- Very extensive experiments on a wide variety of tasks\n\nCons:\n- Experiments do not validate the necessity of FP32 accumulation\n- No comparison of training time speedup from mixed precision\n\nWith new hardware (such as NVIDIA\u2019s Volta architecture) providing large computational speedups for MP computation, I expect that MP training will become standard practice in deep learning in the near future. Naively porting FP32 training recipes can fail due to the reduced numeric range of FP16 arithmetic; however by adopting the techniques of this paper, practitioners will be able to migrate their existing FP32 training pipelines to MP without modifying any hyperparameters. I expect these techniques to be hugely impactful as more people begin migrating to new MP hardware.\n\nThe experiments in this paper are very exhaustive, covering nearly every major application of deep learning. Matching state-of-the-art results on so many tasks increases my confidence that I will be able to apply these techniques to my own tasks and architectures to achieve stable MP training.\n\nMy first concern with the paper is that there are no experiments to demonstrate the necessity of FP32 accumulation. With an FP32 master copy of the weights and loss scaling, can all arithmetic be performed solely in FP16, or are there some tasks where training will still diverge?\n\nMy second concern is that there is no comparison of training-time speedup using MP. The main reason that MP is interesting is because new hardware promises to accelerate it. If people are willing to endure the extra engineering overhead of implementing the techniques from this paper, what kind of practical speedups can they expect to see from their workloads? NVIDIA\u2019s marketing material claims that the Tensor Cores in the V100 offer an 8x speedup over its general-purpose CUDA cores (https://www.nvidia.com/en-us/data-center/tesla-v100/). Since in this paper some operations are performed in FP32 (weight updates, batch normalization) and other operations are bound by memory and not compute bandwidth, what kinds of speedups do you see in practice when moving from FP32 to MP on V100?\n\nMy other concerns are minor. Mandarin speech recognition results are reported on \u201cour internal test set\u201d. Is there any previously published work on this dataset, or any publicly available test set for this task?\n\nThe notation around the Inception architectures should be clarified. According to [3] and [4], \u201cInception-v1\u201d and \u201cGoogLeNet\u201d both refer to the architecture used in [1]. The architecture used in [2] is referred to as \u201cBN-Inception\u201d by [3] and \u201cInception-v2\u201d by [4]. \u201cInception-v3\u201d is the architecture from [3], which is not currently cited. To improve clarity in Table 1, I suggest renaming \u201cGoogLeNet\u201d to \u201cInception-v1\u201d, changing \u201cInception-v1\u201d to \u201cInception-v2\u201d, and adding explicit citations to all rows of the table.\n\nIn Section 4.3 the authors note that \u201chalf-precision storage format may act as a regularizer during training\u201d. Though the effect is most obvious from the speech recognition experiments in Section 4.3, MP also achieves slightly higher performance than baseline for all ImageNet models but Inception-v1 and for both object detection models; these results add support to the idea of FP16 as a regularizer.\n\nMinor typos:\nSection 3.3, Paragraph 3: \u201ceither FP16 or FP16 math\u201d -> \u201ceither FP16 or FP32 math\u201d\nSection 4.1, Paragraph 4: \u201c pre-ativation\u201d -> \u201cpre-activation\u201d\n\nOverall this is a strong paper, and I believe that it will be impactful as MP hardware becomes more widely used.\n\n\nReferences\n\n[1] Szegedy et al, \u201cGoing Deeper with Convolutions\u201d, CVPR 2015\n[2] Ioffe and Szegedy, \u201cBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\u201d, ICML 2015\n[3] Szegedy et al, \u201cRethinking the Inception Architecture for Computer Vision\u201d, CVPR 2016\n[4] Szegedy et al, \u201cInception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\u201d, ICLR 2016 Workshop", "gold_annotation": {"interpretation": 1, "review_id": "rJwXkeOgM", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.5, "tokenized_review_text": ["The paper considers the problem of training neuralnetworks in mixed precision (MP), using both 16-bit floating point (FP16) and 32-bit floating point (FP32).", "The paper proposes three techniques for training networks in mixed precision: first, keep a master copy of network parameters in FP32; secnd, use loss scalng to ensure that gradients are representable using the limited range of FP16; third, compute dot products and reductions with FP32 accumulation.", "Using these techniques alows the authors to match the results of traditionalFP32 training on a wide variety of tasks without modifying any training hyperparameters.", "The authors show results on ImageNet classification (with AlexNet, VGG, GoogLeNet, Inception-v1, Inception-v3, and ResNet-50), VOC object detection (with Faster R-CNN and Multibox SSD), speech recognition in English and Mandarin (with CNN+GRU), English to French machine translation (with multilayer LSTMs), language modeling on the 1 Billion Words dataset (with a bigLSTM), and generative adversarialnetworks on CelebFaces (with DCGAN).", "Pros: - Three simple techniques to use for mixed-precision training - Matches performance of traditionalFP32 training without modifying any hyperparameters - Very extensive experiments on a wide variety of tasks Cons: - Experiments do not valdate the necessity of FP32 accumulation - No comparison of training time speedup from mixed precision With new hardware (such as NVIDIA\u2019s Volta architecture) providing large computationalspeedups for MP computation, I expect that MP training will become standard practice in deep learning in the near future.", "Naively porting FP32 training recipes can fail due to the reduced numeric range of FP16 arithmetic; however by adopting the techniques of this paper, practitioners will be able to migrate their existing FP32 training pipelines to MP without modifying any hyperparameters.", "I expect these techniques to be hugely impactful as more people begin migrating to new MP hardware.", "The experiments in this paper are very exhaustive, covering nearly every major application of deep learning.", "Matching state-of-the-art results on so many tasks increases my confidence that I will be able to apply these techniques to my own tasks and architectures to achieve stable MP training.", "My first concern with the paper is that there are no experiments to demonstrate the necessity of FP32 accumulation.", "With an FP32 master copy of the weights and loss scalng, can al arithmetic be performed solely in FP16, or are there some tasks where training will still diverge?", "My secnd concern is that there is no comparison of training-time speedup using MP.", "The main reason that MP is interesting is because new hardware promises to accelerate it.", "If people are willing to endure the extra engineering overhead of implementing the techniques from this paper, what kind of practicalspeedups can they expect to see from their workloads?", "NVIDIA\u2019s marketing materialclaims that the Tensor Cores in the V100 offer an 8x speedup over its generalpurpose CUDA cores (https://www.nvidia.com/en-us/data-center/tesla-v100/).", "Since in this paper some operations are performed in FP32 (weight updates, batch normalzation) and other operations are bound by memory and not compute bandwidth, what kinds of speedups do you see in practice when moving from FP32 to MP on V100?", "My other concerns are minor.", "Mandarin speech recognition results are reported on \u201cour internaltest set\u201d.", "Is there any previously published work on this dataset, or any publicly available test set for this task?", "The notation around the Inception architectures should be clarified.", "According to [3] and [4], \u201cInception-v1\u201d and \u201cGoogLeNet\u201d both refer to the architecture used in [1].", "The architecture used in [2] is referred to as \u201cBN-Inception\u201d by [3] and \u201cInception-v2\u201d by [4].", "\u201cInception-v3\u201d is the architecture from [3], which is not currently cited.", "To improve clarity in Table 1, I suggest renaming \u201cGoogLeNet\u201d to \u201cInception-v1\u201d, changing \u201cInception-v1\u201d to \u201cInception-v2\u201d, and adding explicit citations to al rows of the table.", "In secion 4 3 the authors note that \u201chal-precision storage format may act as a regularizer during training\u201d.", "Though the effect is most obvious from the speech recognition experiments in secion 4 3, MP alo achieves slightly higher performance than baseline for al ImageNet models but Inception-v1 and for both object detection models; these results add support to the idea of FP16 as a regularizer.", "Minor typos: secion 3 3, Paragraph 3: \u201ceither FP16 or FP16 math\u201d -> \u201ceither FP16 or FP32 math\u201d secion 4 1, Paragraph 4: \u201c pre-ativation\u201d -> \u201cpre-activation\u201d Overal this is a strong paper, and I believe that it will be impactful as MP hardware becomes more widely used.", "References [1] Szegedy et al \u201cGoing Deeper with Convolutions\u201d, CVPR 2015 [2] Ioffe and Szegedy, \u201cBatch Normalzation: Accelerating Deep Network Training by Reducing InternalCovariate Shift\u201d, ICML 2015 [3] Szegedy et al \u201cRethinking the Inception Architecture for Computer Vision\u201d, CVPR 2016 [4] Szegedy et al \u201cInception-v4, Inception-ResNet and the Impact of ResidualConnections on Learning\u201d, ICLR 2016 Workshop"], "all_annotations": [{"interpretation": 1, "review_id": "rJwXkeOgM", "importance": 1, "reproducibility": 1, "constructiveness": 5, "overall": 5, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rJW-33tlG", "review_text": "This paper present the application of the memory buffer concept to speech synthesis, and additionally learns a \"speaker vector\" that makes the system adaptive and work reasonably well on \"in-the-wild\" speech data. This is a relevant problem, and a novel solution, but synthesis is a wicked problem to evaluate, so I am not sure if ICLR is the best venue for this paper. I see two competing goals:\n\n- If the focus is on showing that the presented approach outperforms other approaches under given conditions, a different task would be better (for example recognition, or some sort of trajectory reconstruction)\n- If the focus is on showing that the system outperforms other synthesis systems, then a speech oriented venue might be best (and it is unfortunate that optimized hyper-parameters for the other systems are not available for a fair comparsion)\n- If fair comparisons with the other appraoches cannot be made, my sense is that the multi-speaker (post-training fitting) option is really the most interesting and novel contribution here, which could be discussed in mroe detail\n\nStill, the approach is creative and interesting and deserves to be presented. I have a few questions/ suggestions:\n\nIntroduction\n\n- The link to Baddeley's \"phonological loop\" concept seems weak at best. There is nothing phonological about the features that this model stores and retrieves, and no evidence that the model behaves in a way consistent with \"phonologcial\" (or articulatory) assumptions or models - maybe best to avoid distracting the reader with this concept and strengthen the speaker adaptation aspect?\n- The memory model is not an RNN, but it is a recurrently called structure (as the name \"phonological loop\" also implies) - so I would also not highlight this point much\n- Why would the four properties of the proposed method (mid of p. 2, end of introduction: memory buffer, shared memory, shallow fully connected networks, and simple reader mechanism) lead to better robustness and improve performance on noisy and limited training data? Maybe the proposed approach works better for any speech synthesis task? Why specifically for \"in-the-wild\" data? The results in Table 2 show that the proposed system outperforms other systems on Blizzard 2013, but not Blizzard 2011 - does this support the previous argument?\n- Why not also evaluate MCD scores? This should be a quick and automatic way to diagnose what the system is doing? Or is this not meaningful with the noisy training data?\n\nPrevious work\n\n- Please introduce abbreviations the first time they are used (\"CBHG\" for example)\n- There is other work on using \"in-the-wild\" speech as well: Pallavi Baljekar and Alan W Black. Utterance Selection Techniques for TTS Systems using Found Speech, SSW 2016, Sunnyvale, USA Sept 2016\n\nThe architecture\n- Please explain the \"GMM\" (Gaussian Mixture Model?) attention mechanism in a bit more detail, how does back-propagation work in this case?\n- Why was this approach chosen? Does it promise to be robust or good for low data situations specifically?\n- The fonts in Figure 2 are very small, please make them bigger, and the Figure may not print well in b/w. Why does the mean of the absolute weights go up for high buffer positions? Is there some \"leaking\" from even longer contexts?\n- I don't understand \"However, human speech is not deterministic and one cannot expect [...] truth\". You are saying that the model cannot be excepted to reproduce the input exactly? Or does this apply only to the temporal distribution of the sequence (but not the spectral characteristics)? The previous sentence implies that it does. And how does teacher-forcing help in this case?\n- what type of speed is \"x5\"? Five times slower or faster than real-time?\n\nExperiments\n- Table 2: maybe mention how these results were computed, i.e. which systems use optimized hyper parameters, and which don't? How do these results support the interpretation of hte results in the introruction re in-the-wild data and found data?\n- I am not sure how to read Figure 4. Maybe it would be easier to plot the different phone sequences against each other and show how the timings are off, i.e. plot the time of the center of panel one vs the time of the center of panel 2 for the corresponding phone, and show how this is different from a straight line. Or maybe plot phones as rectangles that get deformed from square shape as durations get learned?\n- Figure 5: maybe provide spectrograms and add pitch contours to better show the effect of the dfifferent intonations? \n- Figure 4 uses a lot of space, could be reduced, if needed\n\nDiscussion\n- I think the first claim is a bit to broad - nowhere is it shown that the method is inherently more robust to clapping and laughs, and variable prosody. The authors will know the relevant data-sets better than I do, maybe they can simply extend the discussion to show that this is what happens. \n- Efficiency: I think Wavenet has also gotten much faster and runs in less than real-time now - can you expand that discussion a bit, or maybe give estimates in times of FLOPS required, rather than anecdotal evidence for systems that may or may not be comparable?\n\nConclusion\n- Now the advantage of the proposed model is with the number of parameters, rather than the computation required. Can you clarify? Are your models smaller than competing models?\n", "gold_annotation": {"interpretation": 1, "review_id": "rJW-33tlG", "importance": 1, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper present the application of the memory buffer concept to speech synthesis, and additionaly learns a \"speaker vector\" that makes the system adaptive and work reasonably well on \"in-the-wild\" speech data.", "This is a relevant problem, and a novel solution, but synthesis is a wicked problem to evalate, so I am not sure if ICLR is the best venue for this paper.", "I see two competing goal: - If the focus is on showing that the presented approach outperforms other approaches under given conditions, a different task would be better (for example recognition, or some sort of trajectory reconstruction) - If the focus is on showing that the system outperforms other synthesis systems, then a speech oriented venue might be best (and it is unfortunate that optimized hyper-parameters for the other systems are not available for a fair comparsion) - If fair comparisons with the other appraoches cannot be made, my sense is that the multi-speaker (post-training fitting) option is realy the most interesting and novel contribution here, which could be discussed in mroe detail Still, the approach is creative and interesting and deserves to be presented.", "I have a few questions/ suggestions: Introduction - The link to Baddeley's \"phonologicalloop\" concept seems weak at best.", "There is nothing phonologicalabout the features that this model stores and retrieves, and no evidence that the model behaves in a way consistent with \"phonologcial (or articulatory) assumptions or models - maybe best to avoid distracting the reader with this concept and strengthen the speaker adaptation aspect?", "- The memory model is not an RNN, but it is a recurrently caled structure (as the name \"phonologicalloop\" alo implies) - so I would alo not highlight this point much - Why would the four properties of the proposed method (mid of p 2, end of introduction: memory buffer, shared memory, shalow fully connected networks, and simple reader mechanism) lead to better robustness and improve performance on noisy and limited training data?", "Maybe the proposed approach works better for any speech synthesis task?", "Why specificaly for \"in-the-wild\" data?", "The results in Table 2 show that the proposed system outperforms other systems on Blizzard 2013, but not Blizzard 2011 - does this support the previous argument?", "- Why not alo evalate MCD scores?", "This should be a quick and automatic way to diagnose what the system is doing?", "Or is this not meaningful with the noisy training data?", "Previous work - Please introduce abbreviations the first time they are used (\"CBHG\" for example) - There is other work on using \"in-the-wild\" speech as well: Palavi Balekar and Alan W Black.", "Utterance Selection Techniques for TTS Systems using Found Speech, SSW 2016, Sunnyval, USA Sept 2016 The architecture - Please explain the \"GMM\" (Gaussian Mixture Model?)", "attention mechanism in a bit more detail, how does back-propagation work in this case?", "- Why was this approach chosen?", "Does it promise to be robust or good for low data situations specificaly?", "- The fonts in figre 2 are very smal, please make them bigger, and the figre may not print well in b/w Why does the mean of the absolute weights go up for high buffer positions?", "Is there some \"leaking\" from even longer contexts?", "- I don't understand \"However, human speech is not deterministic and one cannot expect [...] truth\".", "You are saying that the model cannot be excepted to reproduce the input exactly?", "Or does this apply only to the temporaldistribution of the seqence (but not the spectralcharacteristics)?", "The previous sentence implies that it does.", "And how does teacher-forcing help in this case?", "- what type of speed is \"x5\"?", "Five times slower or faster than realtime?", "Experiments - Table 2: maybe mention how these results were computed, i e which systems use optimized hyper parameters, and which don't?", "How do these results support the interpretation of hte results in the introruction re in-the-wild data and found data?", "- I am not sure how to read figre 4, Maybe it would be easier to plot the different phone seqences against each other and show how the timings are off, i e plot the time of the center of panel one vs the time of the center of panel 2 for the corresponding phone, and show how this is different from a straight line.", "Or maybe plot phones as rectangles that get deformed from square shape as durations get learned?", "- figre 5: maybe provide spectrograms and add pitch contours to better show the effect of the dfifferent intonations?", "- figre 4 uses a lot of space, could be reduced, if needed Discussion - I think the first claim is a bit to broad - nowhere is it shown that the method is inherently more robust to clapping and laughs, and variable prosody.", "The authors will know the relevant data-sets better than I do, maybe they can simply extend the discussion to show that this is what happens.", "- Efficiency: I think Wavenet has alo gotten much faster and runs in less than realtime now - can you expand that discussion a bit, or maybe give estimates in times of FLOPS reqired, rather than anecdotalevidence for systems that may or may not be comparable?", "Conclusion - Now the advantage of the proposed model is with the number of parameters, rather than the computation reqired.", "Can you clarify?", "Are your models smaler than competing models?"], "all_annotations": [{"interpretation": 1, "review_id": "rJW-33tlG", "importance": 1, "reproducibility": 1, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rJOVWxjez", "review_text": "The authors describe a new defense mechanism against adversarial attacks on classifiers (e.g., FGSM). They propose utilizing Generative Adversarial Networks (GAN), which are usually used for training generative models for an unknown distribution, but have a natural adversarial interpretation. In particular, a GAN consists of a generator NN G which maps a random vector z to an example x, and a discriminator NN D which seeks to discriminate between an examples produced by G and examples drawn from the true distribution. The GAN is trained to minimize the max min loss of D on this discrimination task, thereby producing a G (in the limit) whose outputs are indistinguishable from the true distribution by the best discriminator. \n\nUtilizing a trained GAN, the authors propose the following defense at inference time. Given a sample x (which has been adversarially perturbed), first project x onto the range of G by solving the minimization problem z* = argmin_z ||G(z) - x||_2. This is done by SGD. Then apply any classifier trained on the true distribution on the resulting x* = G(z*). \n\nIn the case of existing black-box attacks, the authors argue (convincingly) that the method is both flexible and empirically effective. In particular, the defense can be applied in conjunction with any classifier (including already hardened classifiers), and does not assume any specific attack model. Nevertheless, it appears to be effective against FGSM attacks, and competitive with adversarial training specifically to defend against FGSM. \n\nThe authors provide less-convincing evidence that the defense is effective against white-box attacks. In particular, the method is shown to be robust against FGSM, RAND+FGSM, and CW white-box attacks. However, it is not clear to me that the method is invulnerable to novel white-box attacks. In particular, it seems that the attacker can design an x which projects onto some desired x* (using some other method entirely), which then fools the classifier downstream.\n\nNevertheless, the method is shown to be an effective tool for hardening any classifier against existing black-box attacks \n(which is arguably of great practical value). It is novel and should generate further research with respect to understanding its vulnerabilities more completely. \n\nMinor Comments:\nThe sentence starting \u201cUnless otherwise specified\u2026\u201d at the top of page 7 is confusing given the actual contents of Tables 1 and 2, which are clarified only by looking at Table 5 in the appendix. This should be fixed.  \n", "gold_annotation": {"interpretation": 1, "review_id": "rJOVWxjez", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["The authors describe a new defense mechanism against adversarialattacks on classifiers (e g , FGSM).", "They propose utilizing Generative AdversarialNetworks (GAN), which are usualy used for training generative models for an unknown distribution, but have a naturaladversarialinterpretation.", "In particular, a GAN consists of a generator NN G which maps a random vector z to an example x, and a discriminator NN D which seeks to discriminate between an examples produced by G and examples drawn from the true distribution.", "The GAN is trained to minimize the max min loss of D on this discrimination task, thereby producing a G (in the limit) whose outputs are indistinguishable from the true distribution by the best discriminator.", "Utilizing a trained GAN, the authors propose the following defense at inference time.", "Given a sample x (which has been adversarialy perturbed), first project x onto the range of G by solving the minimization problem z* = argmin_z ||G(z) - x||_2, This is done by SGD.", "Then apply any classifier trained on the true distribution on the resulting x* = G(z*).", "In the case of existing black-box attacks, the authors argue (convincingly) that the method is both flexible and empiricaly effective.", "In particular, the defense can be applied in conjunction with any classifier (including aleady hardened classifiers), and does not assume any specific attack model.", "Nevertheless, it appears to be effective against FGSM attacks, and competitive with adversarialtraining specificaly to defend against FGSM.", "The authors provide less-convincing evidence that the defense is effective against white-box attacks.", "In particular, the method is shown to be robust against FGSM, RAND+FGSM, and CW white-box attacks.", "However, it is not clear to me that the method is invulnerable to novel white-box attacks.", "In particular, it seems that the attacker can design an x which projects onto some desired x* (using some other method entirely), which then fools the classifier downstream.", "Nevertheless, the method is shown to be an effective tool for hardening any classifier against existing black-box attacks (which is arguably of great practicalvale).", "It is novel and should generate further research with respect to understanding its vulnerabilities more completely.", "Minor Comments: The sentence starting \u201cUnless otherwise specified\u2026\u201d at the top of page 7 is confusing given the actualcontents of Tables 1 and 2, which are clarified only by looking at Table 5 in the appendix.", "This should be fixed."], "all_annotations": [{"interpretation": 1, "review_id": "rJOVWxjez", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rJGK3urgz", "review_text": "\n-----UPDATE------\n\nHaving read the responses from the authors, and the other reviews, I am happy with my rating and maintain that this paper should be accepted.\n\n----------------------\n\n\n\nIn this paper, the authors trains a large number of MNIST classifier networks with differing attributes (batch-size, activation function, no. layers etc.) and then utilises the inputs and outputs of these networks to predict said attributes successfully. They then show that they are able to use the methods developed to predict the family of Imagenet-trained networks and use this information to improve adversarial attack.\n\nI enjoyed reading this paper. It is a very interesting set up, and a novel idea.\n\nA few comments:\n\nThe paper is easy to read, and largely written well. The article is missing from the nouns quite often though so this is something that should be amended. There are a few spelling slip ups (\"to a certain extend\" --> \"to a certain extent\", \"as will see\" --> \"as we will see\")\n\nIt appears that the output for kennen-o is a discrete probability vector for each attribute, where each entry corresponds to a possibility (for example, for \"batch-size\" it is a length 3 vector where the first entry corresponds to 64, the second 128, and the third 256). What happens if you instead treat it as a regression task, would it then be able to hint at intermediates (a batch size of 96) or extremes (say, 512).\n\nA flaw of this paper is that kennen-i and io appear to require gradients from the network being probed (you do mention this in passing), which realistically you would never have access to. (Please do correct me if I have misunderstood this)\n\nIt would be helpful if Section 4 had a paragraph as to your thoughts regarding why certain attributes are easier/harder to predict. Also, the caption for Table 2 could contain more information regarding the network outputs.\n\nYou have jumped from predicting 12 attributes on MNIST to 1 attribute on Imagenet. It could be beneficial to do an intermediate experiment (a handful of attributes on a middling task).\n\nI think this paper should be accepted as it is interesting and novel.\n\nPros\n------\n- Interesting idea\n- Reads well\n- Fairly good experimental results\n\nCons\n------\n- kennen-i seems like it couldn't be realistically deployed\n- lack of an intermediate difficulty task\n", "gold_annotation": {"interpretation": 1, "review_id": "rJGK3urgz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": [" -----UPDATE------ Having read the responses from the authors, and the other reviews, I am happy with my rating and maintain that this paper should be accepted.", "---------------------- In this paper, the authors trains a large number of MNIST classifier networks with differing attributes (batch-size, activation function, no.", "layers etc) and then utilises the inputs and outputs of these networks to predict said attributes successfully.", "They then show that they are able to use the methods developed to predict the family of Imagenet-trained networks and use this information to improve adversarialattack.", "I enjoyed reading this paper.", "It is a very interesting set up, and a novel idea.", "A few comments: The paper is easy to read, and largely written well.", "The article is missing from the nouns quite often though so this is something that should be amended.", "There are a few spelling slip ups (\"to a certain extend\" --> \"to a certain extent\", \"as will see\" --> \"as we will see\") It appears that the output for kennen-o is a discrete probability vector for each attribute, where each entry corresponds to a possibility (for example, for \"batch-size\" it is a length 3 vector where the first entry corresponds to 64, the secnd 128, and the third 256).", "What happens if you instead treat it as a regression task, would it then be able to hint at intermediates (a batch size of 96) or extremes (say, 512).", "A flaw of this paper is that kennen-i and io appear to reqire gradients from the network being probed (you do mention this in passing), which realsticaly you would never have access to.", "(Please do correct me if I have misunderstood this) It would be helpful if secion 4 had a paragraph as to your thoughts regarding why certain attributes are easier/harder to predict.", "Also, the caption for Table 2 could contain more information regarding the network outputs.", "You have jumped from predicting 12 attributes on MNIST to 1 attribute on Imagenet.", "It could be beneficialto do an intermediate experiment (a handful of attributes on a middling task).", "I think this paper should be accepted as it is interesting and novel.", "Pros ------ - Interesting idea - Reads well - Fairly good experimentalresults Cons ------ - kennen-i seems like it couldn't be realsticaly deployed - lack of an intermediate difficulty task"], "all_annotations": [{"interpretation": 1, "review_id": "rJGK3urgz", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rJBLYC--f", "review_text": "The paper proposes a novel approach on estimating the parameters  \nof Mean field games (MFG). The key of the method is a reduction of the unknown parameter MFG to an  unknown parameter Markov Decision Process (MDP).\n\nThis is an important class of models and I recommend the acceptance of the paper.\n\nI think that the general discussion about the collective behavior application should be more carefully presented and some better examples of applications should be easy to provide.  In addition the authors may want to enrich their literature review and give references to alternative work on unknown MDP estimation methods cf. [1], [2] below. \n\n[1] Burnetas, A. N., & Katehakis, M. N. (1997). Optimal adaptive policies for Markov decision processes. Mathematics of Operations Research, 22(1), 222-255.\n\n[2] Budhiraja, A., Liu, X., & Shwartz, A. (2012). Action time sharing policies for ergodic control of Markov chains. SIAM Journal on Control and Optimization, 50(1), 171-195.", "gold_annotation": {"interpretation": 1, "review_id": "rJBLYC--f", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}, "score": 3.0, "tokenized_review_text": ["The paper proposes a novel approach on estimating the parameters of Mean field games (MFG).", "The key of the method is a reduction of the unknown parameter MFG to an unknown parameter Markov Decision Process (MDP).", "This is an important class of models and I recommend the acceptance of the paper.", "I think that the generaldiscussion about the collective behavior application should be more carefully presented and some better examples of applications should be easy to provide.", "In addition the authors may want to enrich their literature review and give references to alernative work on unknown MDP estimation methods cf.", "[1], [2] below.", "[1] Burnetas, A N , & Katehakis, M N (1997).", "Optimaladaptive policies for Markov decision processes.", "Mathematics of Operations Research, 22(1), 222-255, [2] Budhiraja, A , Liu, X , & Shwartz, A (2012).", "Action time sharing policies for ergodic control of Markov chains.", "SIAM Journalon Control and Optimization, 50(1), 171-195."], "all_annotations": [{"interpretation": 1, "review_id": "rJBLYC--f", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 2, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "rJ6Z7prxf", "review_text": "This paper introdues NoisyNets, that are neural networks whose parameters are perturbed by a parametric noise function, and they apply them to 3 state-of-the-art deep reinforcement learning algorithms: DQN, Dueling networks and A3C. They obtain a substantial performance improvement over the baseline algorithms, without explaining clearly why.\n\nThe general concept is nice, the paper is well written and the experiments are convincing, so to me this paper should be accepted, despite a weak analysis.\n\nBelow are my comments for the authors.\n\n---------------------------------\nGeneral, conceptual comments:\n\nThe second paragraph of the intro is rather nice, but it might be updated with recent work about exploration in RL.\nNote that more than 30 papers are submitted to ICLR 2018 mentionning this topic, and many things have happened since this paper was\nposted on arxiv (see the \"official comments\" too).\n\np2: \"our NoisyNet approach requires only one extra parameter per weight\" Parameters in a NN are mostly weights and biases, so from this sentence\none may understand that you close-to-double the number of parameters, which is not so few! If this is not what you mean, you should reformulate...\n\np2: \"Though these methods often rely on a non-trainable noise of vanishing size as opposed to NoisyNet which tunes the parameter of noise by gradient descent.\"\nTwo ideas seem to be collapsed here: the idea of diminishing noise over an experiment, exploring first and exploiting later, and the idea of\nadapting the amount of noise to a specific problem. It should be made clearer whether NoisyNet can address both issues and whether other\nalgorithms do so too...\n\nIn particular, an algorithm may adapt noise along an experiment or from an experiment to the next.\nFrom Fig.3, one can see that having the same initial noise in all environments is not a good idea, so the second mechanism may help much.\n\nBTW, the short section in Appendix B about initialization of noisy networks should be moved into the main text.\n\np4: the presentation of NoisyNets is not so easy to follow and could be clarified in several respects:\n- a picture could be given to better explain the structure of parameters, particularly in the case of factorised (factorized, factored?) Gaussian noise.\n- I would start with the paragraph \"Considering a linear layer [...] below)\" and only after this I would introduce \\theta and \\xi as a more synthetic notation.\nLater in the paper, you then have to state \"...are now noted \\xi\" several times, which I found rather clumsy.\n\np5: Why do you use option (b) for DQN and Dueling and option (a) for A3C? The reason why (if any) should be made clear from the clearer presentation required above.\n\nBy the way, a wild question: if you wanted to use NoisyNets in an actor-critic architecture like DDPG, would you put noise both in the actor and the critic?\n\nThe paragraph above Fig3 raises important questions which do not get a satisfactory answer.\nWhy is it that, in deterministic environments, the network does not converge to a deterministic policy, which should be able to perform better?\nWhy is it that the adequate level of noise changes depending on the environment? By the way, are we sure that the curves of Fig3 correspond to some progress\nin noise tuning (that is, is the level of noise really \"better\" through time with these curves, or they they show something poorly correlated with the true reasons of success?)?\n\nFinally, I would be glad to see the effect of your technique on algorithms like TRPO and PPO which require a stochastic policy for exploration, and where I believe that the role of the KL divergence bound is mostly to prevent the level of stochasticity from collasping too quickly.\n\n-----------------------------------\nLocal comments:\n\nThe first sentence may make the reader think you only know about 4-5 old works about exploration.\n\nPp. 1-2 : \"the approach differs ... from variational inference. [...] It also differs variational inference...\"\nIf you mean it differs from variational inference in two ways, the paragraph should be reorganized.\n\np2: \"At a high level our algorithm induces a randomised network for exploration, with care exploration\nvia randomised value functions can be provably-efficient with suitable linear basis (Osband et al., 2014)\"\n=> I don't understand this sentence at all.\n\nAt the top of p3, you may update your list with PPO and ACKTR, which are now \"classical\" baselines too.\n\nAppendices A1 and A2 are a lot redundant with the main text (some sentences and equations are just copy-pasted), this should be improved.\nThe best would be to need to reject nothing to the Appendix.\n\n---------------------------------------\nTypos, language issues:\n\np2\nthe idea ... the optimization process have been => has\n\np2\nThough these methods often rely on a non-trainable noise of vanishing size as opposed to NoisyNet which tunes the parameter of noise by gradient descent.\n=> you should make a sentence...\n\np3\nthe the double-DQN\n\nseveral times, an equation is cut over two lines, a line finishing with \"=\", which is inelegant\n\nYou should deal better with appendices: Every \"Sec. Ax/By/Cz\" should be replaced by \"Appendix Ax/By/Cz\".\nBesides, the big table and the list of performances figures should themselves be put in two additional appendices\nand you should refer to them as Appendix D or E rather than \"the Appendix\".\n\n\n\n\n", "gold_annotation": {"interpretation": 1, "review_id": "rJ6Z7prxf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["This paper introdues NoisyNets, that are neuralnetworks whose parameters are perturbed by a parametric noise function, and they apply them to 3 state-of-the-art deep reinforcement learning alorithms: DQN, Dueling networks and A3C.", "They obtain a substantialperformance improvement over the baseline alorithms, without explaining clearly why.", "The generalconcept is nice, the paper is well written and the experiments are convincing, so to me this paper should be accepted, despite a weak analsis.", "Below are my comments for the authors.", "--------------------------------- General conceptualcomments: The secnd paragraph of the intro is rather nice, but it might be updated with recent work about exploration in RL.", "Note that more than 30 papers are submitted to ICLR 2018 mentionning this topic, and many things have happened since this paper was posted on arxiv (see the \"officialcomments\" too).", "p2: \"our NoisyNet approach reqires only one extra parameter per weight\" Parameters in a NN are mostly weights and biases, so from this sentence one may understand that you close-to-double the number of parameters, which is not so few!", "If this is not what you mean, you should reformulate... p2: \"Though these methods often rely on a non-trainable noise of vanishing size as opposed to NoisyNet which tunes the parameter of noise by gradient descent.\"", "Two ideas seem to be collapsed here: the idea of diminishing noise over an experiment, exploring first and exploiting later, and the idea of adapting the amount of noise to a specific problem.", "It should be made clearer whether NoisyNet can address both issues and whether other alorithms do so too...", "In particular, an alorithm may adapt noise alng an experiment or from an experiment to the next.", "From fig3, one can see that having the same initialnoise in al environments is not a good idea, so the secnd mechanism may help much.", "BTW, the short secion in Appendix B about initialzation of noisy networks should be moved into the main text.", "p4: the presentation of NoisyNets is not so easy to follow and could be clarified in severalrespects: - a picture could be given to better explain the structure of parameters, particularly in the case of factorised (factorized, factored?)", "Gaussian noise.", "- I would start with the paragraph \"Considering a linear layer [...] below)\" and only after this I would introduce \\theta and \\xi as a more synthetic notation.", "Later in the paper, you then have to state \"...are now noted \\xi\" severaltimes, which I found rather clumsy.", "p5: Why do you use option (b) for DQN and Dueling and option (a) for A3C?", "The reason why (if any) should be made clear from the clearer presentation reqired above.", "By the way, a wild question: if you wanted to use NoisyNets in an actor-critic architecture like DDPG, would you put noise both in the actor and the critic?", "The paragraph above fig raises important questions which do not get a satisfactory answer.", "Why is it that, in deterministic environments, the network does not converge to a deterministic policy, which should be able to perform better?", "Why is it that the adeqate level of noise changes depending on the environment?", "By the way, are we sure that the curves of fig correspond to some progress in noise tuning (that is, is the level of noise realy \"better\" through time with these curves, or they they show something poorly correlated with the true reasons of success?)?", "Finaly, I would be glad to see the effect of your technique on alorithms like TRPO and PPO which reqire a stochastic policy for exploration, and where I believe that the role of the KL divergence bound is mostly to prevent the level of stochasticity from collasping too quickly.", "----------------------------------- Localcomments: The first sentence may make the reader think you only know about 4-5 old works about exploration.", "Pp.", "1-2 : \"the approach differs ... from variationalinference.", "[...] It alo differs variationalinference...\" If you mean it differs from variationalinference in two ways, the paragraph should be reorganized.", "p2: \"At a high level our alorithm induces a randomised network for exploration, with care exploration via randomised vale functions can be provably-efficient with suitable linear basis (Osband et al, 2014)\" => I don't understand this sentence at al.", "At the top of p3, you may update your list with PPO and ACKTR, which are now \"classical baselines too.", "Appendices A1 and A2 are a lot redundant with the main text (some sentences and eqations are just copy-pasted), this should be improved.", "The best would be to need to reject nothing to the Appendix.", "--------------------------------------- Typos, language issues: p2 the idea ... the optimization process have been => has p2 Though these methods often rely on a non-trainable noise of vanishing size as opposed to NoisyNet which tunes the parameter of noise by gradient descent.", "=> you should make a sentence... p3 the the double-DQN severaltimes, an eqation is cut over two lines, a line finishing with \"=\", which is inelegant You should dealbetter with appendices: Every \"sec Ax/By/Cz\" should be replaced by \"Appendix Ax/By/Cz\".", "Besides, the big table and the list of performances figres should themselves be put in two additionalappendices and you should refer to them as Appendix D or E rather than \"the Appendix\"."], "all_annotations": [{"interpretation": 1, "review_id": "rJ6Z7prxf", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rJ96Jgclf", "review_text": "I quite liked the revival of the dual memory system ideas and the cognitive (neuro) science inspiration. The paper is overall well written and tackles serious modern datasets, which was impressive, even though it relies on a pre-trained, fixed ResNet (see point below).\n\nMy only complaint is that I felt I couldn\u2019t understand why the model worked so well. A better motivation for some of the modelling decisions would be helpful. For instance, how much the existence (and training) of a BLA network really help \u2014 which is a central new part of the paper, and wasn\u2019t in my view well motivated. It would be nice to compare with a simpler baseline, such as a HC classifier network with reject option. I also don\u2019t really understand why the proposed pseudorehearsal works so well. Some formal reasoning, even if approximate, would be appreciated.\n\nSome additional comments below:\n\n- Although the paper is in general well written, it falls on the lengthy side and I found it difficult at first to understand the flow of the algorithm. I think it would be helpful to have a high-level pseudocode presentation of the main steps.\n\n- It was somewhat buried in the details that the model actually starts with a fixed, advanced feature pre-processing stage (the ResNet, trained on a distinct dataset, as it should). I\u2019m fine with that, but this should be discussed. Note that there is evidence that the neuronal responses in areas as early as V1 change as monkeys learn to solve discrimination tasks. It should be stressed that the model does not yet model end-to-end learning in the incremental setting.\n\n- p. 4, Eq. 4, is it really necessary to add a loss for the intermediate layers, and not only for the input layer? I think it would be clearer to define the \\mathcal{L} explictily somewhere. Also, shouldn\u2019t the sum start at j=0?", "gold_annotation": {"interpretation": 1, "review_id": "rJ96Jgclf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["I quite liked the revivalof the dualmemory system ideas and the cognitive (neuro) science inspiration.", "The paper is overal well written and tackles serious modern datasets, which was impressive, even though it relies on a pre-trained, fixed ResNet (see point below).", "My only complaint is that I felt I couldn\u2019t understand why the model worked so well.", "A better motivation for some of the modelling decisions would be helpful.", "For instance, how much the existence (and training) of a BLA network realy help \u2014 which is a centralnew part of the paper, and wasn\u2019t in my view well motivated.", "It would be nice to compare with a simpler baseline, such as a HC classifier network with reject option.", "I alo don\u2019t realy understand why the proposed pseudorehearsalworks so well.", "Some formalreasoning, even if approximate, would be appreciated.", "Some additionalcomments below: - Although the paper is in generalwell written, it fals on the lengthy side and I found it difficult at first to understand the flow of the alorithm.", "I think it would be helpful to have a high-level pseudocode presentation of the main steps.", "- It was somewhat buried in the details that the model actualy starts with a fixed, advanced feature pre-processing stage (the ResNet, trained on a distinct dataset, as it should).", "I\u2019m fine with that, but this should be discussed.", "Note that there is evidence that the neuronalresponses in areas as early as V1 change as monkeys learn to solve discrimination tasks.", "It should be stressed that the model does not yet model end-to-end learning in the incrementalsetting.", "- p 4, eq 4, is it realy necessary to add a loss for the intermediate layers, and not only for the input layer?", "I think it would be clearer to define the \\mathcalL} explictily somewhere.", "Also, shouldn\u2019t the sum start at j=0?"], "all_annotations": [{"interpretation": 1, "review_id": "rJ96Jgclf", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "rJ74wm5xM", "review_text": "The paper describes a neural network-based approach to active localization based upon RGB images. The framework employs Bayesian filtering to maintain an estimate of the agent's pose using a convolutional network model for the measurement (perception) function. A convolutional network models the policy that governs the action of the agent. The architecture is trained in an end-to-end manner via reinforcement learning. The architecture is evaluated in 2D and 3D simulated environments of varying complexity and compared favorably to traditional (structured) approaches to passive and active localization.\n\nAs the paper correctly points out, there is large body of work on map-based localization, but relatively little attention has been paid to decision theoretic formulations to localization, whereby the agent's actions are chosen in order to improve localization accuracy. More recent work instead focuses on the higher level objective of navigation, whereby any effort act in an effort to improve localization are secondary to the navigation objective. The idea of incorporating learned representations with a structured Bayesian filtering approach is interesting, but it's utility could be better motivated. What are the practical benefits to learning the measurement and policy model beyond (i) the temptation to apply neural networks to this problem and (ii) the ability to learn these in an end-to-end fashion? That's not to say that there aren't benefits, but rather that they aren't clearly demonstrated here. Further, the paper seems to assume (as noted below) that there is no measurement uncertainty and, with the exception of the 3D evaluations, no process noise.\n\nThe evaluation demonstrates that the proposed method yields estimates that are more accurate according to the proposed metric than the baseline methods, with a significant reduction in computational cost. However, the environments considered are rather small by today's standards and the baseline methods almost 20 years old. Further, the evaluation makes a number of simplifying assumptions, the largest being that the measurements are not subject to noise (the only noise that is present is in the motion for the 3D experiments). This assumption is clearly not valid in practice. Further, it is not clear from the evaluation whether the resulting distribution that is maintained is consistent (e.g., are the estimates over-/under-confident?). This has important implications if the system were to actually be used on a physical system. Further, while the computational requirements at test time are significantly lower than the baselines, the time required for training is likely very large. While this is less of an issue in simulation, it is important for physical deployments. Ideally, the paper would demonstrate performance when transferring a policy trained in simulation to a physical environment (e.g., using diversification, which has proven effective at simulation-to-real transfer).\n\nComments/Questions:\n\n* The nature of the observation space is not clear.\n\n* Recent related work has focused on learning neural policies for navigation, and any localization-specific actions are secondary to the objective of reaching the goal. It would be interesting to discuss how one would balance the advantages of choosing actions that improve localization with those in the context of a higher-level task (or at least including a cost on actions as with the baseline method of Fox et al.).\n\n* The evaluation that assigns different textures to each wall is unrealistic.\n\n* It is not clear why the space over which the belief is maintained flips as the robot turns and shifts as it moves.\n\n* The 3D evaluation states that a 360 deg view is available. What happens when the agent can only see in one (forward) direction?\n\n* AML includes a cost term in the objective. Did the author(s) experiment with setting this cost to zero?\n\n* The 3D environments rely upon a particular belief size (70 x 70) being suitable for all environments. What would happen if the test environment was larger than those encountered in training?\n\n* The comment that the PoseNet and VidLoc methods \"lack a strainghtforward method to utilize past map data to do localization in a new environment\" is unclear.\n\n* The environments that are considered are quite small compared to the domains currently considered for\n\n* Minor: It might be better to move Section 3 into Section 4 after introducing notation (to avoid redundancy).\n* The paper should be proofread for grammatical errors (e.g., \"bayesian\" --> \"Bayesian\", \"gaussian\" --> \"Gaussian\")\n\n\nUPDATES FOLLOWING AUTHORS' RESPONSE\n\n(Apologies if this is a duplicate. I added a comment in light of the authors' response, but don't see it and so I am updating my review for completeness).\n\nI appreciate the authors's response to the initial reviews and thank them for addressing several of my comments.\n\nRE: Consistency\nMy concerns regarding consistency remain. For principled ways of evaluating the consistency of an estimator, see Bar-Shalom \"Estimation with Applications to Tracking and Navigation\".\n\nRE: Measurement/Process Noise\nThe fact that the method assumes perfect measurements and, with the exception of the 3D experiments, no process noise is concerning as neither assumptions are valid for physical systems. Indeed, it is this noise in particular that makes localization (and its variants) challenging.\n\nRE: Motivation\nThe response didn't address my comments about the lack motivation for the proposed method. Is it largely the temptation of applying an end-to-end neural method to a new problem? The paper should be updated to make the advantages over traditional approaches to active localization.", "gold_annotation": {"interpretation": 1, "review_id": "rJ74wm5xM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper describes a neuralnetwork-based approach to active localzation based upon RGB images.", "The framework employs Bayesian filtering to maintain an estimate of the agent's pose using a convolutionalnetwork model for the measurement (perception) function.", "A convolutionalnetwork models the policy that governs the action of the agent.", "The architecture is trained in an end-to-end manner via reinforcement learning.", "The architecture is evalated in 2D and 3D simulated environments of varying complexity and compared favorably to traditional(structured) approaches to passive and active localzation.", "As the paper correctly points out, there is large body of work on map-based localzation, but relatively little attention has been paid to decision theoretic formulations to localzation, whereby the agent's actions are chosen in order to improve localzation accuracy.", "More recent work instead focuses on the higher level objective of navigation, whereby any effort act in an effort to improve localzation are secndary to the navigation objective.", "The idea of incorporating learned representations with a structured Bayesian filtering approach is interesting, but it's utility could be better motivated.", "What are the practicalbenefits to learning the measurement and policy model beyond (i) the temptation to apply neuralnetworks to this problem and (ii) the ability to learn these in an end-to-end fashion?", "That's not to say that there aren't benefits, but rather that they aren't clearly demonstrated here.", "Further, the paper seems to assume (as noted below) that there is no measurement uncertainty and, with the exception of the 3D evalations, no process noise.", "The evalation demonstrates that the proposed method yields estimates that are more accurate according to the proposed metric than the baseline methods, with a significant reduction in computationalcost.", "However, the environments considered are rather smal by today's standards and the baseline methods alost 20 years old.", "Further, the evalation makes a number of simplifying assumptions, the largest being that the measurements are not subject to noise (the only noise that is present is in the motion for the 3D experiments).", "This assumption is clearly not vald in practice.", "Further, it is not clear from the evalation whether the resulting distribution that is maintained is consistent (e g , are the estimates over-/under-confident?).", "This has important implications if the system were to actualy be used on a physicalsystem.", "Further, while the computationalreqirements at test time are significantly lower than the baselines, the time reqired for training is likely very large.", "While this is less of an issue in simulation, it is important for physicaldeployments.", "Idealy, the paper would demonstrate performance when transferring a policy trained in simulation to a physicalenvironment (e g , using diversification, which has proven effective at simulation-to-realtransfer).", "Comments/Questions: * The nature of the observation space is not clear.", "* Recent related work has focused on learning neuralpolicies for navigation, and any localzation-specific actions are secndary to the objective of reaching the goal It would be interesting to discuss how one would balnce the advantages of choosing actions that improve localzation with those in the context of a higher-level task (or at least including a cost on actions as with the baseline method of Fox et al).", "* The evalation that assigns different textures to each wal is unrealstic.", "* It is not clear why the space over which the belief is maintained flips as the robot turns and shifts as it moves.", "* The 3D evalation states that a 360 deg view is available.", "What happens when the agent can only see in one (forward) direction?", "* AML includes a cost term in the objective.", "Did the author(s) experiment with setting this cost to zero?", "* The 3D environments rely upon a particular belief size (70 x 70) being suitable for al environments.", "What would happen if the test environment was larger than those encountered in training?", "* The comment that the PoseNet and VidLoc methods \"lack a strainghtforward method to utilize past map data to do localzation in a new environment\" is unclear.", "* The environments that are considered are quite smal compared to the domains currently considered for * Minor: It might be better to move secion 3 into secion 4 after introducing notation (to avoid redundancy).", "* The paper should be proofread for grammaticalerrors (e g , \"bayesian\" --> \"Bayesian\", \"gaussian\" --> \"Gaussian\") UPDATES FOLLOWING AUTHORS' RESPONSE (Apologies if this is a duplicate.", "I added a comment in light of the authors' response, but don't see it and so I am updating my review for completeness).", "I appreciate the authors's response to the initialreviews and thank them for addressing severalof my comments.", "RE: Consistency My concerns regarding consistency remain.", "For principled ways of evalating the consistency of an estimator, see Bar-Shalm \"Estimation with Applications to Tracking and Navigation\".", "RE: Measurement/Process Noise The fact that the method assumes perfect measurements and, with the exception of the 3D experiments, no process noise is concerning as neither assumptions are vald for physicalsystems.", "Indeed, it is this noise in particular that makes localzation (and its variants) chalenging.", "RE: Motivation The response didn't address my comments about the lack motivation for the proposed method.", "Is it largely the temptation of applying an end-to-end neuralmethod to a new problem?", "The paper should be updated to make the advantages over traditionalapproaches to active localzation."], "all_annotations": [{"interpretation": 1, "review_id": "rJ74wm5xM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "r1k_ETYlM", "review_text": "This article aims at understanding the role played by the different words in a sentence, taking into account their order in the sentence. In sentiment analysis for instance, this capacity is critical to model properly negation.\nAs state-of-the-art approaches rely on LSTM, the authors want to understand which information comes from which gate. After a short remainder regarding LSTM, the authors propose a framework to disambiguate interactions between gates. In order to obtain an analytic formulation of the decomposition, the authors propose to linearize activation functions in the network.\nIn the experiment section, authors compare themselves to a standard logistic regression (based on a bag of words representation). They also check the unigram sentiment scores (without context).\nThe main issue consists in modeling the dynamics inside a sentence (when a negation or a 'used to be' reverses the sentiment). The proposed approach works fine on selected samples.\n\n\nThe related work section is entirely focused on deep learning while the experiment section is dedicated to sentiment analysis. This section should be rebalanced. Even if the authors claim that their approach is general, they also show that it fits well the sentiment analysis task in particular.\n\nOn top of that, a lot of fine-grained sentiment analysis tools has been developed outside deep-learning: the authors should refer to those works.\n\nFinally, authors should provide some quantitative analysis on sentiment classification: a lot of standard benchmarks are widely use in the literature and we need to see how the proposed method performs with respect to the state-of-the-art.\n\n\nGiven the chosen tasks, this work should be compared to the beermind system:\nhttp://deepx.ucsd.edu/#/home/beermind\nand the associated publication\nhttp://arxiv.org/pdf/1511.03683.pdf", "gold_annotation": {"interpretation": 0, "review_id": "r1k_ETYlM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["This article aims at understanding the role played by the different words in a sentence, taking into account their order in the sentence.", "In sentiment analsis for instance, this capacity is criticalto model properly negation.", "As state-of-the-art approaches rely on LSTM, the authors want to understand which information comes from which gate.", "After a short remainder regarding LSTM, the authors propose a framework to disambiguate interactions between gates.", "In order to obtain an analtic formulation of the decomposition, the authors propose to linearize activation functions in the network.", "In the experiment secion, authors compare themselves to a standard logistic regression (based on a bag of words representation).", "They alo check the unigram sentiment scores (without context).", "The main issue consists in modeling the dynamics inside a sentence (when a negation or a 'used to be' reverses the sentiment).", "The proposed approach works fine on selected samples.", "The related work secion is entirely focused on deep learning while the experiment secion is dedicated to sentiment analsis.", "This secion should be rebalnced.", "Even if the authors claim that their approach is general they alo show that it fits well the sentiment analsis task in particular.", "On top of that, a lot of fine-grained sentiment analsis tools has been developed outside deep-learning: the authors should refer to those works.", "Finaly, authors should provide some quantitative analsis on sentiment classification: a lot of standard benchmarks are widely use in the literature and we need to see how the proposed method performs with respect to the state-of-the-art.", "Given the chosen tasks, this work should be compared to the beermind system: http://deepx.ucsd.edu/#/home/beermind and the associated publication http://arxiv.org/pdf/1511.03683.pdf"], "all_annotations": [{"interpretation": 0, "review_id": "r1k_ETYlM", "importance": 1, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 0, "metareview": "nota", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "r1cczyqef", "review_text": "The authors propose a new network architecture for RL that contains some relevant inductive biases about planning. This fits into the recent line of work on implicit planning where forms of models are learned to be useful for a prediction/planning task. The proposed architecture performs something analogous to a full-width tree search using an abstract model (learned end-to-end). This is done by expanding all possible transitions to a fixed depth before performing a max backup on all expanded nodes. The final backup value is the Q-value prediction for a given state, or can represent a policy through a softmax.\n\nI thought the paper was clear and well-motivated. The architecture (and various associated tricks like state vector normalization) are well-described for reproducibility. \n\nExperimental results seem promising but I wasn\u2019t fully convinced of its conclusions. In both domains, TreeQN and AtreeC are compared to a DQN architecture, but it wasn\u2019t clear to me that this is the right baseline. Indeed TreeQN and AtreeC share the same conv stack in the encoder (I think?), but also have the extra capacity of the tree on top. Can the performance gain we see in the Push task as a function of tree depth be explained by the added network capacity? Same comment in Atari, but there it\u2019s not really obvious that the proposed architecture is helping. Baselines could include unsharing the weights in the tree, removing the max backup, having a regular MLP with similar capacity, etc.\n\nPage 5, the auxiliary loss on reward prediction seems appropriate, but it\u2019s not clear from the text and experiments whether it actually was necessary. Is it that makes interpretability of the model easier (like we see in Fig 5c)? Or does it actually lead to better performance?  \n\nDespite some shortcomings in the result section, I believe this is good work and worth communicating as is.", "gold_annotation": {"interpretation": 0, "review_id": "r1cczyqef", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The authors propose a new network architecture for RL that contains some relevant inductive biases about planning.", "This fits into the recent line of work on implicit planning where forms of models are learned to be useful for a prediction/planning task.", "The proposed architecture performs something analgous to a full-width tree search using an abstract model (learned end-to-end).", "This is done by expanding al possible transitions to a fixed depth before performing a max backup on al expanded nodes.", "The finalbackup vale is the Q-vale prediction for a given state, or can represent a policy through a softmax.", "I thought the paper was clear and well-motivated.", "The architecture (and various associated tricks like state vector normalzation) are well-described for reproducibility.", "Experimentalresults seem promising but I wasn\u2019t fully convinced of its conclusions.", "In both domains, Treeqand AtreeC are compared to a DQN architecture, but it wasn\u2019t clear to me that this is the right baseline.", "Indeed Treeqand AtreeC share the same conv stack in the encoder (I think?", "), but alo have the extra capacity of the tree on top.", "Can the performance gain we see in the Push task as a function of tree depth be explained by the added network capacity?", "Same comment in Atari, but there it\u2019s not realy obvious that the proposed architecture is helping.", "Baselines could include unsharing the weights in the tree, removing the max backup, having a regular MLP with similar capacity, etc Page 5, the auxiliary loss on reward prediction seems appropriate, but it\u2019s not clear from the text and experiments whether it actualy was necessary.", "Is it that makes interpretability of the model easier (like we see in fig5c)?", "Or does it actualy lead to better performance?", "Despite some shortcomings in the result secion, I believe this is good work and worth communicating as is."], "all_annotations": [{"interpretation": 0, "review_id": "r1cczyqef", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "r1ajkbceM", "review_text": "The authors present a new RL algorithm for sparse reward tasks. The work is fairly novel in its approach, combining a learned reward estimator with a contextual bandit algorithm for exploration/exploitation. The paper was mostly clear in its exposition, however some additional information of the motivation for why the said reduction is better than simpler alternatives would help.  \n\nPros\n1. The results on bandit structured prediction problems are pretty good\n2. The idea of a learnt credit assignment function, and using that to separate credit assignment from the exploration/exploitation tradeoff is good. \n\nCons: \n1. The method seems fairly more complicated than PPO / A2C, yet those methods seem to perform equally well on the RL problems (Figure 2.). It also seems to be designed only for discrete action spaces.\n2. Reslope Boltzmann performs much worse than Reslope Bootstrap, thus having a bag of policies helps. However, in the comparison in Figures 2 and 3, the policy gradient methods dont have the advantage of using a bag of policies. A fairer comparison would be to compare with methods that use ensembles of Q-functions. (like this https://arxiv.org/abs/1706.01502 by Chen et al.). The Q learning methods in general would also have better sample efficiency than the policy gradient methods.\n3. The method claims to learn an internal representation of a denser reward function for the sparse reward problem, however the experimental analysis of this is pretty limited (Section 5.3). It would be useful to do a more thorough investigation of whether it learnt a good credit assignment function in the games. One way to do this would be to check the qualitative aspects of the function in a well understood game, like Blackjack.\n\nSuggestions:\n1. What is the advantage of the method over a simple RL method that predicts a reward at every step (such that the dense rewards add up to match the sparse reward for the episode), and uses this predicted dense reward to perform RL? This, and also a bigger discussion on prior bandit learning methods like LOLS will help under the context for why we\u2019re performing the reduction stated in the paper.  \n\nSignificance: While the method is novel and interesting, the experimental analysis and the explanations in the paper leave it unclear as to whether its significant compared to prior work.\n\nRevision: I thank the authors for addressing some of my concerns. The comparison with relative gain of bootstrap wrt ensemble of policies still needs more thorough experimentation, but the approach is novel and as the authors point out, does improve continually with better Contextual Bandit algorithms. I update my review to 6. ", "gold_annotation": {"interpretation": 0, "review_id": "r1ajkbceM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The authors present a new RL alorithm for sparse reward tasks.", "The work is fairly novel in its approach, combining a learned reward estimator with a contextualbandit alorithm for exploration/exploitation.", "The paper was mostly clear in its exposition, however some additionalinformation of the motivation for why the said reduction is better than simpler alernatives would help.", "Pros 1, The results on bandit structured prediction problems are pretty good 2, The idea of a learnt credit assignment function, and using that to separate credit assignment from the exploration/exploitation tradeoff is good.", "Cons: 1, The method seems fairly more complicated than PPO / A2C, yet those methods seem to perform eqaly well on the RL problems (figre 2 ).", "It alo seems to be designed only for discrete action spaces.", "2, Reslope Boltzmann performs much worse than Reslope Bootstrap, thus having a bag of policies helps.", "However, in the comparison in figres 2 and 3, the policy gradient methods dont have the advantage of using a bag of policies.", "A fairer comparison would be to compare with methods that use ensembles of Q-functions.", "(like this https://arxiv.org/abs/1706.01502 by Chen et al).", "The Q learning methods in generalwould alo have better sample efficiency than the policy gradient methods.", "3, The method claims to learn an internalrepresentation of a denser reward function for the sparse reward problem, however the experimentalanalsis of this is pretty limited (secion 5 3).", "It would be useful to do a more thorough investigation of whether it learnt a good credit assignment function in the games.", "One way to do this would be to check the qualtative aspects of the function in a well understood game, like Blackjack.", "Suggestions: 1, What is the advantage of the method over a simple RL method that predicts a reward at every step (such that the dense rewards add up to match the sparse reward for the episode), and uses this predicted dense reward to perform RL?", "This, and alo a bigger discussion on prior bandit learning methods like LOLS will help under the context for why we\u2019re performing the reduction stated in the paper.", "Significance: While the method is novel and interesting, the experimentalanalsis and the explanations in the paper leave it unclear as to whether its significant compared to prior work.", "Revision: I thank the authors for addressing some of my concerns.", "The comparison with relative gain of bootstrap wrt ensemble of policies still needs more thorough experimentation, but the approach is novel and as the authors point out, does improve continualy with better ContextualBandit alorithms.", "I update my review to 6,"], "all_annotations": [{"interpretation": 0, "review_id": "r1ajkbceM", "importance": 0, "reproducibility": 0, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "r1Ps9aPez", "review_text": "This paper discusses a text-to-speech system which is based on a convolutional attentive seq2seq architecture.  It covers experiments on a few datasets, testing the model's ability to handle increasing numbers of speakers.\n\nBy and large, this is a \"system\" paper - it mostly describes the successful application of many different existing ideas to an important problem (with some exceptions, e.g. the novel method of enforcing monotonic alignments during inference).  In this type of paper, I typically am most interested in hearing about *why* a particular design choice was made, what alternatives were tried, and how different ideas worked.  This paper is lacking in this regard - I frequently was left looking for more insight into the particular system that was designed.  Beyond that, I think more detailed description of the system would be necessary in order to reimplement it suitably (another important potential takeaway for a \"system\" paper).  Separately, I the thousands-of-speakers results are just not that impressive - a MOS of 2 is not really useable in the real-world.  For that reason, I think it's a bit disingenuous to sell this system as \"2000-Speaker Neural Text-to-Speech\".\n\nFor the above reasons, I'm giving the paper a \"marginally above\" rating.  If the authors provide improved insight, discussion of system specifics, and experiments, I'd be open to raising my review.  Below, I give some specific questions and suggestions that could be addressed in future drafts.\n\n- It might be worth giving a sentence or two defining the TTS problem - the paper is written assuming background knowledge about the problem setting, including different possible input sources, what a vocoder is, etc.  The ICLR community at large may not have this domain-specific knowledge.\n- Why \"softsign\" and not tanh?  Seems like an unusual choice.\n- What do the \"c\" and \"2c\" in Figure 2a denote?\n- Why scale (h_k + h_e) by \\sqrt{0.5} when computing the attention value vectors?\n- \"An L1 loss is computed using the output spectrograms\" I assume you mean the predicted and target spectrograms are compared via an L1 loss.  Why L1?\n- In Vaswani et al., it was shown that a learned positional encoding worked about as well as the sinusoidal position encodings despite being potentially more flexible/less \"hand-designed\" for machine translation.  Did you also try this for TTS?  Any insight?\n- Some questions about monotonic attention: Did you use the training-time \"soft\" monotonic attention algorithm from Raffel et al. during training and inference, or did you use the \"hard\" monotonic attention at inference time?  IIUC the \"soft\" algorithm doesn't actually force strict monotonicity.  You wrote \"monotonic attention results in the model frequently mumbling words\", can you provide evidence/examples of this?  Why do you think this happens?  The monotonic attention approach seems more principled than post-hoc limiting softmax attention to be monotonic, why do you think it didn't work as well?\n- I can't find an actual reference to what you mean by a \"wavenet vocoder\".  The original wavenet paper describes an autoregressive model for waveform generation.  In order to use it as a vocoder, you'd have to do conditioning in some way.  How?  What was the structure of the wavenet you used?   Why?  These details appear to be missing.  All you write is the sentence (which seems to end without a period) \"In the WaveNet vocoder, we use mel-scale spectrograms from the decoder to condition a Wavenet, which was trained separated\".\n- Can you provide examples of the mispronunciations etc. which were measured for Table 1?  Was the evaluation of each attention mechanism done blindly?\n- The 2.07 MOS figure produced for tacotron seems extremely low, and seems to indicate that something went wrong or that insufficient care was taken to report this baseline.  How did you adapt tacotron (which as I understand is a single-speaker model) to the multi-speaker setting?\n- Table 3 begs the question of whether Deep Voice 3 can outperform Deep Voice 2 when using a wavenet vocoder on VCTK (or improve upon the poor 2.09 MOS score reported).  Why wasn't this experiment run?\n- The paragraph and appendix about deploying at scale is interesting and impressive, but seems a bit out of place - it probably makes more sense to include this information in a separate \"systems\" paper.", "gold_annotation": {"interpretation": 0, "review_id": "r1Ps9aPez", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["This paper discusses a text-to-speech system which is based on a convolutionalattentive seqseqarchitecture.", "It covers experiments on a few datasets, testing the model's ability to handle increasing numbers of speakers.", "By and large, this is a \"system\" paper - it mostly describes the successful application of many different existing ideas to an important problem (with some exceptions, e g the novel method of enforcing monotonic algnments during inference).", "In this type of paper, I typicaly am most interested in hearing about *why* a particular design choice was made, what alernatives were tried, and how different ideas worked.", "This paper is lacking in this regard - I freqently was left looking for more insight into the particular system that was designed.", "Beyond that, I think more detailed description of the system would be necessary in order to reimplement it suitably (another important potentialtakeaway for a \"system\" paper).", "Separately, I the thousands-of-speakers results are just not that impressive - a MOS of 2 is not realy useable in the realworld.", "For that reason, I think it's a bit disingenuous to sell this system as \"2000-Speaker NeuralText-to-Speech\".", "For the above reasons, I'm giving the paper a \"marginaly above\" rating.", "If the authors provide improved insight, discussion of system specifics, and experiments, I'd be open to raising my review.", "Below, I give some specific questions and suggestions that could be addressed in future drafts.", "- It might be worth giving a sentence or two defining the TTS problem - the paper is written assuming background knowledge about the problem setting, including different possible input sources, what a vocoder is, etc The ICLR community at large may not have this domain-specific knowledge.", "- Why \"softsign\" and not tanh?", "Seems like an unusualchoice.", "- What do the \"c\" and \"2c\" in figre 2a denote?", "- Why scal (h_k + h_e) by \\sqrt{0 5} when computing the attention vale vectors?", "- \"An L1 loss is computed using the output spectrograms\" I assume you mean the predicted and target spectrograms are compared via an L1 loss.", "Why L1?", "- In Vaswani et al, it was shown that a learned positionalencoding worked about as well as the sinusoidalposition encodings despite being potentialy more flexible/less \"hand-designed\" for machine translation.", "Did you alo try this for TTS?", "Any insight?", "- Some questions about monotonic attention: Did you use the training-time \"soft\" monotonic attention alorithm from Raffel et al during training and inference, or did you use the \"hard\" monotonic attention at inference time?", "IIUC the \"soft\" alorithm doesn't actualy force strict monotonicity.", "You wrote \"monotonic attention results in the model freqently mumbling words\", can you provide evidence/examples of this?", "Why do you think this happens?", "The monotonic attention approach seems more principled than post-hoc limiting softmax attention to be monotonic, why do you think it didn't work as well?", "- I can't find an actualreference to what you mean by a \"wavenet vocoder\".", "The originalwavenet paper describes an autoregressive model for waveform generation.", "In order to use it as a vocoder, you'd have to do conditioning in some way.", "How?", "What was the structure of the wavenet you used?", "Why?", "These details appear to be missing.", "All you write is the sentence (which seems to end without a period) \"In the WaveNet vocoder, we use mel-scal spectrograms from the decoder to condition a Wavenet, which was trained separated\".", "- Can you provide examples of the mispronunciations etc which were measured for Table 1?", "Was the evalation of each attention mechanism done blindly?", "- The 2 07 MOS figre produced for tacotron seems extremely low, and seems to indicate that something went wrong or that insufficient care was taken to report this baseline.", "How did you adapt tacotron (which as I understand is a single-speaker model) to the multi-speaker setting?", "- Table 3 begs the question of whether Deep Voice 3 can outperform Deep Voice 2 when using a wavenet vocoder on VCTK (or improve upon the poor 2 09 MOS score reported).", "Why wasn't this experiment run?", "- The paragraph and appendix about deploying at scal is interesting and impressive, but seems a bit out of place - it probably makes more sense to include this information in a separate \"systems\" paper."], "all_annotations": [{"interpretation": 0, "review_id": "r1Ps9aPez", "importance": 1, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 0, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "r1IWuK2lf", "review_text": "The paper presents a method for navigating in an unknown and partially observed environment is presented. The proposed approach splits planning into two levels: 1) local planning based on the observed space and 2) a global planner which receives the local plan, observation features, and access to an addressable memory to decide on which action to select and what to write into memory. \n\nThe contribution of this work is the use of value iteration networks (VINs) for local planning on a locally observed map that is fed into a learned global controller that references history and a differential neural computer (DNC), local policy, and observation features select an action and update the memory. The core concept of learned local planner providing additional cues for a global, memory-based planner is a clever idea and the thorough analysis clearly demonstrates the benefit of the approach.\n\nThe proposed method is tested against three problems: a gridworld, a graph search, and a robot environment. In each case the proposed method is more performant than the baseline methods.  The ablation study of using LSTM instead of the DNC and the direct comparison of CNN + LSTM support the authors\u2019 hypothesis about the benefits of the two components of their method. While the author\u2019s compare to DRL methods with limited horizon (length 4), there is no comparison to memory-based RL techniques. Furthermore, a comparison of related memory-based visual navigation techniques on domains for which they are applicable should be considered as such an analysis would illuminate the relative performance over the overlapping portions problem domains  For example, analysis of the metric map approaches on the grid world or of MACN on their tested environments.\n\nPrior work in visual navigation in partially observed and unknown environments have used addressable memory (e.g., Oh et al.) and used VINs (e.g., Gupta et al.) to plan as noted. In discussing these methods, the authors state that these works are not comparable as they operate strictly on discretized 2d spaces. However, it appears to the reviewer that several of these methods can be adapted to higher dimensions and be applicable at least a subclass (for the euclidean/metric map approaches) or the full class of the problems (for Oh et al.), which appears to be capable to solve non-euclidean tasks like the graph search problem. If this assessment is correct, the authors should differentiate between these approaches more thoroughly and consider empirical comparisons. The authors should further consider contrasting their approach with \u201cNeural SLAM\u201d by Zhang et al.\n\nA limitation of the presented method is requirement that the observation \u201creveals the labeling of nearby states.\u201d This assumption holds in each of the examples presented: the neighborhood map in the gridworld and graph examples and the lidar sensor in the robot navigation example. It would be informative for the authors to highlight this limitation and/or identify how to adapt the proposed method under weaker assumptions such as a sensor that doesn\u2019t provide direct metric or connectivity information such as a RGB camera. \n\nMany details of the paper are missing and should be included to clarify the approach and ensure reproducible results. The reviewer suggests providing both more details in the main section of the paper and providing the precise architecture including hyperparameters in the supplementary materials section. \n", "gold_annotation": {"interpretation": 0, "review_id": "r1IWuK2lf", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["The paper presents a method for navigating in an unknown and partialy observed environment is presented.", "The proposed approach splits planning into two levels: 1) localplanning based on the observed space and 2) a globalplanner which receives the localplan, observation features, and access to an addressable memory to decide on which action to select and what to write into memory.", "The contribution of this work is the use of vale iteration networks (VINs) for localplanning on a localy observed map that is fed into a learned globalcontroller that references history and a differentialneuralcomputer (DNC), localpolicy, and observation features select an action and update the memory.", "The core concept of learned localplanner providing additionalcues for a global memory-based planner is a clever idea and the thorough analsis clearly demonstrates the benefit of the approach.", "The proposed method is tested against three problems: a gridworld, a graph search, and a robot environment.", "In each case the proposed method is more performant than the baseline methods.", "The ablation study of using LSTM instead of the DNC and the direct comparison of CNN + LSTM support the authors\u2019 hypothesis about the benefits of the two components of their method.", "While the author\u2019s compare to DRL methods with limited horizon (length 4), there is no comparison to memory-based RL techniques.", "Furthermore, a comparison of related memory-based visualnavigation techniques on domains for which they are applicable should be considered as such an analsis would illuminate the relative performance over the overlapping portions problem domains For example, analsis of the metric map approaches on the grid world or of MACN on their tested environments.", "Prior work in visualnavigation in partialy observed and unknown environments have used addressable memory (e g , Oh et al) and used VINs (e g , Gupta et al) to plan as noted.", "In discussing these methods, the authors state that these works are not comparable as they operate strictly on discretized 2d spaces.", "However, it appears to the reviewer that severalof these methods can be adapted to higher dimensions and be applicable at least a subclass (for the euclidean/metric map approaches) or the full class of the problems (for Oh et al), which appears to be capable to solve non-euclidean tasks like the graph search problem.", "If this assessment is correct, the authors should differentiate between these approaches more thoroughly and consider empiricalcomparisons.", "The authors should further consider contrasting their approach with \u201cNeuralSLAM\u201d by Zhang et al A limitation of the presented method is reqirement that the observation \u201creveal the labeling of nearby states.\u201d This assumption holds in each of the examples presented: the neighborhood map in the gridworld and graph examples and the lidar sensor in the robot navigation example.", "It would be informative for the authors to highlight this limitation and/or identify how to adapt the proposed method under weaker assumptions such as a sensor that doesn\u2019t provide direct metric or connectivity information such as a RGB camera.", "Many details of the paper are missing and should be included to clarify the approach and ensure reproducible results.", "The reviewer suggests providing both more details in the main secion of the paper and providing the precise architecture including hyperparameters in the supplementary material secion."], "all_annotations": [{"interpretation": 0, "review_id": "r1IWuK2lf", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "r14eWGtez", "review_text": "The authors propose a technique to compress LSTMs in RNNs by using a group Lasso regularizer which results in structured sparsity, by eliminating individual hidden layer inputs at a particular layer. The authors present experiments on unidirectional and bidirectional LSTM models which demonstrate the effectiveness of this method. The proposed techniques are evaluated on two models: a fairly large LSTM with ~66.0M parameters, as well as a more compact LSTM with ~2.7M parameters, which can be sped up significantly through compression.\nOverall this is a clearly written paper that is easy to follow, with experiments that are well motivated. To the best of my knowledge most previous papers in the area of RNN compression focus on pruning or compression of the node outputs/connections, but do not focus as much on reducing the computation/parameters within an RNN cell. I only have a few minor comments/suggestions which are listed below:\n\n1. It is interesting that the model structure where the number of parameters is reduced to the number of ISSs chosen from the proposed procedure does not attain the same performance as when training with a larger number of nodes, with the group lasso regularizer. It would be interesting to conduct experiments for a range of \\lambda values: i.e., to allow for different degrees of compression, and then examine whether the model trained from scratch with the \u201coptimal\u201d structure achieves performance closer to the ISS-based strategy, for example, for smaller amounts of compression, this might be the case?\n\n2. In the experiment, the authors use a weaker dropout when training with ISS. Could the authors also report performance for the baseline model if trained with the same dropout (but without the group LASSO regularizer)?\n\n3. The colors in the figures: especially the blue vs. green contrast is really hard to see. It might be nicer to use lighter colors, which are more distinct.\n\n4. The authors mention that the thresholding operation to zero-out weights based on the hyperparameter \\tau is applied \u201cafter each iteration\u201d. What is an iteration in this context? An epoch, a few mini-batch updates, per mini-batch? Could the authors please clarify.\n\n5. Clarification about the hyperparameter \\tau used for sparsification: Is \\tau determined purely based on the converged weight values in the model when trained without the group LASSO constraint? It would be interesting to plot a histogram of weight values in the baseline model, and perhaps also after the group LASSO regularized training.\n\n6. Is the same value of \\lambda used for all groups in the model? It would be interesting to consider the effect of using stronger sparsification in the earlier layers, for example.\n\n7. Section 4.2: Please explain what the exact match (EM) and F1 metrics used to measure performance of the BIDAF model are, in the text. \n\nMinor Typographical/Grammatical errors:\n- Sec 1: \u201c... in LSTMs meanwhile maintains the dimension consistency.\u201d \u2192 \u201c... in LSTMs while maintaining the dimension consistency.\u201d\n- Sec 1: \u201c... is public available\u201d \u2192 \u201cis publically available\u201d\n- Sec 2: Please rephrase: \u201cAfter learning those structures, compact LSTM units remain original structural schematic but have the sizes reduced.\u201d\n- Sec 4.1: \u201cThe exactly same training scheme of the baseline ...\u201d \u2192 \u201cThe same training scheme as the baseline ...\u201d", "gold_annotation": {"interpretation": 0, "review_id": "r14eWGtez", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["The authors propose a technique to compress LSTMs in RNNs by using a group Lasso regularizer which results in structured sparsity, by eliminating individualhidden layer inputs at a particular layer.", "The authors present experiments on unidirectionaland bidirectionalLSTM models which demonstrate the effectiveness of this method.", "The proposed techniques are evalated on two models: a fairly large LSTM with ~66.0M parameters, as well as a more compact LSTM with ~2 7M parameters, which can be sped up significantly through compression.", "Overal this is a clearly written paper that is easy to follow, with experiments that are well motivated.", "To the best of my knowledge most previous papers in the area of RNN compression focus on pruning or compression of the node outputs/connections, but do not focus as much on reducing the computation/parameters within an RNN cell.", "I only have a few minor comments/suggestions which are listed below: 1, It is interesting that the model structure where the number of parameters is reduced to the number of ISSs chosen from the proposed procedure does not attain the same performance as when training with a larger number of nodes, with the group lasso regularizer.", "It would be interesting to conduct experiments for a range of \\lambda vales: i e , to alow for different degrees of compression, and then examine whether the model trained from scratch with the \u201coptimal structure achieves performance closer to the ISS-based strategy, for example, for smaler amounts of compression, this might be the case?", "2, In the experiment, the authors use a weaker dropout when training with ISS.", "Could the authors alo report performance for the baseline model if trained with the same dropout (but without the group LASSO regularizer)?", "3, The colors in the figres: especialy the blue vs. green contrast is realy hard to see.", "It might be nicer to use lighter colors, which are more distinct.", "4, The authors mention that the thresholding operation to zero-out weights based on the hyperparameter \\tau is applied \u201cafter each iteration\u201d.", "What is an iteration in this context?", "An epoch, a few mini-batch updates, per mini-batch?", "Could the authors please clarify.", "5, Clarification about the hyperparameter \\tau used for sparsification: Is \\tau determined purely based on the converged weight vales in the model when trained without the group LASSO constraint?", "It would be interesting to plot a histogram of weight vales in the baseline model, and perhaps alo after the group LASSO regularized training.", "6, Is the same vale of \\lambda used for al groups in the model?", "It would be interesting to consider the effect of using stronger sparsification in the earlier layers, for example.", "7, secion 4 2: Please explain what the exact match (EM) and F1 metrics used to measure performance of the BIDAF model are, in the text.", "Minor TypographicalGrammaticalerrors: - sec1: \u201c... in LSTMs meanwhile maintains the dimension consistency.\u201d \u2192 \u201c... in LSTMs while maintaining the dimension consistency.\u201d - sec1: \u201c... is public available\u201d \u2192 \u201cis publicaly available\u201d - sec2: Please rephrase: \u201cAfter learning those structures, compact LSTM units remain originalstructuralschematic but have the sizes reduced.\u201d - sec4 1: \u201cThe exactly same training scheme of the baseline ...\u201d \u2192 \u201cThe same training scheme as the baseline ...\u201d"], "all_annotations": [{"interpretation": 0, "review_id": "r14eWGtez", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "r11STCqxG", "review_text": "This paper presents a generic unbiased low-rank stochastic approximation to full rank matrices that makes it possible to do online RNN training without the O(n^3) overhead of real-time recurrent learning (RTRL). This is an important and long-sought-after goal of connectionist learning and this paper presents a clear and concise description of why their method is a natural way of achieving that goal, along with experiments on classic toy RNN tasks with medium-range time dependencies for which other low-memory-overhead RNN training heuristics fail. My only major complaint with the paper is that it does not extend the method to large-scale problems on real data, for instance work from the last decade on sequence generation, speech recognition or any of the other RNN success stories that have led to their wide adoption (eg Graves 2013, Sutskever, Martens and Hinton 2011 or Graves, Mohamed and Hinton 2013). However, if the paper does achieve what it claims to achieve, I am sure that many people will soon try out UORO to see if the results are in any way comparable.", "gold_annotation": {"interpretation": 0, "review_id": "r11STCqxG", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["This paper presents a generic unbiased low-rank stochastic approximation to full rank matrices that makes it possible to do online RNN training without the O(n^3) overhead of realtime recurrent learning (RTRL).", "This is an important and long-sought-after goalof connectionist learning and this paper presents a clear and concise description of why their method is a naturalway of achieving that goal alng with experiments on classic toy RNN tasks with medium-range time dependencies for which other low-memory-overhead RNN training heuristics fail.", "My only major complaint with the paper is that it does not extend the method to large-scal problems on realdata, for instance work from the last decade on seqence generation, speech recognition or any of the other RNN success stories that have led to their wide adoption (eg Graves 2013, Sutskever, Martens and Hinton 2011 or Graves, Mohamed and Hinton 2013).", "However, if the paper does achieve what it claims to achieve, I am sure that many people will soon try out UORO to see if the results are in any way comparable."], "all_annotations": [{"interpretation": 0, "review_id": "r11STCqxG", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "SysTGDdxf", "review_text": "\nThe authors took my comments nicely into account in their revision, and their answers are convincing. I increase my rating from 5 to 7. The authors could also integrate their discussion about their results on CIFAR in the paper, I think it would help readers understand better the advantage of the contribution.\n\n----\n\nThis paper is based on the theory of group equivariant CNNs (G-CNNs), proposed by Cohen and Welling ICML'16.\n\nRegular convolutions are translation-equivariant, meaning that if an image is translated, its convolution by any filter is also translated. They are however not rotation-invariant for example.  G-CNN introduces G-convolutions, which are equivariant to a given transformation group G.\n\nThis paper proposes an efficient implementation of G-convolutions for 6-fold rotations (rotations of multiple of 60 degrees), using a hexagonal lattice. The approach is evaluated on CIFAR-10 and AID, a dataset of aerial scene classification. The approach outperforms G-convolutions implemented on a squared lattice, which allows only 4-fold rotations on AID by a short margin. On CIFAR-10, the difference does not seem significative (according to Tables 1 and 2).\nI guess this can be explained by the fact that rotation equivariance makes sense for aerial images, where the scene is mostly fronto-parallel, but less for CIFAR (especially in the upper layers), which exhibits 3D objects.\n\nI like the general approach of explicitly putting desired equivariance in the convolutional networks. Using a hexagonal lattice is elegant, even if it is not new in computer vision (as written in the paper). However, as the transformation group is limited to rotations, this is interesting in practice mostly for fronto-parallel scenes, as the experiences seem to show. It is not clear how the method can be extended to other groups than 2D rotations.\n\nMoreover, I feel like the paper sometimes tries to mask the fact that the proposed method is limited to rotations. It is admittedly clearly stated in the abstract and introduction, but much less in the rest of the paper.\n\nThe second paragraph of Section 5.1 is difficult to keep in a paper. It says that \"From a qualitative inspection of these hexagonal interpolations we conclude that no information is lost during the sampling procedure.\"  \"No information is lost\" is a strong statement from a qualitative inspection, especially of a hexagonal image.  This statement should probably be removed. One way to evaluate the information lost could be to iterate interpolation between hexagonal and squared lattices to see if the image starts degrading at some point.\n\n\n\n", "gold_annotation": {"interpretation": 0, "review_id": "SysTGDdxf", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": [" The authors took my comments nicely into account in their revision, and their answers are convincing.", "I increase my rating from 5 to 7, The authors could alo integrate their discussion about their results on CIFAR in the paper, I think it would help readers understand better the advantage of the contribution.", "---- This paper is based on the theory of group eqivariant CNNs (G-CNNs), proposed by Cohen and Welling ICML'16, Regular convolutions are translation-eqivariant, meaning that if an image is translated, its convolution by any filter is alo translated.", "They are however not rotation-invariant for example.", "G-CNN introduces G-convolutions, which are eqivariant to a given transformation group G This paper proposes an efficient implementation of G-convolutions for 6-fold rotations (rotations of multiple of 60 degrees), using a hexagonallattice.", "The approach is evalated on CIFAR-10 and AID, a dataset of aerialscene classification.", "The approach outperforms G-convolutions implemented on a squared lattice, which alows only 4-fold rotations on AID by a short margin.", "On CIFAR-10, the difference does not seem significative (according to Tables 1 and 2).", "I guess this can be explained by the fact that rotation eqivariance makes sense for aerialimages, where the scene is mostly fronto-paralel, but less for CIFAR (especialy in the upper layers), which exhibits 3D objects.", "I like the generalapproach of explicitly putting desired eqivariance in the convolutionalnetworks.", "Using a hexagonallattice is elegant, even if it is not new in computer vision (as written in the paper).", "However, as the transformation group is limited to rotations, this is interesting in practice mostly for fronto-paralel scenes, as the experiences seem to show.", "It is not clear how the method can be extended to other groups than 2D rotations.", "Moreover, I feel like the paper sometimes tries to mask the fact that the proposed method is limited to rotations.", "It is admittedly clearly stated in the abstract and introduction, but much less in the rest of the paper.", "The secnd paragraph of secion 5 1 is difficult to keep in a paper.", "It says that \"From a qualtative inspection of these hexagonalinterpolations we conclude that no information is lost during the sampling procedure.\"", "\"No information is lost\" is a strong statement from a qualtative inspection, especialy of a hexagonalimage.", "This statement should probably be removed.", "One way to evalate the information lost could be to iterate interpolation between hexagonaland squared lattices to see if the image starts degrading at some point."], "all_annotations": [{"interpretation": 0, "review_id": "SysTGDdxf", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "SyrOMN9eM", "review_text": "The authors propose WAGE, which discretized weights, activations, gradients, and errors at both training and testing time. By quantization and shifting, SGD training without momentum, and removing the softmax at output layer as well, the model managed to remove all cumbersome computations from every aspect of the model, thus eliminating the need for a floating point unit completely. Moreover, by keeping up to 8-bit accuracy, the model performs even better than previously proposed models. I am eager to see a hardware realization for this method because of its promising results. \n\nThe model makes a unified discretization scheme for 4 different kinds of components, and the accuracy for each of the kind becomes independently adjustable. This makes the method quite flexible and has the potential to extend to more complicated networks, such as attention or memory. \n\nOne caveat is that there seem to be some conflictions in the results shown in Table 1, especially ImageNet. Given the number of bits each of the WAGE components asked for, a 28.5% top 5 error rate seems even lower than XNOR. I suspect it is due to the fact that gradients and errors need higher accuracy for real-valued input, but if that is the case, accuracies on SVHN and CIFAR-10 should also reflect that. Or, maybe it is due to hyperparameter setting or insufficient training time?\n\nAlso, dropout seems not conflicting with the discretization. If there are no other reasons, it would make sense to preserve the dropout in the network as well.\n\nIn general, the paper was written in good quality and in detail, I would recommend a clear accept.\n", "gold_annotation": {"interpretation": 0, "review_id": "SyrOMN9eM", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 4.0, "tokenized_review_text": ["The authors propose WAGE, which discretized weights, activations, gradients, and errors at both training and testing time.", "By quantization and shifting, SGD training without momentum, and removing the softmax at output layer as well, the model managed to remove al cumbersome computations from every aspect of the model, thus eliminating the need for a floating point unit completely.", "Moreover, by keeping up to 8-bit accuracy, the model performs even better than previously proposed models.", "I am eager to see a hardware realzation for this method because of its promising results.", "The model makes a unified discretization scheme for 4 different kinds of components, and the accuracy for each of the kind becomes independently adjustable.", "This makes the method quite flexible and has the potentialto extend to more complicated networks, such as attention or memory.", "One caveat is that there seem to be some conflictions in the results shown in Table 1, especialy ImageNet.", "Given the number of bits each of the WAGE components asked for, a 28.5% top 5 error rate seems even lower than XNOR.", "I suspect it is due to the fact that gradients and errors need higher accuracy for realvaled input, but if that is the case, accuracies on SVHN and CIFAR-10 should alo reflect that.", "Or, maybe it is due to hyperparameter setting or insufficient training time?", "Also, dropout seems not conflicting with the discretization.", "If there are no other reasons, it would make sense to preserve the dropout in the network as well.", "In general the paper was written in good qualty and in detail, I would recommend a clear accept."], "all_annotations": [{"interpretation": 0, "review_id": "SyrOMN9eM", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "SymYit2xf", "review_text": "The paper shows that several recently proposed interpretation techniques for neural network are performing similar processing and yield similar results. The authors show that these techniques can all be seen as a product of input activations and a modified gradient, where the local derivative of the activation function at each neuron is replaced by some fixed function.\n\nA second part of the paper looks at whether explanations are global or local. The authors propose a metric called sensitivity-n for that purpose, and make some observations about the optimality of some interpretation techniques with respect to this metric in the linear case. The behavior of each explanation w.r.t. these properties is then tested on multiple DNN models tested on real-world datasets. Results further outline the resemblance between the compared methods.\n\nIn the appendix, the last step of the proof below Eq. 7 is unclear. As far as I can see, the variable g_i^LRP wasn\u2019t defined, and the use of Eq. 5 to achieve this last could be better explained. There also seems to be some issues with the ordering i,j, where these indices alternatively describe the lower/higher layers, or the higher/lower layers.", "gold_annotation": {"interpretation": 0, "review_id": "SymYit2xf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper shows that severalrecently proposed interpretation techniques for neuralnetwork are performing similar processing and yield similar results.", "The authors show that these techniques can al be seen as a product of input activations and a modified gradient, where the localderivative of the activation function at each neuron is replaced by some fixed function.", "A secnd part of the paper looks at whether explanations are globalor local The authors propose a metric caled sensitivity-n for that purpose, and make some observations about the optimalty of some interpretation techniques with respect to this metric in the linear case.", "The behavior of each explanation w r t these properties is then tested on multiple DNN models tested on realworld datasets.", "Results further outline the resemblance between the compared methods.", "In the appendix, the last step of the proof below eq 7 is unclear.", "As far as I can see, the variable g_i^LRP wasn\u2019t defined, and the use of eq 5 to achieve this last could be better explained.", "There alo seems to be some issues with the ordering i,j, where these indices alernatively describe the lower/higher layers, or the higher/lower layers."], "all_annotations": [{"interpretation": 0, "review_id": "SymYit2xf", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "SylxFWcgG", "review_text": "I thank the authors for their updates and clarifications.  I stand by my original review and score.  I think their method and their evaluation has some major weaknesses, but I think that it still provides a good baseline to force work in this space towards tasks which can not be solved by simpler models like this.  So while I'm not super excited about the paper I think it is above the accept threshold.\n--------------------------------------------------------------------------\nThis paper extends an existing thread of neural computation research focused on learning resuable subprocedures (or options in RL-speak).  Instead of simply input and output examples, as in most of the work in neural computation, they follow in the vein of the Neural Programmer-Interpreter (Reed and de Freitas, 2016) and Li et. al., 2017, where the supervision contains the full sequence of elementary actions in the domain for all samples, and some samples also contain the hierarchy of subprocedure calls.\n\nThe main focus of their work is learning from fewer fully annotated samples than prior work.  They introduce two new ideas in order to enable this:\n1.  They limit the memory state of each level in the program heirarchy to simply a counter indicating the number of elementary actions/subprocedure calls taken so far (rather than a full RNN embedded hidden/cell state as in prior work).  They also limit the subprocedures such that they do not accept any arguments.\n2.  By considering this very limited set of possible hidden states, they can compute the gradients using a dynamic program that seems to be more accurate than the approximate dynamic program used in Li et. al., 2017.  \n\nThe main limitation of the work is this extremely limited memory state, and the lack of arguments.  Without arguments, everything that parameterizes the subprocedures must be in the visible world state.  In both of their domains, this is true, but this places a significant limitation on the algorithms which can be modeled with this technique.  Furthermore, the limited memory state means that the only way a subprocedure can remember anything about the current observation is to call a different subprocedure.  Again, their two evalation tasks fit into this paradigm, but this places very significant limitations on the set of applicable domains.  I would have like to see more discussion on how constraining these limitations would be in practice.  For example, it seems it would be impossible for this architecture to perform the Nanocraft task if the parameters of the task (width, height, etc.) were only provided in the first observation, rather than every observation.  \n\nNone-the-less I think this work is an important step in our understanding of the learning dynamics for neural programs.  In particular, while the RNN hidden state memory used by the prior work enables the learning of more complicted programs *in theory*, this has not been shown in practice. So, it's possible that all the prior work is doing is learning to approixmate a much simpler architecture of this form.  Specifically, I think this work can act as a great base-line by forcing future work to focus on domains which cannot be easily solved by a simpler architecture of this form.  This limitation will also force the community to think about which tasks require a more complicated form of memory, and which can be solved with a very simple memory of this form.\n\n\nI also have the following additional concerns about the paper:\n\n1.  I found the current explanation of the algorithm to be very difficult to understand.  It's extremely difficult to understand the core method without reading the appendix, and even with the appendix I found the explanation of the level-by-level decomposition to be too terse.\n\n2.  It's not clear how their gradient approximation compares to the technique used by Li et. al.  They obviously get better results on the addition and Nanocraft domains, but I would have liked a more clear explanation and/or some experiments providing insights into what enables these improvements (or at least an admission by the authors that they don't really understand what enabled the performance improvements).\n", "gold_annotation": {"interpretation": 1, "review_id": "SylxFWcgG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}, "score": 3.0, "tokenized_review_text": ["I thank the authors for their updates and clarifications.", "I stand by my originalreview and score.", "I think their method and their evalation has some major weaknesses, but I think that it still provides a good baseline to force work in this space towards tasks which can not be solved by simpler models like this.", "So while I'm not super excited about the paper I think it is above the accept threshold.", "-------------------------------------------------------------------------- This paper extends an existing thread of neuralcomputation research focused on learning resuable subprocedures (or options in RL-speak).", "Instead of simply input and output examples, as in most of the work in neuralcomputation, they follow in the vein of the NeuralProgrammer-Interpreter (Reed and de Freitas, 2016) and Li et.", "al, 2017, where the supervision contains the full seqence of elementary actions in the domain for al samples, and some samples alo contain the hierarchy of subprocedure cals.", "The main focus of their work is learning from fewer fully annotated samples than prior work.", "They introduce two new ideas in order to enable this: 1, They limit the memory state of each level in the program heirarchy to simply a counter indicating the number of elementary actions/subprocedure cals taken so far (rather than a full RNN embedded hidden/cell state as in prior work).", "They alo limit the subprocedures such that they do not accept any arguments.", "2, By considering this very limited set of possible hidden states, they can compute the gradients using a dynamic program that seems to be more accurate than the approximate dynamic program used in Li et.", "al, 2017, The main limitation of the work is this extremely limited memory state, and the lack of arguments.", "Without arguments, everything that parameterizes the subprocedures must be in the visible world state.", "In both of their domains, this is true, but this places a significant limitation on the alorithms which can be modeled with this technique.", "Furthermore, the limited memory state means that the only way a subprocedure can remember anything about the current observation is to cal a different subprocedure.", "Again, their two evaltion tasks fit into this paradigm, but this places very significant limitations on the set of applicable domains.", "I would have like to see more discussion on how constraining these limitations would be in practice.", "For example, it seems it would be impossible for this architecture to perform the Nanocraft task if the parameters of the task (width, height, etc) were only provided in the first observation, rather than every observation.", "None-the-less I think this work is an important step in our understanding of the learning dynamics for neuralprograms.", "In particular, while the RNN hidden state memory used by the prior work enables the learning of more complicted programs *in theory*, this has not been shown in practice.", "So, it's possible that al the prior work is doing is learning to approixmate a much simpler architecture of this form.", "Specificaly, I think this work can act as a great base-line by forcing future work to focus on domains which cannot be easily solved by a simpler architecture of this form.", "This limitation will alo force the community to think about which tasks reqire a more complicated form of memory, and which can be solved with a very simple memory of this form.", "I alo have the following additionalconcerns about the paper: 1, I found the current explanation of the alorithm to be very difficult to understand.", "It's extremely difficult to understand the core method without reading the appendix, and even with the appendix I found the explanation of the level-by-level decomposition to be too terse.", "2, It's not clear how their gradient approximation compares to the technique used by Li et.", "al They obviously get better results on the addition and Nanocraft domains, but I would have liked a more clear explanation and/or some experiments providing insights into what enables these improvements (or at least an admission by the authors that they don't realy understand what enabled the performance improvements)."], "all_annotations": [{"interpretation": 1, "review_id": "SylxFWcgG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "Sye2eNDxM", "review_text": "This paper aims to learn hierarchical policies by using a recursive policy structure regulated by a stochastic temporal grammar. The experiments show that the method is better than a flat policy for learning a simple set of block-related skills in minecraft (find, get, put, stack) and generalizes better to a modification of the environment (size of room). The sequence of subtasks generated by the policy are interpretable.\n\nStrengths:\n- The grammar and policies are trained using a sparse reward upon task completion. \n- The method is well ablated; Figures 4 and 5 answered most questions I had while reading.\n- Theoretically, the method makes few assumptions about the environment and the relationships between tasks.\n- The interpretability of the final behaviors is a good result. \n\nWeaknesses:\n- The implementation gives the agent a -0.5 reward if it generates a currently unexecutable goal g\u2019. Providing this reward requires knowing the full state of the world. If this hack is required, then this method would not be useful in a real world setting, defeating the purpose of the sparse reward mentioned above. I would really like to see how the method performs without this hack. \n- There are no comparisons to other multitask or hierarchical methods. Progressive Networks or Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning seem like natural comparisons.\n- A video to show what the environments and tasks look like during execution would be helpful.\n- The performances of the different ablations are rather close. Please a standard deviation over multiple training runs. Also, why does figure 4.b not include a flat policy?\n- The stages are ordered in a semantically meaningful order (find is the first stage), but the authors claim that the order is arbitrary. If this claim is going to be included in the paper, it needs to be proven (results shown for random orderings) because right now I do not believe it. \n\nQuality:\nThe method does provide hierarchical and interpretable policies for executing instructions, this is a meaningful direction to work on.\n\nClarity:\nAlthough the method is complicated, the paper was understandable.\n\nOriginality and significance:\nAlthough the method is interesting, I am worried that the environment has been too tailored for the method, and that it would fail in realistic scenarios. The results would be more significant if the tasks had an additional degree of complexity, e.g. \u201cput blue block next to the green block\u201d \u201cget the blue block in room 2\u201d. Then the sequences of subtasks would be a bit less linear (e.g., first need to find blue, then get, then find green, then put). At the moment the tasks are barely more than the actions provided in the environment.\n\nAnother impedance to the paper\u2019s significance is the number of hacks to make the method work (ordering of stages, alternating policy optimization, first training each stage on only tasks of previous stage). Because the method is only evaluated on one simple environment, it unclear which hacks are for the method generally, and which hacks are for the method to work on the environment.", "gold_annotation": {"interpretation": 1, "review_id": "Sye2eNDxM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["This paper aims to learn hierarchicalpolicies by using a recursive policy structure regulated by a stochastic temporalgrammar.", "The experiments show that the method is better than a flat policy for learning a simple set of block-related skills in minecraft (find, get, put, stack) and generalzes better to a modification of the environment (size of room).", "The seqence of subtasks generated by the policy are interpretable.", "Strengths: - The grammar and policies are trained using a sparse reward upon task completion.", "- The method is well ablated; figres 4 and 5 answered most questions I had while reading.", "- Theoreticaly, the method makes few assumptions about the environment and the relationships between tasks.", "- The interpretability of the finalbehaviors is a good result.", "Weaknesses: - The implementation gives the agent a -0 5 reward if it generates a currently unexecutable goalg\u2019.", "Providing this reward reqires knowing the full state of the world.", "If this hack is reqired, then this method would not be useful in a realworld setting, defeating the purpose of the sparse reward mentioned above.", "I would realy like to see how the method performs without this hack.", "- There are no comparisons to other multitask or hierarchicalmethods.", "Progressive Networks or Zero-Shot Task Generalzation with Multi-Task Deep Reinforcement Learning seem like naturalcomparisons.", "- A video to show what the environments and tasks look like during execution would be helpful.", "- The performances of the different ablations are rather close.", "Please a standard deviation over multiple training runs.", "Also, why does figre 4 b not include a flat policy?", "- The stages are ordered in a semanticaly meaningful order (find is the first stage), but the authors claim that the order is arbitrary.", "If this claim is going to be included in the paper, it needs to be proven (results shown for random orderings) because right now I do not believe it.", "Qualty: The method does provide hierarchicaland interpretable policies for executing instructions, this is a meaningful direction to work on.", "Clarity: Although the method is complicated, the paper was understandable.", "Originalty and significance: Although the method is interesting, I am worried that the environment has been too tailored for the method, and that it would fail in realstic scenarios.", "The results would be more significant if the tasks had an additionaldegree of complexity, e g \u201cput blue block next to the green block\u201d \u201cget the blue block in room 2\u201d.", "Then the seqences of subtasks would be a bit less linear (e g , first need to find blue, then get, then find green, then put).", "At the moment the tasks are barely more than the actions provided in the environment.", "Another impedance to the paper\u2019s significance is the number of hacks to make the method work (ordering of stages, alernating policy optimization, first training each stage on only tasks of previous stage).", "Because the method is only evalated on one simple environment, it unclear which hacks are for the method generaly, and which hacks are for the method to work on the environment."], "all_annotations": [{"interpretation": 1, "review_id": "Sye2eNDxM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SycLo2FxG", "review_text": "Summary\nThe paper presents an interesting view on the recently proposed MAML formulation of meta-learning (Finn et al). The main contribution is a) insight into the connection between the MAML procedure and MAP estimation in an equivalent linear hierarchical Bayes model with explicit priors, b) insight into the connection between MAML and MAP estimation in non-linear HB models with implicit priors, c) based on these insights, the paper proposes a variant of MALM using a Laplace approximation (with additional approximations for the covariance matrix. The paper finally provides an evaluation on the mini ImageNet problem without significantly improving on the MAML results on the same task.\n\nPro:\n-            The topic is timely and of relevance to the ICLR community continuing a current trend in building meta-learning system for few-shot learning.\n-            Provides valuable insight into the MAML objective and its relation to probabilistic models\n\nCon:\n-            The paper is generally well-written but I find (as a non-meta-learner expert) that certain fundamental aspects could have been explained better or in more detail (see below for details).\n-            The toy example is quite difficult to interpret the first time around and does not provide any empirical insight into the converge of the proposed method (compared to e.g. MAML)\n-            I do not think the empirical results provide enough evidence that it is a useful/robust method. Especially it does not provide insight into which types of problems (small/large, linear/ non-linear) the method is applicable to. \n\n\nDetailed comments/questions:\n-            The use of Laplace approximation is (in the paper) motivated from a probabilistic/Bayes and uncertainty point-of-view. It would, however, seem that the truncated iterations do not result in the approximation being very accurate during optimization as the truncation does not result in the approximation being created at a mode. Could the authors perhaps comment on:\na) whether it is even meaningful to talk about the approximations as probabilistic distribution during the optimization (given the psd approximation to the Hessian), or does it only make sense after convergence? \nb) the consequence of the approximation errors on the general convergence of the proposed method (consistency and rate)\n\n-            Sec 4.1, p5: Last equation: Perhaps useful to explain the term $log(\\phi_j^* | \\theta)$ and why it is not in subroutine 4 . Should $\\phi^*$  be $\\hat \\phi$ ?\n-            Sec 4.2: \u201cA straightforward\u2026\u201d: I think it would improve readability to refer back to the to the previous equation (i.e. H) such that it is clear what is meant by \u201cstraightforward\u201d.\n-            Sec 4.2: Several ideas are being discussed in Sec 4.2 and it is not entirely clear to me what has actually been adopted here; perhaps consider formalizing the actual computations in Subroutine 4 \u2013 and provide a clearer argument (preferably proof) that this leads to consistent and robust estimator of \\theta.\n-            It is not clear from the text or experiment how the learning parameters are set.\n-            Sec 5.1: It took some effort to understand exactly what was going on in the example and particular figure 5.1; e.g., in the model definition in the body text there is no mention of the NN mentioned/used in figure 5, the blue points are not defined in the caption, the terminology e.g.  \u201cpre-update density\u201d is new at this point. I think it would benefit the readability to provide the reader with a bit more guidance.\n-            Sec 5.1: While the qualitative example is useful (with a bit more text), I believe it would have been more convincing with a quantitative example to demonstrate e.g. the convergence of the proposal compared to std MAML and possibly compare to a std Bayesian inference method from the HB formulation of the problem (in the linear case)\n-            Sec 5.2: The abstract clams increased performance over MAML but the empirical results do not seem to be significantly better than MAML ? I find it quite difficult to support the specific claim in the abstract from the results without adding a comment about the significance.\n-            Sec 5.2: The authors have left out \u201cMishral et al\u201d from the comparison due to the model being significantly larger than others. Could the authors provide insight into why they did not use the ResNet structure from the  tcml paper in their L-MLMA scheme ?\n-            Sec 6+7: The paper clearly states that it is not the aim to (generally) formulate the MAML as a HB. Given the advancement in gradient based inference for HB the last couple of years (e.g. variational, nested laplace , expectation propagation etc) for explicit models, could the authors perhaps indicate why they believe their approach of looking directly to the MAML objective is more scalable/useful than trying to formulate the same or similar objective in an explicit HB model and using established inference methods from that area ?\n\nMinor:\n-            Sec 4.1 \u201c\u2026each integral in the sum in (2)\u2026\u201d eq 2 is a product\n", "gold_annotation": {"interpretation": 1, "review_id": "SycLo2FxG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}, "score": 4.0, "tokenized_review_text": ["Summary The paper presents an interesting view on the recently proposed MAML formulation of meta-learning (Finn et al.", "The main contribution is a) insight into the connection between the MAML procedure and MAP estimation in an eqivalnt linear hierarchicalBayes model with explicit priors, b) insight into the connection between MAML and MAP estimation in non-linear HB models with implicit priors, c) based on these insights, the paper proposes a variant of MALM using a Laplace approximation (with additionalapproximations for the covariance matrix.", "The paper finaly provides an evalation on the mini ImageNet problem without significantly improving on the MAML results on the same task.", "Pro: - The topic is timely and of relevance to the ICLR community continuing a current trend in building meta-learning system for few-shot learning.", "- Provides valable insight into the MAML objective and its relation to probabilistic models Con: - The paper is generaly well-written but I find (as a non-meta-learner expert) that certain fundamentalaspects could have been explained better or in more detail (see below for details).", "- The toy example is quite difficult to interpret the first time around and does not provide any empiricalinsight into the converge of the proposed method (compared to e g MAML) - I do not think the empiricalresults provide enough evidence that it is a useful/robust method.", "Especialy it does not provide insight into which types of problems (smal/large, linear/ non-linear) the method is applicable to.", "Detailed comments/questions: - The use of Laplace approximation is (in the paper) motivated from a probabilistic/Bayes and uncertainty point-of-view.", "It would, however, seem that the truncated iterations do not result in the approximation being very accurate during optimization as the truncation does not result in the approximation being created at a mode.", "Could the authors perhaps comment on: a) whether it is even meaningful to tal about the approximations as probabilistic distribution during the optimization (given the psd approximation to the Hessian), or does it only make sense after convergence?", "b) the conseqence of the approximation errors on the generalconvergence of the proposed method (consistency and rate) - sec4 1, p5: Last eqation: Perhaps useful to explain the term $log(\\phi_j^* | \\theta)$ and why it is not in subroutine 4 .", "Should $\\phi^*$ be $\\hat \\phi$ ?", "- sec4 2: \u201cA straightforward\u2026\u201d: I think it would improve readability to refer back to the to the previous eqation (i e H) such that it is clear what is meant by \u201cstraightforward\u201d.", "- sec4 2: Severalideas are being discussed in sec4 2 and it is not entirely clear to me what has actualy been adopted here; perhaps consider formalzing the actualcomputations in Subroutine 4 \u2013 and provide a clearer argument (preferably proof) that this leads to consistent and robust estimator of \\theta.", "- It is not clear from the text or experiment how the learning parameters are set.", "- sec5 1: It took some effort to understand exactly what was going on in the example and particular figre 5 1; e g , in the model definition in the body text there is no mention of the NN mentioned/used in figre 5, the blue points are not defined in the caption, the terminology e g \u201cpre-update density\u201d is new at this point.", "I think it would benefit the readability to provide the reader with a bit more guidance.", "- sec5 1: While the qualtative example is useful (with a bit more text), I believe it would have been more convincing with a quantitative example to demonstrate e g the convergence of the proposalcompared to std MAML and possibly compare to a std Bayesian inference method from the HB formulation of the problem (in the linear case) - sec5 2: The abstract clams increased performance over MAML but the empiricalresults do not seem to be significantly better than MAML ?", "I find it quite difficult to support the specific claim in the abstract from the results without adding a comment about the significance.", "- sec5 2: The authors have left out \u201cMishralet al from the comparison due to the model being significantly larger than others.", "Could the authors provide insight into why they did not use the ResNet structure from the tcml paper in their L-MLMA scheme ?", "- sec6+7: The paper clearly states that it is not the aim to (generaly) formulate the MAML as a HB.", "Given the advancement in gradient based inference for HB the last couple of years (e g variational nested laplace , expectation propagation etc for explicit models, could the authors perhaps indicate why they believe their approach of looking directly to the MAML objective is more scalble/useful than trying to formulate the same or similar objective in an explicit HB model and using established inference methods from that area ?", "Minor: - sec4 1 \u201c\u2026each integralin the sum in (2)\u2026\u201d eq2 is a product"], "all_annotations": [{"interpretation": 1, "review_id": "SycLo2FxG", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 4, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 1, "method": 1}]}, {"conference": "iclr18", "review_id": "SyOiDTtef", "review_text": "The paper proposes an online distillation method, called co-distillation, where the two different models are trained to match the predictions of other model in addition to minimizing its own loss. The proposed method is applied to two large-scale datasets and showed to perform better than other baselines such as label smoothing, and the standard ensemble. \n\nThe paper is clearly written and was easy to understand. My major concern is the significance and originality of the proposed method. As written by the authors, the main contribution of the paper is to apply the codistillation method, which is pretty similar to Zhang et. al (2017), at scale. But, because from Zhang's method, I don't see any significant difficulty in applying to large-scale problems, I'm not sure that this can be a significant contribution. Rather, I think, it would have been better for the authors to apply the proposed methods to a smaller scale problems as well in order to explore more various aspects of the proposed methods including the effects of number of different models. In this sense, it is also a limitation that the authors showing experiments where only two models are codistillated. Usually, ensemble becomes stronger as the number of model increases.\n", "gold_annotation": {"interpretation": 0, "review_id": "SyOiDTtef", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper proposes an online distillation method, caled co-distillation, where the two different models are trained to match the predictions of other model in addition to minimizing its own loss.", "The proposed method is applied to two large-scal datasets and showed to perform better than other baselines such as label smoothing, and the standard ensemble.", "The paper is clearly written and was easy to understand.", "My major concern is the significance and originalty of the proposed method.", "As written by the authors, the main contribution of the paper is to apply the codistillation method, which is pretty similar to Zhang et.", "al(2017), at scal.", "But, because from Zhang's method, I don't see any significant difficulty in applying to large-scal problems, I'm not sure that this can be a significant contribution.", "Rather, I think, it would have been better for the authors to apply the proposed methods to a smaler scal problems as well in order to explore more various aspects of the proposed methods including the effects of number of different models.", "In this sense, it is alo a limitation that the authors showing experiments where only two models are codistillated.", "Usualy, ensemble becomes stronger as the number of model increases."], "all_annotations": [{"interpretation": 0, "review_id": "SyOiDTtef", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "SyKUVctlM", "review_text": "This paper proposes a recurrent neural network for visual question answering. The recurrent neural network is equipped with a carefully designed recurrent unit called MAC (Memory, Attention and Control) cell, which encourages sequential reasoning by restraining interaction between inputs and its hidden states. The proposed model shows the state-of-the-art performance on CLEVR and CLEVR-Humans dataset, which are standard benchmarks for visual reasoning problem. Additional experiments with limited training data shows the data efficiency of the model, which supports its strong generalization ability.\n\nThe proposed model in this paper is designed with reasonable motivations and shows strong experimental results in terms of overall accuracy and the data efficiency. However, an issue in the writing, usage of external component and lack of experimental justification of the design choices hinder the clear understanding of the proposed model.\n\nAn issue in the writing\nOverall, the paper is well written and easy to understand, but Section 3.2.3 (The Write Unit) has contradictory statements about their implementation. Specifically, they proposed three different ways to update the memory (simple update, self attention and memory gate), but it is not clear which method is used in the end.\n\nUsage of external component\nThe proposed model uses pretrained word vectors called GloVE, which has boosted the performance on visual question answering. This experimental setting makes fair comparison with the previous works difficult as the pre-trained word vectors are not used for the previous works. To isolate the strength of the proposed reasoning module, I ask to provide experiments without pretrained word vectors.\n\nLack of experimental justification of the design choices\nThe proposed recurrent unit contains various design choices such as separation of three different units (control unit, read unit and memory unit), attention based input processing and different memory updates stem from different motivations. However, these design choices are not justified well because there is neither ablation study nor visualization of internal states. Any analysis or empirical study on these design choices is necessary to understand the characteristics of the model. Here, I suggest to provide few visualizations of attention weights and ablation study that could support indispensability of the design choices.\n", "gold_annotation": {"interpretation": 0, "review_id": "SyKUVctlM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}, "score": 3.0, "tokenized_review_text": ["This paper proposes a recurrent neuralnetwork for visualquestion answering.", "The recurrent neuralnetwork is eqipped with a carefully designed recurrent unit caled MAC (Memory, Attention and Control) cell, which encourages seqentialreasoning by restraining interaction between inputs and its hidden states.", "The proposed model shows the state-of-the-art performance on CLEVR and CLEVR-Humans dataset, which are standard benchmarks for visualreasoning problem.", "Additionalexperiments with limited training data shows the data efficiency of the model, which supports its strong generalzation ability.", "The proposed model in this paper is designed with reasonable motivations and shows strong experimentalresults in terms of overal accuracy and the data efficiency.", "However, an issue in the writing, usage of externalcomponent and lack of experimentaljustification of the design choices hinder the clear understanding of the proposed model.", "An issue in the writing Overal, the paper is well written and easy to understand, but secion 3 2 3 (The Write Unit) has contradictory statements about their implementation.", "Specificaly, they proposed three different ways to update the memory (simple update, self attention and memory gate), but it is not clear which method is used in the end.", "Usage of externalcomponent The proposed model uses pretrained word vectors caled GloVE, which has boosted the performance on visualquestion answering.", "This experimentalsetting makes fair comparison with the previous works difficult as the pre-trained word vectors are not used for the previous works.", "To isolate the strength of the proposed reasoning module, I ask to provide experiments without pretrained word vectors.", "Lack of experimentaljustification of the design choices The proposed recurrent unit contains various design choices such as separation of three different units (control unit, read unit and memory unit), attention based input processing and different memory updates stem from different motivations.", "However, these design choices are not justified well because there is neither ablation study nor visualzation of internalstates.", "Any analsis or empiricalstudy on these design choices is necessary to understand the characteristics of the model.", "Here, I suggest to provide few visualzations of attention weights and ablation study that could support indispensability of the design choices."], "all_annotations": [{"interpretation": 0, "review_id": "SyKUVctlM", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 4, "originality": 1, "metareview": "no", "presentation": 1, "method": 0}]}, {"conference": "iclr18", "review_id": "Sy4HaTtlz", "review_text": "Quality: The work focuses on a novel problem of generating text sample using GAN and a novel in-filling mechanism of words. Using GAN to generate samples in adversarial setup in texts has been limited due to the mode collapse and training instability issues. As a remedy to these problems an in-filling-task conditioning on the surrounding text has been proposed. But, the use of the rewards at every time step (RL mechanism) to employ the actor-critic training procedure could be challenging computationally challenging.\n\nClarity: The mechanism of generating the text samples using the proposed methodology has been described clearly. However the description of the reinforcement learning step could have been made a bit more clear.\n\nOriginality: The work indeed use a novel mechanism of in-filling via a conditioning approach to overcome the difficulties of GAN training in text settings. There has been some work using GAN to generate adversarial examples in textual context too to check the robustness of classifiers. How this current work compares with the existing such literature?\n\nSignificance: The research problem is indeed significant since the use of GAN in generating adversarial examples in image analysis has been more prevalent compared to text settings. Also, the proposed actor-critic training procedure via RL methodology is indeed significant from its application in natural language processing.\n\npros:\n(a) Human evaluations applications to several datasets show the usefulness of MaskGen over the maximum likelihood trained model in generating more realistic text samples.\n(b) Using a novel in-filling procedure to overcome the complexities in GAN training.\n(c) generation of high quality samples even with higher perplexity on ground truth set.\n\ncons:\n(a) Use of rewards at every time step to the actor-critic training procure could be computationally expensive.\n(b) How to overcome the situation where in-filling might introduce implausible text sequences with respect to the surrounding words?\n(c) Depending on the Mask quality GAN can produce low quality samples. Any practical way of choosing the mask?", "gold_annotation": {"interpretation": 0, "review_id": "Sy4HaTtlz", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Qualty: The work focuses on a novel problem of generating text sample using GAN and a novel in-filling mechanism of words.", "Using GAN to generate samples in adversarialsetup in texts has been limited due to the mode collapse and training instability issues.", "As a remedy to these problems an in-filling-task conditioning on the surrounding text has been proposed.", "But, the use of the rewards at every time step (RL mechanism) to employ the actor-critic training procedure could be chalenging computationaly chalenging.", "Clarity: The mechanism of generating the text samples using the proposed methodology has been described clearly.", "However the description of the reinforcement learning step could have been made a bit more clear.", "Originalty: The work indeed use a novel mechanism of in-filling via a conditioning approach to overcome the difficulties of GAN training in text settings.", "There has been some work using GAN to generate adversarialexamples in textualcontext too to check the robustness of classifiers.", "How this current work compares with the existing such literature?", "Significance: The research problem is indeed significant since the use of GAN in generating adversarialexamples in image analsis has been more prevalnt compared to text settings.", "Also, the proposed actor-critic training procedure via RL methodology is indeed significant from its application in naturallanguage processing.", "pros: (a) Human evalations applications to severaldatasets show the usefulness of MaskGen over the maximum likelihood trained model in generating more realstic text samples.", "(b) Using a novel in-filling procedure to overcome the complexities in GAN training.", "(c) generation of high qualty samples even with higher perplexity on ground truth set.", "cons: (a) Use of rewards at every time step to the actor-critic training procure could be computationaly expensive.", "(b) How to overcome the situation where in-filling might introduce implausible text seqences with respect to the surrounding words?", "(c) Depending on the Mask qualty GAN can produce low qualty samples.", "Any practicalway of choosing the mask?"], "all_annotations": [{"interpretation": 0, "review_id": "Sy4HaTtlz", "importance": 1, "reproducibility": 0, "constructiveness": 2, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "SkxHS_vlz", "review_text": "Summary of paper:\n\nThe authors present a novel attack for generating adversarial examples, deemed OptMargin, in which the authors attack an ensemble of classifiers created by classifying at random L2 small perturbations. They compare this optimization method with two baselines in MNIST and CIFAR, and provide an analysis of the decision boundaries by their adversarial examples, the baselines and non-altered examples. \n\nReview summary:\n\nI think this paper is interesting. The novelty of the attack is a bit dim, since it seems it's just the straightforward attack against the region cls defense. The authors fail to include the most standard baseline attack, namely FSGM. The authors also miss the most standard defense, training with adversarial examples. As well, the considered attacks are in L2 norm, and the distortion is measured in L2, while the defenses measure distortion in L_\\infty (see detailed comments for the significance of this if considering white-box defenses). The provided analysis is insightful, though the authors mostly fail to explain how this analysis could provide further work with means to create new defenses or attacks.\n\nIf the authors add FSGM to the batch of experiments (especially section 4.1) and address some of the objections I will consider updating my score.\n\nA more detailed review follows.\n\n\nDetailed comments:\n\n- I think the novelty of the attack is not very strong. The authors essentially develop an attack targeted to the region cls defense. Designing an attack for a specific defense is very well established in the literature, and the fact that the attack fools this specific defense is not surprising.\n\n- I think the authors should make a claim on whether their proposed attack works only for defenses that are agnostic to the attack (such as PGD or region based), or for defenses that know this is a likely attack (see the following comment as well). If the authors want to make the second claim, training the network with adversarial examples coming from OptMargin is missing.\n\n- The attacks are all based in L2, in the sense that the look for they measure perturbation in an L2 sense (as the paper evaluation does), while the defenses are all L_\\infty based (since the region classifier method samples from a hypercube, and PGD uses an L_\\infty perturbation limit). This is very problematic if the authors want to make claims about their attack being effective under defenses that know OptMargin is a possible attack.\n\n- The simplest most standard baseline of all (FSGM) is missing. This is important to compare properly with previous work.\n\n- The fact that the attack OptMargin is based in L2 perturbations makes it very susceptible to a defense that backprops through the attack. This and / or the defense of training to adversarial examples is an important experiment to assessing the limitations of the attack. \n\n- I think the authors rush to conclude that \"a small ball around a given input distance can be misleading\". Wether balls are in L2 or L_\\infty, or another norm makes a big difference in defense and attacks, given that they are only equivalent to a multiplicative factor of sqrt(d) where d is the dimension of the space, and we are dealing with very high dimensional problems. I find the analysis made by the authors to be very simplistic.\n\n- The analysis of section 4.1 is interesting, it was insightful and to the best of my knowledge novel. Again I would ask the authors to make these plots for FSGM. Since FSGM is known to be robust to small random perturbations, I would be surprised that for a majority of random directions, the adversarial examples are brought back to the original class.\n\n- I think a bit more analysis is needed in section 4.2. Do the authors think that this distinguishability can lead to a defense that uses these statistics? If so, how?\n\n- I think the analysis of section 5 is fairly trivial. Distinguishability in high dimensions is an easy problem (as any GAN experiment confirms, see for example Arjovsky & Bottou, ICLR 2017), so it's not surprising or particularly insightful that one can train a classifier to easily recognize the boundaries.\n\n- Will the authors release code to reproduce all their experiments and methods?\n\nMinor comments:\n- The justification of why OptStrong is missing from Table2 (last three sentences of 3.3) should be summarized in the caption of table 2 (even just pointing to the text), otherwise a first reader will mistake this for the omission of a baseline.\n\n- I think it's important to state in table 1 what is the amount of distortion noticeable by a human.\n\n=========================================\n\nAfter the rebuttal I've updated my score, due to the addition of FSGM added as a baseline and a few clarifications. I now understand more the claims of the paper, and their experiments towards them. I still think the novelty, significance of the claims and protocol are still perhaps borderline for publication (though I'm leaning towards acceptance), but I don't have a really high amount of experience in the field of adversarial examples in order to make my review with high confidence.", "gold_annotation": {"interpretation": 1, "review_id": "SkxHS_vlz", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["Summary of paper: The authors present a novel attack for generating adversarialexamples, deemed OptMargin, in which the authors attack an ensemble of classifiers created by classifying at random L2 smal perturbations.", "They compare this optimization method with two baselines in MNIST and CIFAR, and provide an analsis of the decision boundaries by their adversarialexamples, the baselines and non-alered examples.", "Review summary: I think this paper is interesting.", "The novelty of the attack is a bit dim, since it seems it's just the straightforward attack against the region cls defense.", "The authors fail to include the most standard baseline attack, namely FSGM.", "The authors alo miss the most standard defense, training with adversarialexamples.", "As well, the considered attacks are in L2 norm, and the distortion is measured in L2, while the defenses measure distortion in L_\\infty (see detailed comments for the significance of this if considering white-box defenses).", "The provided analsis is insightful, though the authors mostly fail to explain how this analsis could provide further work with means to create new defenses or attacks.", "If the authors add FSGM to the batch of experiments (especialy secion 4 1) and address some of the objections I will consider updating my score.", "A more detailed review follows.", "Detailed comments: - I think the novelty of the attack is not very strong.", "The authors essentialy develop an attack targeted to the region cls defense.", "Designing an attack for a specific defense is very well established in the literature, and the fact that the attack fools this specific defense is not surprising.", "- I think the authors should make a claim on whether their proposed attack works only for defenses that are agnostic to the attack (such as PGD or region based), or for defenses that know this is a likely attack (see the following comment as well).", "If the authors want to make the secnd claim, training the network with adversarialexamples coming from OptMargin is missing.", "- The attacks are al based in L2, in the sense that the look for they measure perturbation in an L2 sense (as the paper evalation does), while the defenses are al L_\\infty based (since the region classifier method samples from a hypercube, and PGD uses an L_\\infty perturbation limit).", "This is very problematic if the authors want to make claims about their attack being effective under defenses that know OptMargin is a possible attack.", "- The simplest most standard baseline of al (FSGM) is missing.", "This is important to compare properly with previous work.", "- The fact that the attack OptMargin is based in L2 perturbations makes it very susceptible to a defense that backprops through the attack.", "This and / or the defense of training to adversarialexamples is an important experiment to assessing the limitations of the attack.", "- I think the authors rush to conclude that \"a smal bal around a given input distance can be misleading\".", "Wether bals are in L2 or L_\\infty, or another norm makes a big difference in defense and attacks, given that they are only eqivalnt to a multiplicative factor of sqrt(d) where d is the dimension of the space, and we are dealng with very high dimensionalproblems.", "I find the analsis made by the authors to be very simplistic.", "- The analsis of secion 4 1 is interesting, it was insightful and to the best of my knowledge novel.", "Again I would ask the authors to make these plots for FSGM.", "Since FSGM is known to be robust to smal random perturbations, I would be surprised that for a majority of random directions, the adversarialexamples are brought back to the originalclass.", "- I think a bit more analsis is needed in secion 4 2, Do the authors think that this distinguishability can lead to a defense that uses these statistics?", "If so, how?", "- I think the analsis of secion 5 is fairly trivial Distinguishability in high dimensions is an easy problem (as any GAN experiment confirms, see for example Arjovsky & Bottou, ICLR 2017), so it's not surprising or particularly insightful that one can train a classifier to easily recognize the boundaries.", "- Will the authors release code to reproduce al their experiments and methods?", "Minor comments: - The justification of why OptStrong is missing from Table2 (last three sentences of 3 3) should be summarized in the caption of table 2 (even just pointing to the text), otherwise a first reader will mistake this for the omission of a baseline.", "- I think it's important to state in table 1 what is the amount of distortion noticeable by a human.", "========================================= After the rebuttalI've updated my score, due to the addition of FSGM added as a baseline and a few clarifications.", "I now understand more the claims of the paper, and their experiments towards them.", "I still think the novelty, significance of the claims and protocol are still perhaps borderline for publication (though I'm leaning towards acceptance), but I don't have a realy high amount of experience in the field of adversarialexamples in order to make my review with high confidence."], "all_annotations": [{"interpretation": 1, "review_id": "SkxHS_vlz", "importance": 0, "reproducibility": 1, "constructiveness": 3, "overall": 3, "annotator": "anno2", "evidence": 5, "originality": 1, "metareview": "maybe", "presentation": 0, "method": 1}]}, {"conference": "iclr18", "review_id": "SkSMlWcgG", "review_text": "The paper provides methods for training deep networks using half-precision floating point numbers without losing model accuracy or changing the model hyper-parameters. The main ideas are to use a master copy of weights when updating the weights, scaling the loss before back-prop and using full precision variables to store products. Experiments are performed on a large number of state-of-art deep networks, tasks and datasets which show that the proposed mixed precision training does provide the same accuracy at half the memory.\n\nPositives\n- The experimental evaluation is fairly exhaustive on a large number of deep networks, tasks and datasets and the proposed training preserves the accuracy of all the tested networks at half the memory cost.\n\nNegatives\n- The overall technical contribution is fairly small and are ideas that are regularly implemented when optimizing systems.\n- The overall advantage is only a 2x reduction in memory which can be gained by using smaller batches at the cost of extra compute. ", "gold_annotation": {"interpretation": 0, "review_id": "SkSMlWcgG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["The paper provides methods for training deep networks using hal-precision floating point numbers without losing model accuracy or changing the model hyper-parameters.", "The main ideas are to use a master copy of weights when updating the weights, scalng the loss before back-prop and using full precision variables to store products.", "Experiments are performed on a large number of state-of-art deep networks, tasks and datasets which show that the proposed mixed precision training does provide the same accuracy at hal the memory.", "Positives - The experimentalevalation is fairly exhaustive on a large number of deep networks, tasks and datasets and the proposed training preserves the accuracy of al the tested networks at hal the memory cost.", "Negatives - The overal technicalcontribution is fairly smal and are ideas that are regularly implemented when optimizing systems.", "- The overal advantage is only a 2x reduction in memory which can be gained by using smaler batches at the cost of extra compute."], "all_annotations": [{"interpretation": 0, "review_id": "SkSMlWcgG", "importance": 0, "reproducibility": 0, "constructiveness": 2, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "SkPNib9ez", "review_text": "This paper extends and speeds up PROSE, a programming by example system, by posing the selection of the next production rule in the grammar as a supervised learning problem.\n\nThis paper requires a large amount of background knowledge as it depends on understanding program synthesis as it is done in the programming languages community. Moreover the work mentions a neurally-guided search, but little time is spent on that portion of their contribution. I am not even clear how their system is trained.\n\nThe experimental results do show the programs can be faster but only if the user is willing to suffer a loss in accuracy. It is difficult to conclude overall if the technique helps in synthesis.", "gold_annotation": {"interpretation": 0, "review_id": "SkPNib9ez", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 2.0, "tokenized_review_text": ["This paper extends and speeds up PROSE, a programming by example system, by posing the selection of the next production rule in the grammar as a supervised learning problem.", "This paper reqires a large amount of background knowledge as it depends on understanding program synthesis as it is done in the programming languages community.", "Moreover the work mentions a neuraly-guided search, but little time is spent on that portion of their contribution.", "I am not even clear how their system is trained.", "The experimentalresults do show the programs can be faster but only if the user is willing to suffer a loss in accuracy.", "It is difficult to conclude overal if the technique helps in synthesis."], "all_annotations": [{"interpretation": 0, "review_id": "SkPNib9ez", "importance": 0, "reproducibility": 0, "constructiveness": 1, "overall": 2, "annotator": "anno2", "evidence": 1, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "SkDHZUXlG", "review_text": "The authors train an RNN to perform deduced reckoning (ded reckoning) for spatial navigation, and then study the responses of the model neurons in the RNN. They find many properties reminiscent of neurons in the mammalian entorhinal cortex (EC): grid cells, border cells, etc. When regularization of the network is not used during training, the trained RNNs no longer resemble the EC. This suggests that those constraints (lower overall connectivity strengths, and lower metabolic costs) might play a role in the EC's navigation function. \n\nThe paper is overall quite interesting and the study is pretty thorough: no major cons come to mind. Some suggestions / criticisms are given below.\n\n1) The findings seem conceptually similar to the older sparse coding ideas from the visual cortex. That connection might be worth discussing because removing the regularizing (i.e., metabolic cost) constraint from your RNNS makes them learn representations that differ from the ones seen in EC. The sparse coding models see something similar: without sparsity constraints, the image representations do not resemble those seen in V1, but with sparsity, the learned representations match V1 quite well. That the same observation is made in such disparate brain areas (V1, EC) suggests that sparsity / efficiency might be quite universal constraints on the neural code.\n\n2) The finding that regularizing the RNN makes it more closely match the neural code is also foreshadowed somewhat by the 2015 Nature Neuro paper by Susillo et al. That could be worthy of some (brief) discussion.\n\nSussillo, D., Churchland, M. M., Kaufman, M. T., & Shenoy, K. V. (2015). A neural network that finds a naturalistic solution for the production of muscle activity. Nature neuroscience, 18(7), 1025-1033.\n\n3) Why the different initializations for the recurrent weights for the hexagonal vs other environments? I'm guessing it's because the RNNs don't \"work\" in all environments with the same initialization (i.e., they either don't look like EC, or they don't obtain small errors in the navigation task). That seems important to explain more thoroughly than is done in the current text.\n\n4) What happens with ongoing training? Animals presumably continue to learn throughout their lives. With on-going (continous) training, do the RNN neurons' spatial tuning remain stable, or do they continue to \"drift\" (so that border cells turn into grid cells turn into irregular cells, or some such)? That result could make some predictions for experiment, that would be testable with chronic methods (like Ca2+ imaging) that can record from the same neurons over multiple experimental sessions.\n\n5) It would be nice to more quantitatively map out the relation between speed tuning, direction tuning, and spatial tuning (illustrated in Fig. 3). Specifically, I would quantify the cells' direction tuning using the circular variance methods that people use for studying retinal direction selective neurons. And I would quantify speed tuning via something like the slope of the firing rate vs speed curves. And quantify spatial tuning somehow (a natural method would be to use the sparsity measures sometimes applied to neural data to quantify how selective the spatial profile is to one or a few specific locations). Then make scatter plots of these quantities against each other. Basically, I'd love to see the trends for how these types of tuning relate to each other over the whole populations: those trends could then be tested against experimental data (possibly in a future study).", "gold_annotation": {"interpretation": 0, "review_id": "SkDHZUXlG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}, "score": 3.0, "tokenized_review_text": ["The authors train an RNN to perform deduced reckoning (ded reckoning) for spatialnavigation, and then study the responses of the model neurons in the RNN.", "They find many properties reminiscent of neurons in the mammalan entorhinalcortex (EC): grid cells, border cells, etc When regularization of the network is not used during training, the trained RNNs no longer resemble the EC.", "This suggests that those constraints (lower overal connectivity strengths, and lower metabolic costs) might play a role in the EC's navigation function.", "The paper is overal quite interesting and the study is pretty thorough: no major cons come to mind.", "Some suggestions / criticisms are given below.", "1) The findings seem conceptualy similar to the older sparse coding ideas from the visualcortex.", "That connection might be worth discussing because removing the regularizing (i e , metabolic cost) constraint from your RNNS makes them learn representations that differ from the ones seen in EC.", "The sparse coding models see something similar: without sparsity constraints, the image representations do not resemble those seen in V1, but with sparsity, the learned representations match V1 quite well.", "That the same observation is made in such disparate brain areas (V1, EC) suggests that sparsity / efficiency might be quite universalconstraints on the neuralcode.", "2) The finding that regularizing the RNN makes it more closely match the neuralcode is alo foreshadowed somewhat by the 2015 Nature Neuro paper by Susillo et al That could be worthy of some (brief) discussion.", "Sussillo, D , Churchland, M M , Kaufman, M T , & Shenoy, K V (2015).", "A neuralnetwork that finds a naturalstic solution for the production of muscle activity.", "Nature neuroscience, 18(7), 1025-1033, 3) Why the different initialzations for the recurrent weights for the hexagonalvs other environments?", "I'm guessing it's because the RNNs don't \"work\" in al environments with the same initialzation (i e , they either don't look like EC, or they don't obtain smal errors in the navigation task).", "That seems important to explain more thoroughly than is done in the current text.", "4) What happens with ongoing training?", "Animal presumably continue to learn throughout their lives.", "With on-going (continous) training, do the RNN neurons' spatialtuning remain stable, or do they continue to \"drift\" (so that border cells turn into grid cells turn into irregular cells, or some such)?", "That result could make some predictions for experiment, that would be testable with chronic methods (like Ca2+ imaging) that can record from the same neurons over multiple experimentalsessions.", "5) It would be nice to more quantitatively map out the relation between speed tuning, direction tuning, and spatialtuning (illustrated in fig 3).", "Specificaly, I would quantify the cells' direction tuning using the circular variance methods that people use for studying retinaldirection selective neurons.", "And I would quantify speed tuning via something like the slope of the firing rate vs speed curves.", "And quantify spatialtuning somehow (a naturalmethod would be to use the sparsity measures sometimes applied to neuraldata to quantify how selective the spatialprofile is to one or a few specific locations).", "Then make scatter plots of these quantities against each other.", "Basicaly, I'd love to see the trends for how these types of tuning relate to each other over the whole populations: those trends could then be tested against experimentaldata (possibly in a future study)."], "all_annotations": [{"interpretation": 0, "review_id": "SkDHZUXlG", "importance": 1, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 0}]}, {"conference": "iclr18", "review_id": "SkF57lqez", "review_text": "******\nUpdate: revising reviewer score to 6 after acknowledging revisions and improved manuscript\n******\n\nThe authors propose a new regularization term modifying the VAE (Kingma et al 2013) objective to encourage learning disentangling representations.\nSpecifically, the authors suggest to add penalization to ELBO in the form of -KL(q(z)||p(z)) , which encourages a more global criterion than the local ELBOs.\nIn practice, the authors decide that the objective they want to optimize is unwieldy and resort to moment matching of covariances of q(z) and p(z) via gradient descent.\nThe final objective uses a persistent estimate of the covariance matrix of q and upgrades it at each mini-batch to perform learning.\n\nThe authors use this objective function to perform experiments measuring disentanglement and find minor benefits compared to other objectives in quantitative terms.\n\nComments:\n1. The originally proposed modification in Equation (4) appears to be rigorous and as far as I can tell still poses a lower bound to log(p(x)). The proof could use the result posed earlier: KL(q(z)||p(z)) is smaller than E_x KL(q(z|x)||p(z|x)).\n2. The proposed moment matching scheme performing decorrelation resembles approaches for variational PCA and especially independent component analysis. The relationship to these techniques is not discussed adequately. In addition, this paper could really benefit from an empirical figure of the marginal statistics of z under the different regularizers in order to establish what type of structure is being imposed here and what it results in.\n3. The resulting regularizer with the decorrelation terms could be studied as a modeling choice. In the probabilistic sense, regularizers can be seen as structural and prior assumptions on variables. As it stands, it is unnecessarily vague which assumptions this extra regularizer is making on variables.\n4. Why is using the objective in Equation (4) not tried and tested and compared to? It could be thought that subsampling would be enough to evaluate this extra KL term without any need for additional variational parameters \\psi. The reason for switching to the moment matching scheme seems not well motivated here without showing explicitly that Eq (4) has problems.\n5. The model seems to be making on minor progress in its stated goal, disentanglement. It would be more convincing to clarify the structural properties of this regularizer in a statistical sense more clearly given that experimentally it seems to only have a minor effect.\n6. Is there a relationship to NICE (Laurent Dinh et al)?\n7. The infogan is also an obvious point of reference and comparison here.\n8. The authors claim that there are no models which can combine GANs with inference in a satisfactory way, which is obviously not accurate nowadays given the progress on literature combining GANs and variational inference.\n\nAll in all I find this paper interesting but would hope that a more careful technical justification and derivation of the model would be presented given that it seems to not be an empirically overwhelming change.", "gold_annotation": {"interpretation": 1, "review_id": "SkF57lqez", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}, "score": 3.0, "tokenized_review_text": ["****** Update: revising reviewer score to 6 after acknowledging revisions and improved manuscript ****** The authors propose a new regularization term modifying the VAE (Kingma et al2013) objective to encourage learning disentangling representations.", "Specificaly, the authors suggest to add penalzation to ELBO in the form of -KL(q(z)||p(z)) , which encourages a more globalcriterion than the localELBOs.", "In practice, the authors decide that the objective they want to optimize is unwieldy and resort to moment matching of covariances of q(z) and p(z) via gradient descent.", "The finalobjective uses a persistent estimate of the covariance matrix of q and upgrades it at each mini-batch to perform learning.", "The authors use this objective function to perform experiments measuring disentanglement and find minor benefits compared to other objectives in quantitative terms.", "Comments: 1, The originaly proposed modification in eqation (4) appears to be rigorous and as far as I can tell still poses a lower bound to log(p(x)).", "The proof could use the result posed earlier: KL(q(z)||p(z)) is smaler than E_x KL(q(z|x)||p(z|x)).", "2, The proposed moment matching scheme performing decorrelation resembles approaches for variationalPCA and especialy independent component analsis.", "The relationship to these techniques is not discussed adeqately.", "In addition, this paper could realy benefit from an empiricalfigre of the marginalstatistics of z under the different regularizers in order to establish what type of structure is being imposed here and what it results in.", "3, The resulting regularizer with the decorrelation terms could be studied as a modeling choice.", "In the probabilistic sense, regularizers can be seen as structuraland prior assumptions on variables.", "As it stands, it is unnecessarily vague which assumptions this extra regularizer is making on variables.", "4, Why is using the objective in eqation (4) not tried and tested and compared to?", "It could be thought that subsampling would be enough to evalate this extra KL term without any need for additionalvariationalparameters \\psi.", "The reason for switching to the moment matching scheme seems not well motivated here without showing explicitly that eq(4) has problems.", "5, The model seems to be making on minor progress in its stated goal disentanglement.", "It would be more convincing to clarify the structuralproperties of this regularizer in a statisticalsense more clearly given that experimentaly it seems to only have a minor effect.", "6, Is there a relationship to NICE (Laurent Dinh et al?", "7, The infogan is alo an obvious point of reference and comparison here.", "8, The authors claim that there are no models which can combine GANs with inference in a satisfactory way, which is obviously not accurate nowadays given the progress on literature combining GANs and variationalinference.", "All in al I find this paper interesting but would hope that a more careful technicaljustification and derivation of the model would be presented given that it seems to not be an empiricaly overwhelming change."], "all_annotations": [{"interpretation": 1, "review_id": "SkF57lqez", "importance": 0, "reproducibility": 0, "constructiveness": 4, "overall": 3, "annotator": "anno2", "evidence": 3, "originality": 1, "metareview": "no", "presentation": 0, "method": 1}]}]